---
## 1. Patterns vs. Patients: Evaluating LLMs against Mental Health Professionals on Personality Disorder Diagnosis through First-Person Narratives

- 作者：Karolina Drożdż, Kacper Dudzic, Anna Sterna, Marcin Moskalewicz
- 子主题：医学LLM（临床NLP）
- 推荐：极度推荐
- 关键词：大型语言模型, 人格障碍（BPD/NPD）诊断, 诊断偏差与可靠性
- Abstract：http://arxiv.org/abs/2512.20298v1
- PDF：https://arxiv.org/pdf/2512.20298v1

**中文摘要**

随着对大型语言模型（LLM）在精神健康自评中的依赖增加，人们对其解读定性病人叙述能力产生了疑问。我们首次直接比较了最先进的LLM与精神健康专业人员，使用波兰语第一人称自传性叙述对边缘型人格障碍（BPD）和自恋型人格障碍（NPD）进行诊断。结果表明，表现最佳的Gemini Pro模型在总体诊断准确率上比人类专家高出21.91个百分点（65.48% vs. 43.57%）。尽管模型与专家在识别BPD方面均表现优异（F1 = 83.4 与 F1 = 80.0），但模型严重低估了NPD的出现（F1 = 6.7 vs. 50.0），表现出对带有价值判断色彩的术语“自恋”的回避。定性分析显示，模型往往给出自信且详尽的理由，侧重于模式和形式化类别，而人类专家则更为简洁和谨慎，强调患者的自我感受与时间体验。本研究表明，尽管LLM在解读复杂第一人称临床资料方面能力很强，但仍面临重要的可靠性与偏见问题。

---
## 2. Reason2Decide: Rationale-Driven Multi-Task Learning

- 作者：H M Quamran Hasan, Housam Khalifa Bashier, Jiayi Dai, Mi-Young Kim, Randy Goebel
- 子主题：医学LLM
- 推荐：极度推荐
- 关键词：医学决策支持, 自我推理/可解释性, 多任务学习
- Abstract：http://arxiv.org/abs/2512.20074v1
- PDF：https://arxiv.org/pdf/2512.20074v1

**中文摘要**

尽管大型语言模型（LLM）被广泛采用，临床决策支持系统仍面临关键挑战：在保证高预测准确性的同时生成与预测一致的解释。现有方法存在暴露偏差，导致解释与预测不一致。为此我们提出了 Reason2Decide，一种解决自我理性化（self-rationalization）中暴露偏差和任务分离等关键问题的两阶段训练框架。在第一阶段，模型专注于生成推理/理由；在第二阶段，模型在标签预测与理由生成上进行联合训练，并采用调度采样（scheduled sampling），逐步从以真实标签为条件过渡到以模型预测为条件。我们在三个医学数据集上评估了 Reason2Decide，包括一个专有分诊数据集和公开的生物医学问答数据集。在不同模型规模上，Reason2Decide 在预测性能（F1）和理由一致性（BERTScore、BLEU、以LLM为裁判）方面均优于其他微调基线和部分零-shot LLM。在分诊任务中，Reason2Decide 对理由来源具有稳健性，适用于 LLM 生成、护士撰写和护士后处理的理由。我们的实验还表明，即便仅在第一阶段使用 LLM 生成的理由进行训练，Reason2Decide 仍优于其他微调变体，表明 LLM 生成的理由可作为预训练材料，减少对人工标注的依赖。值得注意的是，Reason2Decide 在参数规模比当代基础模型小约40倍的情况下也能取得这些改进，使得在资源受限环境中实现可解释的临床推理成为可能。

---
## 3. Benchmarking LLMs for Predictive Applications in the Intensive Care Units

- 作者：Chehak Malhotra, Mehak Gopal, Akshaya Devadiga, Pradeep Singh, Ridam Pal, Ritwik Kashyap, Tavpritesh Sethi
- 子主题：Medical LLM (临床NLP)
- 推荐：极度推荐
- 关键词：临床LLM, ICU休克预测, 模型基准对比
- Abstract：http://arxiv.org/abs/2512.20520v1
- PDF：https://arxiv.org/pdf/2512.20520v1

**中文摘要**

随着大语言模型（LLM）的出现，自然语言处理领域的多项任务已经发生变革，然而它们在预测型任务中的应用研究较少。本研究在预测重症病房患者发生休克（Shock）这一任务上，对比了包括在临床数据上训练的GatorTron-Base、Llama 8B、Mistral 7B等LLM与BioBERT、DocBERT、BioClinicalBERT、Word2Vec和Doc2Vec等小型语言模型（SLM），以建立基准。及时预测休克可促使早期干预，从而改善患者预后。本研究使用MIMIC-III数据库中17,294次ICU住院记录的文本数据，按住院时间>24小时和休克指数（SI）>0.7进行标注，得到分别为355例和87例的正常与异常SI索引样本。在微调过程中采用了focal loss与交叉熵损失以应对类别不平衡问题。结果表明，GatorTron-Base取得了最高的加权召回率80.5%，但总体性能指标在SLM与LLM之间差异不大。这表明尽管LLM在文本相关任务上表现优异，但在预测未来临床事件方面并不天然优于SLM。为实现有意义的临床效果，未来训练LLM的工作应优先发展能够预测临床轨迹的模型，而非仅聚焦命名实体识别或表型识别等相对简单的任务。

---
## 4. Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent

- 作者：Humza Nusrat, Luke Francisco, Bing Luo, Hassan Bagher-Ebadian, Joshua Kim, Karen Chin-Snyder, Salim Siddiqui, Mira Shah, Eric Mellon, Mohammad Ghassemi, Anthony Doemer, Benjamin Movsas, Kundan Thind
- 子主题：Medical LLM
- 推荐：极度推荐
- 关键词：立体定向放射外科, 大型语言模型, 链式推理
- Abstract：http://arxiv.org/abs/2512.20586v1
- PDF：https://arxiv.org/pdf/2512.20586v1

**中文摘要**

立体定向放射外科（SRS）要求在关键结构周围实现精确的剂量塑形，但黑箱式人工智能系统由于不透明性而在临床应用中受限。我们评估了链式推理（chain-of-thought reasoning）是否能改进具代理性的放疗计划，在一项包括41例脑转移、接受单次18 Gy SRS的回顾性队列中进行测试。为此我们开发了SAGE（Secure Agent for Generative Dose Expertise），一个基于大型语言模型的自动化SRS计划代理。对每例病例生成两种变体的计划：一种为非推理模型，另一种为具推理能力的模型。具推理能力的变体在主要剂量学终点上与人工计划者相当（靶区覆盖、最大剂量、适形指数、梯度指数；均 p > 0.21），同时将耳蜗剂量显著降低至低于人工基线（p = 0.022）。在被指示改善适形性时，推理模型表现出系统性的规划行为，包括前瞻性约束验证（457 次）和权衡讨论（609 次），而标准模型则几乎未表现出这些审慎过程（分别为0和7次）。内容分析显示约束验证和因果解释主要集中于推理代理。优化轨迹可作为可审计日志，为实现透明的自动化放疗计划提供了一条可行路径。

---
## 5. HARMON-E: Hierarchical Agentic Reasoning for Multimodal Oncology Notes to Extract Structured Data

- 作者：Shashi Kant Gupta, Arijeet Pramanik, Jerrin John Thomas, Regina Schwind, Lauren Wiener, Avi Raju, Jeremy Kornbluth, Yanshan Wang, Zhaohui Su, Hrituraj Singh
- 子主题：LLM
- 推荐：极度推荐
- 关键词：肿瘤学电子病历, 大语言模型代理, 结构化临床信息抽取
- Abstract：http://arxiv.org/abs/2512.19864v1
- PDF：https://arxiv.org/pdf/2512.19864v1

**中文摘要**

电子病历（EHR）中的非结构化病历包含对癌症治疗决策与研究至关重要的大量临床信息，但由于内容高度可变、术语专业化且文档格式不一致，可靠地提取结构化肿瘤学数据仍然具有挑战性。尽管人工抽取准确，但成本高且难以扩展。现有自动化方法通常只针对狭窄场景——使用合成数据集、限于文档级抽取，或仅聚焦若干临床变量（例如分期、生物标志物、组织学），难以在包含相互矛盾信息的大量临床文档中实现病人级别的综合判断。为此，本研究提出了一种智能代理框架，将复杂的肿瘤学数据抽取系统地分解为模块化、可自适应的子任务。具体而言，我们将大语言模型（LLM）作为推理代理，配备上下文敏感的检索与迭代合成能力，以全面、详尽地从真实世界的肿瘤学病历中抽取结构化临床变量。在涵盖超过40万条非结构化临床病历与扫描PDF报告、共2250名癌症患者的大规模数据集上评估时，本方法平均F1值达到0.93，其中103个肿瘤学特定临床变量中有100个超过0.85，关键变量（如生物标志物和药物）超过0.95。此外，将该代理系统整合到数据整理工作流中后实现了0.94的直接人工批准率，显著降低了标注成本。据我们所知，这是首个基于LLM代理的、面向肿瘤学结构化数据抽取的端到端、规模化且尽可能穷尽的应用实例。

---
## 6. A DeepSeek-Powered AI System for Automated Chest Radiograph Interpretation in Clinical Practice

- 作者：Yaowei Bai, Ruiheng Zhang, Yu Lei, Xuhua Duan, Jingfeng Yao, Shuguang Ju, Chaoyang Wang, Wei Yao, Yiwan Guo, Guilin Zhang, Chao Wan, Qian Yuan, Lei Chen, Wenjuan Tang, Biqiang Zhu, Xinggang Wang, Tao Sun, Wei Zhou, Dacheng Tao, Yongchao Xu, Chuansheng Zheng, Huangxuan Zhao, Bo Du
- 子主题：医学LLM
- 推荐：极度推荐
- 关键词：胸部X线自动解读, 医学大模型, 前瞻性多中心验证
- Abstract：http://arxiv.org/abs/2512.20344v1
- PDF：https://arxiv.org/pdf/2512.20344v1

**中文摘要**

放射科医师的全球短缺在基层医疗中因胸部X线工作量大而愈加严重。尽管多模态大模型展现出潜力，现有评估大多依赖自动化指标或回顾性分析，缺乏严格的前瞻性临床验证。本文提出并开发了基于DeepSeek Janus-Pro模型的胸片解读系统Janus-Pro-CXR（1B），并通过一项多中心前瞻性试验（NCT07117266）进行了严格验证。该系统在自动化报告生成上优于现有最先进的X线报告生成模型，甚至超过了参数更大的模型（例如 ChatGPT 4o，200B参数），并能可靠地检测六类临床关键影像学征象。回顾性评估显示其报告准确率显著高于Janus-Pro和ChatGPT 4o。在前瞻性临床部署中，AI辅助显著提升了报告质量评分，使解读时间缩短了18.3%（P < 0.001），且在54.3%的病例中获得专家多数偏好。通过轻量化架构和领域特定优化，Janus-Pro-CXR在资源受限环境中提升了诊断可靠性与工作流程效率。论文将开源模型架构与实现框架，以促进AI辅助放射学的临床转化。

---
## 7. QE-Catalytic: A Graph-Language Multimodal Base Model for Relaxed-Energy Prediction in Catalytic Adsorption

- 作者：Yanjie Li, Jian Xu, Xueqing Chen, Lina Yu, Shiming Xiang, Weijun Li, Cheng-lin Liu
- 子主题：LLM + 图神经网络（材料计算/多模态科学机器学习）
- 推荐：极度推荐
- 关键词：催化吸附能, 多模态（语言+图）, E(3)-等变图神经网络
- Abstract：http://arxiv.org/abs/2512.20084v1
- PDF：https://arxiv.org/pdf/2512.20084v1

**中文摘要**

吸附能是描述催化反应活性的重要指标。其本质定义为吸附物-表面体系弛豫总能量与适当参考态能量之差，因此弛豫能预测的准确性直接决定了基于机器学习的催化剂筛选的可靠性。E(3)-等变图神经网络（GNN）能够在周期性边界条件下以三维原子坐标为本征输入，已在此类任务上表现出色。相比之下，基于语言模型的方法虽然便于生成人类可读的文本描述并降低对显式图结构的依赖（从而扩展适用性），但在吸附构型能量预测精度以及区分“相同体系不同构型”方面仍不足，即使采用类似GAP-CATBERTa的图辅助预训练也难以完全解决。为此，我们提出了QE-Catalytic，这是一种多模态框架，深度耦合大语言模型（Qwen）与E(3)-等变图Transformer（Equiformer-V2），实现对复杂催化表面上吸附构型性质预测和逆向设计的统一支持。在预测阶段，QE-Catalytic联合利用三维结构与结构化的构型文本，并通过图-文本对齐将“3D几何信息”注入语言通道，使得当精确坐标不可得时模型仍能作为高性能的基于文本的预测器运行；同时它还能以自回归方式生成用于目标能量驱动的结构设计和信息补全的CIF文件。在OC20基准上，QE-Catalytic将弛豫吸附能的平均绝对误差（MAE）从0.713 eV降低到0.486 eV，并在多种评估协议下持续优于如CatBERTa和GAP-CATBERTa等基线模型。

---
## 8. Neuron-Guided Interpretation of Code LLMs: Where, Why, and How?

- 作者：Zhe Yin, Xiaodong Gu, Beijun Shen
- 子主题：LLM（代码模型）
- 推荐：极度推荐
- 关键词：代码LLM可解释性, 神经元选择性, 概念层表示
- Abstract：http://arxiv.org/abs/2512.19980v1
- PDF：https://arxiv.org/pdf/2512.19980v1

**中文摘要**

代码语言模型在代码智能任务上表现优异，但其内部可解释性研究尚不充分。由于编程语言的形式化、层次化和可执行性，来自自然语言处理领域的现有神经元可解释性方法并不适用于源代码。本文在神经元粒度上对代码LLM进行了实证研究，定位了两类结构：对单一编程语言有选择性响应的语言专用神经元，以及在前馈层中编码与语言无关代码表示的“概念层”。我们在多语言代码（C++、Java、Python、Go、JavaScript）上对 Llama-3.1-8B 和 Qwen2.5-Coder-32B 进行分析，衡量神经元选择性与生成过程中的逐层贡献。研究发现：一方面存在针对单一语言的专用神经元，同时也有支持通用生成的通用子集；另一方面模型较低层主要编码语言特定的语法信息，而中间层则捕捉跨语言共享的语义抽象，呈现为概念层。基于这些发现，我们在三个下游任务上展示了实用性：用于代码生成的神经元引导微调、基于概念层嵌入的克隆检测，以及基于概念层的代码摘要迁移，每项在多语言设置下均带来了稳定的性能提升。

---
## 9. Multi-LLM Thematic Analysis with Dual Reliability Metrics: Combining Cohen's Kappa and Semantic Similarity for Qualitative Research Validation

- 作者：Nilesh Jain, Seyi Adeyinka, Leor Roseman, Aza Allsop
- 子主题：LLM
- 推荐：极度推荐
- 关键词：大语言模型 (LLM), 主题分析, 可靠性评估
- Abstract：http://arxiv.org/abs/2512.20352v1
- PDF：https://arxiv.org/pdf/2512.20352v1

**中文摘要**

定性研究面临一个关键的可靠性挑战：传统的评审者间一致性方法依赖多名人工编码者，耗时且常常只得到中等一致性。我们提出了一种用于基于大语言模型（LLM）主题分析的多视角验证框架，结合集成验证与双重可靠性度量：用于评审者间一致性的 Cohen's Kappa（κ）和用于语义一致性的余弦相似度。该框架支持可配置的分析参数（种子数1–6、temperature 0.0–2.0）、支持带变量替换的自定义提示结构，并能够对任意 JSON 格式进行一致性主题提取。作为概念验证，我们在一份迷幻艺术治疗访谈文本上评估了三款主流 LLM（Gemini 2.5 Pro、GPT-4o、Claude 3.5 Sonnet），对每款模型进行了六次独立运行。结果显示，Gemini 的可靠性最高（κ = 0.907，余弦相似度 = 95.3%），其后为 GPT-4o（κ = 0.853，余弦 = 92.6%）和 Claude（κ = 0.842，余弦 = 92.1%）。三款模型均达到较高一致性（κ > 0.80），验证了多次运行集成方法的可行性。该框架能够跨运行提取共识主题：Gemini 识别出 6 个共识主题（一致性范围 50%–83%），GPT-4o 识别 5 个主题，Claude 识别 4 个主题。我们的开源实现为研究者提供了透明的可靠性度量、灵活的配置选项以及与结构无关的共识提取方法，奠定了可靠的 AI 辅助定性研究的方法学基础。

---
## 10. Learned Digital Codes for Over-the-Air Computation in Federated Edge Learning

- 作者：Antonio Tarizzo, Mohammad Kazemi, Deniz Gündüz
- 子主题：联邦边缘学习（FEEL）与无线通信
- 推荐：很推荐
- 关键词：联邦边缘学习, 数字空中聚合(OTA), 端到端学习/AMP解码
- Abstract：http://arxiv.org/abs/2512.19777v1
- PDF：https://arxiv.org/pdf/2512.19777v1

**中文摘要**

联邦边缘学习（FEEL）使无线设备在不共享原始数据的情况下协同训练集中模型，但模型更新的反复上行传输使通信成为主要瓶颈。过空中（OTA）聚合通过利用无线信道的叠加特性缓解了这一问题，实现了并行传输并将通信与计算合并。数字化OTA方案将传统数字通信的鲁棒性引入此框架，但现有设计在低信噪比（SNR）条件下仍表现受限。本文提出了一种学习式数字OTA框架，在保持与最先进方法相同上行开销的前提下，提升了恢复精度、收敛性并增强了在苛刻SNR条件下的鲁棒性。该设计将无源随机接入（URA）码本与矢量量化相结合，并引入AMP-DA-Net——一种以近似消息传递（AMP）为风格的展开解码器，端到端联合训练数字码本与参数服务器的本地训练统计信息。所提出的方法将OTA聚合从简单平均扩展到包括修剪均值和基于多数表决的规则在内的一大类对称函数。针对高度异构设备数据集和不同活动设备数量的实验表明，该设计在低SNR区间可将可靠数字OTA操作的可用范围向下扩展超过10 dB，并在整个SNR范围内匹配或优于现有性能。学习得到的解码器在消息损坏和非线性聚合情况下依然有效，凸显了端到端学习式设计在FEEL数字OTA通信中的广泛潜力。

---
## 11. QMBench: A Research Level Benchmark for Quantum Materials Research

- 作者：Yanzhen Wang, Yiyang Jiang, Diana Golovanova, Kamal Das, Hyeonhu Bae, Yufei Zhao, Huu-Thong Le, Abhinava Chatterjee, Yunzhe Liu, Chao-Xing Liu, Felipe H. da Jornada, Binghai Yan, Xiao-Liang Qi
- 子主题：LLM（AI for Science）
- 推荐：很推荐
- 关键词：量子材料, 大型语言模型(LLM), 密度泛函理论
- Abstract：http://arxiv.org/abs/2512.19753v1
- PDF：https://arxiv.org/pdf/2512.19753v1

**中文摘要**

我们提出 QMBench，这是一个用于评估大型语言模型代理在量子材料研究中能力的综合基准。该专门基准评估模型运用凝聚态物理知识以及密度泛函理论等计算技术来解决量子材料科学中的研究问题的能力。QMBench 涵盖量子材料研究的不同领域，包括结构性质、电子性质、热力学及其他性质、对称性原理和计算方法学。通过提供一个标准化的评估框架，QMBench 旨在加速能够在量子材料研究中做出创造性贡献的 AI 科学家的发展。我们期望 QMBench 能由研究社区持续开发和不断改进。

---
## 12. CoPHo: Classifier-guided Conditional Topology Generation with Persistent Homology

- 作者：Gongli Xi, Ye Tian, Mengyu Yang, Zhenyu Zhao, Yuchao Zhang, Xiangyang Gong, Xirong Que, Wendong Wang
- 子主题：图生成 / 拓扑数据分析
- 推荐：很推荐
- 关键词：持久同调, 分类器引导图生成, 离散扩散模型
- Abstract：http://arxiv.org/abs/2512.19736v1
- PDF：https://arxiv.org/pdf/2512.19736v1

**中文摘要**

拓扑结构对性能与鲁棒性研究具有重要支撑作用，但现有的拓扑数据通常稀缺，因而需要生成具有指定性质的合成图以便测试或发布。先前的基于扩散的方法要么将条件直接嵌入扩散模型中，这需要为每个属性重训练且不利于实时应用；要么在训练后使用基于分类器的引导，但这种方法未能考虑拓扑规模与实际约束。本文从离散角度出发，证明了可将预训练图级分类器的梯度并入离散反向扩散后验，以在生成过程中引导得到期望的结构属性。基于此洞见，我们提出了带持久同调的分类器引导条件拓扑生成方法（CoPHo）：在中间图上构建持久同调滤波，并将由此得到的拓扑特征解释为引导信号，于每一去噪步骤中朝目标性质调整生成过程。我们在四个通用/网络数据集上的实验表明，CoPHo 在匹配目标指标方面优于现有方法，并在 QM9 分子数据集上进一步验证了其可迁移性。

---
## 13. High-Performance Self-Supervised Learning by Joint Training of Flow Matching

- 作者：Kosuke Ukita, Tsuyoshi Okita
- 子主题：SSL
- 推荐：很推荐
- 关键词：流匹配, 自监督学习, 表示学习
- Abstract：http://arxiv.org/abs/2512.19729v1
- PDF：https://arxiv.org/pdf/2512.19729v1

**中文摘要**

扩散模型在数据生成过程中能够学习到丰富的表示，显示出自监督学习（SSL）的潜力，但它们在生成质量与判别性能之间存在权衡。其迭代采样过程还带来大量计算和能耗开销，限制了工业与边缘AI的应用。为了解决这些问题，我们提出了基于流匹配的基础模型（FlowFM），通过联合训练一个表示编码器与一个条件流匹配生成器实现。该解耦设计同时兼顾高保真生成与有效识别。通过利用流匹配学习更简单的速度场，FlowFM 加快并稳定了训练过程，从而提高了表示学习的效率。在可穿戴传感器数据上的实验显示，相较于基于扩散的方法，FlowFM 将训练时间缩短了50.4%。在下游任务中，FlowFM 在五个数据集上均超越了最先进的自监督方法（SSL-Wearables），并在保持高生成质量的同时实现最高达51.0倍的推理加速。实现代码已开源： https://github.com/Okita-Laboratory/jointOptimizationFlowMatching。

---
## 14. PHANTOM: PHysical ANamorphic Threats Obstructing Connected Vehicle Mobility

- 作者：Md Nahid Hasan Shuvo, Moinul Hossain
- 子主题：CV（车载视觉与车联网安全）
- 推荐：很推荐
- 关键词：物理对抗攻击, 车载视觉感知, V2X通信安全
- Abstract：http://arxiv.org/abs/2512.19711v1
- PDF：https://arxiv.org/pdf/2512.19711v1

**中文摘要**

连接式自动驾驶车辆（CAVs）依赖基于视觉的深度神经网络（DNNs）和低延迟的车联网（V2X）通信以实现安全高效的行驶。尽管取得了进展，这些系统仍然容易受到物理对抗性攻击。本文提出PHANTOM（PHysical ANamorphic Threats Obstructing connected vehicle Mobility），一种利用变形艺术（anamorphic art）构造并部署视角依赖物理对抗样本的新框架。PHANTOM 利用几何失真——在人类看来自然、但会被最先进目标检测器高置信误判的图案。不同于传统攻击，PHANTOM 在黑盒设置下运行，无需访问模型参数，并在四种不同检测器架构（YOLOv5、SSD、Faster R-CNN 和 RetinaNet）之间展现出强迁移性。对 CARLA 仿真平台上不同车速、天气和光照条件的全面评估表明，PHANTOM 在最佳条件下攻击成功率超过90%，即使在恶化环境下仍保持60–80%的有效性。该攻击在距离目标6–10米时激活，留下不足的时间用于安全避让。除了对单车的欺骗外，PHANTOM 还会在 CAV 系统中触发网络级扰动：SUMO-OMNeT++ 联合仿真显示，虚假的紧急消息可通过 V2X 链路传播，使信息时效峰值（Peak Age of Information）增加68–89%，从而削弱安全关键通信。这些结果揭示了 CAV 生态在感知层和通信层的关键脆弱性。

---
## 15. SlideTailor: Personalized Presentation Slide Generation for Scientific Papers

- 作者：Wenzheng Zeng, Mingyu Ouyang, Langyuan Cui, Hwee Tou Ng
- 子主题：NLP
- 推荐：很推荐
- 关键词：个性化幻灯片生成, 用户偏好蒸馏, 链式口语对齐
- Abstract：http://arxiv.org/abs/2512.20292v1
- PDF：https://arxiv.org/pdf/2512.20292v1

**中文摘要**

自动生成演示幻灯片可大幅简化内容创作流程。但由于不同用户的偏好各异，现有对问题定义不足的方法常常产生无法满足个体需求的次优结果。我们提出了一个新任务：在用户指定偏好的条件下将论文转为幻灯片。为此设计了受人类行为启发的主体化框架 SlideTailor，该框架以渐进式方式生成可编辑且符合用户偏好的幻灯片。系统不要求用户以详尽文本描述偏好，而只需提供一对论文→幻灯片示例和一个视觉模板——这些自然且易于提供的 artefact 能隐式编码关于内容与视觉风格的丰富偏好。尽管这些输入是隐式且未标注的，我们的方法仍能有效提取并泛化出偏好以引导定制化幻灯片生成。我们还引入了一种新颖的“链式口语（chain-of-speech）”机制，用以将幻灯片内容与预期的口头讲解对齐。该设计显著提升了生成幻灯片的质量，并支持如视频演示等下游应用。为支持该新任务，我们构建了一个涵盖多样用户偏好的基准数据集，并设计了可解释的评估指标以进行稳健评估。大量实验验证了本框架的有效性。

---
## 16. Odysseus: Jailbreaking Commercial Multimodal LLM-integrated Systems via Dual Steganography

- 作者：Songze Li, Jiameng Cheng, Yiming Li, Xiaojun Jia, Dacheng Tao
- 子主题：LLM
- 推荐：很推荐
- 关键词：多模态大模型, 双重隐写, 越狱攻击
- Abstract：http://arxiv.org/abs/2512.20168v1
- PDF：https://arxiv.org/pdf/2512.20168v1

**中文摘要**

通过将语言理解与图像等感知模态相结合，多模态大语言模型（MLLMs）成为现代人工智能系统的重要基础，特别是运行于开放交互环境中的智能代理。然而，这类模型日益普及也带来了被滥用的风险，例如生成有害或不安全内容。为缓解这些风险，常采用对齐技术以使模型行为符合人类价值观。尽管如此，近期研究表明越狱攻击能够规避对齐措施并诱导模型输出不安全内容。目前大多数现有越狱方法针对开源模型设计，对于集成了附加过滤器的商业化MLLM系统效果有限；这些过滤器能够检测并阻止恶意的输入与输出内容，从而显著降低越狱威胁。本文揭示了这些安全过滤器成功的关键依赖是假设恶意内容必须在输入或输出之一中以显性方式可见。该假设在传统的LLM集成系统中通常成立，但在MLLM集成系统中会失效：攻击者可以利用多模态手段将对抗意图隐藏起来，导致现有系统产生虚假的安全感。为挑战该假设，我们提出Odysseus，一种新颖的越狱范式，通过双重隐写术在看似无害的图像中隐蔽地嵌入恶意查询和响应。基准数据集上的大量实验表明，Odysseus能成功越狱若干领先且具现实意义的MLLM集成系统，攻击成功率最高可达99%。该工作揭示了现有防护的根本盲点，并呼吁重新思考MLLM集成系统中的跨模态安全问题。

---
## 17. Concept Generalization in Humans and Large Language Models: Insights from the Number Game

- 作者：Arghavan Bazigaran, Hansem Sohn
- 子主题：LLM
- 推荐：很推荐
- 关键词：概念泛化, 贝叶斯推理, 大型语言模型
- Abstract：http://arxiv.org/abs/2512.20162v1
- PDF：https://arxiv.org/pdf/2512.20162v1

**中文摘要**

我们比较了人类与大型语言模型（LLM）在“数字游戏”——一种概念推断任务中的泛化表现。以贝叶斯模型作为分析框架，我们考察了人类与LLM的归纳偏好和推断策略。结果表明，贝叶斯模型比LLM更能捕捉人类行为：人类能够在基于规则和基于相似性的概念间灵活推断，而LLM更多依赖数学规则。此外，人类表现出少样本泛化能力，甚至能从单个示例推断概念，而LLM需要更多样本才能实现泛化。这些差异突显了人类与LLM在数学概念的推断与泛化方式上的根本不同。

---
## 18. AXIOM: Benchmarking LLM-as-a-Judge for Code via Rule-Based Perturbation and Multisource Quality Calibration

- 作者：Ruiqi Wang, Xinchen Wang, Cuiyun Gao, Chun Yong Chong, Xin Xia, Qing Liao
- 子主题：LLM
- 推荐：很推荐
- 关键词：LLM评判, 代码质量基准, 规则化扰动
- Abstract：http://arxiv.org/abs/2512.20159v1
- PDF：https://arxiv.org/pdf/2512.20159v1

**中文摘要**

大型语言模型（LLM）越来越多地被部署于真实的软件工程场景，推动了用于研究LLM生成代码质量的代码评估度量的发展。传统的基于规则的度量仅仅根据程序与参考程序的表面相似度对程序打分，而未能深入分析功能性和代码质量。为了解决这一局限，研究者提出了“LLM作为评判者”的度量方法，提示LLM对代码进行评估和打分，并构建了多种代码评估基准来验证其有效性。然而，这些基准存在关键性限制，阻碍了对评估能力的可靠测量：一些基准使用粗粒度的二元标签，将丰富的代码行为压缩为一位信息，从而掩盖了细微错误；另一些基准虽然提出了细粒度但主观性强且定义模糊的评估标准，导致人工注释分数作为真值时存在不可靠性。此外，这些基准常使用不可控的数据合成方法，导致分数分布不平衡，不能很好地代表真实世界的代码生成场景。为策划一个在各类质量水平上具有均衡分布且多样化的程序基准，并简化人工注释流程，我们提出了AXIOM——一个用于大规模合成代码评估基准的新型扰动式框架。该框架将程序分数重新表述为部署所需的改进工作量，由两阶段构成：(1) 基于规则的扰动：提示LLM对现有高质量程序按预定义扰动规则序列进行修改，以改变其功能性和代码质量，从而能够精确控制每个程序的目标分数以实现均衡的分数分布；(2) 多源质量校准：首先选择一部分...

---
## 19. Enhancing Zero-Shot Time Series Forecasting in Off-the-Shelf LLMs via Noise Injection

- 作者：Xingyou Yin, Ceyao Zhang, Min Hu, Kai Chen
- 子主题：LLM
- 推荐：很推荐
- 关键词：零样本时间序列预测, 噪声注入, 无微调LLM
- Abstract：http://arxiv.org/abs/2512.20140v1
- PDF：https://arxiv.org/pdf/2512.20140v1

**中文摘要**

大型语言模型（LLMs）已被证明在零样本时间序列（TS）预测中具有一定效果。关键挑战在于将时间序列数据转化为与LLM预训练知识相一致的文本表示。尽管现有工作常通过微调专门模块来弥合二者差距，但另一条独特且具有挑战性的范式旨在直接利用完全不做任何微调的现成LLM，仅依赖于对数值序列的策略性分词。由于模型参数在推理时保持冻结，这类模型对输入文本表示的敏感性极高。为克服这种脆弱性，本文提出了一种简单而高效的策略：在分词前向原始时间序列注入噪声。该非侵入性干预作为一种推理时的数据增强，促使冻结的LLM基于稳健的时序模式进行外推，而非依赖表面的数值细节。我们对该现象进行了理论分析，并在多种基准上进行了实证验证。尤其是为完全消除LLM预训练期间数据污染的潜在偏差，我们构建了两组新的时间序列数据集，这些数据集不在所用LLM的预训练范围内，并在这些数据上持续观察到性能提升。本研究为直接利用现成LLM进行时间序列预测提供了进一步的可行方法。

---
## 20. M$^3$KG-RAG: Multi-hop Multimodal Knowledge Graph-enhanced Retrieval-Augmented Generation

- 作者：Hyeongcheol Park, Jiyoung Seo, Jaewon Mun, Hogun Park, Wonmin Byeon, Sung June Kim, Hyeonsoo Im, JeungSub Lee, Sangpil Kim
- 子主题：LLM
- 推荐：很推荐
- 关键词：多模态知识图谱, 检索增强生成（RAG）, 实体落地与选择性剪枝（GRASP）
- Abstract：http://arxiv.org/abs/2512.20136v1
- PDF：https://arxiv.org/pdf/2512.20136v1

**中文摘要**

检索增强生成（RAG）最近已扩展到多模态场景，将多模态大语言模型（MLLM）与诸如多模态知识图谱（MMKG）等海量外部知识库相连接。尽管取得了一定进展，视听领域的多模态RAG仍面临挑战：一是现有MMKG在模态覆盖和多跳连通性方面有限；二是仅基于共享多模态嵌入空间相似度的检索，难以剔除离题或冗余知识。为了解决这些问题，我们提出了M$^3$KG-RAG，一种基于多跳多模态知识图谱的增强RAG方法，用于从MMKG中检索与查询对齐的视听知识，以提升MLLM的推理深度和答案可信度。具体而言，我们设计了一个轻量级的多代理流水线来构建多跳MMKG（M$^3$KG），该图由富含上下文的多模态三元组组成，支持按模态针对输入查询的检索。此外，我们提出了GRASP（Grounded Retrieval And Selective Pruning），用于确保对查询的精确实体落地、评估对答案有支持性的相关性，并剪除冗余上下文，仅保留生成回答所必需的知识。大量在多项多模态基准上的实验证明，M$^3$KG-RAG较现有方法显著提升了MLLM的多模态推理能力和落地性。

---
## 21. Cube Bench: A Benchmark for Spatial Visual Reasoning in MLLMs

- 作者：Dhruv Anand, Ehsan Shareghi
- 子主题：多模态大模型 (MLLM)
- 推荐：很推荐
- 关键词：空间视觉推理, 多模态大模型, 基准评测
- Abstract：http://arxiv.org/abs/2512.20595v1
- PDF：https://arxiv.org/pdf/2512.20595v1

**中文摘要**

我们提出了 Cube Bench，一个以魔方为基础的基准，用于评估多模态大模型（MLLM）在空间与序列推理方面的能力。该基准将模型表现分解为五项能力：(i) 从图像与文本重建魔方面，(ii) 选择最优下一步操作，(iii) 在不实际执行的情况下预测候选动作的结果，(iv) 在出现失误时执行多步计划并恢复，(v) 检测并修正自身错误。通过使用一组共享的打乱魔方状态、统一的提示与解析器以及单一的“到解状态距离”度量，我们按打乱深度对近期若干 MLLM 进行了并列比较。对七个模型的实验表明，随着打乱深度增加，准确率显著下降；一旦轨迹停滞或偏离，模型很少能够恢复；并且高的面重建准确率并不保证其在动作选择或多步执行上的能力。我们还观察到封闭源模型与开源模型之间明显的差距：表现最好的封闭模型在单步感知与多步控制任务上均领先，而开源权重模型在最困难的设置中接近随机水平；即便最佳模型在更高复杂度下也会退化。简单的反思式自我纠错带来有限提升，但也可能引入过度思考。Cube Bench 提供了一个紧凑且可复现的探针，用以评估 MLLM 的序列化空间推理能力。

---
## 22. Fail Fast, Win Big: Rethinking the Drafting Strategy in Speculative Decoding via Diffusion LLMs

- 作者：Rui Pan, Zhuofu Chen, Ravi Netravali
- 子主题：LLM
- 推荐：很推荐
- 关键词：扩散式大模型, 投机解码, 动态投机长度
- Abstract：http://arxiv.org/abs/2512.20573v1
- PDF：https://arxiv.org/pdf/2512.20573v1

**中文摘要**

扩散式大型语言模型（dLLMs）具备快速并行的生成能力，但单独使用时存在效率与质量之间的固有权衡。我们证明了在与自回归（AR）验证器配合的投机解码场景中，合理利用dLLMs的特性反而能成为草稿生成器的优势。我们的核心观点是：dLLMs通过并行解码带来的速度显著降低了代价高昂的拒绝风险，从而为实现那些能在投机解码中带来巨大加速的长草稿提供了可行手段。为此我们提出了FailFast——一种基于dLLM的投机解码框架，通过动态调整投机长度来实现这一思路。该方法在“难以投机”的区域以最少计算快速失败以缩短投机延迟，而在“易于投机”的区域大胆延长草稿以降低验证延迟（在许多情况下可一次性投机并接受70个标记）。在无需任何微调的前提下，FailFast能够实现对自回归LLM的无损加速，在多种模型与工作负载上相较于原生解码最高获得4.9×的加速，相较于最强的朴素dLLM草稿者提升1.7×，并超过EAGLE-3约1.4×。我们已开源FailFast（https://github.com/ruipeterpan/failfast）。

---
## 23. Advancing Multimodal Teacher Sentiment Analysis:The Large-Scale T-MED Dataset & The Effective AAM-TSA Model

- 作者：Zhiyi Duan, Xiangren Wang, Hongyu Yuan, Qianli Xing
- 子主题：NLP (多模态情感分析)
- 推荐：很推荐
- 关键词：教师情感分析, 多模态融合, T-MED 数据集
- Abstract：http://arxiv.org/abs/2512.20548v1
- PDF：https://arxiv.org/pdf/2512.20548v1

**中文摘要**

教师的情绪状态在教育情境中至关重要，对教学效果、学生参与度和学习成果有深刻影响。然而，现有研究常因教师的表演性行为难以准确捕捉其真实情绪，同时往往忽视了教学信息对情绪表达的关键影响。本文系统性地研究了教师情感分析，构建了相应的数据集与模型。我们构建了首个大规模教师多模态情感分析数据集 T-MED。为确保标注的准确性和效率，采用了人机协同的标注流程。T-MED 包含来自 250 个真实课堂、覆盖 11 个学科、从 K-12 到高校共计 14,938 条教师情绪实例，集成了文本、音频、视频及教学信息等多模态数据。此外，我们提出了一种新颖的基于不对称注意力的多模态教师情感分析模型 AAM-TSA。AAM-TSA 引入不对称注意力机制与层次门控单元，以实现差异化的跨模态特征融合和更精确的情感分类。实验结果表明，AAM-TSA 在 T-MED 数据集上在准确率和可解释性方面显著优于现有最先进方法。

---
## 24. Evolutionary Neural Architecture Search with Dual Contrastive Learning

- 作者：Xian-Rong Zhang, Yue-Jiao Gong, Wei-Neng Chen, Jun Zhang
- 子主题：神经架构搜索（AutoML/NAS）
- 推荐：很推荐
- 关键词：神经架构搜索 (NAS), 对比学习, 神经预测器
- Abstract：http://arxiv.org/abs/2512.20112v1
- PDF：https://arxiv.org/pdf/2512.20112v1

**中文摘要**

进化神经架构搜索（ENAS）因能够自动设计神经网络架构而受到关注。近来的研究使用神经预测器来指导搜索过程，但获取训练数据的高计算开销——每个标签都需对一个架构进行完全训练——使得在有限计算预算（即有限数量的完全训练的架构-标签对）下获得高精度预测器成为ENAS成功的关键。本文提出了基于双重对比学习的ENAS（DCL-ENAS），该方法通过两个阶段的对比学习来训练神经预测器。第一阶段采用对比自监督学习，从架构数据中学习有意义的表示而无需标签；第二阶段通过对比学习微调，目标是准确预测不同架构的相对性能而非绝对性能，这对于引导进化搜索已足够。实验表明，在NASBench-101和NASBench-201基准上，DCL-ENAS取得了最高的验证精度，较最强的已发表基线提升0.05%（ImageNet16-120）到0.39%（NASBench-101）。在真实世界的心电图（ECG）心律失常分类任务中，DCL-ENAS比通过随机搜索获得的手工设计非NAS模型约提升了2.5个百分点，同时仅需7.7 GPU·天的计算资源。

---
## 25. Item Region-based Style Classification Network (IRSN): A Fashion Style Classifier Based on Domain Knowledge of Fashion Experts

- 作者：Jinyoung Choi, Youngchae Kwon, Injung Kim
- 子主题：CV
- 推荐：很推荐
- 关键词：时尚风格分类, 物品区域特征, 双主干与门控融合
- Abstract：http://arxiv.org/abs/2512.20088v1
- PDF：https://arxiv.org/pdf/2512.20088v1

**中文摘要**

时尚风格分类是一项具有挑战性的任务，因为同一风格内部存在较大的视觉差异，同时不同风格之间也可能有视觉相似性。风格不仅由整体外观表达，还由单个服饰项的属性及其组合所决定。为此，我们提出了一种基于物品区域的时尚风格分类网络（IRSN），通过分析物品特定特征及其组合，结合全局特征来有效分类时尚风格。IRSN 使用物品区域池化（IRP）提取每个物品区域的特征，分别进行分析后通过门控特征融合（GFF）进行组合。此外，我们通过双主干架构改进特征提取器，将领域专用的特征提取器与在大规模图文数据集上预训练的通用特征提取器结合起来。在实验中，将 IRSN 应用于六种常用主干网络（包括 EfficientNet、ConvNeXt 和 Swin Transformer）后，在 FashionStyle14 数据集上平均提升了 6.9%，最高提升 14.5%；在 ShowniqV3 数据集上平均提升了 7.6%，最高提升 15.1%。可视化分析也支持 IRSN 模型在捕捉相似风格类别间差异方面优于基线模型。

---
## 26. Spatio-Temporal Graphs Beyond Grids: Benchmark for Maritime Anomaly Detection

- 作者：Jeehong Kim, Youngseok Hwang, Minchan Kim, Sungho Bae, Hyunwoo Park
- 子主题：时空图神经网络（Spatio-Temporal GNN）/异常检测
- 推荐：很推荐
- 关键词：海事异常检测, 时空图神经网络, 基准数据集
- Abstract：http://arxiv.org/abs/2512.20086v1
- PDF：https://arxiv.org/pdf/2512.20086v1

**中文摘要**

时空图神经网络（ST-GNN）在交通和公共运输等具有固定节点结构的领域取得了显著成果，但许多现实系统（如海事交通）缺乏这种固定锚点，使得构建时空图成为一项根本性挑战。非格点环境中的异常检测尤其困难，原因在于缺乏规范参照点、轨迹的稀疏性与不规则性，以及异常可能在多个粒度上出现。本文提出了一个用于海事领域异常检测的新型基准数据集，将开放海事交通分析数据集（OMTAD）扩展为面向基于图的异常检测的评估基准。该数据集支持在节点级、边级和图级三个不同粒度上进行系统评估。我们计划引入两个基于大模型的专用代理：Trajectory Synthesizer（轨迹合成器）和Anomaly Injector（异常注入器），以构建更丰富的交互语境并生成语义上有意义的异常。我们期望该基准促进可复现性并推动非格点时空系统异常检测方法的发展。

---
## 27. Towards Generative Location Awareness for Disaster Response: A Probabilistic Cross-view Geolocalization Approach

- 作者：Hao Li, Fabian Deuser, Wenping Yin, Steffen Knoblauch, Wufan Zhao, Filip Biljecki, Yong Xue, Wei Huang
- 子主题：CV
- 推荐：很推荐
- 关键词：跨视角地理定位, 概率建模与不确定性量化, 灾害响应
- Abstract：http://arxiv.org/abs/2512.20056v1
- PDF：https://arxiv.org/pdf/2512.20056v1

**中文摘要**

随着地球气候变化，灾害和极端天气事件在全球范围内愈发频繁且强烈，如破纪录的热浪、暴雨、极端野火以及飓风引发的广泛洪涝。对灾害事件进行快速而高效的响应对提升气候适应力与可持续性至关重要，而准确、迅速地识别灾害位置是支持决策与资源调配的一项关键挑战。本文提出了一种名为 ProbGLC 的概率化跨视角地理定位方法，探索面向快速灾害响应的生成式位置感知新路径。我们将概率化与确定性地理定位模型结合为一个统一框架，以在提升地理定位性能的同时通过不确定性量化增强模型的可解释性。为适应快速灾害响应场景，ProbGLC 能够处理多种灾害事件下的跨视角地理定位任务，并提供概率分布与可定位性评分等独特功能。为验证方法有效性，我们在两个跨视角灾害数据集（MultiIAN 和 SAGAINDisaster）上进行了大量实验，这些数据集包含多种灾害类型（如飓风、野火、洪水和龙卷风）的多视角影像对。初步结果表明，ProbGLC 在地理定位准确性上表现优异（Acc@1km = 0.86，Acc@25km = 0.97），且通过概率分布与可定位性评分提升了模型的可解释性，突显了基于生成式跨视角方法在快速定位以支持更好、更快灾害响应方面的巨大潜力。相关数据与代码已公开发布于 https://github.com/bobleegogogo/ProbGLC。

---
## 28. DecoKAN: Interpretable Decomposition for Forecasting Cryptocurrency Market Dynamics

- 作者：Yuan Gao, Zhenguo Dong, Xuelong Wang, Zhiqiang Wang, Yong Zhang, Shaofan Wang
- 子主题：时序预测（金融/加密货币）
- 推荐：很推荐
- 关键词：加密货币时间序列预测, 离散小波变换（DWT）, 可解释性建模（符号化）
- Abstract：http://arxiv.org/abs/2512.20028v1
- PDF：https://arxiv.org/pdf/2512.20028v1

**中文摘要**

准确且可解释的多变量时间序列预测对于理解数字资产系统中加密货币市场的复杂动态至关重要。先进的深度学习方法，尤其是基于 Transformer 和 MLP 的架构，在加密货币预测任务上取得了有竞争力的性能。然而，加密货币数据本质上由长期的社会经济趋势与局部的高频投机性振荡组成，现有的深度学习“黑盒”模型无法有效解耦这些复合动态，也难以为可信的金融决策提供所需的可解释性。为克服这些限制，我们提出了 DecoKAN，一种可解释的预测框架：该框架集成了多级离散小波变换（DWT）用于分解与层级信号解耦，并在各分解子序列上引入 Kolmogorov–Arnold 网络（KAN）混合器以实现透明且可解释的非线性建模。DWT 组件将复杂的加密货币时间序列分解为不同频率成分，实现频段特定的分析；而 KAN 混合器则在每个子序列上提供本征可解释的样条映射。进一步通过稀疏化、剪枝与符号化的符号分析管线增强可解释性，生成简洁的解析表达式以符号化地表示所学模式。大量实证实验表明，DecoKAN 在所有测试的真实加密货币数据集（BTC、ETH、XMR）上取得了最低的平均均方误差，持续优于一系列先进基线方法。这些结果验证了 DecoKAN 在提升预测精度与模型透明性之间架桥的潜力，从而推动了在复杂加密货币市场中可信决策支持的发展。

---
## 29. Schoenfeld's Anatomy of Mathematical Reasoning by Language Models

- 作者：Ming Li, Chenrui Fan, Yize Cheng, Soheil Feizi, Tianyi Zhou
- 子主题：LLM
- 推荐：很推荐
- 关键词：推理步骤抽象, 模型可解释性, 数学推理
- Abstract：http://arxiv.org/abs/2512.19995v1
- PDF：https://arxiv.org/pdf/2512.19995v1

**中文摘要**

大型语言模型越来越多地暴露出推理痕迹，但其底层的认知结构和推理步骤仍难以在表层统计之外被识别和分析。我们采用Schoenfeld的事件（Episode）理论作为一种归纳性的中尺度视角，提出ThinkARM（模型推理解剖），这是一个可扩展的框架，将推理痕迹明确抽象为诸如分析（Analysis）、探索（Explore）、实现（Implement）、验证（Verify）等功能性推理步骤。将该抽象应用于不同模型的数学问题求解时，揭示了可复现的思维动力学以及推理型与非推理型模型之间的结构性差异，这些差异在基于token的视角下并不明显。我们进一步给出两个诊断性案例研究：一是探索（explore）作为与正确性相关的关键分支步骤；二是以效率为导向的方法并非简单缩短响应，而是选择性地压制评估性反馈步骤。综合来看，基于事件级别的表征能使推理步骤显性化，从而能够系统地分析现代语言模型中推理的结构、稳定性与变动方式。

---
## 30. Interpolative Decoding: Exploring the Spectrum of Personality Traits in LLMs

- 作者：Eric Yeh, John Cadigan, Ran Chen, Dick Crouch, Melinda Gervasio, Dayne Freitag
- 子主题：LLM
- 推荐：很推荐
- 关键词：插值解码, 大五人格, LLM行为模拟
- Abstract：http://arxiv.org/abs/2512.19937v1
- PDF：https://arxiv.org/pdf/2512.19937v1

**中文摘要**

近期研究探索了将大型语言模型（LLM）作为人类的代理，用于模拟、问卷和行为研究等任务。尽管LLM并不具备人类心理，但它们常能以足够高的保真度模拟人类行为，从而用于检验人类行为假设，且比行为经济学中常用的基于规则的智能体展现出更多细腻性和多样性。人格对决策的影响是一个重要研究方向，但为每一种人格配置都设计一个提示词会带来实验开销并削弱可复现性。为了解决这一问题，我们采用了插值解码方法：将人格的每个维度表示为一对相对立的提示，并使用插值参数在该维度上模拟行为变化。我们证明了插值解码能够可靠地调节模型在大五人格各维度上的得分。随后我们展示了插值解码如何使LLM在经济博弈中模仿人类决策行为，重复了人类心理学研究中的部分结果。最后，我们给出初步结果，说明通过在插值空间中系统搜索能够“孪生”个体玩家，即找到使模型复制该人类被试所采取动作的插值点。

---
## 31. A Branch-and-Price Algorithm for Fast and Equitable Last-Mile Relief Aid Distribution

- 作者：Mahdi Mostajabdaveh, F. Sibel Salman, Walter J. Gutjahr
- 子主题：救灾物流/运筹优化
- 推荐：很推荐
- 关键词：救灾物资分配, 分支定价算法, 公平性-效率权衡
- Abstract：http://arxiv.org/abs/2512.19882v1
- PDF：https://arxiv.org/pdf/2512.19882v1

**中文摘要**

救援物资向避难所的分发是灾后人道主义物流的关键环节。在重大灾害中，预置的物资往往无法满足全部需求。本文研究了从配送中心向避难所规划车辆路线并分配有限救援物资的问题。为在效率与公平之间取得平衡，我们构建了一个双目标问题：以基于基尼系数的不满足需求不公平度最小化作为公平性目标，同时以总行驶时间最小化作为时效性目标。我们提出了一个混合整数规划（MIP）模型，并采用ε约束法处理双目标问题。通过推导最优解的数学性质，构造了有效不等式，并设计了在给定可行车辆路线下求解最优配送分配的算法。基于此，我们开发了一种分支定价（Branch-and-Price, B&P）算法以提高求解效率。在对土耳其凡（Van）地区历史地震的真实数据及伊斯坦布尔卡尔塔尔（Kartal）区域的预测数据进行的计算测试中，B&P算法显著优于商业MIP求解器。我们的双目标方法在不牺牲效率的前提下将救援分配不公平性降低了34%。结果还表明：当时间约束非常宽松或非常严格时，按词典序优先覆盖需求（将需求覆盖置于公平性之前）是有效的；而在时间约束中度受限时，需要在公平与效率之间采取平衡策略以避免产生不公平的分配结果。

---
## 32. S$^3$IT: A Benchmark for Spatially Situated Social Intelligence Test

- 作者：Zhe Sun, Xueyuan Yang, Yujie Lu, Zhenliang Zhang
- 子主题：LLM
- 推荐：很推荐
- 关键词：具身社交智能, 座位排序基准, LLM评估
- Abstract：http://arxiv.org/abs/2512.19992v1
- PDF：https://arxiv.org/pdf/2512.19992v1

**中文摘要**

将具身代理整合进人类环境要求具身社交智能：即在社交规范与物理约束之间进行推理。然而，现有评估方法未能同时覆盖这两者，要么是非具身的社交推理（例如基于文本），要么是忽视社会因素的物理任务。两类方法都无法评估代理在真实具身情境中如何在物理和社交约束之间进行权衡。为了解决这一挑战，我们提出了空间化情境下的社交智能测试基准（S³IT），专门用于评估具身社交智能。该基准以一个新颖且具有挑战性的座位排序任务为核心，要求代理在三维环境中为一组由大语言模型驱动的NPC安排座位，这些NPC具有多样的身份、偏好和复杂的人际关系。我们提出的程序化可扩展框架能够生成大规模且多样的场景空间，并可控地调整难度，从而迫使代理通过主动对话获取偏好、通过自主探索感知环境，并在复杂的约束网络中进行多目标优化。我们在S³IT上评估了最先进的大语言模型，发现它们在该问题上仍然存在较大困难，明显落后于人类基线。结果表明，当前大语言模型在空间智能方面存在不足，但在解决具有明确文本线索的冲突时已能达到接近人类水平的能力。

---
## 33. Mitigating LLM Hallucination via Behaviorally Calibrated Reinforcement Learning

- 作者：Jiayun Wu, Jiashuo Liu, Zhiyuan Zeng, Tianyang Zhan, Wenhao Huang
- 子主题：LLM
- 推荐：很推荐
- 关键词：LLM幻觉缓解, 行为校准强化学习, 不确定性校准
- Abstract：http://arxiv.org/abs/2512.19920v1
- PDF：https://arxiv.org/pdf/2512.19920v1

**中文摘要**

在关键应用场景中部署大型语言模型（LLM）受到持续的“幻觉”问题阻碍——即模型生成看似合理但事实错误的断言。尽管规模扩展显著提升了通用能力，理论框架表明幻觉并非单纯的随机错误，而是训练目标更侧重模仿数据分布而非追求认识论诚实性的可预测统计后果。采用二元奖励信号的标准强化学习与验收（RL/VR）范式无意中鼓励模型成为“擅长应试”的答题者而非诚实的交流者，导致只要正确概率大于零模型就倾向于猜测。本论文对“行为校准”进行了详尽研究——通过激励模型在不自信时以概率性方式承认不确定性（例如弃答或不对某些陈述给出保证），使模型行为与其准确性保持一致。本工作综合了最近进展，提出并评估了若干训练干预措施，这些干预直接优化严格适当评分规则（strictly proper scoring rules），促使模型输出经校准的正确性概率。我们的方法使模型能够选择不给出完整回答或标注个别存在不确定性的断言。以Qwen3-4B-Instruct为基线的实证分析表明，行为校准的强化学习使得小规模模型在不确定性量化方面超过前沿模型——这一能力是一种可迁移的元技能，可与原始预测准确率解耦。在数学推理任务上训练的模型，在具有挑战性的同域评测（BeyondAIME）中，其对数尺度的“准确率-幻觉比”增益为0.806，优于GPT-5的0.207。此外，在跨域事实问答（SimpleQA）中，我们的4B模型在零样本校准误差上达到了与Grok-4和Gemini-2.5-Pro等前沿模型相当的水平，尽管其事实准确率明显低于这些前沿模型。

---
## 34. A Time-efficient Prioritised Scheduling Algorithm to Optimise Initial Flock Formation of Drones

- 作者：Sujan Warnakulasooriya, Andreas Willig, Xiaobing Wu
- 子主题：多智能体系统（无人机编队/运动规划）
- 推荐：很推荐
- 关键词：无人机编队, 优先级调度, 碰撞避免
- Abstract：http://arxiv.org/abs/2512.19914v1
- PDF：https://arxiv.org/pdf/2512.19914v1

**中文摘要**

无人机应用在各领域持续扩展，编队控制增强了协同能力，但在初始编队阶段带来了显著挑战。现有编队算法在效率与可扩展性方面常常力不从心，尤其是在潜在碰撞迫使无人机采取次优轨迹时。本文提出一种时间高效的优先级调度算法，以改进无人机编队的初始形成过程。该方法根据每架无人机的潜在碰撞数量及其在不永久阻碍其他无人机的情况下到达目标位置的可能性，为无人机分配优先级。基于该层级关系，每架无人机计算适当的延迟以确保无碰撞路径。仿真结果表明，所提出的算法能够为多达5000架无人机生成无碰撞轨迹，并在性能与计算效率上均优于耦合度启发式优先规划方法（CDH-PP）。

---
## 35. Clust-PSI-PFL: A Population Stability Index Approach for Clustered Non-IID Personalized Federated Learning

- 作者：Daniel M. Jimenez-Gutierrez, Mehrdad Hassanzadeh, Aris Anagnostopoulos, Ioannis Chatzigiannakis, Andrea Vitaletti
- 子主题：个性化联邦学习 (PFL)
- 推荐：很推荐
- 关键词：个性化联邦学习, 人口稳定性指数(PSI), 非IID聚类
- Abstract：http://arxiv.org/abs/2512.20363v1
- PDF：https://arxiv.org/pdf/2512.20363v1

**中文摘要**

联邦学习（FL）通过将数据保留在客户端设备上，支持隐私保护的去中心化机器学习模型训练。然而，客户端间存在的非独立同分布（non-IID）数据会导致更新偏差并降低性能。为了解决这些问题，本文提出了Clust-PSI-PFL，一种基于聚类的个性化联邦学习框架，利用人口稳定性指数（PSI）来量化非IID程度。我们提出了加权PSI度量WPSI^L，并证明其相较于常用的非IID度量（Hellinger、Jensen-Shannon 和 Earth Mover's distance）更具判别力。基于PSI特征，采用K-means++将客户端划分为分布上同质的群组；最优簇数通过基于轮廓系数的系统化程序选择，通常可得到较少的簇且开销适中。在六个数据集（表格、图像和文本模态）、两种划分协议（参数α的Dirichlet划分和参数S的相似度划分）以及多种客户端规模的实验中，Clust-PSI-PFL相比最新基线在全局精度上最高提升18%，并在严重非IID情形下将客户端公平性相对提升37%。这些结果表明，以PSI引导的聚类是一种有理论依据、轻量且在标签偏斜下稳健的个性化联邦学习机制。

---
## 36. SynCraft: Guiding Large Language Models to Predict Edit Sequences for Molecular Synthesizability Optimization

- 作者：Junren Li, Luhua Lai
- 子主题：LLM (分子生成/化学信息学)
- 推荐：很推荐
- 关键词：合成可行性优化, 原子级分子编辑, 大语言模型推理
- Abstract：http://arxiv.org/abs/2512.20333v1
- PDF：https://arxiv.org/pdf/2512.20333v1

**中文摘要**

生成式人工智能极大地推动了化学空间的探索，但一个关键瓶颈是大量生成分子在合成上不可行。当前的解决方案，如事后筛选或基于投影的方法，往往以牺牲结构新颖性或破坏关键药效团为代价，将分子强行映射到预定义的合成模板中。为此，我们提出了SynCraft，一种基于推理的框架，将合成可行性优化从序列翻译任务重新表述为精确的结构编辑问题。SynCraft 利用大型语言模型的涌现推理能力，能够在“合成悬崖”（即通过最小结构改动即可显著提升合成可行性的区域）中进行有效导航。通过预测可执行的原子级编辑序列而不是直接生成SMILES字符串，SynCraft 避免了LLM在语法上脆弱性的问题，同时利用其化学直觉。大量基准测试表明，SynCraft 在生成具有高度结构保真度的可合成类似物方面优于最先进的基线方法。此外，通过交互式提示（interaction-aware prompting），SynCraft 成功地复制了药物化学专家在编辑PLK1抑制剂时的直觉，并在以往分子生成文献中挽救了此前被丢弃的高评分RIPK1候选分子。

---
## 37. ${D}^{3}${ETOR}: ${D}$ebate-Enhanced Pseudo Labeling and Frequency-Aware Progressive ${D}$ebiasing for Weakly-Supervised Camouflaged Object ${D}$etection with Scribble Annotations

- 作者：Jiawei Ge, Jiuxin Cao, Xinyi Li, Xuelin Zhu, Chang Liu, Bo Liu, Chen Feng, Ioannis Patras
- 子主题：CV
- 推荐：很推荐
- 关键词：伪装目标检测, 弱监督学习, 伪标签与去偏
- Abstract：http://arxiv.org/abs/2512.20260v1
- PDF：https://arxiv.org/pdf/2512.20260v1

**中文摘要**

弱监督伪装目标检测（WSCOD）旨在仅依赖诸如涂鸦（scribble）标注等稀疏监督信息，定位并分割与背景高度融合、难以被视觉察觉的目标。尽管近期取得了一些进展，现有的弱监督方法仍远落后于全监督方法，主要有两方面的限制：一是通用分割模型（例如 SAM）生成并通过规则筛选得到的伪掩码通常不可靠，因为这些模型缺乏针对伪装目标检测的任务特定语义理解，导致伪标签质量不足；二是涂鸦标注固有的偏置被忽视，阻碍了模型对伪装目标全局结构的捕捉。为了解决上述问题，我们提出了 D^3ETOR，一个包含“辩论增强伪标签生成”（Debate-Enhanced Pseudo Labeling）和“频率感知渐进去偏”（Frequency-Aware Progressive Debiasing）两阶段的 WSCOD 框架。第一阶段中，我们引入自适应熵驱动的点采样策略和多智能体辩论机制，以增强 SAM 在伪装目标检测任务上的能力，从而提升伪掩码的可解释性与精确度；第二阶段中，我们设计了 FADeNet，通过渐进式融合多层次的频率感知特征，在兼顾全局语义理解与局部细节建模的同时，动态重加权各区域的监督强度以缓解涂鸦偏差。在伪掩码与涂鸦语义的联合监督下，D^3ETOR 显著缩小了弱监督与全监督在伪装目标检测上的差距，并在多项基准测试上达到了最新的最优性能。

---
## 38. TongSIM: A General Platform for Simulating Intelligent Machines

- 作者：Zhe Sun, Kunlun Wu, Chuanjian Fu, Zeming Song, Langyong Shi, Zihe Xue, Bohan Jing, Ying Yang, Xiaomeng Gao, Aijia Li, Tianyu Guo, Huiying Li, Xueyuan Yang, Rongkai Liu, Xinyi He, Yuxi Wang, Yue Li, Mingyuan Liu, Yujie Lu, Hongzhao Xie, Shiyun Zhao, Bo Dai, Wei Wang, Tao Yuan, Song-Chun Zhu, Yujia Peng, Zhenliang Zhang
- 子主题：具身智能 (Embodied AI)
- 推荐：很推荐
- 关键词：具身智能仿真, 通用训练平台, 评估基准
- Abstract：http://arxiv.org/abs/2512.20206v1
- PDF：https://arxiv.org/pdf/2512.20206v1

**中文摘要**

随着人工智能（AI）尤其是多模态大语言模型（MLLM）的快速发展，研究重心正从单一文本处理向更加复杂的多模态与具身智能领域转移。具身智能强调在真实感的模拟环境中训练智能体，利用物理交互与动作反馈而非传统的标注数据集。然而，目前大多数仿真平台设计狭窄，多针对特定任务，缺乏能够覆盖从低层次的具身导航到高层次复合活动（如多智能体社交模拟和人机协作）的通用训练环境。为弥补这一空白，我们提出了TongSIM，一个高保真、通用的具身智能训练与评估平台。TongSIM 提供100余个多房间室内场景以及一个开放式、交互丰富的城镇室外模拟，适用于广泛的研究需求。其完备的评估框架和基准测试可精确衡量智能体在感知、认知、决策、人机协作以及空间与社交推理等方面的能力。通过支持自定义场景、任务自适应的保真度、多样化智能体类型和动态环境模拟等特性，TongSIM 为研究者提供了灵活且可扩展的统一平台，加速训练、评估与朝向通用具身智能的推进。

---
## 39. Corpus of Cross-lingual Dialogues with Minutes and Detection of Misunderstandings

- 作者：Marko Čechovič, Natália Komorníková, Dominik Macháček, Ondřej Bojar
- 子主题：NLP
- 推荐：很推荐
- 关键词：跨语言对话, 自动翻译/同声传译, 误解检测
- Abstract：http://arxiv.org/abs/2512.20204v1
- PDF：https://arxiv.org/pdf/2512.20204v1

**中文摘要**

语音处理和翻译技术有望促进不共通语言的个人之间的会议交流。为评估此类自动系统，需要一个多用途且真实的评估语料库。因此，我们创建并发布了一个由不具备共同语言的参与者在自动同声传译辅助下进行的跨语言对话语料库。该语料包含5小时的语音录音，提供12种源语言的自动语音识别（ASR）结果与人工逐字稿，以及对应的自动翻译与人工修正的英文译文。为支持跨语言摘要研究，语料还包括会议的书面摘要（会议纪要）。此外，我们提出了误解的自动检测任务。为概述该任务及其复杂性，我们尝试对跨语言会议中的误解进行量化，并对误解进行了人工标注，同时测试了当前大型语言模型自动检测误解的能力。结果表明，Gemini模型能够以77%的召回率和47%的精确率识别出包含误解的文本片段。

---
## 40. AI Security Beyond Core Domains: Resume Screening as a Case Study of Adversarial Vulnerabilities in Specialized LLM Applications

- 作者：Honglin Mu, Jinghao Liu, Kaiyang Wan, Rui Xing, Xiuying Chen, Timothy Baldwin, Wanxiang Che
- 子主题：LLM
- 推荐：很推荐
- 关键词：对抗性指令, 简历筛选安全, LoRA 微调防御
- Abstract：http://arxiv.org/abs/2512.20164v1
- PDF：https://arxiv.org/pdf/2512.20164v1

**中文摘要**

大型语言模型（LLM）在文本理解与生成方面表现优异，因而被广泛用于自动化任务（如代码审查和内容审核）。然而，我们的研究发现一个漏洞：隐藏在输入数据（如简历或代码）中的“对抗性指令”可以操纵 LLM，使其偏离原本预期的任务。值得注意的是，尽管在成熟领域（例如代码审查）可能已有防护措施，但在诸如简历筛选和同行评审等常见应用中往往缺乏相应防御。本文提出了一个用于评估简历筛选中该脆弱性的基准测试，结果显示某些攻击类型的成功率超过 80%。我们评估了两种防御机制：基于提示的防御能将攻击成功率降低 10.1%，但同时误拒率增加 12.5%；而我们提出的 FIDS（通过分离检测外来指令）方法，结合 LoRA 适配能将攻击成功率降低 15.4%，误拒率增加 10.4%。将两者结合使用可实现 26.3% 的攻击降低，表明训练时的防御相比推理时的缓解措施在安全性和效用保持方面更具优势。

---
## 41. Performative Policy Gradient: Optimality in Performative Reinforcement Learning

- 作者：Debabrota Basu, Udvas Das, Brahim Driss, Uddalak Mukherjee
- 子主题：RL
- 推荐：很推荐
- 关键词：表演性强化学习, 策略梯度, 收敛与最优性
- Abstract：http://arxiv.org/abs/2512.20576v1
- PDF：https://arxiv.org/pdf/2512.20576v1

**中文摘要**

部署后的机器学习算法常常会影响其所作用的环境，从而导致标准强化学习（RL）方法所忽略的底层动态发生变化。虽然在监督学习中，针对这种“表演性（performative）”设置的最优算法设计已被研究，但RL领域的对应问题仍未得到充分探讨。本文证明了RL中表演性对应的性能差分引理与策略梯度定理，并进而提出了表演性策略梯度算法（Performative Policy Gradient，PePG）。PePG 是首个为考虑表演性效应而设计的策略梯度算法。在 softmax 参数化条件下（包括有无熵正则化的情形），我们证明了 PePG 收敛到表演性最优策略，即在由策略自身引起的分布漂移下仍然保持最优的策略。因此，PePG 在理论上显著扩展了先前仅能保证表演性稳定性而非最优性的表演性RL工作。此外，我们在标准的表演性RL环境上的实证分析验证了 PePG 在性能上优于标准策略梯度算法以及现有以稳定性为目标的表演性RL算法。

---
## 42. LEAD: Minimizing Learner-Expert Asymmetry in End-to-End Driving

- 作者：Long Nguyen, Micha Fauth, Bernhard Jaeger, Daniel Dauner, Maximilian Igl, Andreas Geiger, Kashyap Chitta
- 子主题：CV (自动驾驶 / 模仿学习)
- 推荐：很推荐
- 关键词：端到端驾驶, 模仿学习/专家-学习者不对称, 仿真到现实（sim-to-real）
- Abstract：http://arxiv.org/abs/2512.20563v1
- PDF：https://arxiv.org/pdf/2512.20563v1

**中文摘要**

仿真器可以生成几乎无限的驾驶数据，但在仿真中训练的模仿学习策略在闭环驾驶性能上仍然难以达到鲁棒性。为了解决这一差距，我们实证研究了特权专家示例（privileged expert demonstrations）与基于传感器的学生观测之间的不匹配如何限制模仿学习的有效性。具体而言，专家具有显著更高的可视性（例如能忽略遮挡）和更低的不确定性（例如知道其他车辆的动作），这使得基于学生观测的策略难以可靠地模仿。此外，导航意图（即要行驶的路线）在测试时学生模型仅通过单个目标点来指定，这一表达也存在欠确定性。我们展示了这些不对称性在CARLA仿真中会显著限制驾驶性能，并提出了若干实用干预措施以缩小专家与学生之间的差距。在对模型和训练流程进行针对性修改后，我们的TransFuser v6（TFv6）学生策略在所有主要公开CARLA闭环基准上达到了新的最先进水平：在Bench2Drive上达到95 DS，并在Longest6~v2和Town13上将此前性能翻倍以上。此外，通过将我们数据集中的感知监督整合进统一的sim-to-real流水线，我们在NAVSIM和Waymo基于视觉的端到端驾驶基准上也取得了持续的性能提升。我们的代码、数据和模型已在 https://github.com/autonomousvision/lead 上公开。

---
## 43. How Many Experts Are Enough? Towards Optimal Semantic Specialization for Mixture-of-Experts

- 作者：Sumin Park, Noseong Park
- 子主题：Mixture-of-Experts（MoE）/ 模型架构
- 推荐：很推荐
- 关键词：语义专化, 自适应专家扩展, 动态路由
- Abstract：http://arxiv.org/abs/2512.19765v1
- PDF：https://arxiv.org/pdf/2512.19765v1

**中文摘要**

找到能够最大化专家之间语义区分的稀疏混合专家（Sparse Mixture-of-Experts, SMoE）最优配置，对于充分发挥MoE架构的潜力至关重要。然而，现有的SMoE框架要么高度依赖超参数调优，要么在调整专家池规模时忽视了专家语义角色多样化的重要性。我们提出了面向自适应语义专化的Mixture-of-Experts框架（MASS），用于自适应专家扩展和动态路由。MASS包含两项关键改进：第一，基于梯度的语义漂移检测器，当现有专家池无法捕捉数据的全部语义多样性时触发有针对性的专家扩展；第二，结合了基于token级路由置信度质量的自适应路由策略，动态调整专家的使用。我们首先在高度受控的合成设置中展示了MASS能够可靠地收敛到成本-性能权衡的最优点，并显著提升语义专化程度。随后在覆盖语言与视觉领域的真实数据集上的实证结果表明，MASS持续优于一系列强有力的MoE基线，显示出良好的领域鲁棒性和增强的专家专化能力。

---
## 44. Development and external validation of a multimodal artificial intelligence mortality prediction model of critically ill patients using multicenter data

- 作者：Behrooz Mamandipoor, Chun-Nan Hsu, Martin Krause, Ulrich H. Schmidt, Rodney A. Gabriel
- 子主题：医疗多模态
- 推荐：很推荐
- 关键词：多模态融合, ICU死亡风险预测, 外部验证
- Abstract：http://arxiv.org/abs/2512.19716v1
- PDF：https://arxiv.org/pdf/2512.19716v1

**中文摘要**

背景：在重症监护病房（ICU）入院后早期预测院内死亡率可帮助临床医师优化治疗决策。目的：构建并外部验证一个多模态深度学习模型，利用结构化与非结构化临床数据在ICU入院后24小时内预测随后住院期间的死亡风险。方法：基于MIMIC-III、MIMIC-IV、eICU和HiRID四个多中心数据库开发模型。该多模态模型在MIMIC数据集上训练，包含首24小时内的时间序列分量，输入包括时间不变变量、时间变异变量、临床病程记录（文本）和胸部X光影像，以预测后续住院死亡风险。对外验证在时间上独立的MIMIC人群、HiRID和eICU数据集上进行。结果：共纳入2001–2022年间来自200余家医院的203,434次ICU入院，四个数据集中死亡率在5.2%至7.9%之间。仅整合结构化数据的模型在测试集上的AUROC、AUPRC和Brier分数分别为0.92、0.53和0.19。在eICU数据集中对八家不同机构的外部验证显示AUROC范围为0.84–0.92。在仅考虑那些同时具有临床记录和影像的患者子集时，将临床文本与影像信息加入模型，使AUROC从0.87提升至0.89，AUPRC从0.43提升至0.48，Brier分数从0.37降至0.17。结论：研究结果强调将多源患者信息（结构化数据、临床文本和影像）整合用于死亡预测的重要性，并突出进行了严格外部验证以评估模型泛化性的必要性。

---
## 45. Generative AI for Analysts

- 作者：Jian Xue, Qian Zhang, Wu Zhu
- 子主题：LLM
- 推荐：很推荐
- 关键词：生成式AI, 金融分析, 生产力与认知限制
- Abstract：http://arxiv.org/abs/2512.19705v1
- PDF：https://arxiv.org/pdf/2512.19705v1

**中文摘要**

本文研究生成式人工智能（AI）如何改变金融分析师的工作。以2023年FactSet推出其AI平台作为自然实验，我们发现AI的采用显著提升了报告的丰富性与全面性——报告引用的信息来源增加了40%，覆盖的话题范围拓宽了34%，使用高级分析方法的频率提升了25%，并且提高了报告的时效性。然而，基于AI的报告的预测误差增加了59%，因为AI辅助的报告呈现出更为均衡的正负信息混合，这使得信息更难综合，尤其对认知负荷较重的分析师影响更大。针对其他数据供应商的安慰剂检验表明，这些影响是FactSet AI整合所特有的。总体而言，我们的研究揭示了生成式AI在金融信息生产中既带来的生产力提升，也存在明显的认知限制。

---
## 46. Large Language Models for EDA Cloud Job Resource and Lifetime Prediction

- 作者：Yuxuan Yin, Shengke Zhou, Yunjie Zhang, Ajay Mohindra, Boxun Xu, Peng Li
- 子主题：LLM
- 推荐：很推荐
- 关键词：EDA资源预测, 大型语言模型微调, 文本到文本回归
- Abstract：http://arxiv.org/abs/2512.19701v1
- PDF：https://arxiv.org/pdf/2512.19701v1

**中文摘要**

随着电子设计自动化（EDA）行业云计算的快速发展，准确预测资源需求和作业生命周期以实现最优调度成为一项关键需求。传统机器学习方法在应对EDA工作负载的复杂性和异质性时常常受限，需要大量特征工程和领域知识。我们提出了一种新颖框架，通过将大型语言模型（LLM）微调为文本到文本回归器来解决这一挑战。为提高输出格式的可靠性，我们引入了科学计数法表示和前缀填充策略以约束LLM输出。此外，我们发现对滑动窗口注意力结构的LLM采用全注意力（full-attention）进行微调和推理能够提升预测精度。我们在真实的云端数据集上验证了所提框架的有效性，并在EDA领域的性能预测任务上建立了新的基准。

---
## 47. Bohrium + SciMaster: Building the Infrastructure and Ecosystem for Agentic Science at Scale

- 作者：Linfeng Zhang, Siheng Chen, Yuzhu Cai, Jingyi Chai, Junhan Chang, Kun Chen, Zhi X. Chen, Zhaohan Ding, Yuwen Du, Yuanpeng Gao, Yuan Gao, Jing Gao, Zhifeng Gao, Qiangqiang Gu, Yanhui Hong, Yuan Huang, Xi Fang, Xiaohong Ji, Guolin Ke, Zixing Lei, Xinyu Li, Yongge Li, Ruoxue Liao, Hang Lin, Xiaolu Lin, Yuxiang Liu, Xinzijian Liu, Zexi Liu, Jintan Lu, Tingjia Miao, Haohui Que, Weijie Sun, Yanfeng Wang, Bingyang Wu, Tianju Xue, Rui Ye, Jinzhe Zeng, Duo Zhang, Jiahui Zhang, Linfeng Zhang, Tianhan Zhang, Wenchang Zhang, Yuzhi Zhang, Zezhong Zhang, Hang Zheng, Hui Zhou, Tong Zhu, Xinyu Zhu, Qingguo Zhou, Weinan E
- 子主题：LLM
- 推荐：很推荐
- 关键词：代理化科学, 可追溯基础设施, 工作流编排
- Abstract：http://arxiv.org/abs/2512.20469v1
- PDF：https://arxiv.org/pdf/2512.20469v1

**中文摘要**

AI 代理正成为运行多步科学工作流的实用手段，这类工作流将推理与工具使用及验证交织在一起，标志着从孤立的 AI 辅助步骤向“可扩展的代理化科学”转变。随着科学工具与模型可以通过稳定接口调用并以记录的执行轨迹进行验证，这一转变愈发可行；同时，AI 加速科学产出并对同行评审与出版流程施加压力，提升了可追溯性与可信评估的需求。然规模化代理化科学仍面临诸多困难：工作流难以观测与复现；许多工具与实验系统尚未具备对代理友好的能力；执行难以追踪与治理；而现有的 AI 科学家原型往往为定制化实现，限制了从真实工作流信号中复用与系统性改进。我们认为，要实现代理化科学的规模化，需采取基础设施与生态系统并重的策略，并以 Bohrium+SciMaster 为实例予以实现。Bohrium 充当受管控且可追溯的 AI for Science 资产枢纽——类似科研领域的 HuggingFace——将多样的科学数据、软件、算力和实验系统转化为对代理可调用的能力。SciMaster 将这些能力编排为面向长期目标的科学工作流，供科学代理组合与执行。在基础设施与编排之间，一个“科学智能基座”把可复用的模型、知识与组件组织为可执行构件，用于工作流的推理与行动，从而实现组合能力、可审计性并通过使用获得改进。我们在真实工作流中用 11 个代表性主控代理演示了该技术栈，实现了端到端科学周期时间的数量级缩短，并在数百万规模的真实工作负载中生成了基于执行的信号。

---
## 48. Discovering Lie Groups with Flow Matching

- 作者：Jung Yeon Park, Yuxuan Chen, Floor Eijkelboom, Jan-Willem van de Meent, Lawson L. S. Wong, Robin Walters
- 子主题：CV（几何/对称性学习）
- 推荐：很推荐
- 关键词：Lie群, 流匹配, 对称性发现
- Abstract：http://arxiv.org/abs/2512.20043v1
- PDF：https://arxiv.org/pdf/2512.20043v1

**中文摘要**

对称性是理解物理系统的基础，同时也能提高机器学习中的性能和样本效率。为了从数据中获知潜在对称性，我们提出通过在Lie群上进行流匹配（flow matching）来直接学习对称性。我们将对称性发现表述为在更大的假设群上学习一个分布，使得该分布与数据中观察到的对称性相匹配。相较于以往工作，我们的方法LieFlow在可发现的群类型上更具灵活性，并且需要更少的先验假设。在二维和三维点云上的实验表明，本文能成功发现离散群，包括通过在复域上进行流匹配发现反射等对称性。我们还识别出一个关键挑战：目标模态的对称排列会导致“最后时刻收敛”现象，即样本在流的大部分过程保持静止直至较晚阶段才移动；为此我们提出了一种用于对称性发现的流匹配插值新方案来缓解该问题。

---
## 49. Block-Recurrent Dynamics in Vision Transformers

- 作者：Mozes Jacobs, Thomas Fel, Richard Hakim, Alessandra Brondetta, Demba Ba, T. Andy Keller
- 子主题：CV
- 推荐：很推荐
- 关键词：视觉Transformer, 块-递归结构, 动力学可解释性
- Abstract：http://arxiv.org/abs/2512.19941v1
- PDF：https://arxiv.org/pdf/2512.19941v1

**中文摘要**

随着视觉Transformer（ViT）成为标准的视觉骨干网络，构建其计算现象学的机械化解释变得至关重要。尽管架构上存在提示深度具有动力学结构的线索，但尚无公认的框架将Transformer的深度解释为明确的流动过程。本文提出了“块-递归假说”（Block-Recurrent Hypothesis, BRH），认为经过训练的ViT在深度方向上呈现块-递归结构：原始的L个块的计算可以通过仅有k ≪ L个不同块的递归应用来精确重写。对多种ViT的跨层表征相似性矩阵表明存在少数连续的相位。为检验这些相位是否代表真正可重用的计算，我们训练了预训练ViT的块-递归替代模型：相位结构化变换器的递归近似（Raptor）。在小规模实验中我们展示了随机深度与训练过程会促进递归结构，并且这一点与我们准确拟合Raptor的能力相关联。我们随后提供了BRH的实证存在性证明：训练出的Raptor模型在仅用2个块且计算成本等价的情形下，恢复了DINOv2在ImageNet-1k线性探测准确率的96%。最后，我们利用该假说推进了一套动力学可解释性研究方案，发现：i) 表征沿深度呈现朝向性的收敛，进入与类别相关的角度基域，并在小扰动下表现出自我修正的轨迹；ii) 存在令牌特异性的动态行为，其中cls令牌在后期发生明显的快速重定向，而patch令牌在后期趋向其平均方向表现出强烈的一致性；iii) 在深度后期更新趋向低秩塌缩，符合收敛到低维吸引子（attractors）的描述。总体来看，ViT深度方向上展现出一种紧凑的递归程序，指向一种低复杂度的规范性解，使得这些模型可以通过有原则的动力系统分析来研究。

---
## 50. TableGPT-R1: Advancing Tabular Reasoning Through Reinforcement Learning

- 作者：Saisai Yang, Qingyi Huang, Jing Yuan, Liangyu Zha, Kai Tang, Yuhang Yang, Ning Wang, Yucheng Wei, Liyao Li, Wentao Ye, Hao Chen, Tao Zhang, Junlin Zhou, Haobo Wang, Gang Chen, Junbo Zhao
- 子主题：LLM+RL
- 推荐：很推荐
- 关键词：表格推理, 强化学习, 奖励设计
- Abstract：http://arxiv.org/abs/2512.20312v1
- PDF：https://arxiv.org/pdf/2512.20312v1

**中文摘要**

表格数据是现代数据分析和科学研究的核心支柱。尽管通过监督微调（SFT）得到优化的大型语言模型（LLM）在与结构化表格数据的自然语言交互方面取得了显著进展，但在应对现实表格任务中所需的复杂多步推理和可靠的代码执行方面仍存在不足。强化学习（RL）为提升这些能力提供了有前景的路径，然而其在表格领域的应用面临三大关键挑战：一是缺乏包含闭环代码执行和环境反馈的高质量智能代理轨迹，且这些轨迹需覆盖多样化的表格结构；二是反馈信号高度异质，从严格的SQL执行结果到开放式的数据解释均有差异；三是在垂直专化过程中存在遗忘通用知识的风险。为了解决这些问题并在复杂表格上实现更高级的推理能力，我们提出了TableGPT-R1，一个基于系统化强化学习框架的专用表格模型。我们的方法整合了一套全面的数据工程流水线，用于合成按难度分层的智能代理轨迹以支持监督对齐和RL rollout；设计了任务自适应的奖励体系，将基于规则的校验与注入准则的奖励模型相结合，并引入了过程级的步奖励整形与行为正则化；同时采用多阶段训练框架，先逐步稳固推理能力，再向表格专用任务专化。大量评测表明，TableGPT-R1在权威基准上取得了最先进的性能，显著优于基线模型且保持了稳健的通用能力。我们的模型已发布于：https://huggingface.co/tablegpt/TableGPT-R1。

---
## 51. UbiQVision: Quantifying Uncertainty in XAI for Image Recognition

- 作者：Akshat Dubey, Aleksandar Anžel, Bahar İlgen, Georges Hattab
- 子主题：CV
- 推荐：很推荐
- 关键词：不确定性量化, 可解释人工智能（XAI）, SHAP 与 Dempster–Shafer
- Abstract：http://arxiv.org/abs/2512.20288v1
- PDF：https://arxiv.org/pdf/2512.20288v1

**中文摘要**

近年来深度学习的进步使其在包括医学影像在内的众多领域得到广泛应用。推动这一进展的是日益复杂的模型架构，例如 ResNet、Vision Transformer 和混合卷积神经网络，这些模型在提升性能的同时也带来了更高的复杂性，从而削弱了模型的可解释性和可理解性。SHAP 已成为一种重要的方法，用于生成可解释的可视化，帮助领域专家理解模型预测。然而，在存在认知不确定性（epistemic uncertainty）和随机不确定性（aleatoric uncertainty）的情况下，SHAP 的解释可能表现出不稳定性和不可靠性。本研究针对这一问题，提出采用狄利克雷（Dirichlet）后验采样和邓普斯特-沙弗（Dempster–Shafer）理论来量化医学影像应用中由不稳定解释引起的不确定性。该框架使用信念（belief）、可置信（plausible）和融合（fusion）图谱方法，结合统计量化分析，对 SHAP 解释的不确定性进行度量。我们在三个医学影像数据集上对该框架进行了评估，这些数据集在类别分布、图像质量和模态类型上存在差异（涵盖病理学、眼科和放射学的示例），不同图像分辨率和模态特性引入了显著的噪声与认知不确定性。

---
## 52. MemR$^3$: Memory Retrieval via Reflective Reasoning for LLM Agents

- 作者：Xingbo Du, Loka Li, Duzhen Zhang, Le Song
- 子主题：LLM
- 推荐：很推荐
- 关键词：记忆检索, 闭环控制, 反思推理
- Abstract：http://arxiv.org/abs/2512.20237v1
- PDF：https://arxiv.org/pdf/2512.20237v1

**中文摘要**

记忆系统被设计用于让大型语言模型（LLM）代理利用过去的经验。然而，许多已部署的记忆系统主要优化压缩与存储，对记忆检索的显式闭环控制关注较少。基于这一观察，我们构建了一个将记忆检索视为自治、精确且兼容的代理系统——MemR³。该系统包含两大核心机制：一是路由器（router），在检索（retrieve）、反思（reflect）与回答（answer）三类动作间选择，以优化回答质量；二是全局证据-缺口追踪器（global evidence-gap tracker），该机制使回答过程透明化并显式跟踪证据收集过程。该设计有别于传统的“检索后回答”流水线，引入了闭环控制机制以实现自主决策。基于 LoCoMo 基准的实证结果表明，MemR³ 在 LLM-as-a-Judge 评分上超越了强基线，且显著提升了现有检索器在四类场景下的表现——在使用 GPT-4.1-mini 后端时，对 RAG 的总体提升为 +7.29%，对 Zep 的提升为 +1.94%，同时可作为现有记忆存储的即插即用控制器。

---
## 53. FaithLens: Detecting and Explaining Faithfulness Hallucination

- 作者：Shuzheng Si, Qingyi Wang, Haozhe Zhao, Yuzhuo Bai, Guanqiao Chen, Kangyang Luo, Gang Chen, Fanchao Qi, Minjia Zhang, Baobao Chang, Maosong Sun
- 子主题：LLM
- 推荐：很推荐
- 关键词：忠实性幻觉检测, 可解释性生成, 训练数据合成与强化学习优化
- Abstract：http://arxiv.org/abs/2512.20182v1
- PDF：https://arxiv.org/pdf/2512.20182v1

**中文摘要**

识别大型语言模型（LLM）输出中是否存在忠实性（faithfulness）幻觉对检索增强生成与摘要等实际应用至关重要。本文提出FaithLens，一种既高效又具成本效益的忠实性幻觉检测模型，能够同时给出二分类预测与相应解释以提升可信度。为此，我们首先利用先进LLM合成带解释的训练数据，并通过明确的数据过滤策略保证标签正确性、解释质量与数据多样性。随后，将模型在这些精心筛选的训练数据上微调作为冷启动，并进一步采用基于规则的强化学习进行优化，奖励项同时考量预测正确性与解释质量。在12个多样任务上的实验证明，8B参数的FaithLens在性能上超越了GPT-4.1与o3等先进模型，同时能生成高质量解释，在可信性、效率与有效性之间取得了显著平衡。

---
## 54. Offline Safe Policy Optimization From Heterogeneous Feedback

- 作者：Ze Gong, Pradeep Varakantham, Akshat Kumar
- 子主题：RL
- 推荐：很推荐
- 关键词：离线偏好强化学习, 安全强化学习, 偏好与安全对齐
- Abstract：http://arxiv.org/abs/2512.20173v1
- PDF：https://arxiv.org/pdf/2512.20173v1

**中文摘要**

离线基于偏好的强化学习（Preference-based Reinforcement Learning, PbRL）通过学习与人类偏好一致的回报和策略，避免大量的回报工程和与人工标注者的直接交互。然而，在许多领域和任务中，确保策略的安全性仍然是一个关键挑战。先前关于来自人类反馈的安全强化学习（RLHF）的工作通常先从离线数据中学习回报与代价模型，再使用约束强化学习优化安全策略。尽管这种思路在上下文化赌博机（contextual bandits，例如大模型）设置中可行，但在长时域的连续控制任务中，回报和代价模型的误差会累积，导致与约束RL方法联合使用时性能下降。为了解决这些问题，本文提出以下贡献： (a) 我们不再通过间接学习回报与代价来获得策略，而是提出了一个框架，直接基于关于智能体在回报方面行为的成对偏好以及表示轨迹片段安全性的二元标注来学习策略；(b) 我们提出了PreSa（Preference and Safety Alignment）方法，将偏好学习模块与安全对齐整合为一个约束优化问题。该优化问题在拉格朗日范式下求解，能够直接学习在满足安全约束下最大化回报的策略，且无需显式地学习回报和代价模型，从而避免了对约束强化学习的依赖；(c) 我们在连续控制任务上使用合成与真实人类反馈对该方法进行了评估。实证结果表明，我们的方法能够学到既安全又高回报的策略，优于现有的最先进基线方法以及那些使用真实回报与代价的离线安全RL方法。

---
## 55. A Bidirectional Gated Recurrent Unit Model for PUE Prediction in Data Centers

- 作者：Dhivya Dharshini Kannan, Anupam Trivedi, Dipti Srinivasan
- 子主题：时间序列预测 / 数据中心能耗管理
- 推荐：很推荐
- 关键词：数据中心能效, PUE预测, 双向GRU（BiGRU）
- Abstract：http://arxiv.org/abs/2512.20161v1
- PDF：https://arxiv.org/pdf/2512.20161v1

**中文摘要**

数据中心在全球能源消耗和碳足迹中占据重要份额。随着边缘计算需求和人工智能的发展，数据中心存储容量呈增长趋势，提高能效是应对气候变化、降低能源成本、提升企业竞争力并促进信息技术与环境可持续发展的经济有效手段。因此，优化数据中心能耗管理是实现可持续性的关键因素。功率使用效率（PUE）用于衡量数据中心的运营效率。利用神经网络预测PUE可以帮助理解各特征对能耗的影响，从而针对性地调整关键特征以提升能效。本文提出了一种基于双向门控循环单元（BiGRU）的PUE预测模型，并将其与单向GRU模型进行了性能比较。数据集由EnergyPlus模拟新加坡某数据中心得到，包含52,560条样本与117个特征。针对不同参数设置，采用递归特征消除并结合交叉验证（RFECV）选择若干最相关的特征子集。使用这些特征子集进行超参数搜索并训练BiGRU模型。最终，通过均方误差（MSE）、平均绝对误差（MAE）和R平方（R²）等指标对优化后的BiGRU模型与GRU模型的预测性能进行了比较评估。

---
## 56. MolAct: An Agentic RL Framework for Molecular Editing and Property Optimization

- 作者：Zhuo Yang, Yeyun chen, Jiaqing Xie, Ben Gao, Shuaike Shen, Wanhao Liu, Liujia Yang, Beilun Wang, Tianfan Fu, Yuqiang Li
- 子主题：LLM, 强化学习(RL), 计算化学
- 推荐：很推荐
- 关键词：分子编辑, 智能体式强化学习, 工具化大语言模型
- Abstract：http://arxiv.org/abs/2512.20135v1
- PDF：https://arxiv.org/pdf/2512.20135v1

**中文摘要**

分子编辑与优化是需要在保持分子化学有效性和结构相似性的前提下，通过多步迭代改进目标性质的任务。我们将这两类任务表述为序列化、由工具引导的决策过程，并提出MolAct，一种智能体式强化学习框架，采用两阶段训练范式：先构建编辑能力，然后在复用已学编辑行为的基础上进行性质优化。据我们所知，这是首个将分子设计形式化为Agentic Reinforcement Learning问题的工作，其中大语言模型（LLM）智能体学习交替进行推理、工具使用与分子优化。该框架允许智能体进行多轮交互，调用化学工具以进行有效性检查、性质评估与相似性控制，并利用这些反馈来细化后续编辑。我们基于MolAct训练了两类模型：用于分子编辑任务的MolEditAgent和用于分子优化任务的MolOptAgent。在分子编辑实验中，MolEditAgent-7B在添加、删除和替换编辑任务上分别实现了100、95和98的有效编辑，优于如DeepSeek-R1等强大的闭环“思考”基线；MolEditAgent-3B的性能接近体量更大的开放“思考”模型（如Qwen3-32B-think）。在分子优化实验中，基于MolEditAgent-7B训练的MolOptAgent-7B在LogP指标上超越了最佳闭环“思考”基线（例如Claude 3.7），在可溶性指标上保持竞争力，并在其他目标上表现均衡。这些结果表明，将分子设计视为多步、工具增强的过程是实现可靠且可解释改进的关键。

---
## 57. LongVideoAgent: Multi-Agent Reasoning with Long Videos

- 作者：Runtao Liu, Ziyi Liu, Jiaqi Tang, Yue Ma, Renjie Pi, Jipeng Zhang, Qifeng Chen
- 子主题：多模态LLM / 长视频问答
- 推荐：很推荐
- 关键词：长视频问答, 多智能体协作, 强化学习训练
- Abstract：http://arxiv.org/abs/2512.20618v1
- PDF：https://arxiv.org/pdf/2512.20618v1

**中文摘要**

近年来，多模态大模型和利用工具进行长视频问答的系统进展表明对小时级视频进行推理具有很大潜力。然而，许多方法仍然将内容压缩为有损的摘要或依赖有限的工具集，从而削弱了时序定位能力并错失细粒度线索。我们提出了一种多智能体框架：由一个主控大模型（master LLM）协调一个定位（grounding）智能体用于定位与问题相关的片段，以及一个视觉智能体用于提取针对性的文本化观测。主控智能体在有限步数规划下工作，并通过强化学习训练以鼓励简洁、正确且高效的多智能体协作。该设计通过定位帮助主控智能体关注相关片段、以视觉细节补充字幕信息，并产生可解释的推理轨迹。在我们构建的 LongTVQA 与 LongTVQA+（基于 TVQA/TVQA+ 聚合的集级数据集）上，多智能体系统显著优于强大的非智能体基线。实验还表明，强化学习进一步增强了所训练智能体的推理与规划能力。代码与数据将在 https://longvideoagent.github.io/ 上发布。

---
## 58. Emergent temporal abstractions in autoregressive models enable hierarchical reinforcement learning

- 作者：Seijin Kobayashi, Yanick Schimpf, Maximilian Schlegel, Angelika Steger, Maciej Wolczyk, Johannes von Oswald, Nino Scherre, Kaitlin Maile, Guillaume Lajoie, Blake A. Richards, Rif A. Saurous, James Manyika, Blaise Agüera y Arcas, Alexander Meulemans, João Sacramento
- 子主题：强化学习（层次强化学习 与 自回归模型）
- 推荐：很推荐
- 关键词：自回归模型, 层次强化学习, 时间抽象
- Abstract：http://arxiv.org/abs/2512.20605v1
- PDF：https://arxiv.org/pdf/2512.20605v1

**中文摘要**

在许多问题域中，基于下一令牌预测进行大规模预训练并通过强化学习（RL）微调的自回归模型取得了前所未有的成功。在强化学习过程中，这些模型通过一次生成一个令牌来探索环境。然而，逐令牌采样的动作执行在奖励稀疏时会导致学习极为低效。本文提出通过在自回归模型的内部表征上进行动作与探索来克服这一问题。具体而言，我们引入了一种高阶的非因果序列模型，其输出用于控制基自回归模型的残差流激活（residual stream activations），以发现时间抽象的动作。在具有层次结构的网格世界和基于 MuJoCo 的任务中，我们发现高阶模型学会将长的激活序列片段压缩到内部控制器上。关键在于，每个控制器执行一段在行为上有意义、在较长时间尺度上展开的动作序列，并伴随一个学习得到的终止条件，从而多个控制器的串联能够在新任务上实现高效探索。我们展示了对内部控制器的直接强化（我们称之为“内部 RL”）能够在标准 RL 微调失败的稀疏奖励情形下实现学习。我们的结果表明在自回归模型中生成潜在动作并对其进行强化具有显著益处，提示“内部 RL”可能是将在基础模型中实现层次化强化学习的有前景方向。

---
## 59. Distilling to Hybrid Attention Models via KL-Guided Layer Selection

- 作者：Yanhong Li, Songlin Yang, Shawn Tan, Mayank Mishra, Rameswar Panda, Jiawei Zhou, Yoon Kim
- 子主题：LLM
- 推荐：很推荐
- 关键词：模型蒸馏, 混合注意力, KL 引导层选择
- Abstract：http://arxiv.org/abs/2512.20569v1
- PDF：https://arxiv.org/pdf/2512.20569v1

**中文摘要**

将预训练的 softmax 注意力 Transformer 蒸馏为更高效的混合架构（在 softmax 与线性注意力层间交错）是一种有前景的方法，可在无需昂贵的从头预训练下提升大型语言模型的推理效率。转换过程中的一个关键因素是层选择，即决定哪些层应转换为线性注意力变体。本文提出了一种简单且高效的层选择方案：通过在少量通用文本上进行短时训练，计算各层的重要性评分以指导层的选择。层选择完成后，我们采用近期的蒸馏流水线（RADLADS），包括注意力权重迁移、隐藏状态对齐、基于 KL 的分布匹配，随后进行少量微调。实验结果表明，该方法在层选择上优于现有方法，包括基于固定比例均匀交错线性注意力的启发式策略以及依赖专门诊断数据集的复杂方案。

---
## 60. Dual-Encoder Transformer-Based Multimodal Learning for Ischemic Stroke Lesion Segmentation Using Diffusion MRI

- 作者：Muhammad Usman, Azka Rehman, Muhammad Mutti Ur Rehman, Abd Ur Rehman, Muhammad Umar Farooq
- 子主题：CV
- 推荐：很推荐
- 关键词：缺血性脑卒中分割, 多模态扩散MRI, 双编码器 Transformer
- Abstract：http://arxiv.org/abs/2512.20436v1
- PDF：https://arxiv.org/pdf/2512.20436v1

**中文摘要**

准确地从扩散磁共振成像（MRI）中分割缺血性脑卒中病灶对临床决策和结局评估至关重要。扩散加权成像（DWI）和表观扩散系数（ADC）扫描对急性和亚急性缺血改变提供互补信息，但由于病灶外观多变，自动化勾画仍具有挑战性。本研究基于ISLES 2022数据集，研究了使用多模态扩散MRI的缺血性脑卒中病灶分割问题。对多种最先进的卷积和基于Transformer的架构（包括U-Net变体、Swin-UNet和TransUNet）进行了基准比较。基于性能分析，提出了一种双编码器的TransUNet结构，用于从DWI和ADC输入中分别学习模态特异的表征。为引入空间上下文信息，采用三切片输入配置整合相邻切片信息。所有模型在统一框架下训练，并以Dice相似性系数（DSC）进行评估。结果表明，基于Transformer的模型优于卷积基线，所提出的双编码器TransUNet在测试集上取得了85.4%的Dice得分，表现最佳。该框架为基于扩散MRI的缺血性脑卒中病灶自动分割提供了稳健的解决方案。

---
## 61. DETACH : Decomposed Spatio-Temporal Alignment for Exocentric Video and Ambient Sensors with Staged Learning

- 作者：Junho Yoon, Jaemo Jung, Hyunju Kim, Dongman Lee
- 子主题：CV
- 推荐：很推荐
- 关键词：时空分解对齐, 传感器-视频多模态融合, 时空加权对比学习
- Abstract：http://arxiv.org/abs/2512.20409v1
- PDF：https://arxiv.org/pdf/2512.20409v1

**中文摘要**

将第一视角（egocentric）视频与可穿戴传感器对齐在人体动作识别中已展示出潜力，但在用户舒适度、隐私和可扩展性方面存在局限。我们探索将外视（exocentric）视频与环境传感器结合，作为一种无侵入且可扩展的替代方案。以往的以全局对齐为主的方法通过将整段序列编码为统一表示来工作，但在外视-环境传感器场景中面临两类问题：（P1）无法捕捉诸如细微运动等局部细节；（P2）过度依赖模态不变的时间模式，导致在时间模式相似但时空语义背景不同的动作间发生错配。为了解决上述问题，我们提出了DETACH，一种分解的时空对齐框架。该显式分解有助于保留局部细节；同时，我们通过在线聚类发现的新型传感器-空间特征为语义化的上下文感知对齐提供了基础。为对齐这些分解后的特征，所提出的两阶段方法先通过互监督建立空间对应关系，然后通过一种时空加权对比损失进行时间对齐，该损失自适应处理易负样本、硬负样本以及假负样本。基于 Opportunity++ 与 HWU-USP 数据集的下游任务的全面实验表明，所提方法较改编自第一视角-可穿戴基线取得了显著改进。

---
## 62. Identifying Appropriately-Sized Services with Deep Reinforcement Learning

- 作者：Syeda Tasnim Fabiha, Saad Shafiq, Wesley Klewerton Guez Assunção, Nenad Medvidović
- 子主题：RL
- 推荐：很推荐
- 关键词：服务化架构, 深度强化学习, 服务分解
- Abstract：http://arxiv.org/abs/2512.20381v1
- PDF：https://arxiv.org/pdf/2512.20381v1

**中文摘要**

面向服务的架构（SBA）在工业界和学术界中日益受到重视，作为改造遗留系统的一种手段。SBA 指的是将系统设计为一组小型、低耦合且自治的组件（服务），通过与语言无关的 API 进行通信，从而封装功能。然而，如何划分出能够捕捉系统内聚功能子集的合适尺度服务仍然具有挑战性。现有工作通常依赖文档可得性、项目人员访谈或目标服务数量的先验知识，但这些假设在许多实际场景中并不成立。为了解决这些局限性，我们提出了一种基于深度强化学习的方案，从实现工件中直接识别合适尺度的服务。我们提出了 Rake，一种利用可用系统文档和源代码来引导在实现方法级别上进行服务分解的强化学习技术。Rake 无需特定类型的文档或项目人员访问且与编程语言无关，同时支持可定制的目标函数以在模块化质量与业务能力对齐（即服务覆盖目标业务能力的程度）之间进行权衡。我们在四个开源遗留项目上应用 Rake，并与两种最先进技术进行了比较。平均而言，Rake 在模块化质量上提高了 7–14%，在业务能力对齐上提升了 18–22%。结果还表明，在高度耦合的系统中，若仅优化业务上下文可能会降低分解质量，这凸显了平衡目标的重要性。

---
## 63. UCCL-EP: Portable Expert-Parallel Communication

- 作者：Ziming Mao, Yihan Zhang, Chihan Cui, Kaichao You, Zhongjie Chen, Zhiying Xu, Scott Shenker, Costin Raiciu, Yang Zhou, Ion Stoica
- 子主题：LLM
- 推荐：很推荐
- 关键词：专家并行, RDMA 与 GPU-NIC 互联, 可移植通信系统
- Abstract：http://arxiv.org/abs/2512.19849v1
- PDF：https://arxiv.org/pdf/2512.19849v1

**中文摘要**

混合专家（Mixture-of-Experts, MoE）工作负载依赖专家并行（Expert Parallelism, EP）来实现高 GPU 利用率。最先进的 EP 通信系统（如 DeepEP）尽管性能优异，但在异构 GPU 与网卡（NIC）平台上的可移植性较差。可移植性差的根源在于架构设计：基于 GPU 发起的逐 token RDMA 通信需要 GPU 与 NIC 之间紧密的垂直集成，例如 GPU 直接写入 NIC 驱动或 MMIO 接口。我们提出了 UCCL-EP，一种可移植的 EP 通信系统，能够在异构 GPU 与 NIC 硬件上实现与 DeepEP 相当的性能。UCCL-EP 用高吞吐的 GPU-CPU 控制通道替代 GPU 发起的 RDMA：紧凑的 token 路由指令先传输到多线程的 CPU 代理，再由这些代理代表 GPU 发起 GPUDirect RDMA 操作。UCCL-EP 还利用 RDMA immediate data 仿真多种专用 EP 通信模式所需的排序语义，使得在缺乏此类排序特性的网卡（如 AWS EFA）上也能保证正确性。我们在配备 EFA 和 Broadcom 网卡的 NVIDIA 与 AMD GPU 平台上实现了 UCCL-EP。在 EFA 上，UCCL-EP 在 dispatch 和 combine 吞吐上较现有最佳 EP 方案提升最多 2.1×；在仅 NVIDIA 平台上，其性能可与原始 DeepEP 相媲美。在 NVIDIA+EFA 平台上，UCCL-EP 在 SGLang 的 token 吞吐量上最多提升 40%；在 16 节点 AMD+Broadcom 平台上，UCCL-EP 在基于 AMD Primus/Megatron-LM 的 DeepSeek-V3 训练中将吞吐量最多提升 45%。

---
## 64. PhysMaster: Building an Autonomous AI Physicist for Theoretical and Computational Physics Research

- 作者：Tingjia Miao, Jiawen Dai, Jingkun Liu, Jinxin Tan, Muhua Zhang, Wenkai Jin, Yuwen Du, Tian Jin, Xianghe Pang, Zexi Liu, Tu Guo, Zhengliang Zhang, Yunjie Huang, Shuo Chen, Rui Ye, Yuzhi Zhang, Linfeng Zhang, Kun Chen, Wei Wang, Weinan E, Siheng Chen
- 子主题：LLM
- 推荐：很推荐
- 关键词：自动化物理学家代理, LANDAU学术数据层, 数值-解析耦合与自适应探索
- Abstract：http://arxiv.org/abs/2512.19799v1
- PDF：https://arxiv.org/pdf/2512.19799v1

**中文摘要**

随着大规模语言模型（LLM）的进步，已出现具备与人类科学家相当的知识与操作能力的智能体，显示出辅助、加速和自动化科研的潜力。然而，现有研究主要在定义良好的基准或诸如文献检索等通用任务上评估此类系统，限制了它们在开放科学场景下的端到端问题求解能力。物理学尤其如此：它高度抽象、数学密集，需要将分析推理与基于代码的计算紧密结合。为此，我们提出PhysMaster，一种基于LLM的智能体，作为自主的理论与计算物理学家。PhysMaster将抽象推理与数值计算耦合，并利用LANDAU（Layered Academic Data Universe，层次学术数据宇宙），该体系保存检索到的文献、人工整理的先验知识和经验证的方法论轨迹，从而提高决策的可靠性与稳定性。它还采用一种在效率与开放式探索之间取得平衡的自适应探索策略，使其在超长时序任务中表现稳健。我们在高能理论、凝聚态理论与天体物理等问题上对PhysMaster进行了评估，结果包括：(i) 加速——将需数月人力的研究压缩到数小时；(ii) 自动化——自主执行假设驱动的循环；(iii) 自主发现——独立探索开放性问题。

---
## 65. Thermodynamic Focusing for Inference-Time Search: Practical Methods for Target-Conditioned Sampling and Prompted Inference

- 作者：Zhan Zhang
- 子主题：LLM
- 推荐：很推荐
- 关键词：目标条件采样, 推理时聚焦, 提示式与算法重加权
- Abstract：http://arxiv.org/abs/2512.19717v1
- PDF：https://arxiv.org/pdf/2512.19717v1

**中文摘要**

在语言生成、规划和强化学习等领域，从极大候选空间中找到稀有但有用的解是一个反复出现的实际挑战。我们提出了一个实用框架——反向因果聚焦算法（Inverted Causality Focusing Algorithm，ICFA），将搜索视为一种目标条件化的重加权过程。ICFA 重用已有的候选采样器和任务特定的相似性函数来构建聚焦的采样分布，同时自适应地控制聚焦强度以避免分布退化。我们给出了清晰的操作配方、基于有效样本数的稳定性诊断、一个紧凑的理论说明（解释在何种条件下 ICFA 能减少样本需求），并在受约束的语言生成和稀疏奖励导航两个可复现实验上验证了方法。我们进一步展示了结构化提示如何体现 ICFA 的一种近似语言级形式，并描述了一种将提示式推理与算法级重加权相结合的混合架构。

---
## 66. Brain-Grounded Axes for Reading and Steering LLM States

- 作者：Sandro Andric
- 子主题：LLM
- 推荐：很推荐
- 关键词：神经生理对齐, LLM可解释性, 隐状态操控
- Abstract：http://arxiv.org/abs/2512.19399v1
- PDF：https://arxiv.org/pdf/2512.19399v1

**中文摘要**

可解释性方法通常从文本监督中导出方向，但这些方向可能缺乏外部锚定。我们提出将人类脑活动用作阅读和操控大型语言模型（LLM）内部状态的坐标系，而不是训练信号。利用 SMN4Lang 的 MEG 数据集，我们构建了基于相位锁定值（PLV）模式的词级大脑图谱，并通过独立成分分析（ICA）提取潜在轴。我们用独立词典和基于命名实体识别（NER）的标注对这些轴进行验证（使用词性/POS 和对数词频作为合理性检查），随后训练轻量级适配器将 LLM 隐状态映射到这些脑轴，且不对 LLM 进行微调。沿脑源方向进行操控在 TinyLlama 的中间层产出了稳健的词汇（与词频相关）轴，该效应在与困惑度匹配的对照下依然存在；与基于文本的探针比较显示，脑轴在词频对数的位移上更大且具有更低的困惑度。另一个功能/内容轴（轴13）在 TinyLlama、Qwen2-0.5B 和 GPT-2 上表现出一致的操控效果，并通过困惑度匹配的文本层面证据得到佐证。TinyLlama 第4层的效应虽较大但不稳定，因而被视为次要结果（详见附录）。当在不使用 GPT 嵌入变化特征或改用 word2vec 嵌入重建图谱时，轴结构保持稳定（匹配轴间相关 |r|=0.64–0.95），这降低了循环因果的担忧。探索性 fMRI 锚定表明嵌入变化和对数词频可能存在对齐，但该效应对血氧动力学建模假设敏感，仅作为群体水平证据处理。总体而言，这些结果支持一种新的接口：以神经生理为基础的轴为 LLM 行为提供可解释且可控的把手。

---
## 67. Synthesizing Procedural Memory: Challenges and Architectures in Automated Workflow Generation

- 作者：Nishant Gaurav, Adit Akarsh, Ankit Ranjan, Manoj Bajaj
- 子主题：LLM (Agentic/工作流生成)
- 推荐：很推荐
- 关键词：过程化记忆, 自动化技能合成, 线性状态锚定
- Abstract：http://arxiv.org/abs/2512.20278v1
- PDF：https://arxiv.org/pdf/2512.20278v1

**中文摘要**

尽管 CodeMem 将可执行代码确立为最优的代理式过程化记忆表征，但如何从零开始自主合成此类记忆的机制尚未得到充分探索。本文将大型语言模型从被动工具使用者转变为主动工作流构建者的过程进行操作化。在一个涉及 Outlook 与 OneDrive 的高保真跨服务编排任务案例研究中，我们识别并解决了自动化技能生成中的四个结构性瓶颈：一是发现差距（Discovery Gap），涉及在大型工具注册表中进行导航；二是验证差距（Verification Gap），关乎将工具响应结构进行落地约束；三是分解差距（Decomposition Gap），提出以“线性状态锚定”替代低效搜索；四是扩展差距（Scaling Gap），聚焦并发性与持久化问题。我们证明，通过强制执行假设—探测—编码的科学方法论，代理能够自主编写健壮且可投入生产的代码技能。

---
## 68. Graph-Symbolic Policy Enforcement and Control (G-SPEC): A Neuro-Symbolic Framework for Safe Agentic AI in 5G Autonomous Networks

- 作者：Divya Vijay, Vignesh Ethiraj
- 子主题：LLM (网络自动化)
- 推荐：很推荐
- 关键词：神经符号, 网络知识图 (NKG), 5G网络自动化
- Abstract：http://arxiv.org/abs/2512.20275v1
- PDF：https://arxiv.org/pdf/2512.20275v1

**中文摘要**

随着网络向5G独立组网和6G演进，运营商面临的编排挑战已超出静态自动化与深度强化学习的能力。尽管大规模语言模型（LLM）代理为基于意图的网络管理提供了一条路径，但它们也带来随机性风险，包括拓扑幻觉与策略不遵从等问题。为缓解这些风险，我们提出了图-符号策略执行与控制（G-SPEC），这是一种通过确定性验证约束概率规划的神经符号框架。该架构基于一个电信适配的“治理三元组”——电信定制代理（TSLAM-4B）、网络知识图（NKG）和SHACL约束。我们在一个450节点的5G核心网仿真环境中评估了G-SPEC，达到零安全违规并实现94.1%的修复成功率，显著优于基线的82.4%。消融分析表明，NKG验证贡献了大部分安全收益（68%），其后是SHACL策略（24%）。对规模在1万至10万节点的拓扑进行的可扩展性测试显示，验证延迟随子图规模k的增长近似为O(k^{1.2})。在142毫秒的处理开销下，G-SPEC在SMO层操作上具有可行性。

---
## 69. A Declarative Language for Building And Orchestrating LLM-Powered Agent Workflows

- 作者：Ivan Daunis
- 子主题：LLM
- 推荐：很推荐
- 关键词：声明式DSL, 代理工作流编排, 跨语言/跨环境部署
- Abstract：http://arxiv.org/abs/2512.19769v1
- PDF：https://arxiv.org/pdf/2512.19769v1

**中文摘要**

构建可部署的基于大模型的代理需要对工具、数据源和控制流逻辑进行复杂的编排，而现有系统通常将代理逻辑与特定编程语言和部署模型紧耦合。我们提出一种声明式系统，将代理工作流的规格从实现中分离，使得相同的管道定义可以在多种后端语言（Java、Python、Go）和部署环境（云原生、本地）上运行。我们的核心见解是大多数代理工作流由一些常见模式组成——数据序列化、过滤、基于检索的生成（RAG）检索、API编排——这些都可以通过统一的领域专用语言（DSL）来表达，而非命令式代码。这一方法将代理开发从应用编程转变为配置：新增工具或微调代理行为仅需修改管道规格，而无需重新部署代码。系统原生支持代理策略的A/B测试，允许在相同后端基础设施上运行多个管道变体，并自动收集与比较指标。我们在PayPal的真实电商工作流上评估了该方法，处理每天数百万次交互。结果表明，与命令式实现相比，开发时间减少了60%，部署速度提高了3倍。该语言的声明式方法使非工程人员也能安全地修改代理行为，同时保持低于100ms的编排开销。我们还展示了复杂工作流（包括商品检索、个性化和购物车管理）可以用不到50行DSL代码表达，而相应的命令式实现通常超过500行。

---
## 70. From Theory to Throughput: CUDA-Optimized APML for Large-Batch 3D Learning

- 作者：Sasan Sharifipour, Constantino Álvarez Casado, Manuel Lage Cañellas, Miguel Bordallo López
- 子主题：CV（3D 点云学习）
- 推荐：很推荐
- 关键词：点云损失函数, 稀疏 GPU 实现, Sinkhorn 最优传输
- Abstract：http://arxiv.org/abs/2512.19743v1
- PDF：https://arxiv.org/pdf/2512.19743v1

**中文摘要**

损失函数对于学习准确的三维点云模型至关重要，但常用的选择在几何保真度与计算成本之间存在权衡。Chamfer 距离计算高效但允许多对一的对应，Earth Mover 距离更能反映一对一的传输但计算代价高昂。APML 通过可微的 Sinkhorn 迭代和解析导出的温度参数来近似传输，但其稠密形式在内存上呈二次增长。我们提出了 CUDA-APML，一种稀疏的 GPU 实现：通过阈值化去除可忽略的分配，并直接在 COO 格式上运行自适应 softmax、双向对称化和 Sinkhorn 归一化。该方法在保存已存储支持集梯度的同时，获得近线性的内存伸缩性；当前实现中，成对距离的计算仍为二次复杂度。在 ShapeNet 和 MM-Fi 数据集上，CUDA-APML 在小容差范围内重现了稠密 APML 的结果，同时将峰值 GPU 内存降低了 99.9%。代码已开源： https://github.com/Multimodal-Sensing-Lab/apml

---
## 71. Tiny, On-Device Decision Makers with the MiniConv Library

- 作者：Carlos Purves
- 子主题：RL
- 推荐：很推荐
- 关键词：边缘设备推理, 分割策略（split-policy）, 视觉强化学习
- Abstract：http://arxiv.org/abs/2512.19726v1
- PDF：https://arxiv.org/pdf/2512.19726v1

**中文摘要**

强化学习（RL）已在许多任务上取得显著成果，但在资源受限的边缘设备上部署视觉策略仍面临计算开销和通信延迟的挑战。很多部署因此将策略推理下发到远程服务器，导致网络往返延迟并需要传输高维观测数据。本文提出了一种拆分策略（split-policy）体系结构：在设备端运行一个小型编码器（通过 OpenGL 片段着色器实现，以便广泛支持嵌入式 GPU），将每帧观测压缩为紧凑的特征张量并传输给远程的策略头进行决策。在强化学习闭环中，这种通信开销表现为决策延迟，而不仅仅是单次推理延迟。所提出的方法在带宽受限场景下显著减少了传输数据量、降低了决策延迟并减少了服务器端的每次计算开销，同时在单次运行的基准测试中以最终回报（最后100集的均值）实现了大致可比的学习性能，仅在平均回报上有适度的权衡。我们在 NVIDIA Jetson Nano、Raspberry Pi 4B 和 Raspberry Pi Zero 2 W 上进行了评估，报告了学习效果、设备在持续负载下的执行表现以及在带宽限速下的端到端决策延迟和可扩展性测量。训练、部署和测量的代码已作为开源项目发布。

---
## 72. Multiscale Dual-path Feature Aggregation Network for Remaining Useful Life Prediction of Lithium-Ion Batteries

- 作者：Zihao Lv, Siqi Ai, Yanbin Zhang
- 子主题：时序预测/预测维护
- 推荐：很推荐
- 关键词：剩余寿命预测(RUL), 多尺度特征学习, 电池退化预测
- Abstract：http://arxiv.org/abs/2512.19719v1
- PDF：https://arxiv.org/pdf/2512.19719v1

**中文摘要**

针对性维护策略对于保证工业设备的可靠性和安全性至关重要。然而，现有用于评估电池退化序列的局部与全局相关性的建模方法效率较低，难以满足实际应用需求。为此，我们提出了一种新型深度学习架构——多尺度双路特征聚合网络（MDFA-Net）用于剩余寿命（RUL）预测。MDFA-Net 由双路网络组成：第一路为多尺度特征网络（MF-Net），用于保持浅层信息并避免信息丢失；第二路为编码器网络（EC-Net），用于捕捉序列的连续趋势并保留深层细节。通过融合深层与浅层特征，MDFA-Net 能有效把握局部与全局模式。在两个公开的锂离子电池数据集上的测试表明，本方法在 RUL 预测方面优于现有顶级方法，能够更准确地拟合容量衰减轨迹。

---
## 73. Bidirectional human-AI collaboration in brain tumour assessments improves both expert human and AI agent performance

- 作者：James K Ruffle, Samia Mohinta, Guilherme Pombo, Asthik Biswas, Alan Campbell, Indran Davagnanam, David Doig, Ahmed Hamman, Harpreet Hyare, Farrah Jabeen, Emma Lim, Dermot Mallon, Stephanie Owen, Sophie Wilkinson, Sebastian Brandner, Parashkev Nachev
- 子主题：CV
- 推荐：很推荐
- 关键词：人机协作, 脑肿瘤 MRI, 医学影像分析
- Abstract：http://arxiv.org/abs/2512.19707v1
- PDF：https://arxiv.org/pdf/2512.19707v1

**中文摘要**

人工智能（AI）与人类协作——即评估 AI 代理如何增强专家人类表现——的益处正越来越受到研究关注。在医疗领域很少被评估的情况下，也存在一种相反的方法：AI 从专家人类代理的支持中受益。本文研究了两种人机临床协作范式在基于磁共振成像（MRI）的脑肿瘤患者表征中的应用。我们发现，人机协作不仅能提升由 AI 支持的放射科医生的准确性和元认知能力，也能提升由放射科医生支持的 AI 代理的表现。此外，患者获益最大体现在“由人类支持的 AI 代理”这一组合。代理之间在准确性、元认知表现和评估者间一致性上的协同改进表明，无论是人类还是基于模型的代理，AI 都能创造出更有能力、更自信且更一致的临床代理。我们的研究表明，AI 在医疗中的最大价值可能并非替代人类智能，而是通过常规性地利用并放大人类智能来实现。

---
## 74. Toward Explaining Large Language Models in Software Engineering Tasks

- 作者：Antonio Vitale, Khai-Nguyen Nguyen, Denys Poshyvanyk, Rocco Oliveto, Simone Scalabrino, Antonio Mastropaolo
- 子主题：LLM
- 推荐：很推荐
- 关键词：可解释性, Shapley值, 软件工程（代码生成/摘要）
- Abstract：http://arxiv.org/abs/2512.20328v1
- PDF：https://arxiv.org/pdf/2512.20328v1

**中文摘要**

近期大型语言模型（LLM）的进展显著推动了软件工程（SE）任务的自动化，能够执行代码生成和代码摘要等复杂活动。然而，LLM 的黑箱特性仍然是其在高风险与安全关键领域广泛应用的主要障碍，因为可解释性与透明性对于信任、问责和有效的人类监督至关重要。尽管可解释性人工智能在软件工程领域的兴趣不断增加，现有方法仍缺乏与从业者对软件工程工件推理方式相契合的领域特定解释。为填补这一空白，我们提出了 FeatureSHAP，这是首个针对软件工程任务的、完全自动化且与模型无关的可解释性框架。FeatureSHAP 基于 Shapley 值，通过系统化的输入扰动和任务特定的相似性比较，将模型输出归因于高层次的输入特征，同时兼容开源与专有的 LLM。我们在两类双模态软件工程任务（代码生成与代码摘要）上评估了 FeatureSHAP。结果表明，FeatureSHAP 对无关输入特征赋予更低的重要性，并生成比基线方法具有更高保真度的解释。对 37 名从业者进行的调查显示，FeatureSHAP 有助于从业者更好地理解模型输出并做出更明智的决定。总体而言，FeatureSHAP 代表了面向软件工程的实用可解释 AI 的重要进展。FeatureSHAP 的实现可在 https://github.com/deviserlab/FeatureSHAP 获取。

---
## 75. KnowVal: A Knowledge-Augmented and Value-Guided Autonomous Driving System

- 作者：Zhongyu Xia, Wenhao Chen, Yongtao Wang, Ming-Hsuan Yang
- 子主题：自动驾驶（知识增强 + LLM）
- 推荐：很推荐
- 关键词：知识图谱, 价值对齐, 视觉-语言推理
- Abstract：http://arxiv.org/abs/2512.20299v1
- PDF：https://arxiv.org/pdf/2512.20299v1

**中文摘要**

视觉-语言推理、驾驶知识与价值对齐对于先进的自动驾驶系统至关重要。然而，现有方法主要依赖数据驱动的学习，难以通过模仿或受限的强化奖励捕捉决策过程中复杂的逻辑规则。为此，我们提出了KnowVal，一种通过开放世界感知与知识检索协同实现视觉-语言推理的自动驾驶系统。具体地，我们构建了一个全面的驾驶知识图谱，编码交通法规、防御性驾驶原则与伦理规范，并设计了针对驾驶场景高效的基于大模型的检索机制。此外，我们构建了一个人工偏好数据集并训练了一个价值模型，用以指导可解释且与价值对齐的轨迹评估。实验结果表明，该方法显著提升了规划性能且兼容现有架构，尤其在nuScenes上实现了最低碰撞率，并在Bench2Drive上达到了最先进的结果。

---
## 76. Retrieval-augmented Prompt Learning for Pre-trained Foundation Models

- 作者：Xiang Chen, Yixin Ou, Quan Feng, Lei Li, Piji Li, Haibo Ye, Sheng-Jun Huang, Shuofei Qiao, Shumin Deng, Huajun Chen, Ningyu Zhang
- 子主题：LLM
- 推荐：很推荐
- 关键词：检索增强提示学习, 预训练基础模型, 少样本泛化
- Abstract：http://arxiv.org/abs/2512.20145v1
- PDF：https://arxiv.org/pdf/2512.20145v1

**中文摘要**

预训练基础模型（PFMs）已成为推动大规模多模态学习的关键。研究者通过提示学习采用“预训练—提示—预测”范式，显著提升了少样本性能。然而，针对PFMs的提示学习仍沿用参数化学习范式，因此在记忆与死记硬背之间的泛化稳定性可能受到影响。更具体地，传统提示学习在全监督训练中可能难以充分利用异常样本，并容易在数据有限时对浅层模式产生过拟合。为克服这些限制，我们提出了RetroPrompt方法，旨在通过将知识从单纯记忆中解耦，平衡记忆与泛化能力。与传统提示方法不同，RetroPrompt利用从训练数据构建的公开知识库，并在输入、训练和推理阶段引入检索机制，使模型能够主动从语料中检索相关上下文信息以增强提示线索。我们在多个自然语言处理和计算机视觉数据集上进行了全面实验，证明了RetroPrompt在零样本和少样本情形下的优越性能。通过对记忆模式的详细分析，我们观察到RetroPrompt有效减少了对死记硬背的依赖，从而提升了泛化能力。

---
## 77. Evasion-Resilient Detection of DNS-over-HTTPS Data Exfiltration: A Practical Evaluation and Toolkit

- 作者：Adam Elaoumari
- 子主题：网络安全 (流量分析与检测)
- 推荐：很推荐
- 关键词：DNS-over-HTTPS (DoH), 数据外泄检测, 对抗性规避
- Abstract：http://arxiv.org/abs/2512.20423v1
- PDF：https://arxiv.org/pdf/2512.20423v1

**中文摘要**

本项目旨在评估防御方检测基于 DNS-over-HTTPS (DoH) 的文件外泄的能力，以及攻击者可采用的规避策略。我们提供了一个可复现的工具包，用于生成、拦截与分析 DoH 外泄流量，并在对抗性场景下比较机器学习与基于阈值的检测方法。本项目的创新之处在于提出了一个端到端的容器化流水线，该流水线可配置地通过 DoH 实施文件外泄（支持分片、编码、填充、解析器轮换等参数），并允许在解析器端重构文件，同时利用 DoHLyzer 的衍生版本提取流级特征。流水线包含预测模块，可基于公开标注数据集训练机器学习模型，并将其与阈值检测方法在恶意及规避性 DoH 流量上并列评估。我们在公开的 DoH 数据集上训练了随机森林、梯度提升和逻辑回归分类器，并在多种规避外泄场景中对其进行了基准测试。该工具包协调流量生成、文件捕获、特征提取、模型训练与分析，并封装为若干 Docker 容器以便跨平台易于部署与完全复现。未来工作包括在混合企业流量中验证结果、扩展至 HTTP/3/QUIC 请求、加入良性流量生成以及实现实时流量评估。一个关键目标是量化在何种隐蔽性约束下，DoH 外泄对于攻击者变得不经济或不可取。

---
## 78. Simplifying Multi-Task Architectures Through Task-Specific Normalization

- 作者：Mihai Suteu, Ovidiu Serban
- 子主题：CV (Multi-Task Learning)
- 推荐：很推荐
- 关键词：多任务学习, 任务特定归一化, 可解释性/参数效率
- Abstract：http://arxiv.org/abs/2512.20420v1
- PDF：https://arxiv.org/pdf/2512.20420v1

**中文摘要**

多任务学习（MTL）旨在利用任务间的共享知识以提升泛化能力并提高参数效率，但如何在资源分配与减少任务间干扰之间取得平衡仍是未解决的问题。现有的架构性解决方案通常通过引入复杂的任务专用模块或路由机制来缓解干扰，但这也带来了实现复杂度和计算开销的增加。本文展示了仅通过归一化层就能应对许多此类挑战：将共享归一化替换为任务专用的变体即可取得具有竞争力的性能，从而质疑复杂设计的必要性。在此基础上，我们提出了一种轻量级机制——任务特定Sigmoid批量归一化（TSσBN），它允许在完全共享特征提取器的同时，使各任务软性地分配网络容量。TSσBN在CNN和Transformer上均提升了训练稳定性，并在NYUv2、Cityscapes、CelebA和PascalContext等数据集上达到或超越基线性能，同时保持高度的参数效率。此外，其学习到的门控机制为分析多任务学习动态提供了自然的框架，可解释性地揭示容量分配、滤波器专门化和任务间关系。我们的研究结果表明，复杂的多任务架构可能并非必需，任务特定归一化提供了一种简单、可解释且高效的替代方案。

---
## 79. Scaling Reinforcement Learning for Content Moderation with Large Language Models

- 作者：Hamed Firooz, Rui Liu, Yuchen Lu, Zhenyu Hou, Fangzhou Xiong, Xiaoyang Zhang, Changshu Jian, Zhicheng Zhu, Jiayuan Ma, Jacob Tao, Chaitali Gupta, Xiaochang Peng, Shike Mei, Hang Cui, Yang Qin, Shuo Tang, Jason Gaedtke, Arpit Mittal
- 子主题：RL
- 推荐：很推荐
- 关键词：内容审核, 强化学习, 大规模语言模型
- Abstract：http://arxiv.org/abs/2512.20061v1
- PDF：https://arxiv.org/pdf/2512.20061v1

**中文摘要**

在当前数字生态中，大规模内容审核仍然是最紧迫的挑战之一，需要对数十亿条用户与AI生成的内容持续评估是否违反政策。尽管大规模语言模型（LLM）在基于政策的审核方面展现了强大潜力，但在现实场景中将这些系统训练到专家级准确性仍面临诸多实际困难，尤其是在标签稀缺、政策定义不断演变以及需要超越浅层模式匹配的细粒度推理的情形下。本文对将强化学习（RL）扩展用于内容分类进行了全面的实证研究，系统评估了多种RL训练配方与奖励塑形策略——包括可验证奖励和“LLM作为裁判”的框架——以将通用语言模型转化为在策略上对齐的专业分类器，并在三个真实世界的内容审核任务上进行了验证。我们的研究结果为工业级审核系统提供了可操作的见解：RL呈现出类似S形的扩展行为，随训练数据量、rollout规模和优化步数的增加性能平滑提升并逐步趋于饱和；此外，RL在需要复杂政策驱动推理的任务上显著提升了性能，并在数据效率方面相比监督微调最高可达100倍，使其在专家标注稀缺或昂贵的领域尤为有效。

---
## 80. An Optimal Policy for Learning Controllable Dynamics by Exploration

- 作者：Peter N. Loxley
- 子主题：强化学习 (RL)
- 推荐：很推荐
- 关键词：可控马尔可夫链, 探索与信息增益, 非平稳最优策略
- Abstract：http://arxiv.org/abs/2512.20053v1
- PDF：https://arxiv.org/pdf/2512.20053v1

**中文摘要**

可控马尔可夫链刻画了序贯决策任务的动力学，是最优控制与强化学习的核心组成部分。本文给出了在有限时间视界内通过探索学习未知环境中可控动力学的最优策略的一般形式。该策略实现简单、计算高效，允许智能体以贪婪方式最大化信息增益来“通过探索学习”，其控制动作从一个随时间在探索过程中变化的约束集合中选择。我们为该控制集合给出了一种简洁的参数化，并提出了求解最优策略的算法。之所以需要这样的策略，是由于某些类型的状态会限制对动力学的控制，例如瞬态状态、吸收态和不可回溯状态。我们论证了这些状态的存在使得非平稳策略对于实现最优探索是必不可少的。论文详细讨论了六个有趣的可控动力学示例，并通过计数论证、与次优策略比较以及利用动态规划的序列改进性质来证明策略的最优性。

---
## 81. Bring My Cup! Personalizing Vision-Language-Action Models with Visual Attentive Prompting

- 作者：Sangoh Lee, Sangwoo Mo, Wook-Shin Han
- 子主题：VLA (视觉-语言-动作)
- 推荐：很推荐
- 关键词：视觉-语言-动作, 个性化物体识别, 视觉注意提示
- Abstract：http://arxiv.org/abs/2512.20014v1
- PDF：https://arxiv.org/pdf/2512.20014v1

**中文摘要**

尽管视觉-语言-动作（VLA）模型在处理通用指令时具有良好泛化能力，但在处理“把我的杯子拿来”这类需要辨识特定实例的个性化指令时表现欠佳——机器人必须在视觉上相似的物体中选中并操作某一用户特定实例。我们研究了操控个人物品这一场景，其中VLA需仅凭少量参考图像识别并控制训练时未见过的用户指定对象。为了解决此挑战，我们提出了Visual Attentive Prompting（VAP），一种简单且有效的免训练感知适配器，为冻结的VLA模型提供自上而下的选择性注意能力。VAP将参考图像视为非参数化的视觉记忆，通过开放词汇检测和基于嵌入的匹配在场景中定位个人物体，然后通过高亮目标并重写指令的方式将该定位注入为视觉提示。我们构建了两个仿真基准（Personalized-SIMPLER 和 Personalized-VLABench）以及一个真实桌面基准，用以在多种机器人和任务上评估个性化操作。实验结果表明，VAP在成功率和正确物体操作方面均显著优于通用策略和基于token学习的基线，帮助弥合语义理解与实例级控制之间的差距。

---
## 82. FGDCC: Fine-Grained Deep Cluster Categorization -- A Framework for Intra-Class Variability Problems in Plant Classification

- 作者：Luciano Araujo Dourado Filho, Rodrigo Tripodi Calumby
- 子主题：CV
- 推荐：很推荐
- 关键词：类内变异, 细粒度视觉分类, 类别内聚类与伪标签
- Abstract：http://arxiv.org/abs/2512.19960v1
- PDF：https://arxiv.org/pdf/2512.19960v1

**中文摘要**

类内变异指的是同一类中图像之间不相似程度的显著性。根据其强度，类内变异会妨碍深度学习模型的学习过程，特别是在这些类别样本本就稀少的情况下——这在细粒度视觉分类（FGVC）任务中非常常见。本文提出了一种新方法，旨在通过对类内簇分配进行分类来学习细粒度特征，从而提升FGVC任务的分类性能。我们的目标是对每个类别单独进行聚类，以发现编码图像间潜在相似度程度的伪标签。随后，这些伪标签可用于分层分类流程，从而学习更细粒度的视觉特征并减轻类内变异问题。在PlantNet300k数据集上的初步实验揭示了若干关键点，指出未来需进一步开展的工作以获得更具决定性的有效性证据。尽管方法的某些组件尚未完全优化，我们的方法在PlantNet300k上仍取得了当前最先进的性能。我们的代码已开源，地址为 https://github.com/ADAM-UEFS/FGDCC。

---
## 83. Zero-Shot Segmentation through Prototype-Guidance for Multi-Label Plant Species Identification

- 作者：Luciano Araujo Dourado Filho, Almir Moreira da Silva Neto, Rodrigo Pereira David, Rodrigo Tripodi Calumby
- 子主题：CV
- 推荐：很推荐
- 关键词：原型引导, 零样本分割, 多标签植物识别
- Abstract：http://arxiv.org/abs/2512.19957v1
- PDF：https://arxiv.org/pdf/2512.19957v1

**中文摘要**

本文提出了一种为应对 PlantClef 2025 挑战而设计的方法，该挑战目标是在高分辨率图像上进行细粒度多标签物种识别。我们的方案利用来自训练集的类别原型作为代理引导，在测试图像上训练一个分割型 Vision Transformer（ViT）。为获取这些原型表示，方法先从训练集图像中提取特征，并通过 K-Means 聚类（K 等于数据集类别数）生成类簇。分割模型为定制的窄型 ViT，通过用在训练集上进行单物种分类预训练的冻结 DinoV2 替换 patch embedding 层构建。此模型被训练以从测试图像重构训练集的类别原型，并利用得到的注意力得分识别和定位感兴趣区域，从而辅助分类过程。该方法实现了从单类识别向高分辨率植被图像的多标签分类的域适配。在 PlantCLEF 2025 私有排行榜上，我们的方法以 F1 分数 0.33331 获得第五名；与最优提交相比仅低约 0.03，表明在该基准任务上具有竞争力。我们的代码已开源：https://github.com/ADAM-UEFS/PlantCLEF2025。

---
## 84. How Much 3D Do Video Foundation Models Encode?

- 作者：Zixuan Huang, Xiang Li, Zhaoyang Lv, James M. Rehg
- 子主题：CV (视频与3D理解)
- 推荐：很推荐
- 关键词：视频基础模型, 3D理解, 模型无关评估
- Abstract：http://arxiv.org/abs/2512.19949v1
- PDF：https://arxiv.org/pdf/2512.19949v1

**中文摘要**

视频是三维世界在二维平面上的连续投影。在在大量视频数据上训练后，模型是否会自然而然地形成全局的三维理解？本文通过量化现有在海量视频上预训练的视频基础模型（VidFMs）对三维信息的理解来研究这一问题。我们提出了第一个与模型无关的评估框架，通过对各类VidFM的特征进行浅层读出（shallow read-outs）来估计多种三维属性，从而衡量其三维感知能力。研究在多维度上揭示了VidFMs的三维认知特性。具体而言，我们发现最先进的视频生成模型尽管未接受任何三维数据的训练，仍能展现出对三维物体与场景的强烈理解，这种能力甚至在某些任务上超过了为三维任务专门训练的大型专家模型。我们的发现连同对主要VidFMs的三维基准评测，为构建可扩展的三维模型提供了有价值的观察和参考。

---
## 85. Vehicle-centric Perception via Multimodal Structured Pre-training

- 作者：Wentao Wu, Xiao Wang, Chenglong Li, Jin Tang, Bin Luo
- 子主题：CV
- 推荐：很推荐
- 关键词：车辆感知, 多模态结构化预训练, 掩码重建
- Abstract：http://arxiv.org/abs/2512.19934v1
- PDF：https://arxiv.org/pdf/2512.19934v1

**中文摘要**

车辆中心感知在大规模监控、智能交通和自动驾驶等智能系统中具有关键作用。现有方法在预训练阶段缺乏有效的车辆相关知识学习，导致无法建立通用的车辆感知表示。为此，我们提出了 VehicleMAE-V2，一种新颖的面向车辆的预训练大模型。通过探索并利用车辆相关的多模态结构化先验来引导掩码令牌的重建过程，该方法显著提升了模型学习可泛化车辆感知表示的能力。具体而言，我们设计了对称性引导掩码模块（SMM）、轮廓引导表示模块（CRM）和语义引导表示模块（SRM），将车辆的对称性、轮廓和语义三类结构化先验分别融入令牌重建：SMM 利用车辆对称性约束避免保留对称补丁，从而选择高质量的掩码图像补丁并减少信息冗余；CRM 通过最小化轮廓特征与重建特征之间的概率分布差异，在像素级重建过程中保持整体车辆结构信息；SRM 则通过对比学习与跨模态蒸馏对齐图像-文本特征，以解决掩码重建期间因语义理解不足导致的特征混淆。为支持 VehicleMAE-V2 的预训练，我们构建了 Autobot4M 数据集，包含约 400 万张车辆图像及 12,693 条文本描述。大量下游任务实验（五项任务）验证了 VehicleMAE-V2 的优越性能。

---
## 86. Modeling Non-Ergodic Path Effects Using Conditional Generative Model for Fourier Amplitude Spectra

- 作者：Maxime Lacour, Pu Ren, Rie Nakata, Nori Nakata, Michael Mahoney
- 子主题：生成模型 (Conditional VAE) / 地理空间地震信号建模
- 推荐：很推荐
- 关键词：非遍历地面运动模型, 条件变分自编码器, 傅里叶振幅谱
- Abstract：http://arxiv.org/abs/2512.19909v1
- PDF：https://arxiv.org/pdf/2512.19909v1

**中文摘要**

近期非遍历地面运动模型（GMM）研究通过显式建立震源、场址和传播路径效应的系统性空间变异，将基于遍历假设模型的标准差降低到30%–40%，从而能够进行更准确的场址特定地震危险性分析。现有的非遍历GMM多依赖具有预设相关函数的高斯过程（GP）方法，因此在大规模预测时存在计算瓶颈。本研究提出了一种基于深度学习的替代方法：用于傅里叶振幅谱（FAS）的条件生成建模（CGM-FAS）。CGM-FAS采用条件变分自编码器（Conditional VAE）架构，通过将地震和台站的地理坐标作为条件变量，直接从数据中学习空间模式及频率间相关性。基于旧金山湾区地震数据，我们将CGM-FAS与该区域的近期GP基GMM进行了对比，结果表明CGM-FAS在非遍历路径效应的预测上与GP模型一致。与GP方法相比，CGM-FAS的优势包括：无需预先设定相关函数即可学习空间结构、能够捕捉频率间相关性，并显著加快预测速度——在仅使用几GB内存的情况下，可在约10秒内为1万个站点生成1000个频率点的路径效应分布图。通过调节超参数，CGM-FAS生成的路径效应变异性可与基于GP的经验GMM保持一致。本工作展示了在多频率和大空间域上实现高效非遍历地面运动预测的一条有前景的方向。

---
## 87. Demystifying LLM-as-a-Judge: Analytically Tractable Model for Inference-Time Scaling

- 作者：Indranil Halder, Cengiz Pehlevan
- 子主题：LLM
- 推荐：很推荐
- 关键词：推理时间扩展, 贝叶斯线性回归, 泛化误差/best-of-k
- Abstract：http://arxiv.org/abs/2512.19905v1
- PDF：https://arxiv.org/pdf/2512.19905v1

**中文摘要**

近期大型语言模型的发展显示，将一部分计算资源从训练时间重新分配到推理时间可以带来优势，但推理时间扩展背后的原理尚不清楚。本文提出了一个可解析的推理时间扩展模型：带有奖励加权采样器的贝叶斯线性回归，其中奖励由线性模型决定，以模拟“LLM作为裁判”的场景。我们在高维区域研究该问题，利用确定性等价导出后验预测均值和方差的闭式表达。我们分析了当训练数据由一个教师模型生成时的泛化误差，考虑在推理时抽取k个样本并通过对一个基于二次奖励的温度化softmax进行选择。若奖励与教师模型相差不大，泛化误差随推理样本数k单调下降；然而使推理选择最优的奖励通常不同于教师模型。严重的奖励错设会导致存在一个有限的最优k，超过该k更多采样反而会增加泛化误差。对于固定的k，还存在一个最优的采样温度。我们在大型语言模型推理场景中以另一个大型语言模型作为裁判进行了实证验证。在以教师奖励的“best-of-k”极限下，我们理论上证明泛化误差以Θ(1/k^2)衰减，并通过极值理论确定领先系数。所给公式刻画了在何种情形下将计算资源用于扩展推理时间优于收集更多训练数据的领域。最后我们还展示了随着任务难度增加，推理时间计算带来的优势会减弱。

---
## 88. ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language

- 作者：Aly Lidayan, Jakob Bjorner, Satvik Golechha, Kartik Goyal, Alane Suhr
- 子主题：LLM
- 推荐：很推荐
- 关键词：信念瓶颈, LLM 代理, 强化学习微调
- Abstract：http://arxiv.org/abs/2512.20111v1
- PDF：https://arxiv.org/pdf/2512.20111v1

**中文摘要**

随着序列决策任务长度的增加，将完整的交互历史一直保留在上下文中在计算上变得不可行。我们提出了一个通用框架，使得大型语言模型（LLM）代理能够通过多步交互维护简洁的上下文：以语言表达的信念瓶颈（ABBEL），并介绍了使用强化学习后训练进一步提升 ABBEL 代理的方法。ABBEL 用一个信念状态替代冗长的多步交互历史——即关于任务相关未知量的自然语言摘要。在 ABBEL 下，代理在每一步先用来自环境的最新观测更新先验信念以形成后验信念，然后仅基于该后验信念选择动作。我们在六个多步环境上系统性地评估了前沿模型在 ABBEL 下的表现，发现 ABBEL 在保持近乎恒定的内存使用的同时，能够生成可解释的信念表述。然而，瓶颈方法普遍易受错误传播影响：由于信念更新中的错误，性能常常劣于使用完整上下文的设置。为此，我们在 ABBEL 框架内通过强化学习训练 LLM 来生成并基于信念进行决策。我们尝试了信念评分（对更高质量的信念给予奖励）以及信念长度惩罚（鼓励更压缩的信念）。实验表明，强化学习能够在使用比同期方法更少内存的前提下，将 ABBEL 的性能提升到超过完整上下文设置的水平。

---
## 89. CBA: Communication-Bound-Aware Cross-Domain Resource Assignment for Pipeline-Parallel Distributed LLM Training in Dynamic Multi-DC Optical Networks

- 作者：Dianxuan Fu, Xiaomin Liu, Yihao Zhang, Shikui Shen, Weisheng Hu, Qunbi Zhuge
- 子主题：LLM
- 推荐：很推荐
- 关键词：通信瓶颈感知, 跨域资源分配, 流水线并行训练
- Abstract：http://arxiv.org/abs/2512.20080v1
- PDF：https://arxiv.org/pdf/2512.20080v1

**中文摘要**

我们提出了一种通信瓶颈感知的跨域资源分配框架，用于动态多数据中心光网络环境下的流水线并行分布式训练。该框架在分配跨域计算与网络资源时显式考虑通信受限（communication-bound）条件，以减轻通信延迟和带宽限制对流水线并行训练性能的影响。实验结果表明，与基线方法相比，该方案将训练迭代时间降低了31.25%，并将阻塞请求减少了13.20%。

---
## 90. Learning Skills from Action-Free Videos

- 作者：Hung-Chieh Fang, Kuo-Han Hung, Chu-Rong Chen, Po-Jung Chou, Chun-Kai Yang, Po-Chen Ko, Yu-Chiang Wang, Yueh-Hua Wu, Min-Hung Chen, Shao-Hua Sun
- 子主题：RL (机器人视觉技能学习)
- 推荐：很推荐
- 关键词：光流, 潜在技能空间, 无动作视频学习
- Abstract：http://arxiv.org/abs/2512.20052v1
- PDF：https://arxiv.org/pdf/2512.20052v1

**中文摘要**

从视频中学习为通用机器人提供了一条有前景的路径，因为视频提供了比真实机器人数据集更丰富的视觉与时间先验。尽管现有的视频生成模型在视觉预测方面表现出色，但它们难以转化为低层次的动作信号；相反，潜在动作模型更容易将视频与动作对齐，但通常仅在单步层面工作且缺乏高层规划能力。为弥合这一差距，我们提出了基于光流的技能抽象（Skill Abstraction from Optical Flow，SOF）框架，从大量无动作视频中学习潜在技能。我们的核心思想是通过基于光流的中间表示来学习潜在技能空间，该表示能捕捉与视频动力学和机器人动作对齐的运动信息。通过在这种基于光流的潜在空间中学习技能，SOF使得基于视频提取技能的高层规划成为可能，并更容易将这些技能转译为具体动作。实验表明，我们的方法在多任务和长航时（long-horizon）设置下均能持续提升性能，展示了直接从原始视觉数据中获取并组合技能的能力。

---
## 91. Leveraging High-Fidelity Digital Models and Reinforcement Learning for Mission Engineering: A Case Study of Aerial Firefighting Under Perfect Information

- 作者：İbrahim Oğuz Çetinkaya, Sajad Khodadadian, Taylan G. Topçu
- 子主题：强化学习 / 任务工程（数字工程）
- 推荐：很推荐
- 关键词：任务工程, 强化学习（PPO）, 高保真数字仿真
- Abstract：http://arxiv.org/abs/2512.20589v1
- PDF：https://arxiv.org/pdf/2512.20589v1

**中文摘要**

随着系统工程（SE）目标从单体系统的设计与运行转向复杂的系统群（System of Systems，SoS），任务工程（Mission Engineering，ME）作为一种新的思路在SE界逐渐被接受。任务环境通常具有不确定性和动态性，且任务结果直接取决于任务资产与环境的交互，这使得静态架构显得脆弱，需要更具分析性的ME方法。为此，本文提出了一种融合数字任务模型与强化学习（RL）的智能任务协调方法，专门应对自适应任务分配与重构的需求。具体而言，我们构建了基于数字工程（DE）的基础设施，包含高保真数字任务模型与基于主体的仿真，并将任务战术管理问题建模为马尔可夫决策过程（MDP），采用基于近端策略优化（PPO）的强化学习代理进行训练。通过将仿真作为沙箱环境，我们将系统状态映射到动作，并根据实际任务结果迭代优化策略。在航空灭火的案例研究中，所提出的RL智能任务协调器不仅优于基线方法，而且显著降低了任务绩效的波动性。本研究作为概念验证表明，基于DE的任务仿真结合先进分析工具，可以提供一种与特定任务无关的框架以改进ME实践，并可在未来从任务优先的角度扩展到更复杂的舰队设计与选择问题。

---
## 92. A K-Means, Ward and DBSCAN repeatability study

- 作者：Anthony Bertrand, Engelbert Mephu Nguifo, Violaine Antoine, David Hill
- 子主题：聚类/无监督学习
- 推荐：很推荐
- 关键词：可重复性, 聚类算法, K-Means 多线程问题
- Abstract：http://arxiv.org/abs/2512.19772v1
- PDF：https://arxiv.org/pdf/2512.19772v1

**中文摘要**

可重复性在机器学习中至关重要，因为它确保模型或实验得出相同的科学结论。对于特定算法而言，实现逐位相同（bitwise identical）的重复性也是科学诚信的关键，因为这有助于调试。我们将几种非常流行的聚类算法——K-Means、DBSCAN 和 Ward——分解为其基本步骤，并识别在每个阶段实现可重复性所需的条件。我们以 Python 库 scikit-learn 的实现为示例，检查每种方法的可重复性特点。结果显示，当 OpenMP 线程数超过两个时，K-Means 会产生不一致的结果。该工作旨在提高用户和开发者对该问题的认识，鼓励进一步调查并推动潜在的修复。

---
## 93. Attention Distance: A Novel Metric for Directed Fuzzing with Large Language Models

- 作者：Wang Bin, Ao Yang, Kedan Li, Aofan Liu, Hui Li, Guibo Luo, Weixiang Huang, Yan Zhuang
- 子主题：LLM（软件安全/模糊测试）
- 推荐：很推荐
- 关键词：注意力距离, 定向灰盒模糊测试, 大语言模型
- Abstract：http://arxiv.org/abs/2512.19758v1
- PDF：https://arxiv.org/pdf/2512.19758v1

**中文摘要**

在软件安全测试领域，定向灰盒模糊测试（Directed Grey-Box Fuzzing, DGF）因其高效的目标定位和良好的检测性能而备受关注。然而，现有方法仅衡量种子执行路径与目标位置之间的物理距离，忽视了代码片段之间的逻辑关系；在复杂二进制程序中，这种忽略可能导致冗余或误导性的引导，从而削弱DGF在实际场景中的效果。为此，我们提出了“注意力距离”（attention distance），这是一种新颖的度量指标，利用大语言模型的上下文分析能力计算代码元素之间的注意力得分，从而揭示它们的内在关联。在不改变任何模糊测试组件、仅替换距离度量的相同AFLGo配置下，将物理距离替换为注意力距离，在38个真实漏洞复现实验中平均带来了3.43倍的测试效率提升。与最先进的定向模糊器DAFL和WindRanger相比，我们的方法分别取得了2.89倍和7.13倍的改进。为了进一步验证注意力距离的泛化性，我们将其集成到DAFL和WindRanger中，结果也持续提升了它们的原始性能。所有相关代码和数据集已公开，见：https://github.com/TheBinKing/Attention_Distance.git。

---
## 94. Simulation-Driven Railway Delay Prediction: An Imitation Learning Approach

- 作者：Clément Elliker, Jesse Read, Sonia Vanier, Albert Bifet
- 子主题：RL
- 推荐：很推荐
- 关键词：模仿学习, 铁路延误预测, 漂移校正(DCIL)
- Abstract：http://arxiv.org/abs/2512.19737v1
- PDF：https://arxiv.org/pdf/2512.19737v1

**中文摘要**

可靠的列车延误预测对于提升铁路运输系统的稳健性与效率至关重要。本文将延误预测重新表述为一个随机仿真任务，通过模仿学习来建模状态转移动力学。我们提出了漂移修正模仿学习（Drift-Corrected Imitation Learning, DCIL），这是一种新的自监督算法，通过引入基于距离的漂移校正扩展了DAgger，从而在滚动预测过程中缓解协变量偏移问题，并且无需依赖外部专家或对抗性方案。该方法综合了事件驱动模型的动力学保真性与数据驱动方法的表示能力，并通过蒙特卡洛仿真实现不确定性感知的预测。我们在比利时铁路基础设施管理机构Infrabel提供的真实数据集上评估了DCIL，该数据集包含超过三百万次列车运行记录。针对最长30分钟的预测任务，实验结果表明DCIL在预测性能上优于传统回归模型和基于深度学习架构的行为克隆方法，凸显了其在大规模网络中捕捉延误传播的时序特性与不确定性方面的有效性。

---
## 95. QoS-Aware Dynamic CU Selection in O-RAN with Graph-Based Reinforcement Learning

- 作者：Sebastian Racedo, Brigitte Jaumard, Oscar Delgado, Meysam Masoudi
- 子主题：强化学习（网络优化/无线接入网）
- 推荐：很推荐
- 关键词：O-RAN, 图神经网络, 深度强化学习
- Abstract：http://arxiv.org/abs/2512.19696v1
- PDF：https://arxiv.org/pdf/2512.19696v1

**中文摘要**

开放式无线接入网（O-RAN）将传统的RAN功能解耦为可互操作的组件，从而使资源分配更灵活、节能并支持敏捷的架构设计。在传统部署中，逻辑功能与物理位置之间的绑定是静态的，这在流量和资源随时间变化时会导致效率低下。为了解决这一限制，本文放宽了固定映射，提出了基于运行时O-CU选择的动态服务功能链（SFC）调度方法。我们将问题建模为马尔可夫决策过程（MDP），并提出GRLDyP——一种由图神经网络（GNN）辅助的深度强化学习（DRL）方法来求解。所设计的智能体对每个到达的业务流联合选择路由与O-CU的部署位置（从候选站点中选择），以在满足服务质量（QoS）约束的前提下最小化网络能耗。GNN用于编码瞬时网络拓扑与资源利用情况（例如CPU与带宽），DRL策略学习在服务等级、时延与能耗之间进行权衡。我们在包含蒙特利尔市24小时流量轨迹的数据集上评估了GRLDyP，结果表明与静态映射的基线相比，动态O-CU选择与路由显著降低了能耗且不违反QoS约束。实验结果突出了基于DRL的SFC调度作为面向能耗感知、资源自适应的O-RAN部署的可行控制原语的潜力。

---
## 96. Adaptive Financial Sentiment Analysis for NIFTY 50 via Instruction-Tuned LLMs , RAG and Reinforcement Learning Approaches

- 作者：Chaithra, Kamesh Kadimisetty, Biju R Mohan
- 子主题：LLM
- 推荐：很推荐
- 关键词：金融情感分析, 指令微调 LLM 与 RAG, PPO 强化学习反馈机制
- Abstract：http://arxiv.org/abs/2512.20082v1
- PDF：https://arxiv.org/pdf/2512.20082v1

**中文摘要**

金融情感分析在指导投资决策、评估市场风险与预测股价趋势方面至关重要。现有研究在情感分析中往往忽视了股价或市场反馈对情感判断的影响。本文提出了一种自适应框架，整合大语言模型（LLM）与真实市场反馈，以提升印度股市场景下的情感分类性能。方法上，我们对 LLaMA 3.2 3B 模型在 SentiFin 数据集上进行指令式微调，并构建了基于检索增强生成（RAG）的流水线，按句向量余弦相似度动态选择多源上下文信息以增强情感预测。进一步地，引入了反馈驱动模块，通过将模型预测情感与次日实际股票收益比较来调整信息源的可信度，使系统能够迭代适应市场行为。为将该自适应机制推广到时序数据，我们引入了一名使用近端策略优化（PPO）训练的强化学习代理，该代理根据情感—收益一致性的累积回报学习优化信息源加权策略。对 2024–2025 年间收集的 NIFTY 50 新闻标题的实验结果表明，所提系统在分类准确率、F1 值及与市场行为的一致性方面均显著优于基线模型和静态检索方法，验证了将指令微调的 LLM 与动态反馈及强化学习相结合用于稳健且具市场感知的金融情感建模的潜力。

---
## 97. On the Effectiveness of Instruction-Tuning Local LLMs for Identifying Software Vulnerabilities

- 作者：Sangryu Park, Gihyuk Ko, Homook Cho
- 子主题：LLM
- 推荐：很推荐
- 关键词：指令微调, 软件漏洞识别, 本地可部署 LLM
- Abstract：http://arxiv.org/abs/2512.20062v1
- PDF：https://arxiv.org/pdf/2512.20062v1

**中文摘要**

大规模语言模型（LLM）在自动化软件漏洞分析方面展现出显著潜力，这在现代软件系统安全失败可能带来严重后果的背景下尤为重要。然而，目前利用 LLM 自动化漏洞分析的方法大多依赖于在线 API 型 LLM 服务，要求用户在开发过程中披露源代码；并且大多将任务表述为二分类（是否存在漏洞），从而限制了实际应用价值。本文通过将问题重新表述为软件漏洞识别（Software Vulnerability Identification, SVI），要求 LLM 输出对应弱点类型的通用弱点枚举（CWE）编号，而非仅判断是否存在漏洞，来克服这些局限性。我们还解决了对大型 API 型 LLM 的依赖问题，展示了对较小且可本地部署的 LLM 进行指令微调（instruction-tuning）能够实现更优的识别性能。实验分析表明，指令微调后的本地模型在整体性能与成本权衡上优于在线 API 型 LLM。我们的发现表明，指令微调的本地模型在真实漏洞管理工作流中是一种更有效、更安全且更实用的利用 LLM 的方法。

---
## 98. Beyond Vision: Contextually Enriched Image Captioning with Multi-Modal Retrieva

- 作者：Nguyen Lam Phu Quy, Pham Phu Hoa, Tran Chi Nguyen, Dao Sy Duy Minh, Nguyen Hoang Minh Ngoc, Huynh Trung Kiet
- 子主题：多模态（Vision+Language）
- 推荐：很推荐
- 关键词：检索增强图像描述, 多模态语义检索与几何对齐, LLM 微调（QLoRA）
- Abstract：http://arxiv.org/abs/2512.20042v1
- PDF：https://arxiv.org/pdf/2512.20042v1

**中文摘要**

现实场景下的图像描述常常缺乏上下文深度，遗漏诸如事件背景、时间线索、结果以及视觉上不可直接识别的实体名称等关键信息。这一缺失限制了图像理解在新闻、教育和数字档案等需要更丰富描述的领域的应用。为了解决该问题，我们提出了一种多模态流水线，将视觉输入与外部文本知识相结合。系统首先使用 BEIT-3（Flickr30k-384 和 COCO-384）与 SigLIP So-384 检索语义相似的图像，并采用 ORB 与 SIFT 进行重排序以实现几何对齐；随后通过语义检索从相关报道中提取上下文信息。我们对 Qwen3 进行了 QLoRA 微调，使其将从文章中检索到的上下文与由 Instruct BLIP（Vicuna-7B）生成的基础说明整合，进而生成富含事件信息且具上下文感知的描述。在 OpenEvents v1 数据集上的评估表明，该方法相比传统方法能生成显著更具信息量的图像说明，展现出在需要更深层视觉-文本理解的实际应用场景中的良好潜力。

---
## 99. IoT-based Android Malware Detection Using Graph Neural Network With Adversarial Defense

- 作者：Rahul Yumlembam, Biju Issac, Seibu Mary Jacob, Longzhi Yang
- 子主题：图神经网络/物联网安全/恶意软件检测
- 推荐：很推荐
- 关键词：图神经网络, 对抗生成网络（GAN）, Android 恶意软件检测
- Abstract：http://arxiv.org/abs/2512.20004v1
- PDF：https://arxiv.org/pdf/2512.20004v1

**中文摘要**

随着物联网（IoT）中大量采用基于Android的应用，检测恶意Android应用变得至关重要。近年来，基于图的Android深度学习研究提出了多种将应用关系表示为图并生成图嵌入的方法。首先，我们展示了基于图的分类方法的有效性：使用图神经网络（GNN）对API关系图进行嵌入表示，并将该图嵌入与权限（Permission）和Intent特征相结合，训练多种机器学习与深度学习模型用于Android恶意软件检测。所提出的分类方法在CICMaldroid数据集上达到了98.33%的准确率，在Drebin数据集上达到了98.68%的准确率。然而，基于图的深度学习模型存在脆弱性，攻击者可以通过添加伪造关系来规避检测器。其次，我们提出了一种基于生成对抗网络（GAN）的攻击算法VGAE-MalGAN，针对基于图的GNN Android恶意软件分类器。VGAE-MalGAN的生成器用于生成对抗性的恶意API图，而替代检测器则试图模拟目标检测器。实验结果表明，VGAE-MalGAN能够显著降低GNN类恶意软件分类器的检测率。尽管模型在初始状态下无法检测到这些对抗样本，但通过使用生成的对抗样本进行重训练，可以提高模型的鲁棒性，从而在一定程度上缓解对抗攻击的影响。

---
## 100. Conditional Adversarial Fragility in Financial Machine Learning under Macroeconomic Stress

- 作者：Samruddhi Baviskar
- 子主题：金融机器学习（对抗鲁棒性）
- 推荐：很推荐
- 关键词：对抗脆弱性, 宏观经济压力, 金融模型鲁棒性
- Abstract：http://arxiv.org/abs/2512.19935v1
- PDF：https://arxiv.org/pdf/2512.19935v1

**中文摘要**

用于金融决策系统的机器学习模型运行在非平稳的经济环境中，但对抗鲁棒性通常在静态假设下评估。本文提出了“条件性对抗脆弱性”（Conditional Adversarial Fragility）的概念，指在宏观经济压力时期，对抗脆弱性会系统性放大，表现为模型在特定经济政权下更易受对抗攻击影响。我们提出了一种面向时间索引表格型金融分类任务的政权感知评估框架，将鲁棒性评估以外部经济压力指标为条件进行考察。以基于波动率的政权分割作为宏观经济状态的代理，在保持模型架构、攻击方法和评估协议不变的情况下，比较模型在平稳期与压力期的行为。结果表明，基线的预测性能在不同政权间大体可比，说明经济压力本身不会导致固有的性能退化；但在对抗扰动下，压力期模型在预测准确率、操作性决策阈值和风险敏感型输出上表现出显著更大的下降。我们进一步展示了这种放大效应会导致假阴性率上升，从而在不利条件下增加遗漏高风险案例的风险。为补充数值鲁棒性指标，本文还引入了基于大语言模型的语义审计解释作为可解释性与治理层。综合结果表明，金融机器学习中的对抗鲁棒性是政权依赖的属性，强调在高风险金融部署中采用压力感知的模型风险评估方法的必要性。

---
## 101. Fine-Tuned In-Context Learners for Efficient Adaptation

- 作者：Jorg Bornschein, Clare Lyle, Yazhe Li, Amal Rannen-Triki, Xu Owen He, Razvan Pascanu
- 子主题：LLM
- 推荐：很推荐
- 关键词：上下文学习, 模型微调, 预验评估
- Abstract：http://arxiv.org/abs/2512.19879v1
- PDF：https://arxiv.org/pdf/2512.19879v1

**中文摘要**

在将大型语言模型（LLM）适配到特定下游任务时，通常采用两类主要方法：（1）提示工程，常结合上下文少样本学习，利用模型的固有泛化能力；（2）在任务特定数据上进行微调，直接优化模型参数。提示类方法在少样本情形下表现优异，但随着可用数据增多其效果常常趋于平稳；相反，微调随着数据规模扩大表现良好，但在训练样本稀少时可能表现欠佳。我们研究了一种将这两种范式桥接的统一方法，通过在微调过程中直接引入上下文学习。具体而言，我们在任务特定数据上进行微调，同时用包含上下文示例的数据进行增强，模拟 k-shot 提示的结构。尽管该方法需要针对每个任务进行微调，但它结合了上下文学习的样本效率与微调带来的性能提升，能够稳定地匹配并常常显著超越这两种基线方法。为在低数据环境中进行超参数选择，我们提出使用预验（prequential）评估，该方法无需昂贵的交叉验证，能够在利用所有可用训练数据的同时提供稳健的验证信号。我们进行了一项广泛的实证研究，以判断在具体下游任务上哪种适配范式——微调、上下文学习或我们提出的统一方法——能提供最佳的预测性能。

---
## 102. SweRank+: Multilingual, Multi-Turn Code Ranking for Software Issue Localization

- 作者：Revanth Gangi Reddy, Ye Liu, Wenting Zhao, JaeHyeok Doo, Tarun Suresh, Daniel Lee, Caiming Xiong, Yingbo Zhou, Semih Yavuz, Shafiq Joty
- 子主题：LLM（代码检索/软件缺陷定位）
- 推荐：很推荐
- 关键词：多语言代码定位, 代码检索与重排, 多轮主体式搜索（Agent）
- Abstract：http://arxiv.org/abs/2512.20482v1
- PDF：https://arxiv.org/pdf/2512.20482v1

**中文摘要**

维护大规模、多语言的代码库依赖于准确的故障定位，这需要将自然语言的错误描述映射到需要修改的相关函数。然而，现有的排序方法通常以 Python 为中心，并且只对代码库执行一次性检索。本文提出了 SweRank+ 框架，将跨语言代码排序工具 SweRankMulti 与具备主体化搜索能力的 SweRankAgent 结合，用于对代码仓库进行迭代的多轮推理。SweRankMulti 由代码嵌入检索器和基于列表式排序的 LLM 重排器构成，并使用精心构建的、大规模的跨多种流行编程语言的问题定位数据集进行训练。SweRankAgent 采用一种具备记忆缓冲区的主体式搜索循环，超越单次定位方法，通过多轮推理累积并筛选出相关的定位候选项。我们在覆盖多种语言的问题定位基准上进行的实验表明，SweRankMulti 达到了新的最先进性能，而 SweRankAgent 在单次检索的基础上进一步提升了定位效果。

---
## 103. AUDRON: A Deep Learning Framework with Fused Acoustic Signatures for Drone Type Recognition

- 作者：Rajdeep Chatterjee, Sudip Chakrabarty, Trishaani Acharjee, Deepanjali Mishra
- 子主题：音频处理/声学信号处理
- 推荐：很推荐
- 关键词：无人机声学识别, 特征融合, 深度学习
- Abstract：http://arxiv.org/abs/2512.20407v1
- PDF：https://arxiv.org/pdf/2512.20407v1

**中文摘要**

无人机（UAV）在物流、农业、监控和国防等领域的应用日益广泛，但其滥用带来安全隐患，因此需要有效的检测机制。与基于视觉或雷达的检测相比，声学感知因成本低、非侵入性且无人机螺旋桨会产生特征性声纹而成为可行替代方案。本文提出了AUDRON（AUdio-based Drone Recognition Network），一种用于无人机声学识别的混合深度学习框架。该框架结合了梅尔频率倒谱系数（MFCC）、短时傅里叶变换（STFT）谱图（通过卷积神经网络处理）、用于时间建模的循环层以及基于自编码器的表示，并在分类前通过特征级融合整合互补信息。实验结果表明，AUDRON能够在背景噪声中有效区分无人机声学特征，在不同条件下保持良好的泛化能力；在二分类和多分类任务中分别达到了98.51%和97.11%的准确率。研究结果凸显了多种特征表示与深度学习结合在可靠声学无人机检测中的优势，表明该框架在视觉或雷达受限的安防与监控场景中具有部署潜力。

---
## 104. Generative Digital Twins: Vision-Language Simulation Models for Executable Industrial Systems

- 作者：YuChe Hsu, AnJui Wang, TsaiChing Ni, YuanFu Yang
- 子主题：Multimodal (Vision-Language / LLM)
- 推荐：很推荐
- 关键词：生成式数字孪生, 视觉-语言模拟, 可执行代码生成
- Abstract：http://arxiv.org/abs/2512.20387v1
- PDF：https://arxiv.org/pdf/2512.20387v1

**中文摘要**

我们提出了一种视觉-语言仿真模型（Vision-Language Simulation Model, VLSM），将视觉与文本理解统一起来，从布局草图和自然语言提示中合成可执行的 FlexScript，从而为工业仿真系统提供跨模态推理能力。为支持这一新范式，本研究构建了首个面向生成式数字孪生的大规模数据集，包含超过 12 万条提示—草图—代码三元组，促进文本描述、空间结构与仿真逻辑之间的多模态学习。与此同时，我们专门为该任务设计了三项评估指标：结构有效率（Structural Validity Rate, SVR）、参数匹配率（Parameter Match Rate, PMR）和执行成功率（Execution Success Rate, ESR），用于全面评估结构完整性、参数一致性和在仿真器中的可执行性。通过对视觉编码器、连接器及基于代码预训练的语言骨干网络的系统性消融实验，所提出的模型在结构准确性上接近完美，并表现出较高的执行鲁棒性。本工作为将视觉推理与语言理解整合到可执行工业仿真系统中的生成式数字孪生奠定了基础。

---
## 105. Deep Learning Classification of EEG Responses to Multi-Dimensional Transcranial Electrical Stimulation

- 作者：Alexis Pomares Pastor, Ines Ribeiro Violante, Gregory Scott
- 子主题：神经工程/脑机接口（EEG与深度学习）
- 推荐：很推荐
- 关键词：意识测量, 经颅直流刺激(tDCS), EEG+深度学习
- Abstract：http://arxiv.org/abs/2512.20319v1
- PDF：https://arxiv.org/pdf/2512.20319v1

**中文摘要**

医学实践的一个主要短板是缺乏对意识水平的客观量化指标。意识受损在脑损伤和癫痫后常见，且会干扰感知处理和自主反应，这也使得基于指令遵从来推断意识的神经生理学方法（如功能性磁共振成像或脑电图）存在局限。经颅电刺激（TES）可用于非侵入性地直接刺激大脑、绕过感觉输入，已显示出作为脑态可靠指征的潜力；但现有非侵入性方案多限于磁刺激，在临床可移植性方面存在困难。我们的长期愿景是开发一种可在床边使用的、无需患者理解指令或发起运动反应的客观脑态测量方法。在本研究中，我们展示了利用深度学习算法对由定义的多维TES模式诱发的脑电（EEG）反应进行分类的可行性。我们在11名受试者身上收集了EEG-TES数据，发现对后皮层区域、以角回为靶点施加经颅直流刺激（tDCS）能够诱发高度可靠的脑反应。对于该范式，我们表现最佳的卷积神经网络模型在未见受试者的保留测试集上达到了92%的F1分数，显著超越了人类评估者60–70%的准确率。这些结果为临床可用的稳健意识测量建立了框架。为促进神经科学与人工智能研究社区的复现与推进，我们已完整记录并开源了数据集与代码，便于在GitHub、Kaggle、Colab等免费工具上使用与验证。

---
## 106. TAVID: Text-Driven Audio-Visual Interactive Dialogue Generation

- 作者：Ji-Hoon Kim, Junseok Ahn, Doyeop Kwak, Joon Son Chung, Shinji Watanabe
- 子主题：Multimodal (CV+NLP)
- 推荐：很推荐
- 关键词：音视频交互生成, 跨模态映射, 同步会话语音
- Abstract：http://arxiv.org/abs/2512.20296v1
- PDF：https://arxiv.org/pdf/2512.20296v1

**中文摘要**

本文旨在从文本和参考图像联合合成交互式视频和会话语音。为构建类人会话系统，近期研究探索了会说话/倾听的头部生成以及会话语音生成，但这些工作多独立研究，忽视了人类对话中紧密耦合的视听交互特性。为此，我们提出了TAVID，一个统一框架，能够以同步方式生成交互式人脸和会话语音。TAVID 通过两个跨模态映射器（运动映射器和说话者映射器）将人脸与语音生成流水线连接起来，实现音频与视觉模态之间互补信息的双向交换。我们从四个维度评估系统：说话人脸真实感、倾听头部的响应性、双人交互流畅度和语音质量。大量实验结果表明该方法在以上各方面均表现有效。

---
## 107. ActionFlow: A Pipelined Action Acceleration for Vision Language Models on Edge

- 作者：Yuntao Dai, Hang Gu, Teng Wang, Qianyu Cheng, Yifei Zheng, Zhiyong Qiu, Lei Gong, Wenqi Lou, Xuehai Zhou
- 子主题：多模态/边缘推理(VLA)
- 推荐：很推荐
- 关键词：边缘推理, 跨请求流水线, 视觉-语言-动作(VLA)
- Abstract：http://arxiv.org/abs/2512.20276v1
- PDF：https://arxiv.org/pdf/2512.20276v1

**中文摘要**

视觉-语言-动作（VLA）模型已成为机器人感知与控制的统一范式，能够实现 emergent 泛化能力和长时程任务执行。但它们在动态真实环境中的部署受到高推理延迟的严重制约。平滑的机器人交互需要20–30 Hz的控制频率，而当前VLA模型在边缘设备上通常仅能以3–5 Hz运行，主要受自回归解码的内存带宽限制。现有优化方法往往需要大量重训练或以牺牲精度为代价。为了解决这一问题，我们提出了ActionFlow，一种面向资源受限边缘平台的系统级推理框架。ActionFlow的核心是跨请求流水线（Cross-Request Pipelining）策略，该新型调度器将VLA推理重新定义为由多个微请求组成的宏流水线，在连续时间步内智能地将内存受限的解码阶段与计算受限的预填充（Prefill）阶段进行混合批处理，以最大化硬件利用率。为支持该调度，我们还提出了跨请求状态打包前向算子（Cross Request State Packed Forward）和统一KV环形缓冲区（Unified KV Ring Buffer），将分散的内存操作融合为高效的密集计算。实验证明，ActionFlow在不重训练的前提下，在OpenVLA-7B模型上实现了2.55倍的FPS提升，从而使边缘硬件上实现实时动态操控成为可能。项目地址：https://anonymous.4open.science/r/ActionFlow-1D47。

---
## 108. Asynchronous Fast-Slow Vision-Language-Action Policies for Whole-Body Robotic Manipulation

- 作者：Teqiang Zou, Hongliang Zeng, Yuxuan Nong, Yifan Li, Kehui Liu, Haotian Yang, Xinyang Ling, Xin Li, Lianyang Ma
- 子主题：多模态机器人控制（视觉-语言-动作）
- 推荐：很推荐
- 关键词：异步快慢框架, 视觉-语言-动作（VLA）, 全身机器人操控
- Abstract：http://arxiv.org/abs/2512.20188v1
- PDF：https://arxiv.org/pdf/2512.20188v1

**中文摘要**

大多数视觉-语言-动作（VLA）系统将用于语义推理的视觉-语言模型（VLM）与负责生成连续动作信号的动作专家结合在一起，但两者通常以统一的频率运行。因此，策略性能受到大型 VLM 推理速度较低的制约。这种强制的同步执行在涉及更多关节、更大运动空间和视角动态变化的全身机器人操控中，严重限制了控制稳定性和实时性。为此，我们提出了一种真正异步的快-慢视觉-语言-动作框架 DuoCore-FS，将系统划分为用于高频动作生成的快速通路和用于丰富 VLM 推理的慢速通路。该系统具有两个关键特性：其一，潜在表示缓冲区在慢速与快速系统之间搭建桥梁，存储与场景-指令上下文对齐的指令语义与动作推理表示，从而为快速通路提供高级引导；其二，全身动作分词器提供了对全身动作的紧凑统一表示。重要的是，VLM 与动作专家仍以端到端方式联合训练，既保留了统一策略学习，又实现了异步执行。DuoCore-FS 支持 30 亿参数等级的 VLM，同时实现每 30 Hz 的全身动作块生成，速度约为同规模先前 VLA 模型的三倍。真实世界的全身操控实验表明，与同步的快-慢 VLA 基线相比，本方法在任务成功率和响应性上都有所提升。DuoCore-FS 的训练、推理与部署实现作为 Astribot 机器人平台的一部分提供给商业用户。

---
## 109. Fun-Audio-Chat Technical Report

- 作者：Qian Chen, Luyao Cheng, Chong Deng, Xiangang Li, Jiaqing Liu, Chao-Hong Tan, Wen Wang, Junhao Xu, Jieping Ye, Qinglin Zhang, Qiquan Zhang, Jingren Zhou
- 子主题：LLM (语音-文本融合)
- 推荐：很推荐
- 关键词：双分辨率语音表示, 抗遗忘微调, 多任务 DPO 后训练
- Abstract：http://arxiv.org/abs/2512.20156v1
- PDF：https://arxiv.org/pdf/2512.20156v1

**中文摘要**

近期在联合语音-文本模型方面的进展展示了无缝语音交互的巨大潜力，但现有模型存在关键挑战：语音 token（25Hz）与文本 token（约3Hz）在时间分辨率上的不匹配会稀释语义信息、增加计算开销并导致文本大模型知识的灾难性遗忘。为此我们提出了 Fun-Audio-Chat，一种面向大规模音频语言模型的解决方案，继承并扩展了我们先前工作 DrVoice 的两项关键创新。首先是双分辨率语音表示（Dual-Resolution Speech Representations，DRSR）：共享的 LLM 通过将 token 分组以高效地以 5Hz 处理音频，而语音精炼头（Speech Refined Head）负责生成质量更高的 25Hz token，从而在质量与效率之间取得平衡（约减少 50% GPU 开销）。其次是 Core-Cocktail Training，一种通过中间合并的两阶段微调策略，用以缓解灾难性遗忘。随后我们引入多任务 DPO 训练以增强模型的鲁棒性、音频理解、指令遵循能力和语音共情能力。这种多阶段的后训练使 Fun-Audio-Chat 在保留文本 LLM 知识的同时，获得强大的音频理解、推理与生成能力。不同于需要大规模音频-文本预训练的近期 LALM 方法，Fun-Audio-Chat 借助预训练模型并通过大规模后训练实现目标。Fun-Audio-Chat 8B 与 MoE 30B-A3B 在语音转文本与语音到语音任务上取得了有竞争力的表现，在口语问答基准上位列同规模模型前列，并在音频理解、语音函数调用、指令跟随与语音共情等任务上表现出竞争性甚至优于同类的方法。我们还开发了用于双工交互的 Fun-Audio-Chat-Duplex，展示了在口语问答和全双工交互上的强大能力。我们开源了 Fun-Audio-Chat-8B 的训练与推理代码，并提供了交互演示。

---
## 110. Unified Brain Surface and Volume Registration

- 作者：S. Mazdak Abulnaga, Andrew Hoopes, Malte Hoffmann, Robin Magnet, Maks Ovsjanikov, Lilla Zöllei, John Guttag, Bruce Fischl, Adrian Dalca
- 子主题：医学影像 / 脑影像配准
- 推荐：很推荐
- 关键词：体积-表面联合配准, 球面坐标表示, 脑MRI配准
- Abstract：http://arxiv.org/abs/2512.19928v1
- PDF：https://arxiv.org/pdf/2512.19928v1

**中文摘要**

准确配准脑部MRI对神经科学研究中的跨受试者分析至关重要，这要求同时对大脑皮层表面和内部体积进行对齐。传统方法通常将体积配准与基于表面的配准分开处理，导致两者间常出现不一致，进而限制后续分析的可靠性。我们提出了一种深度学习框架NeurAlign，通过统一的体积-表面表示对三维脑MRI进行联合配准，能够同时对皮层与皮下结构进行对齐。该方法利用中间的球面坐标空间将解剖表面拓扑与体积解剖结构连接起来，实现体积域与表面域之间的一致性与解剖学精确对齐。通过在学习中集成球面配准，NeurAlign 确保了体积与表面配准在几何上的连贯性。在一系列域内与域外数据集上的实验中，我们的方法持续优于经典及基于机器学习的配准方法——Dice 分数最高提高约7个百分点，同时保持了规则的形变场。该方法在推理速度上比标准方法快数个数量级，并且使用更简单：除了原始MRI扫描外不需要额外输入。凭借其更高的精度、快速的推理与易用性，NeurAlign 为皮层与皮下联合配准设定了新的标准。

---
## 111. Automated Fault Detection in 5G Core Networks Using Large Language Models

- 作者：Parsa Hatami, Ahmadreza Majlesara, Ali Majlesi, Babak Hossein Khalaj
- 子主题：LLM (网络运维)
- 推荐：推荐
- 关键词：5G核心网, 大语言模型(LLM), 网络故障自动检测
- Abstract：http://arxiv.org/abs/2512.19697v1
- PDF：https://arxiv.org/pdf/2512.19697v1

**中文摘要**

随着现代电信网络数据量快速增长和规模不断扩展，保持高可靠性已成为关键需求。这些网络承载包括高度敏感和关键任务在内的多种应用与服务，要求能够快速且准确地检测与定位网络故障。传统的故障诊断方法已难以胜任此类复杂环境。本研究利用大语言模型（LLM）实现网络故障的自动检测与分类。在基于Kubernetes的测试网络中，研究团队有意注入多种类型的网络故障，并在健康与故障两种状态下采集数据。数据集包含来自不同网络组件（pod）的日志，以及系统描述、事件、往返时延（RTT）测试和pod状态等补充信息，覆盖常见故障类型如pod故障、pod被强制终止、网络延迟、网络丢包和磁盘I/O故障。研究通过API对GPT-4.1 nano模型进行微调，微调后模型在故障检测准确率上较基础模型有显著提升。结果表明，基于LLM的方法在实现闭环、无人值守的故障管理方面具有潜力，可提升网络可靠性并降低运营商因停机导致的运维成本。

---
## 112. Memory as Resonance: A Biomimetic Architecture for Infinite Context Memory on Ergodic Phonetic Manifolds

- 作者：Tarik Houichime, Abdelghani Souhar, Younes El Amrani
- 子主题：LLM
- 推荐：推荐
- 关键词：轨迹记忆, 神经-符号架构, 共振检索
- Abstract：http://arxiv.org/abs/2512.20245v1
- PDF：https://arxiv.org/pdf/2512.20245v1

**中文摘要**

当代大规模语言模型的记忆受到一个物理悖论的制约：随着学习进行，它们的记忆空间会被填满。键-值状态的线性累积（O(N)）将上下文视为静态条目的仓库，最终迫使系统在遗忘与延迟之间做出毁灭性的选择。我们挑战这种离散正统观，提出长期记忆不是对条目的存储，而是轨迹的持续性。为此我们引入了语音轨迹记忆（Phonetic Trajectory Memory，PTM），一种神经-符号混合架构，将语言编码为在由无理旋转矩阵支配的遍历性流形上的连续路径，而非一系列张量。通过将导航（一个不变的 O(1) 几何信号）与重构（一个概率生成行为）解耦，PTM 相比密集缓存实现了超过 3000 倍的压缩率。我们展示了检索成为一种共振过程：语音轨迹通过“信号一致性”机制稳定模型，抑制幻觉，实证上可达到约 92% 的事实准确率。虽然这种激进的抽象会改变生成的文本质感，但它解锁了与上下文深度无关的即时访问延迟（约 34ms）。我们的结果表明，无穷上下文并不需要无穷硅片；关键在于把记忆视为对一种守恒、不朽物理信号的重构过程，而非单纯的数据存储。

---
## 113. Regression of Functions by Quantum Neural Networks Circuits

- 作者：Fernando M. de Paula Neto, Lucas dos Reis Silva, Paulo S. G. de Mattos Neto, Felipe F. Fanchini
- 子主题：量子机器学习 (QML)
- 推荐：推荐
- 关键词：量子神经网络, 电路架构搜索, 元学习与数据复杂性
- Abstract：http://arxiv.org/abs/2512.19978v1
- PDF：https://arxiv.org/pdf/2512.19978v1

**中文摘要**

量子神经网络模型的性能在很大程度上依赖于架构设计决策，包括电路深度、参数化操作的位置以及数据编码策略。选择有效的架构具有挑战性，并与经典神经网络拓扑选择的困难密切相关——这是一个计算上困难的问题。本工作研究用于回归任务的自动化量子电路构建，提出了一种基于遗传算法的框架，用于发现简化回归器（Reduced Regressor）QNN架构。该方法在电路深度、参数化门配置以及灵活的数据重上传（data re-uploading）模式上进行探索，将量子回归器的构建表述为一个优化过程。研究中将发现的电路与十七种经典回归模型在二十二个非线性基准函数和四个解析函数上进行了比较。尽管经典方法在许多情况下能获得可比的结果，但通常需要更多的参数，而进化得到的量子模型保持紧凑同时提供了具有竞争力的性能。我们进一步使用十二个结构描述子对数据集复杂性进行分析，并在五个难度逐步增加的元学习场景中展示了这些度量可以可靠地预测哪种量子架构表现最好。在若干场景中观察到完美或近乎完美的预测精度，表明复杂性度量能够作为对数据集结构的强有力且紧凑的表征并有效指导自动化模型选择。总体而言，本研究为基于元学习的量子架构设计提供了理论与实践基础，增进了对量子模型在回归设置中行为的理解——这是先前工作较少涉及的主题。这些发现为更系统且有理论支撑的量子回归方法奠定了基础。

---
