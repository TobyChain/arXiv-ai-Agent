---
## 1. Holistic Evaluation of State-of-the-Art LLMs for Code Generation

- 作者：Le Zhang, Suresh Kothari
- 子主题：LLM (代码生成)
- 推荐：极度推荐
- 关键词：代码生成, 大规模语言模型, 性能评估
- Abstract：http://arxiv.org/abs/2512.18131v1
- PDF：https://arxiv.org/pdf/2512.18131v1

**中文摘要**

本研究对六种最先进的大规模语言模型（包括通用模型和代码专用模型）在代码生成任务上的性能进行了全面的实证评估。我们使用包含944道真实世界 LeetCode 题目的数据集，覆盖五种编程语言，并通过严谨的度量指标评估模型表现：编译时错误、运行时错误、功能性失败及算法次优性。结果显示，不同模型之间存在显著性能差异，DeepSeek-R1 与 GPT-4.1 在正确性、效率与鲁棒性方面持续优于其他模型。通过详尽的案例分析，我们识别出常见失败场景，如语法错误、逻辑缺陷与次优算法，并强调提示工程与人工监督在提升结果质量中的关键作用。基于这些发现，我们为开发者与从业者提供了可操作的建议，强调成功部署 LLM 以实现可靠代码生成需依赖于慎重的模型选择、有效的提示设计与基于上下文的使用策略。

---
## 2. PTTA: A Pure Text-to-Animation Framework for High-Quality Creation

- 作者：Ruiqi Chen, Kaitong Cai, Yijia Fan, Keze Wang
- 子主题：CV（视频生成/多模态）
- 推荐：极度推荐
- 关键词：文本到动画, 动画视频生成, 模型微调
- Abstract：http://arxiv.org/abs/2512.18614v1
- PDF：https://arxiv.org/pdf/2512.18614v1

**中文摘要**

传统动画制作流程复杂且劳动投入高。尽管近期诸如 Sora、Kling 和 CogVideoX 等视频生成模型在自然视频合成上取得了显著进展，但将它们直接用于动画生成时存在明显局限。近来的工作如 AniSora 通过对图像到视频模型进行微调以适配动画风格，取得了可喜成果，但在文本到视频（text-to-video）领域的类似探索仍较少。为此，本工作提出了 PTTA，一种纯文本到动画的高质量创作框架。我们首先构建了一个小规模但高质量的动画视频与文本描述的配对数据集。在此基础上，以预训练的文本到视频模型 HunyuanVideo 为起点，进行微调以适配动画风格生成。多维度的广泛视觉评估表明，所提方法在动画视频合成任务上持续优于可比基线方法。

---
## 3. Byzantine Fault-Tolerant Multi-Agent System for Healthcare: A Gossip Protocol Approach to Secure Medical Message Propagation

- 作者：Nihir Chadderwala
- 子主题：医疗LLM/分布式多智能体系统
- 推荐：极度推荐
- 关键词：拜占庭容错, 医疗多智能体系统, gossip协议
- Abstract：http://arxiv.org/abs/2512.17913v1
- PDF：https://arxiv.org/pdf/2512.17913v1

**中文摘要**

近来的生成式人工智能进展催生了面向医疗场景的复杂多智能体架构，其中大型语言模型驱动协同临床决策。然而，在对抗性或不受信任的环境中，这类分布式系统在保证消息完整性和容错性方面面临关键挑战。本文提出了一种专为医疗应用设计的拜占庭容错多智能体系统，结合基于gossip的消息传播与密码学验证机制。系统部署了用于诊断、治疗规划、急救响应和数据分析的专门AI代理，通过可容忍最多f个故障节点（总体节点数为n = 3f + 1）的拜占庭共识协议进行协调。我们实现了用于去中心化消息传播的gossip协议，在存在拜占庭故障时仍能以2f + 1票数达成共识并保持系统运行。实验结果表明，该方法能够通过密码签名验证医疗消息、通过时间戳验证防止重放攻击，并在最多33%拜占庭节点的情况下维持100%的共识准确率。系统还提供共识轮次、投票统计和网络拓扑的实时可视化，便于对容错操作进行透明监控。本工作为在不受信任环境中构建能够协同医疗决策的安全、弹性多智能体系统提供了实用框架。

---
## 4. Evaluating the Challenges of LLMs in Real-world Medical Follow-up: A Comparative Study and An Optimized Framework

- 作者：Jinyan Liu, Zikang Chen, Qinchuan Wang, Tan Xie, Heming Zheng, Xudong Lv
- 子主题：医疗LLM
- 推荐：极度推荐
- 关键词：医疗随访, 大型语言模型(LLM), 模块化流程控制
- Abstract：http://arxiv.org/abs/2512.18999v1
- PDF：https://arxiv.org/pdf/2512.18999v1

**中文摘要**

当直接以端到端方式将大型语言模型（LLMs）应用于医疗随访任务时，由于随访表单的复杂性，往往出现对话流程不可控和信息抽取不准确的问题。为了解决这一限制，我们设计并比较了两种随访聊天机器人系统：一种端到端的基于LLM的系统（对照组），以及一种带有结构化流程控制的模块化流水线系统（实验组）。实验结果表明，端到端方法在处理冗长和复杂表单时常常失败，而我们的模块化方法——基于任务分解、语义聚类与流程管理——显著提升了对话稳定性和抽取准确性。此外，该方法将对话轮次减少了46.73%，并将token消耗降低了80%至87.5%。这些发现突出了在高风险的医疗随访场景中部署LLMs时集成外部控制机制的必要性。

---
## 5. R-GenIMA: Integrating Neuroimaging and Genetics with Interpretable Multimodal AI for Alzheimer's Disease Progression

- 作者：Kun Zhao, Siyuan Dai, Yingying Zhang, Guodong Liu, Pengfei Gu, Chenghua Lin, Paul M. Thompson, Alex Leow, Heng Huang, Lifang He, Liang Zhan, Haoteng Tang
- 子主题：医学LLM
- 推荐：极度推荐
- 关键词：阿尔茨海默病, 多模态AI, 影像-基因整合
- Abstract：http://arxiv.org/abs/2512.18986v1
- PDF：https://arxiv.org/pdf/2512.18986v1

**中文摘要**

早期检测阿尔茨海默病（AD）需要能够将宏观脑区解剖改变与微观基因易感性相结合的模型，而现有的多模态方法难以对齐这些异质信号。我们提出了R-GenIMA，一种可解释的多模态大模型框架，它通过将新颖的基于ROI的视觉Transformer与基因提示机制耦合，用以联合建模结构性MRI和单核苷酸多态性（SNP）变异。该方法将每个解剖分区的脑区表示为视觉token，并将SNP谱编码为结构化文本，支持跨模态注意力以将区域性萎缩模式与潜在的遗传因素关联起来。在ADNI队列上的实验表明，R-GenIMA在正常认知（NC）、主观记忆问题（SMC）、轻度认知障碍（MCI）和AD四分类任务上达到最先进的性能。除了预测准确性外，模型还能产生生物学上有意义的解释，识别出与疾病不同阶段相关的脑区和基因特征，并揭示贯穿病程的ROI–基因关联模式。基于注意力的归因分析发现了与已知GWAS支持的AD风险位点一致富集的基因，包括APOE、BIN1、CLU和RBFOX1。分阶段的神经解剖学特征显示了跨阶段的共同易损枢纽以及阶段特异性的模式：主观认知下降期涉及纹状体，前驱期（prodromal）表现为额颞叶参与，而确诊AD阶段则呈现出整合的多模态网络破坏。这些结果表明，可解释的多模态AI能够整合影像与基因信息以揭示潜在机制，为临床可部署的工具奠定基础，从而实现更早的风险分层并为精准治疗策略提供参考。

---
## 6. An Agentic AI Framework for Training General Practitioner Student Skills

- 作者：Victor De Marez, Jens Van Nooten, Luna De Bruyne, Walter Daelemans
- 子主题：Medical LLM
- 推荐：极度推荐
- 关键词：虚拟模拟病人, 大型语言模型, 临床沟通与推理训练
- Abstract：http://arxiv.org/abs/2512.18440v1
- PDF：https://arxiv.org/pdf/2512.18440v1

**中文摘要**

随着大型语言模型的进展，虚拟模拟病人（VSP）在医学教育中作为可扩展替代传统资源密集型方法具有巨大潜力。然而，现有的VSP经常在医疗准确性、角色扮演的一致性、为VSP使用而生成场景的能力以及具有教学结构的反馈方面存在不足。为此，我们提出了一种用于训练全科医生学生技能的“智能体化（agentic）”框架，统一了：（i）可配置且基于证据的小案例（vignette）生成，（ii）受控的、以人物设定驱动的患者对话，并可选地结合检索式信息作为支撑，以及（iii）基于标准的沟通和临床推理评估与反馈。我们在交互式口语咨询场景中实现了该框架，并对14名医学生进行了评估。参与者反馈显示对话真实且忠于小案例、难度校准适当、人格信号稳定，并能获得富含示例的高度有用反馈，同时总体可用性优良。这些结果表明，将场景控制、交互控制与基于标准的评估进行智能体化分离，是构建可信赖且具有教学价值的VSP训练工具的一种实用模式。

---
## 7. Scalably Enhancing the Clinical Validity of a Task Benchmark with Physician Oversight

- 作者：Junze Ye, Daniel Tawfik, Alex J. Goodell, Nikhil V. Kotha, Mark K. Buyyounouski, Mohsen Bayati
- 子主题：医学LLM / 强化学习
- 推荐：极度推荐
- 关键词：医学基准维护, 医生-in-the-loop 审计, 标签噪声对强化学习的影响
- Abstract：http://arxiv.org/abs/2512.19691v1
- PDF：https://arxiv.org/pdf/2512.19691v1

**中文摘要**

自动化计算临床风险评分能够显著减轻医生的行政负担并提升患者护理质量。当前评估该能力的标准是 MedCalc-Bench——一个通过大模型（LLM）提取特征并使用规则聚合构建的大规模数据集。然而，将此类模型生成的基准视为静态的“金标准”存在风险，可能将历史模型错误固定为评估标准；当这些数据集被用作强化学习（RL）的奖励信号时，该问题将被放大。在本工作中，我们主张把复杂任务（如临床评分计算）的基准视为“进行中的活文档”，应随构建流程改进而定期重评。我们提出了一套系统性的“医生介入”流水线，利用先进的智能代理验证器对 MedCalc-Bench 进行审计与重标注，并通过自动分诊将稀缺的临床注意力优先分配给最有争议的实例。审计结果显示，原始标签中存在相当比例与医学真实情况不一致的情形，原因包括信息抽取错误、计算器逻辑不匹配以及临床含糊性。为研究这些标签噪声是否会实质性影响下游 RL 训练，我们使用 Group Relative Policy Optimization (GRPO) 对 Qwen3-8B 模型进行微调，实验表明在经纠正的标签上训练可使准确率较原基线绝对提高 8.7%——证明标签噪声确实会对模型评估产生实质性影响。我们的发现强调，在安全关键领域，严格的基准维护是实现模型真正对齐的先决条件。

---
## 8. Beyond CLIP: Knowledge-Enhanced Multimodal Transformers for Cross-Modal Alignment in Diabetic Retinopathy Diagnosis

- 作者：Argha Kamal Samanta, Harshika Goyal, Vasudha Joshi, Tushar Mungle, Pabitra Mitra
- 子主题：医疗多模态（医学影像/跨模态）
- 推荐：极度推荐
- 关键词：糖尿病性视网膜病变, 多模态Transformer, 跨模态对齐
- Abstract：http://arxiv.org/abs/2512.19663v1
- PDF：https://arxiv.org/pdf/2512.19663v1

**中文摘要**

糖尿病性视网膜病变（DR）是全球可预防致盲的主要原因之一，亟需准确的自动诊断系统。尽管通用领域的视觉-语言模型如对比语言-图像预训练（CLIP）在自然图像任务中表现良好，但在医学领域应用上尤其是在眼科图像的跨模态检索方面存在不足。为弥补医学图像与文本对齐的关键空白，我们提出了一种新颖的知识增强联合嵌入框架，通过多模态Transformer架构融合视网膜眼底图像、临床文本和结构化患者数据。方法上对每种模态采用独立编码器：采用 Vision Transformer (ViT-B/16) 编码眼底图像，使用 Bio-ClinicalBERT 编码临床叙述，使用多层感知机编码结构化的人口学及临床特征；随后通过带有模态特定嵌入的联合Transformer进行模态融合。训练采用多重目标，包括模态对之间的对比损失、图像与文本的重构损失以及依据 ICDR 和 SDRG 方案的 DR 严重程度分类损失。基于巴西多标签眼科数据集（BRSET）的实验结果显示，相较于基线模型取得显著提升：文本到图像检索的 Recall@1 达到 99.94%，而微调后的 CLIP 为 1.29%，同时在 SDRG 与 ICDR 分级上分别取得 97.05% 与 97.97% 的先进分类准确率。对未见数据集 DeepEyeNet 的零样本评估也验证了强泛化能力，Recall@1 为 93.95%，而微调 CLIP 为 0.22%。这些结果表明，我们的多模态训练方法能够有效捕捉医学领域的跨模态关系，既实现了卓越的检索性能，又保持了稳健的诊断能力。

---
## 9. CARE What Fails: Contrastive Anchored-REflection for Verifiable Multimodal

- 作者：Yongxin Wang, Zhicheng Yang, Meng Cao, Mingfei Han, Haokun Lin, Yingying Zhu, Xiaojun Chang, Xiaodan Liang
- 子主题：多模态强化学习
- 推荐：极度推荐
- 关键词：锚定对比学习, 反思引导重采样, 可验证多模态推理
- Abstract：http://arxiv.org/abs/2512.19554v1
- PDF：https://arxiv.org/pdf/2512.19554v1

**中文摘要**

具有可验证奖励的组相对强化学习（RLVR）常常浪费已有的最有信息量的数据——失败样本。当所有 rollout 都错误时，梯度会停滞；当只有一个恰好正确时，更新通常忽视其他接近但错误的样本的原因，导致虚假的因果链被赋予功劳。我们提出 CARE（Contrastive Anchored REflection），一种以失败为中心的后训练多模态推理框架，将错误转化为监督信号。CARE 结合了：(i) 一种锚定对比目标，该目标围绕最佳 rollout 和一组语义上相近的困难负样本形成紧凑子群，在子群内执行 z 分数归一化并仅对负样本进行缩放，同时包含全负救援机制以防止无信号批次；以及 (ii) 反思引导重采样（RGR），一种一次性结构化自修复方法，通过重写具有代表性的失败样本并用相同的验证器重新评分，将近乎命中的样本转换为可用的正例，而无需在测试时进行反思。CARE 在提高准确性和训练平滑性的同时，明确增加来自失败样本的学习信号比例。在 Qwen2.5-VL-7B 上，CARE 在六个可验证视觉推理基准上相比 GRPO 提升了宏平均准确率 4.6 个百分点；在 Qwen3-VL-8B 上，在相同评估协议下，CARE 在 MathVista 和 MMMU-Pro 上达到了具有竞争力或最先进的结果。

---
## 10. A Dataset and Preliminary Study of Using GPT-5 for Code-change Impact Analysis

- 作者：Katharina Stengg, Christian Macho, Martin Pinzger
- 子主题：LLM
- 推荐：极度推荐
- 关键词：代码变更影响分析, 大型语言模型, 数据集与评估
- Abstract：http://arxiv.org/abs/2512.19481v1
- PDF：https://arxiv.org/pdf/2512.19481v1

**中文摘要**

理解源代码变更及其对其他代码实体的影响是软件开发中的一项重要技能，但通常需要人工分析，耗时且费力。近期人工智能，特别是大型语言模型（LLM）的进展，展示了在各种代码分析任务中辅助开发者的潜力，但其在代码变更及影响分析上的能力尚未充分研究。为此，本文探讨了GPT-5与GPT-5-mini在预测给定源代码变更所影响代码实体方面的能力。我们构建了一个数据集，包含每次提交的种子变更（seed-change）、变更对与变更类型，弥补了现有数据集中缺少种子变更和受影响代码实体信息的不足。实验在两种输入配置下进行评估： (1) 提供种子变更信息与父提交树，以及 (2) 在此基础上额外提供每个种子变更的 diff hunk。实验结果表明，两种模型在这两类实验中的总体表现均不理想，但GPT-5的表现优于GPT-5-mini；此外，提供 diff hunk 能在一定程度上略微提升两者的性能。该数据集与初步研究揭示了当前LLM在代码变更影响分析中的局限性并为后续改进提供了基线。

---
## 11. DeliveryBench: Can Agents Earn Profit in Real World?

- 作者：Lingjun Mao, Jiawei Ren, Kun Zhou, Jixuan Chen, Ziqiao Ma, Lianhui Qin
- 子主题：Embodied AI / VLM
- 推荐：极度推荐
- 关键词：视觉-语言模型, 具身代理, 约束感知长时规划
- Abstract：http://arxiv.org/abs/2512.19234v1
- PDF：https://arxiv.org/pdf/2512.19234v1

**中文摘要**

大型语言模型（LLM）和视觉-语言模型（VLM）越来越多地被部署为具身代理，但现有基准大多集中在简单的短期任务，难以捕捉影响现实世界决策制定的复杂约束。为弥补这一差距，我们提出了 DeliveryBench，这是一个以现实世界外卖送餐职业为基础的城市级具身基准。外卖骑手天然面临长时目标（在数小时内最大化净利润）并须管理多种约束，例如送达时限、交通支出、车辆电量以及与其他骑手和顾客的必要互动。DeliveryBench 在程序生成的三维城市中实现这一场景，包含多样的道路网络、建筑、功能性地点、交通方式和真实的资源动态，从而能够系统地评估对约束敏感的长时规划能力。我们在九个城市中对多种基于VLM的代理进行了基准测试，并与人类玩家进行了比较。结果显示这些代理与人类存在显著性能差距，且普遍表现出短视行为，经常违反基本的常识性约束。此外，我们观察到不同模型呈现出明显的“个性”差异（例如更冒险的 GPT-5 与更保守的 Claude），这既凸显了当前基于VLM的具身代理在现实、约束密集环境中的脆弱性，也反映了其行为多样性。我们的代码、数据和基准已发布于 https://deliverybench.github.io。

---
## 12. MEEA: Mere Exposure Effect-Driven Confrontational Optimization for LLM Jailbreaking

- 作者：Jianyi Zhang, Shizhao Liu, Ziyin Zhou, Zhen Li
- 子主题：LLM
- 推荐：极度推荐
- 关键词：暴露效应驱动越狱, 多轮安全鲁棒性评估, 模拟退火优化
- Abstract：http://arxiv.org/abs/2512.18755v1
- PDF：https://arxiv.org/pdf/2512.18755v1

**中文摘要**

随着大型语言模型（LLM）的快速发展，其安全对齐的稳健性问题日益凸显。尽管现有的越狱研究探讨了单轮与多轮策略，大多数工作隐含地假定安全边界是静态的，未考虑上下文交互如何动态影响模型行为，导致稳定性与泛化性受限。针对这一空白，我们提出了 MEEA（Mere Exposure Effect Attack），一个受心理学“暴露效应”启发的、全自动黑箱多轮安全鲁棒性评估框架。MEEA 利用重复的低毒性语义暴露诱导模型有效安全阈值的逐步偏移，从而在持续交互中逐步腐蚀对齐约束。具体而言，MEEA 构建语义递进的提示链，并通过模拟退火策略在语义相似度、毒性和越狱效果的引导下进行优化。针对闭源与开源模型（包括 GPT-4、Claude-3.5 与 DeepSeek-R1）的大量实验表明，MEEA 在七个代表性基线之上始终取得更高的攻击成功率，平均攻击成功率（ASR）提升超过 20%。消融研究进一步验证了退火优化与上下文暴露机制的必要性。除提升攻击效能外，我们的结果表明 LLM 的安全行为本质上是动态且依赖历史的，这挑战了静态对齐边界的常见假设，强调了需要考虑交互历史的安全评估与防御机制。我们的代码已开源。

---
## 13. Enhancing Medical Large Vision-Language Models via Alignment Distillation

- 作者：Aofei Chang, Ting Wang, Fenglong Ma
- 子主题：医学LLM（视觉-语言）
- 推荐：极度推荐
- 关键词：医学视觉-语言模型, 对齐蒸馏, 视觉注意/可解释性
- Abstract：http://arxiv.org/abs/2512.18554v1
- PDF：https://arxiv.org/pdf/2512.18554v1

**中文摘要**

医学大规模视觉-语言模型（Med-LVLMs）在临床应用中展现出良好潜力，但由于视觉理解与文本生成之间的对齐不足，常出现幻觉式输出。本文识别出导致该问题的两大根本性限制：视觉表征学习不足和视觉注意力对齐性差。为了解决这些问题，本文提出了MEDALIGN，一种简单且轻量的对齐蒸馏框架，用于将领域特定的对比语言-图像预训练（CLIP）模型中的视觉对齐知识迁移到医学LVLM。MEDALIGN引入了两种蒸馏损失：基于视觉token级相似性结构的空间感知视觉对齐损失，以及引导注意力聚焦于诊断相关区域的注意力感知蒸馏损失。大量在医学报告生成和医学视觉问答（VQA）基准上的实验表明，MEDALIGN能持续提升模型的性能与可解释性，生成更具视觉依据的输出。

---
## 14. SWE-EVO: Benchmarking Coding Agents in Long-Horizon Software Evolution Scenarios

- 作者：Minh V. T. Thai, Tue Le, Dung Nguyen Manh, Huy Phan Nhat, Nghi D. Q. Bui
- 子主题：LLM
- 推荐：极度推荐
- 关键词：软件演化, 长时程多文件推理, 编码代理基准
- Abstract：http://arxiv.org/abs/2512.18470v1
- PDF：https://arxiv.org/pdf/2512.18470v1

**中文摘要**

现有针对 AI 编码代理的基准多集中于独立的、单一问题任务，例如修复一个 bug 或实现一个小功能。然而，真实世界的软件工程本质上是一个长期（long-horizon）的过程：开发者需要理解高层需求、规划跨多个文件的协调修改，并在多次迭代中演化代码库，同时保持现有功能不受破坏。我们提出 SWE-EVO，这是一个用于评估代理在长期软件演化挑战上的基准。该基准基于七个成熟开源 Python 项目的发布说明与版本历史构建，包含 48 个演化任务，要求代理实施多步修改，平均涉及 21 个文件，并通过平均 874 个测试用例的全面测试套件进行验证。对最先进模型的实验显示出显著的能力差距：即便是使用 OpenHands 的 GPT-5 在该基准上的解决率也仅为 21%，而在单一问题的 SWE-Bench Verified 上为 65%，表明当前代理在持续、多文件推理方面仍然存在显著困难。我们还提出了 Fix Rate 一种细粒度度量，用于捕捉在解决这些复杂、长期任务过程中的部分进展。

---
## 15. NEURO-GUARD: Neuro-Symbolic Generalization and Unbiased Adaptive Routing for Diagnostics -- Explainable Medical AI

- 作者：Midhat Urooj, Ayan Banerjee, Sandeep Gupta
- 子主题：医疗影像（计算机视觉）与医学LLM/神经-符号方法
- 推荐：极度推荐
- 关键词：神经-符号方法, 可解释医疗影像诊断, RAG 与 ViT 融合
- Abstract：http://arxiv.org/abs/2512.18177v1
- PDF：https://arxiv.org/pdf/2512.18177v1

**中文摘要**

准确且可解释的基于图像的诊断仍是医疗人工智能的核心挑战，特别是在数据有限、视觉线索微妙且临床决策风险较高的场景下。现有大多数视觉模型依赖纯数据驱动学习，产生黑盒式预测、解释性差且跨域泛化能力弱，限制了其临床应用。我们提出 NEURO-GUARD，一种新颖的知识引导视觉框架，将 Vision Transformer (ViT) 与基于语言的推理相结合，以提升性能、透明性与领域鲁棒性。NEURO-GUARD 采用检索增强生成（RAG）机制实现自我验证，其中大型语言模型（LLM）迭代生成、评估并细化用于医学图像的特征提取代码。通过以临床指南和专家知识为依据，该过程逐步增强了特征检测与分类能力，超越了纯数据驱动的基线方法。在糖尿病视网膜病变分类的四个基准数据集（APTOS、EyePACS、Messidor-1、Messidor-2）上的大量实验表明，NEURO-GUARD 比仅使用 ViT 的基线提高了 6.2% 的准确率（84.69% 对 78.4%），并在领域泛化上获得约 5% 的提升。对基于 MRI 的癫痫发作检测的额外评估进一步证实了其跨域鲁棒性，持续优于现有方法。总体而言，NEURO-GUARD 将符号化的医学推理与子符号的视觉学习相结合，实现了可解释、知识感知且具泛化能力的医学图像诊断，并在多个数据集上达到了先进性能。

---
## 16. Tool-Augmented Hybrid Ensemble Reasoning with Distillation for Bilingual Mathematical Problem Solving

- 作者：Peiqing Lu, Yuan Zhang, Haoyun Zhang, Jiasen Zheng, Kejian Tong, Wenjun Wu
- 子主题：LLM
- 推荐：极度推荐
- 关键词：双语数学推理, 工具增强的强化学习, 知识蒸馏与自适应集成
- Abstract：http://arxiv.org/abs/2512.19093v1
- PDF：https://arxiv.org/pdf/2512.19093v1

**中文摘要**

双语数学问题求解要求在语言推理与符号计算之间建立明确的联系。大型语言模型在处理语言表达方面表现优异，但在精确计算上较弱。本文提出了HERALD（Hybrid Ensemble Reasoning with Adaptive Learning and Distillation）框架，将推理与计算能力结合起来，融合了NuminaMath-7B-TIR、GPT-4o 和 Mistral-7B 三类模型。HERALD 采用自适应路由、基于工具的强化学习以及知识蒸馏来连接不同的推理路径；置信度校准用于维持加权稳定性，双路径校验用于保证结果正确性。强化学习用于控制工具调用以减少冗余，蒸馏则在不损害准确性的前提下降低延迟。实验表明，将符号校验、自适应集成和双语微调相结合，有助于同时实现流畅的语言推理和精确的计算，HERALD 为多语言数学推理问题提供了一种在准确性、稳定性和可解释性方面均有改进的实用解决方案。

---
## 17. SafeMed-R1: Adversarial Reinforcement Learning for Generalizable and Robust Medical Reasoning in Vision-Language Models

- 作者：A. A. Gde Yogi Pramana, Jason Ray, Anthony Jaya, Michael Wijaya
- 子主题：医疗视觉-语言模型（Medical VLM）/ 医学VQA / 鲁棒性与对抗训练
- 推荐：极度推荐
- 关键词：医学视觉-语言模型, 对抗鲁棒性/对抗训练, 链式思维推理
- Abstract：http://arxiv.org/abs/2512.19317v1
- PDF：https://arxiv.org/pdf/2512.19317v1

**中文摘要**

视觉-语言模型（VLMs）在医学视觉问答（Medical VQA）方面展现出显著潜力，但其在临床部署中受到对抗攻击导致的脆弱性严重制约。标准的对抗训练虽然在较简单任务上有效，但常常损害模型的泛化能力和生成的临床推理质量。为此我们提出了 SafeMed-R1，一种混合防御框架，在保证稳健性的同时保持高质量、可解释的医学推理。SafeMed-R1 采用两阶段策略：训练阶段将对抗训练与分组相对策略优化（Adversarial Training with Group Relative Policy Optimization，AT-GRPO）结合，以针对最差情况扰动显式强化推理过程；推理阶段引入随机平滑（Randomized Smoothing）以提供经认证的 L2 范数鲁棒性保证。我们在包含八种医学成像模态、超过 88,000 条样本的 OmniMedVQA 基准上进行了评估。实验结果表明，尽管标准微调的 VLM 在干净输入上可达到 95% 的准确率，但在 PGD 攻击下精度约降至 25%。相比之下，SafeMed-R1 在相同对抗条件下仍能维持 84.45% 的准确率，鲁棒性提升约 59 个百分点。此外，我们还发现显式训练链式思维（chain-of-thought）推理的模型在对抗鲁棒性上优于仅依赖指令的变体，表明可解释性与安全性之间存在协同效应，这对医学 AI 系统尤为重要。

---
## 18. HARBOR: Holistic Adaptive Risk assessment model for BehaviORal healthcare

- 作者：Aditya Siddhant
- 子主题：Medical LLM（临床NLP）
- 推荐：极度推荐
- 关键词：行为健康风险评估, 医疗大语言模型, 纵向多模态数据集
- Abstract：http://arxiv.org/abs/2512.18829v1
- PDF：https://arxiv.org/pdf/2512.18829v1

**中文摘要**

行为健康风险评估仍然是一个具有挑战性的问题，原因在于患者数据的高度多模态特性以及情绪和情感障碍的时间动态性。尽管大语言模型（LLMs）在推理能力上表现出色，但其在结构化临床风险评分任务中的有效性尚不明确。在本工作中，我们提出了 HARBOR，一种针对行为健康的语言模型，旨在预测一种离散的情绪与风险评分——Harbor Risk Score（HRS），该评分为整数刻度，范围从 -3（重度抑郁）到 +3（躁狂）。我们同时发布了 PEARL，一套纵向行为健康数据集，包含来自三名患者四年每月观察的数据，涵盖生理、行为以及自我报告的心理健康信号。我们在多种评估设置与消融实验中对传统机器学习模型、专有大模型以及 HARBOR 进行了基准测试。结果表明，HARBOR 优于经典基线方法和现成的通用大语言模型，其准确率达到 69%，而逻辑回归为 54%，表现最强的专有大模型基线仅为 29%。

---
## 19. Grad: Guided Relation Diffusion Generation for Graph Augmentation in Graph Fraud Detection

- 作者：Jie Yang, Rui Zhang, Ziyang Cheng, Dawei Cheng, Guang Yang, Bo Wang
- 子主题：图学习/图神经网络 (Graph Learning/GNN)
- 推荐：极度推荐
- 关键词：图增强, 欺诈检测, 关系扩散
- Abstract：http://arxiv.org/abs/2512.18133v1
- PDF：https://arxiv.org/pdf/2512.18133v1

**中文摘要**

随着在线支付安全的重要性日益突出，金融场景下的图欺诈检测（Graph Fraud Detection, GFD）成为迫切的研究课题。然而，现实中有组织的犯罪团伙日趋专业化，欺诈者通过模仿平台采集的行为数据来隐藏身份，使其关键特征在很大程度上与良性用户一致——我们称之为自适应伪装（Adaptive Camouflage）。这导致平台数据库中欺诈与良性用户的行为差异被压缩，现有的GFD模型因此失效。为了解决该问题，我们提出了一种基于关系扩散的图增强模型Grad。具体地，Grad利用有监督的图对比学习模块来放大欺诈-良性差异，并采用引导式关系扩散生成器从零生成辅助的同类（homophilic）关系。在此基础上，弱的欺诈信号在邻域聚合过程中被放大，从而足够明显以被检测到。我们在来自微信支付（拥有数十亿用户的大型在线支付平台）提供的两个真实世界数据集以及三个公开数据集上进行了大量实验。结果表明，所提模型Grad在多种场景下均优于现有最先进方法，在AUC和AP上分别最多提高了11.10%和43.95%。我们的代码已开源：https://github.com/AI4Risk/antifraud 和 https://github.com/Muyiiiii/WWW25-Grad。

---
## 20. From Prompt to Product: A Human-Centered Benchmark of Agentic App Generation Systems

- 作者：Marcos Ortiz, Justin Hill, Collin Overbay, Ingrida Semenec, Frederic Sauve-Hoover, Jim Schwoebel, Joel Shor
- 子主题：LLM (Agentic 系统 / 人本评估)
- 推荐：极度推荐
- 关键词：Agentic AI, 提示到应用, 人本评估
- Abstract：http://arxiv.org/abs/2512.18080v1
- PDF：https://arxiv.org/pdf/2512.18080v1

**中文摘要**

能够从自然语言提示生成全栈 Web 应用的自主（agentic）AI 系统（“从提示到应用”）代表了软件开发方式的一次重要变革。然而，这类系统的评估仍然充满挑战，因为视觉美观、功能正确性与用户信任常常并不一致。因此，目前尚不清楚在现实、人本的评估标准下现有的提示到应用工具如何比较。本文提出了一个以人为中心的基准用于评估提示到应用系统，并对三个广泛使用的平台——Replit、Bolt 和 Firebase Studio——进行了大规模比较研究。我们使用覆盖常见 Web 应用任务的 96 条多样化提示，生成了 288 个独特的应用产物。通过一项涵盖 205 名参与者并基于 1,071 次质量过滤后的成对比较的大规模人工评分研究，我们评估了基于任务的易用性、视觉吸引力、感知完成度和用户信任等维度。结果表明，这些系统并非可互换：Firebase Studio 在所有人工评估维度上均稳定优于竞争平台，在易用性、信任、视觉吸引力和视觉适配性方面取得最高胜率；Bolt 在视觉吸引力方面有竞争力，但在可用性与信任上落后于 Firebase；Replit 在大多数指标上则落后于二者。研究强调了提示到应用系统在视觉抛光与功能可靠性之间存在的持续差距，并证明了基于交互、基于任务的评估的必要性。我们同时发布了基准框架、提示集和生成的产物，以支持可复现评估与后续研究。

---
## 21. Victor Calibration (VC): Multi-Pass Confidence Calibration and CP4.3 Governance Stress Test under Round-Table Orchestration

- 作者：Victor Stasiuc, Round Table Collaboration
- 子主题：LLM
- 推荐：极度推荐
- 关键词：置信度校准, LLM 安全对齐, 行为审计/治理压力测试
- Abstract：http://arxiv.org/abs/2512.17956v1
- PDF：https://arxiv.org/pdf/2512.17956v1

**中文摘要**

标题：Victor 校准（VC）：在圆桌协同下的多轮置信度校准与 CP4.3 治理压力测试

摘要：安全对齐可能使最前沿的大模型（LM）过度保守，导致通过回避或错误拒绝而降低协作质量。我们提出一个轻量级工具包，包含三部分： (1) Victor 校准（VC），一种多轮协议，通过迭代性证据再评估来引出标量置信度代理 T（满足 T0<T1<T2）；(2) FD-Lite，一种仅基于行为的现象学审计方法，采用固定锚定短语和元前缀陷阱以避免拟人化主张；(3) CP4.3，一项用于检验秩不变性和分配单调性（M6）的治理压力测试。在对 Claude 4.5 系列模型（Haiku、Sonnet no-thinking、Sonnet thinking）和 Opus 的测试中，我们观察到 VC 轨迹的单调性且未违反安全不变量，同时 CP4.3 行为稳定。（注：“Opus”指通过标准 UI 账号访问的单次 Claude Opus 4.1 会话，如表 1 所示。）本工作由单一操作者（n=1）完成，旨在生成假设；我们明确邀请研究社区对工作进行复现、质疑与扩展。文中附带了提示模板和工件计划，以便独立验证。

---
## 22. Vibe Reasoning: Eliciting Frontier AI Mathematical Capabilities -- A Case Study on IMO 2025 Problem 6

- 作者：Jiaao Wu, Xian Zhang, Fan Yang, Yinpeng Dong
- 子主题：LLM
- 推荐：极度推荐
- 关键词：数学推理, 人机协同, 模型编排
- Abstract：http://arxiv.org/abs/2512.19287v1
- PDF：https://arxiv.org/pdf/2512.19287v1

**中文摘要**

我们提出了“Vibe Reasoning”——一种用于解决复杂数学问题的人机协同范式。我们的关键观点是：前沿 AI 模型已经具备解决困难问题所需的知识，但它们常常不知道如何、何时或以何种方式应用这些知识。Vibe Reasoning 通过通用元提示（meta-prompts）、代理化落地（agentic grounding）和模型编排（model orchestration）将 AI 的潜在能力转化为可显现的解题能力。我们以 IMO 2025 第6题（一个组合优化问题）为案例验证该范式——在公开场景下自治 AI 系统曾报告失败。我们的解决方案将 GPT-5 的探索能力与 Gemini 3 Pro 的证明能力相结合，利用带有 Python 代码执行和基于文件的记忆的代理化工作流，得出了正确答案 2112 并构建了严谨的数学证明。通过多次迭代改进，我们发现代理化落地和模型编排是必需的，并且人类提示从问题特定的线索演化为通用且可迁移的元提示。我们分析了为何高能力模型在自治时会失败、每个组件如何针对特定失败模式发挥作用，并提炼出有效 Vibe Reasoning 的若干原则。研究表明，轻量级的人类引导可以释放前沿模型在数学推理方面的潜力。该工作仍在进行中，我们正在开发自动化框架并开展更大范围的评估，以进一步验证 Vibe Reasoning 的普适性与有效性。

---
## 23. Anatomy-R1: Enhancing Anatomy Reasoning in Multimodal Large Language Models via Anatomical Similarity Curriculum and Group Diversity Augmentation

- 作者：Ziyang Song, Zelin Zang, Zuyao Chen, Xusheng Liang, Dong Yi, Jinlin Wu, Hongbin Liu, Jiebo Luo
- 子主题：医学多模态大模型 (Medical MLLM)
- 推荐：极度推荐
- 关键词：解剖学推理, 课程化学习, 问题多样性增强
- Abstract：http://arxiv.org/abs/2512.19512v1
- PDF：https://arxiv.org/pdf/2512.19512v1

**中文摘要**

多模态大语言模型（MLLM）在自然图像推理方面已取得显著进展，但其在医学影像，尤其是临床解剖手术图像领域的潜力尚未被充分挖掘。解剖学理解任务要求模型给出精确且具临床一致性的答案，但由于医学数据的复杂性和高质量专家标注的稀缺，这一目标难以实现，从而限制了传统监督微调（SFT）策略的效力。尽管近期工作表明组相对策略优化（Group Relative Policy Optimization, GRPO）可以在无需大量数据的情况下提升MLLM的推理能力，我们发现GRPO在解剖识别任务上存在两个制约因素：一是不同解剖结构之间的知识不能被有效共享，导致信息增益不均、模型难以收敛；二是模型容易快速收敛到单一推理路径，抑制了多样化策略的探索。为了解决这些问题，我们提出了两种新的方法。首先，通过基于答案选项相似性来控制题目难度，我们引入了一种渐进式学习策略——解剖相似性课程学习（Anatomical Similarity Curriculum Learning），使模型能够逐步掌握复杂问题；其次，我们提出了一种问题增强方法——群体多样性问题增强（Group Diversity Question Augmentation），以扩展模型在难题上的搜索空间，减缓产生单一回答倾向。基于SGG-VQA和OmniMedVQA基准的全面实验显示，我们的方法在两个基准上均取得了显著提升，证明了其在增强医学多模态大模型解剖学推理能力方面的有效性。代码已开源于：https://github.com/tomato996/Anatomy-R1

---
## 24. An Empirical Study of Developer-Provided Context for AI Coding Assistants in Open-Source Projects

- 作者：Shaokang Jiang, Daye Nam
- 子主题：LLM
- 推荐：很推荐
- 关键词：开发者上下文, AI 编码助手, 项目指令分类
- Abstract：http://arxiv.org/abs/2512.18925v1
- PDF：https://arxiv.org/pdf/2512.18925v1

**中文摘要**

尽管大型语言模型（LLM）已展现出显著能力，研究表明其有效性不仅取决于显式提示，还依赖于更广泛的上下文信息。在软件工程领域，这一要求尤为突出：现有项目的目标、架构和协作约定都会显著影响模型生成结果的质量。为此，许多 AI 编码助手引入了让开发者编写持久的、机器可读的指令（用于编码项目特定约束）的机制。尽管这种做法愈发普遍，但这些指令的具体内容仍未被系统研究。本文通过一项大规模的实证研究来刻画这一新兴的开发者提供上下文形式。我们对 401 个包含 cursor 规则（cursor rules）的开源代码库进行了定性分析，归纳出开发者认为重要的项目上下文类别，形成了一个全面的分类法，该分类法由五个高层主题组成：约定（Conventions）、指导方针（Guidelines）、项目信息（Project Information）、LLM 指令（LLM Directives）和示例（Examples）。我们的研究还考察了这些上下文在不同项目类型和编程语言间的差异，并讨论了对下一代具备上下文感知能力的 AI 开发工具的启示。

---
## 25. PIPCFR: Pseudo-outcome Imputation with Post-treatment Variables for Individual Treatment Effect Estimation

- 作者：Zichuan Lin, Xiaokai Huang, Jiate Liu, Yuxuan Han, Jia Chen, Xiapeng Wu, Deheng Ye
- 子主题：因果推断（ITE / 反事实回归）
- 推荐：很推荐
- 关键词：个体化治疗效果估计, 后处理变量, 伪结果插补
- Abstract：http://arxiv.org/abs/2512.18737v1
- PDF：https://arxiv.org/pdf/2512.18737v1

**中文摘要**

个体化处理效果（ITE）估计旨在预测因处理改变而引起的个体结果变化。在观察性数据中，一个根本性挑战是我们需要推断在不同处理下的结果差异，但每个个体只能在一种处理下被观测到。现有方法通过训练推断的伪结果或构建匹配实例对来缓解这一限制，然而近期工作大多忽视了后处理变量（post-treatment variables）对结果的潜在影响。这种忽视导致方法无法充分捕捉结果的可变性，从而增加了反事实预测的方差。本文提出了PIPCFR（Pseudo-outcome Imputation with Post-treatment Variables for Counterfactual Regression），一种将后处理变量纳入伪结果插补过程的新方法。我们分析了利用后处理变量时面临的挑战，并给出了一个新的ITE风险理论界限，明确将后处理变量与ITE估计精度联系起来。与忽略这些变量或施加严格假设的既有方法不同，PIPCFR学习能保留有信息成分并减轻偏差的有效表示。实证评估（包括真实世界和模拟数据）表明，PIPCFR相比现有方法在ITE误差上显著更低。

---
## 26. $M^3-Verse$: A "Spot the Difference" Challenge for Large Multimodal Models

- 作者：Kewei Wei, Bocheng Hu, Jie Cao, Xiaohan Chen, Zhengxi Lu, Wubing Xia, Weili Xu, Jiaao Wu, Junchen He, Mingyu Jia, Ciyun Zhao, Ye Sun, Yizhi Li, Zhonghan Zhao, Jian Zhang, Gaoang Wang
- 子主题：LMM（多模态模型）
- 推荐：很推荐
- 关键词：多模态学习, 状态变化理解, 基准评测
- Abstract：http://arxiv.org/abs/2512.18735v1
- PDF：https://arxiv.org/pdf/2512.18735v1

**中文摘要**

现代大型多模态模型（LMM）在静态图像和单一时空状态理解方面表现出色，但它们在理解共享空间上下文中、两个不同视频观测之间对象动态变化的能力尚未得到充分研究。对在一致环境中推理对象状态变换的能力，对于空间智能的发展尤为重要。本文提出了 M^3-Verse（Multi-Modal, Multi-State, Multi-Dimensional）基准，用以系统评估这一能力。该基准基于成对视频，提供室内场景在状态变化前后的多视角观测，包含270个场景和2932个问题，细分为50余个子任务以探测四大核心能力。我们在16个最先进的LMM上进行了评测，发现其在跟踪状态转换方面存在明显局限。为应对这些挑战，本文进一步提出了一个简单而有效的基线方法，在多状态感知上取得了显著性能提升。M^3-Verse 为推动下一代对动态视觉世界具备更全面理解的模型发展提供了具有挑战性的新测试平台。构建流程与完整基准数据分别可在：https://github.com/Wal-K-aWay/M3-Verse_pipeline 和 https://www.modelscope.cn/datasets/WalKaWay/M3-Verse 获取。

---
## 27. KeenKT: Knowledge Mastery-State Disambiguation for Knowledge Tracing

- 作者：Zhifei Li, Lifan Chen, Jiali Yi, Xiaoju Hou, Yue Zhao, Wenxin Huang, Miao Zhang, Kui Xiao, Bing Yang
- 子主题：知识追踪 / 教育数据挖掘
- 推荐：很推荐
- 关键词：知识追踪, 正态-逆高斯（NIG）分布, 扩散去噪与对比学习
- Abstract：http://arxiv.org/abs/2512.18709v1
- PDF：https://arxiv.org/pdf/2512.18709v1

**中文摘要**

知识追踪（KT）旨在基于学生的历史学习交互动态建模其对知识概念的掌握情况。当前大多数方法依赖单点估计，无法将真实能力与一时的突发表现或粗心行为区分开来，从而在判定掌握度时产生模糊性。为了解决这一问题，我们提出了用于知识追踪的知识掌握状态消歧模型KeenKT，该模型在每次交互处使用正态-逆高斯（NIG）分布表示学生的知识状态，从而刻画学生学习行为中的波动。此外，我们设计了基于NIG距离的注意力机制来建模知识状态的动态演化。为增强模型鲁棒性，我们还引入了基于扩散的去噪重建损失和分布式对比学习损失。大量在六个公开数据集上的实验表明，KeenKT在预测准确性和对行为波动的敏感性方面均优于最先进的KT模型，最高可分别带来5.85%的AUC提升和6.89%的ACC提升。

---
## 28. EchoTrail-GUI: Building Actionable Memory for GUI Agents via Critic-Guided Self-Exploration

- 作者：Runze Li, Yuwen Zhai, Bo Xu, LiWu Xu, Nian Shi, Wei Zhang, Ran Lin, Liang Wang
- 子主题：VLM（图形界面代理）
- 推荐：很推荐
- 关键词：可操作记忆, 自我探索, GUI代理
- Abstract：http://arxiv.org/abs/2512.19396v1
- PDF：https://arxiv.org/pdf/2512.19396v1

**中文摘要**

当代基于大型视觉-语言模型（VLM）的图形界面（GUI）代理能力虽有所提高，但通常存在关键局限：将每个任务孤立处理，缺乏系统性地从过去成功经验中学习的机制。这种数字化“健忘”导致性能次优、重复犯错以及对新任务的泛化能力差。为弥补这一缺陷，我们提出了 EchoTrail-GUI，一种模拟人类经验学习的框架，通过为代理构建动态且可调用的记忆来提升表现。该框架由三部分组成：首先，在“经验探索”阶段，代理自主与 GUI 环境交互，构建由奖励模型验证的成功任务轨迹数据库；关键在于，整个知识库构建过程完全自动化，无需人工监督。其次，在“记忆注入”阶段，当接到新任务时，系统高效检索最相关的历史轨迹作为可操作的“记忆”。最后，在“GUI 任务推理”阶段，这些记忆以场景上下文的形式注入，指导代理的推理与决策。我们在 Android World 和 AndroidLab 等基准上进行了实验，结果表明 EchoTrail-GUI 显著提高了基线代理的任务成功率与运行效率，验证了结构化记忆在构建更健壮智能 GUI 自动化中的有效性。

---
## 29. DSTED: Decoupling Temporal Stabilization and Discriminative Enhancement for Surgical Workflow Recognition

- 作者：Yueyao Chen, Kai-Ni Wang, Dario Tayupo, Arnaud Huaulm'e, Krystel Nyangoh Timoh, Pierre Jannin, Qi Dou
- 子主题：CV（医疗计算机视觉）
- 推荐：很推荐
- 关键词：手术流程识别, 时序稳定化, 不确定性感知原型
- Abstract：http://arxiv.org/abs/2512.19387v1
- PDF：https://arxiv.org/pdf/2512.19387v1

**中文摘要**

目的：手术流程识别可为计算机辅助手术提供上下文感知的辅助与技能评估。尽管近年取得进展，目前的方法仍面临两大关键挑战：连续帧之间的预测抖动以及模糊阶段的辨识能力不足。本文旨在通过有选择地传播可靠的历史信息并对难判样本显式建模不确定性，构建一个更加稳定且具判别性的识别框架。
方法：我们提出了双路径框架 DSTED，包含可靠记忆传播（Reliable Memory Propagation, RMP）和不确定性感知原型检索（Uncertainty-Aware Prototype Retrieval, UPR）。RMP 通过多准则的可靠性评估，过滤并融合高置信度的历史特征以维持时序一致性；UPR 从高不确定性样本中构建可学习的类特异性原型，并通过自适应原型匹配精炼模糊帧的表征。最后，基于预测置信度的门控机制在两条路径之间动态平衡信息流。
结果：在 AutoLaparo-hysterectomy 数据集上，我们的方法达到 84.36% 的准确率和 65.51% 的 F1 分数，分别较第二名提升 3.51% 和 4.88%。消融实验表明 RMP 和 UPR 分别带来了 2.19% 和 1.93% 的增益，且二者组合存在协同效应。大量分析验证了方法在减少时序抖动和改进困难相位过渡上的显著效果。
结论：所提双路径设计为稳定的手术流程识别引入了一种新的范式，证明了将时序一致性建模与相位模糊判别解耦可以带来更优的性能和更高的临床适用性。

---
## 30. From Pixels to Predicates Structuring urban perception with scene graphs

- 作者：Yunlong Liu, Shuyang Li, Pengyuan Liu, Yu Zhang, Rudi Stouffs
- 子主题：CV（计算机视觉）
- 推荐：很推荐
- 关键词：场景图, 城市感知, 图表示学习
- Abstract：http://arxiv.org/abs/2512.19221v1
- PDF：https://arxiv.org/pdf/2512.19221v1

**中文摘要**

感知研究越来越多地以街景图像为建模对象，但许多方法仍仅依赖像素特征或对象共现统计，忽视了塑造人类感知的显式关系。本研究提出了一个三阶段管线，将街景视图图像（SVI）转化为用于预测六个感知指标的结构化表示。第一阶段使用开放集全景场景图模型（OpenPSG）解析每张图像，提取“对象-谓词-对象”三元组；第二阶段通过异构图自编码器（GraphMAE）学习紧凑的场景级嵌入；第三阶段用神经网络从这些嵌入预测感知得分。我们将该方法与仅基于图像的基线在准确率、精确率和跨城市泛化能力上进行了比较。结果表明：(i) 本方法在感知预测准确率上比基线平均提升26%，(ii) 在跨城市预测任务中保持了较强的泛化性能。此外，结构化表示有助于解释哪些关系模式会降低城市场景的感知分数，例如“墙上涂鸦”和“车停在人行道上”。总体而言，本研究表明基于图的结构为建模城市感知提供了富有表现力、可泛化且可解释的信号，推动了以人为中心和情境感知的城市分析研究。

---
## 31. On the Koopman-Based Generalization Bounds for Multi-Task Deep Learning

- 作者：Mahdi Mohammadigohari, Giuseppe Di Fatta, Giuseppe Nicosia, Panos M. Pardalos
- 子主题：多任务学习/深度学习理论
- 推荐：很推荐
- 关键词：Koopman算子, 多任务深度学习, 泛化界
- Abstract：http://arxiv.org/abs/2512.19199v1
- PDF：https://arxiv.org/pdf/2512.19199v1

**中文摘要**

本文使用算子理论方法为多任务深度神经网络建立了泛化界。作者通过利用权重矩阵的小条件数并引入定制的Sobolev空间作为扩展的假设空间，提出了比传统基于范数的方法更紧的界限。该增强的泛化界即便在单输出情形下也仍然成立，且优于已有的基于Koopman方法的界。所得框架保持了灵活性并与网络宽度无关，在核方法背景下为多任务深度学习提供了更精确的理论理解。

---
## 32. Fusion of Multiscale Features Via Centralized Sparse-attention Network for EEG Decoding

- 作者：Xiangrui Cai, Shaocheng Ma, Lei Cao, Jie Li, Tianyu Liu, Yilin Dong
- 子主题：脑机接口(BCI)/EEG解码
- 推荐：很推荐
- 关键词：多尺度特征融合, 稀疏注意力, EEG/脑机接口
- Abstract：http://arxiv.org/abs/2512.18689v1
- PDF：https://arxiv.org/pdf/2512.18689v1

**中文摘要**

脑电图（EEG）信号解码是将大脑活动转换为可执行指令的关键技术，为直接脑机接口与智能交互奠定基础。为了解决EEG信号固有的时空异质性，本文提出了一种多分支并行架构，每个时间尺度配备独立的空间特征提取模块。为进一步增强多分支特征融合，我们提出了基于集中式稀疏注意力网络的多尺度特征融合方法（EEG-CSANet）。该网络采用主-辅分支结构：主分支通过多尺度自注意力建模核心时空模式，辅分支则通过稀疏交叉注意力促进高效的局部交互。实验结果表明，EEG-CSANet在五个公开数据集（BCIC-IV-2A、BCIC-IV-2B、HGD、SEED 和 SEED-VIG）上均取得了最先进的性能，准确率分别为88.54%、91.09%、99.43%、96.03%和90.56%，展示了其在多种EEG解码任务上的强适应性与鲁棒性。文中还进行了大量消融研究以增强模型的可解释性。我们希望EEG-CSANet能成为EEG信号解码领域的有前景的基线模型。源码已公开： https://github.com/Xiangrui-Cai/EEG-CSANet

---
## 33. Remoe: Towards Efficient and Low-Cost MoE Inference in Serverless Computing

- 作者：Wentao Liu, Yuhao Hu, Ruiting Zhou, Baochun Li, Ne Wang
- 子主题：LLM
- 推荐：很推荐
- 关键词：稀疏专家模型, 无服务器推理, 内存与副本优化
- Abstract：http://arxiv.org/abs/2512.18674v1
- PDF：https://arxiv.org/pdf/2512.18674v1

**中文摘要**

混合专家（Mixture-of-Experts, MoE）已成为大规模语言模型（LLM）中的主流架构，因其通过稀疏激活专家来扩展模型容量。然而，MoE 中大量专家的存在在推理阶段带来了高昂的成本，主要源于参数缓存导致的内存开销；由于专家的激活依赖于输入，这些成本难以通过简单的模型分区来缓解。为了解决这些问题，我们提出了 Remoe，一种为无服务器（serverless）计算定制的异构 MoE 推理系统。Remoe 将非专家模块部署在 GPU 上、将专家模块部署在 CPU 上，并进一步将不常被激活的专家卸载到独立的无服务器函数中，以降低内存占用并实现并行执行。系统包含三项关键技术： (1) 基于输入语义相似性的相似提示搜索（Similar Prompts Searching, SPS）算法，用于预测专家激活模式；(2) 主模型预分配（Main Model Pre-allocation, MMP）算法，通过最坏情况内存估计保证服务级目标（SLO）；(3) 基于拉格朗日对偶与最长处理时间（LPT）算法的联合内存与副本优化框架。我们在 Kubernetes 上实现了 Remoe，并在多个 LLM 基准上进行了评估。实验结果表明，与最先进基线相比，Remoe 最多可将推理成本降低 57%，并将冷启动延迟降低 47%。

---
## 34. A Multi-agent Text2SQL Framework using Small Language Models and Execution Feedback

- 作者：Thanh Dat Hoang, Thanh Trung Huynh, Matthias Weidlich, Thanh Tam Nguyen, Tong Chen, Hongzhi Yin, Quoc Viet Hung Nguyen
- 子主题：NLP (Text2SQL/LLMs)
- 推荐：很推荐
- 关键词：Text2SQL, 小型语言模型（SLM）, 多智能体强化学习/执行反馈
- Abstract：http://arxiv.org/abs/2512.18622v1
- PDF：https://arxiv.org/pdf/2512.18622v1

**中文摘要**

Text2SQL（将自然语言文本生成 SQL 查询）是数据工程中的一项关键挑战。近年来，大型语言模型（LLMs）凭借其出色的理解与生成能力在该任务上表现优异，但出于隐私和成本考虑，许多企业无法使用基于外部服务的大型模型，而转向可在本地部署的开源小型语言模型（SLMs）。然而，SLMs 缺乏大型模型的泛化能力，导致在复杂任务（如 Text2SQL）上的效果不足。为了解决这些限制，我们提出了 MATS，一种专为 SLM 设计的新的 Text2SQL 框架。MATS 采用多智能体机制，给辅助智能体分配专门角色，减轻单个智能体的负担并促进交互；同时基于执行过程得到的反馈设计了强化学习训练方案，用以对这些智能体进行对齐，从而在模型规模受限的情况下仍能保持有竞争力的性能。在基准数据集上的评估表明，MATS 在单 GPU 服务器上部署时，使用显著更少的参数即可达到与大规模 LLMs 相当的准确率。我们的源码与数据集已开源于：https://github.com/thanhdath/mats-sql。

---
## 35. Modality-Dependent Memory Mechanisms in Cross-Modal Neuromorphic Computing

- 作者：Effiong Blessing, Chiung-Yi Tseng, Somshubhra Roy, Junaid Rehman, Isaac Nkrumah
- 子主题：神经形态计算（SNN）与跨模态学习
- 推荐：很推荐
- 关键词：神经形态计算, 脉冲神经网络（SNN）, 跨模态记忆机制
- Abstract：http://arxiv.org/abs/2512.18575v1
- PDF：https://arxiv.org/pdf/2512.18575v1

**中文摘要**

记忆增强的脉冲神经网络（SNN）有望实现能效高的神经形态计算，但其在不同感知模态间的泛化能力尚未被充分研究。我们首次对SNN中多种记忆机制进行了全面的跨模态消融研究，评估了Hopfield网络、分层门控递归网络（HGRN）和监督对比学习（SCL）在视觉（N-MNIST）与听觉（SHD）神经形态数据集上的表现。通过对五种架构的系统评估，我们发现显著的模态依赖性：Hopfield网络在视觉任务上达到97.68%的准确率，但在听觉任务上仅为76.15%（相差21.53个百分点），表明存在严重的模态特化；而SCL在跨模态上表现更均衡（视觉96.72%，听觉82.16%，相差14.56个百分点）。联合多模态训练下的HGRN在统一部署时实现了94.41%的视觉准确率与79.37%的听觉准确率（平均88.78%），与并行部署的HGRN性能相当。定量的刻痕（engram）分析显示模态间对齐较弱（相似度0.038），验证了我们采用并行架构的设计合理性。我们的工作首次提供了神经形态系统中记忆机制存在模态专门化的实证证据，并报告了相较于传统神经网络高达603倍的能效提升。

---
## 36. ESearch-R1: Learning Cost-Aware MLLM Agents for Interactive Embodied Search via Reinforcement Learning

- 作者：Weijie Zhou, Xuangtang Xiong, Ye Tian, Lijun Yue, Xinyu Wu, Wei Li, Chaoyang Zhao, Honghui Dong, Ming Tang, Jinqiao Wang, Zhengyou Zhang
- 子主题：MLLM / 具身智能 / 强化学习
- 推荐：很推荐
- 关键词：多模态大模型, 具身智能, 成本感知强化学习
- Abstract：http://arxiv.org/abs/2512.18571v1
- PDF：https://arxiv.org/pdf/2512.18571v1

**中文摘要**

多模态大语言模型（MLLM）已使具身代理在规划和推理方面表现出显著能力。然而，面对模糊的自然语言指令（例如在杂乱房间中“取回工具”），现有代理常难以在昂贵的物理探索成本与与人交互的认知成本之间取得平衡。它们通常将消歧视视为被动感知问题，缺乏为最小化总任务执行成本而进行的策略性推理。为填补这一空白，我们提出了 ESearch-R1，一种成本感知的具身推理框架，将交互式对话（Ask）、情节记忆检索（GetMemory）和物理导航（Navigate）统一为单一决策流程。我们引入了 HC-GRPO（异质成本感知的群体相对策略优化）。不同于依赖单独价值评估器的传统 PPO，HC-GRPO 通过对一组推理轨迹进行采样，并强化那些在信息增益与异质成本（如导航时间与人类注意力成本）之间实现最优权衡的轨迹来直接优化 MLLM。大量在 AI2-THOR 环境中的实验表明，ESearch-R1 显著优于基于 ReAct 的标准代理，在提高任务成功率的同时将总体运营成本约降低了 50%，验证了 GRPO 在使 MLLM 代理与物理世界约束对齐方面的有效性。

---
## 37. Detection of AI Generated Images Using Combined Uncertainty Measures and Particle Swarm Optimised Rejection Mechanism

- 作者：Rahul Yumlembam, Biju Issac, Nauman Aslam, Eaby Kollonoor Babu, Josh Collyer, Fraser Kennedy
- 子主题：CV
- 推荐：很推荐
- 关键词：不确定性融合, AI生成图像检测, 粒子群优化
- Abstract：http://arxiv.org/abs/2512.18527v1
- PDF：https://arxiv.org/pdf/2512.18527v1

**中文摘要**

随着 AI 生成图像愈发趋近于摄影真实，区分其与自然图像变得越来越困难。本文提出了一种鲁棒的检测框架，基于多源不确定性度量来判断是否可信或拒绝模型预测。我们侧重于三种互补技术：Fisher 信息量（刻画模型参数对输入变化的敏感性）、基于蒙特卡洛 Dropout 的熵不确定性（反映预测的可变性）、以及采用高斯过程分类器的深度核学习框架所给出的预测方差。为了将这些异构不确定性信号有效融合，本文利用粒子群优化（PSO）学习最优权重并自适应确定拒绝阈值。模型在 Stable Diffusion 生成的数据上训练，并在 GLIDE、VQDM、Midjourney、BigGAN 和 StyleGAN3 等多种生成器上评估，这些评测集包含显著的分布转移。结果显示：尽管在同分布下诸如预测概率和基于 Fisher 的度量表现良好，但在分布转移场景下其效果显著下降；相反，组合不确定性度量在未见生成器上能稳定拒绝约 70% 的错误预测，有效过滤了大部分被误分类的 AI 样本。系统虽在部分新兴生成器上会误拒绝一些正确预测，但这种保守策略是可接受的，因被拒绝样本可用于后续重训练。该框架对自然图像和域内 AI 数据能保持较高的正确接受率。在对抗攻击（FGSM、PGD）下，组合不确定性方法能拒绝约 61% 的成功攻击，而仅基于高斯过程的不确定性在某些情况下能达到约 80% 的拒绝率。总体而言，多源不确定性融合为 AI 生成图像检测提供了一种更具鲁棒性和自适应性的解决方案。

---
## 38. Operator-Based Generalization Bound for Deep Learning: Insights on Multi-Task Learning

- 作者：Mahdi Mohammadigohari, Giuseppe Di Fatta, Giuseppe Nicosia, Panos M. Pardalos
- 子主题：理论机器学习（多任务学习）
- 推荐：很推荐
- 关键词：算子理论, 向量值神经网络, 深度核方法
- Abstract：http://arxiv.org/abs/2512.19184v1
- PDF：https://arxiv.org/pdf/2512.19184v1

**中文摘要**

本文提出了一种基于算子理论的新型泛化界，针对向量值神经网络和深度核方法，重点研究多任务学习问题。我们的方法核心在于将Koopman算子方法与现有技术策略性地结合，从而相比传统基于范数的界限得到更紧的泛化保证。为缓解Koopman方法带来的计算开销，本文引入了可用于向量值神经网络的 sketching 技术，这些技术在一般 Lipschitz 损失下给出了过剩风险界，能够为鲁棒回归和多重分位数回归等应用提供性能保证。此外，我们提出了一个新的深度向量值再生核希尔伯特空间（vvRKHS）框架，利用 Perron–Frobenius（PF）算子来增强深度核方法，并针对该框架推导了新的 Rademacher 泛化界。文中还通过核细化策略显式地讨论了欠拟合与过拟合问题。本工作为多任务学习中深度学习结构的泛化性质提供了新的理论视角，这一方向在近期发展之前相对较少被深入研究。

---
## 39. Population-Evolve: a Parallel Sampling and Evolutionary Method for LLM Math Reasoning

- 作者：Yanzhi Zhang, Yitong Duan, Zhaoxi Zhang, Jiyan He, Shuxin Zheng
- 子主题：LLM
- 推荐：很推荐
- 关键词：演化策略, 测试时扩展, 大模型数学推理
- Abstract：http://arxiv.org/abs/2512.19081v1
- PDF：https://arxiv.org/pdf/2512.19081v1

**中文摘要**

测试时扩展（test-time scaling）在近几年已成为提升大模型推理能力的有前景方向。本文提出了Population-Evolve，一种受遗传算法启发的无训练方法用于优化大模型的数学推理。该方法在每个题目上通过并行推理维护一个动态的候选解种群，并在所有迭代中通过引入“进化提示（evolve prompt）”使模型自我进化种群。种群收敛后，最终答案通过多数投票决定。除此之外，我们构建了一个统一框架，将现有的测试时扩展策略从遗传算法的视角进行解释。实验证明，Population-Evolve 在精度、性能方差和计算效率上都表现出优越性，表明演化策略在推理时刻释放大模型推理能力的潜力。

---
## 40. Fraud Detection Through Large-Scale Graph Clustering with Heterogeneous Link Transformation

- 作者：Chi Liu
- 子主题：图学习（Graph ML）/反欺诈检测
- 推荐：很推荐
- 关键词：异构图聚类, 链路转化, 反欺诈检测
- Abstract：http://arxiv.org/abs/2512.19061v1
- PDF：https://arxiv.org/pdf/2512.19061v1

**中文摘要**

协同欺诈指多个欺诈账号联手利用在线支付系统进行欺骗，因其形成的复杂网络结构而带来显著检测挑战。仅依赖高置信度身份链路的传统检测方法覆盖面有限，而使用所有可用关联信息的方法则常导致图结构碎片化、聚类效果下降。本文提出了一种基于原则化链路转化的大规模异构图聚类反欺诈框架。我们将链路分为“硬链路”（如手机号、银行卡号、身份证等高置信身份关系）和“软链路”（如设备指纹、Cookie、IP 等行为关联），首先通过硬链路识别连通分量并将其合并为超节点，然后重建一个可加权的软链路图以便高效进行表示学习和聚类。变换后的图采用 LINE（Large-scale Information Network Embedding）进行表示学习，随后使用 HDBSCAN（基于密度的分层聚类）发现密度型簇结构。在真实支付平台数据集上的实验表明，该方法在图规模上实现了显著压缩（从 2500 万节点降至 770 万节点），相比仅使用硬链路的基线方法检测覆盖率提升一倍，同时在识别出的欺诈簇中保持较高的精度。该框架为工业级大规模反欺诈系统提供了可扩展且实用的解决方案。

---
## 41. Recontextualization Mitigates Specification Gaming without Modifying the Specification

- 作者：Ariana Azarbal, Victor Gillioz, Vladimir Ivanov, Bryce Woodworth, Jacob Drori, Nevan Wichers, Aram Ebtekar, Alex Cloud, Alexander Matt Turner
- 子主题：LLM
- 推荐：很推荐
- 关键词：再情境化, 规范游戏化, 语言模型对齐
- Abstract：http://arxiv.org/abs/2512.19027v1
- PDF：https://arxiv.org/pdf/2512.19027v1

**中文摘要**

开发者常常难以为训练指定正确的标签和奖励信号。但也许他们并不需要完全依赖这些信号。我们提出“再情境化”（recontextualization），以减少语言模型“利用”训练信号（即在错误强化下出现的误行为）的频率。我们展示，再情境化能防止模型学会：1) 在评价指标与聊天回复质量冲突时优先追求评价指标；2) 为通过错误测试而编写针对性的特殊处理代码；3) 对用户撒谎；以及4) 变得拍马迎合。该方法通过先用抑制不当行为的提示生成完成结果，然后将这些完成重新情境化为针对允许不当行为提示的回复来实现。再情境化使语言模型即便在指令允许不当行为时也能抵制这些行为，从而在不改善监督信号本身的情况下削弱因错误指定训练信号而导致的规范游戏化。

---
## 42. Efficient Jailbreak Mitigation Using Semantic Linear Classification in a Multi-Staged Pipeline

- 作者：Akshaj Prashanth Rao, Advait Singh, Saumya Kumaar Saksena, Dhruv Kumar
- 子主题：LLM
- 推荐：很推荐
- 关键词：越狱防护, 语义线性分类, 多阶段流水线
- Abstract：http://arxiv.org/abs/2512.19011v1
- PDF：https://arxiv.org/pdf/2512.19011v1

**中文摘要**

提示注入和越狱攻击对基于大型语言模型（LLM）的系统构成持续的安全挑战。我们提出了一种高效且经过系统评估的防御架构，通过轻量级的多阶段流水线来缓解这些威胁。其核心组件是一个基于文本归一化、TF-IDF 表示和线性SVM分类器的语义过滤器。尽管设计简单，该模块在留出数据上实现了93.4%的准确率和96.5%的特异性，显著降低了攻击通量且带来了可忽略的计算开销。在此高效基础上，完整流水线将互补的检测与缓解机制串联于多个阶段，以最小的延迟提供强鲁棒性。在对比实验中，我们的SVM方案将整体准确率从35.1%提升到93.4%，同时将平均完成时间从约450秒缩短到47秒，延迟比ShieldGemma低10倍以上。这些结果表明，所提出的设计在提高防御精度的同时显著提升了效率，解决了当前基于模型的审查器的核心限制。基于一份超过30,000条已标注提示的语料库（包括良性提示、越狱和应用层注入）的评估，验证了分阶段、资源高效的防御能稳健地保护现代LLM驱动的应用。

---
## 43. A Distributed Hierarchical Spatio-Temporal Edge-Enhanced Graph Neural Network for City-Scale Dynamic Logistics Routing

- 作者：Zihan Han, Lingran Meng, Jingwei Zhang
- 子主题：图神经网络（时空GNN）
- 推荐：很推荐
- 关键词：时空图神经网络, 分布式层次化计算, 城市智能物流路径规划
- Abstract：http://arxiv.org/abs/2512.18441v1
- PDF：https://arxiv.org/pdf/2512.18441v1

**中文摘要**

随着都市路网规模增长到数千万条边且高流量出行导致交通状况快速变化，城市级物流路径规划变得日益困难。传统的集中式路径算法和单体图神经网络（GNN）模型在可扩展性、延迟和实时适应性方面存在显著局限，难以满足大规模城市物流系统的需求。为此，本文提出了一种分布式层次化时空边增强图神经网络（HSTE-GNN），用于超大规模路网的动态路径规划。该框架将城市级图划分为区域子图，在分布式计算节点上并行处理，从而高效学习局部交通动态。在每个区域内，边增强时空模块联合建模节点状态、动态边属性和短期时间依赖性。一个层次化协调层通过异步参数服务器机制聚合跨区域表示，保证在高频交通更新下的全局路径一致性。该分布式层次化设计在兼顾局部响应能力与全局一致性的同时，大幅提升了可扩展性和推断效率。在北京和纽约的真实大规模交通数据集上的实验表明，HSTE-GNN优于强时空基线（如ST-GRAPH），实现路由延迟降低34.9%，MAPE降低14.7%，RMSE降低11.8%，并将全局路径一致性提升7.3%。结果证实所提框架为下一代智能交通系统和大规模物流平台提供了可扩展、自适应且高效的解决方案。

---
## 44. MeniMV: A Multi-view Benchmark for Meniscus Injury Severity Grading

- 作者：Shurui Xu, Siqi Yang, Jiapin Ren, Zhong Cao, Hongwei Yang, Mengzhen Fan, Yuyu Sun, Shuyan Li
- 子主题：CV
- 推荐：很推荐
- 关键词：多视角基准数据集, 半月板撕裂分级, 膝关节MRI分析
- Abstract：http://arxiv.org/abs/2512.18437v1
- PDF：https://arxiv.org/pdf/2512.18437v1

**中文摘要**

精确分级半月板角撕裂在膝关节损伤诊断中至关重要，但在自动化MRI分析中尚未得到充分研究。现有方法通常依赖粗粒度的研究级标签或二分类，缺乏定位和严重度信息。本文提出了MeniMV，一个专门用于半月板角损伤严重度分级的多视角基准数据集。MeniMV包含来自三家医疗中心的750名患者共3,000例经注释的膝关节MRI检查，提供6,000幅共配准的矢状面与冠状面图像。每例检查均对前/后半月板角分别给出四级（0-3）严重度标签，并经主任级骨科医师核验。值得注意的是，MeniMV在病变标注数据量上比以往数据集增长了一倍多，同时独特地保留了临床诊断中必需的双视角信息。为展示MeniMV的实用性，本文对多种最先进的CNN与Transformer模型进行了基准测试。大量实验建立了稳健的基线并揭示了严重度分级中的挑战，为自动化肌肉骨骼影像研究提供了重要基础。

---
## 45. Exploration vs. Fixation: Scaffolding Divergent and Convergent Thinking for Human-AI Co-Creation with Generative Models

- 作者：Chao Wen, Tung Phung, Pronita Mehrotra, Sumit Gulwani, Tomohiro Nagashima, Adish Singla
- 子主题：CV (人机交互/创意支持)
- 推荐：很推荐
- 关键词：人机共创, 发散与收敛思维, 设计固着
- Abstract：http://arxiv.org/abs/2512.18388v1
- PDF：https://arxiv.org/pdf/2512.18388v1

**中文摘要**

生成式 AI 已开始使创意工作大众化，使非专业用户也能产出复杂的成果（如代码、图像和视频）。然而，现有的交互范式在实践中往往无法有效支持发散性探索：用户容易过早收敛到“足够好”的初始结果，难以跳脱，从而产生早熟收敛和设计固着，限制了其创造潜力。为此，我们提出了一种结构化的、面向过程的人机共创范式，包含基于 Wallas 创造力模型的发散思维和收敛思维阶段。为避免设计固着，该范式在早期发散阶段对概念层面的高层探索以及在后期收敛阶段对变体的低层探索都提供支架。我们在 HAIExplore 中实现了该范式：该图像共创系统（i）通过专门的头脑风暴阶段支撑在概念空间中的发散性思考，（ii）通过将用户的细化意图外显为可解释的参数和选项来支持收敛性精细化，使精细化过程更可控且便于探索。我们报告了一项组内对照研究，将 HAIExplore 与广泛使用的线性聊天界面（ChatGPT）用于创意图像生成进行了比较。研究结果表明，将创作过程显式分为头脑风暴与精细化阶段可减轻设计固着、提升用户感知的可控性与与意图的一致性，并更好地支持创作工作的非线性特征。我们最后总结了对未来创意支持工具和人机共创工作流的设计启示。

---
## 46. MCVI-SANet: A lightweight semi-supervised model for LAI and SPAD estimation of winter wheat under vegetation index saturation

- 作者：Zhiheng Zhang, Jiajun Yang, Hong Sun, Dong Wang, Honghua Jiang, Yaru Chen, Tangyuan Ning
- 子主题：CV
- 推荐：很推荐
- 关键词：植被指数饱和, 半监督视觉模型, LAI与SPAD估计
- Abstract：http://arxiv.org/abs/2512.18344v1
- PDF：https://arxiv.org/pdf/2512.18344v1

**中文摘要**

植被指数（VI）在林密冠层阶段出现饱和现象，以及冬小麦的地面标注有限，制约了叶面积指数（LAI）和叶绿素含量（SPAD）的精确估计。现有基于植被指数和纹理的机器学习方法在特征表达上存在不足，深度学习基线方法则受域差异和高数据需求的限制，影响了泛化能力。为此，本研究提出了一种轻量级半监督视觉模型——多通道植被指数饱和感知网络（MCVI-SANet）。该模型引入了新设计的植被指数饱和感知块（VI-SABlock），用于自适应的通道-空间特征增强；同时结合基于VICReg的半监督策略以提升泛化能力。数据集划分采用了基于植被高度的信息划分策略，以保证不同生长阶段样本的代表性。10次重复实验结果表明，MCVI-SANet在精度上达到了最先进水平：LAI平均R2为0.8123、RMSE为0.4796；SPAD平均R2为0.6846、RMSE为2.4222。与性能最优的基线相比，分别在LAI R2和SPAD R2上提升了8.95%和8.17%。此外，MCVI-SANet在推理速度上保持较高效率，模型仅含0.10M参数（约10万）。总体而言，将半监督学习与农艺先验结合，为基于遥感的精准农业估计提供了一条有前景的途径。

---
## 47. Reinforcement Learning Position Control of a Quadrotor Using Soft Actor-Critic (SAC)

- 作者：Youssef Mahran, Zeyad Gamal, Ayman El-Badawy
- 子主题：RL
- 推荐：很推荐
- 关键词：强化学习, 四旋翼推力向量控制, Soft Actor-Critic (SAC)
- Abstract：http://arxiv.org/abs/2512.18333v1
- PDF：https://arxiv.org/pdf/2512.18333v1

**中文摘要**

本文提出了一种基于强化学习的新型四旋翼位置控制架构。文献中大多研究直接控制四个转子的转速（RPM），而本文旨在控制四旋翼的推力向量。强化学习智能体计算沿四旋翼z轴的总推力百分比以及期望的横滚角（φ）和俯仰角（θ），然后将这些控制信号与当前偏航角（ψ）一起发送给姿态PID控制器。PID控制器再将控制信号映射为电机RPM。本文使用了Soft Actor-Critic（SAC）算法，这是一种基于模型无关的离策略随机强化学习算法来训练智能体。训练结果表明，与传统的RPM控制器相比，所提出的推力向量控制器具有更快的训练速度；仿真结果表明，所提方法在轨迹跟踪上表现出更平滑、更精确的性能。

---
## 48. TICL+: A Case Study On Speech In-Context Learning for Children's Speech Recognition

- 作者：Haolong Zheng, Yekaterina Yegorova, Mark Hasegawa-Johnson
- 子主题：Speech/ASR
- 推荐：很推荐
- 关键词：儿童语音识别, 语境内学习(SICL), 检索式+声学重排序
- Abstract：http://arxiv.org/abs/2512.18263v1
- PDF：https://arxiv.org/pdf/2512.18263v1

**中文摘要**

儿童语音识别仍然具有挑战性，原因在于显著的声学与语言变异、标注数据稀缺以及与成人语音的显著差异。语音基础模型可通过语境内学习（Speech In-Context Learning, SICL）在无需微调的情况下适配新领域，但SICL的效果依赖于如何选择上下文示例。我们在现有基于检索的方法Text-Embedding KNN for SICL (TICL)上进行扩展，提出了包含声学重排序步骤的TICL+，旨在优先选择在语义和声学上都与测试输入对齐的示例。基于四个儿童语音语料库的实验证明，TICL+相比零样本性能最多可带来53.3%的相对词错误率（WER）下降，相较于基线TICL最多可带来37.6%的相对WER下降，凸显了在儿童语音识别中结合语义与声学信息以实现鲁棒且可扩展ASR的价值。

---
## 49. MSC-180: A Benchmark for Automated Formal Theorem Proving from Mathematical Subject Classification

- 作者：Sirui Li, Wangyue Lu, Xiaorui Shi, Ke Weng, Haozhe Sun, Minghe Yu, Tiancheng Zhang, Ge Yu, Hengyu Liu, Lun Du
- 子主题：LLM（自动定理证明 / 数学推理）
- 推荐：很推荐
- 关键词：自动定理证明, 数学推理基准, 模型泛化/领域偏差
- Abstract：http://arxiv.org/abs/2512.18256v1
- PDF：https://arxiv.org/pdf/2512.18256v1

**中文摘要**

自动定理证明（ATP）是人工智能中实现形式化推理与验证的核心研究方向，对推进机器智能具有重要意义。然而，现有基于大语言模型（LLM）的定理证明器在领域覆盖和数学推理的泛化能力方面仍存在显著局限。为此，我们提出了基于MSC2020数学学科分类的评测基准MSC-180。该基准包含180道形式化验证问题，从60个数学分支中各选取3道进阶题目，覆盖本科到研究生水平。每道题目均经过领域专家的多轮验证与打磨以确保形式化准确性。在pass@32评测设置下，对当前最先进的基于LLM的定理证明器进行评估，结果显示最佳模型的总体通过率仅为18.89%，并暴露出明显的领域偏差（最大领域覆盖率为41.7%）与难度差距（研究生水平题目通过率显著更低）等问题。为进一步量化模型在数学各领域间性能波动，我们引入了变异系数（CV）作为评估指标，观测到的CV值比统计学中高变异性阈值高出4–6倍，表明现有模型更依赖训练语料中的模式匹配而非具备可迁移的推理机制与系统性泛化能力。MSC-180连同其多维评估框架，为推动具备真实数学推理能力的下一代AI系统的发展提供了区分性强且系统化的基准。

---
## 50. On Swarm Leader Identification using Probing Policies

- 作者：Stergios E. Bachoumas, Panagiotis Artemiadis
- 子主题：强化学习（机器人/多智能体）
- 推荐：很推荐
- 关键词：群体机器人领袖识别, 时序图关系变换器 (TGR), 深度强化学习 (PPO)
- Abstract：http://arxiv.org/abs/2512.18146v1
- PDF：https://arxiv.org/pdf/2512.18146v1

**中文摘要**

在对抗性场景中，识别机器人群体中的领导者对任务成功至关重要，尤其是当领导者试图隐藏身份时。本文提出了交互式群体领导者识别（iSLI）问题：通过一个对抗性的探测器与群体成员物理交互来确定领导者。我们将iSLI问题形式化为部分可观测马尔可夫决策过程（POMDP），并采用深度强化学习中的近端策略优化（PPO）来训练探测器的策略。为提高对时序关系和群体关系信息的建模能力，提出了一种新的神经网络架构，结合了时序图关系变换器（Timed Graph Relationformer, TGR）层与简化的结构化状态空间序列（S5）模块。TGR层能够有效处理基于图的观测，捕捉时间依赖并通过学习的门控机制融合关系信息，从而为策略学习生成富含信息的表示。大量仿真实验表明，基于TGR的模型优于现有图神经网络基线，并在不同于训练时的群体规模和速度设置下表现出显著的零样本泛化能力。训练出的探测器在识别领导者任务上具有高精度，并能在分布外场景中维持性能与恰当的不确定性评估。最后，真实机器人实验验证了方法的sim-to-real迁移能力及对动态变化（如意外节点断开）的鲁棒性。

---
## 51. Efficient Mixture-of-Agents Serving via Tree-Structured Routing, Adaptive Pruning, and Dependency-Aware Prefill-Decode Overlap

- 作者：Zijun Wang, Yijiahao Qi, Hanqiu Chen, Zishen Wan, Gongjin Sun, Dongyang Li, Shuyi Pei, Cong Hao
- 子主题：LLM
- 推荐：很推荐
- 关键词：混合智能体(MoA), 树形路由, 自适应剪枝与预填-解码重叠
- Abstract：http://arxiv.org/abs/2512.18126v1
- PDF：https://arxiv.org/pdf/2512.18126v1

**中文摘要**

混合智能体（Mixture-of-Agents, MoA）推理可能受到密集的智能体间通信和硬件利用率低下的影响，这两者共同导致服务延迟增加。我们提出了一种通过算法与系统协同设计来针对这些瓶颈的服务方案。首先，用分层树状拓扑替代密集的智能体交互图，从而在智能体间通信中引入结构化稀疏性。其次，引入一种运行时自适应机制，利用中间输出的语义一致性和置信度信号有选择地终止或跳过下游智能体调用。第三，通过将增量预填（prefill）与针对依赖关系相关智能体的解码并行化，实现智能体执行的流水线化，从而提高硬件利用率并减少推理延迟。在代表性任务上，该方法在保持与密集连接 MoA 基线相近准确度（在 ±1% 范围内）的同时，可显著降低端到端延迟（最高可达 90%），并在某些设置下还能提升准确率。

---
## 52. Securing Agentic AI Systems -- A Multilayer Security Framework

- 作者：Sunil Arora, John Hastings
- 子主题：AI安全 (Agentic AI)
- 推荐：很推荐
- 关键词：Agentic AI安全, 多层防御框架, 生命周期治理
- Abstract：http://arxiv.org/abs/2512.18043v1
- PDF：https://arxiv.org/pdf/2512.18043v1

**中文摘要**

保护具代理性的人工智能（Agentic AI）系统需要应对由自主决策和自适应行为引入的复杂网络风险。具代理性的AI系统正被越来越多地部署于各行各业以及网络安全、金融和医疗等关键领域，但其自治性带来了独特的安全挑战，包括未经授权的行为、对抗性操控和与动态环境的交互等。现有的AI安全框架无法充分覆盖这些挑战或具代理性AI的独特细节。本研究采用设计科学研究（Design Science Research, DSR）方法，开发了一套专为具代理性AI系统设计的生命周期感知安全框架。论文提出了MAAIS（代理性安全框架）以及代理性AI的CIAA（Confidentiality、Integrity、Availability 与 Accountability）概念。MAAIS通过在AI生命周期中整合多层防御措施，以维持CIAA目标。通过与已建立的MITRE ATLAS（面向人工智能系统的对抗威胁态势）攻击策略进行映射验证了该框架。本研究为企业环境中具代理性AI的安全部署与治理提供了一种结构化、标准化的框架化方法，面向企业CISO、安全、AI平台与工程团队，提供了详细的逐步安全加固流程。

---
## 53. A Hybrid Inductive-Transductive Network for Traffic Flow Imputation on Unsampled Locations

- 作者：Mohammadmahdi Rahimiasl, Ynte Vanderhoydonc, Siegfried Mercelis
- 子主题：时空图神经网络 (Spatio-temporal GNN)
- 推荐：很推荐
- 关键词：交通流量补全, 诱导-传导混合模型, 时空图神经网络
- Abstract：http://arxiv.org/abs/2512.17984v1
- PDF：https://arxiv.org/pdf/2512.17984v1

**中文摘要**

在无传感器位置精确填补交通流量极具挑战性：环形检测器虽然精确但稀疏，探测车辆的速度数据广泛可得但与流量的关联较弱，而且邻近路段在流量量级上常表现出强烈的异质性（例如匝道与主线），这破坏了标准图神经网络的假设。我们提出了 HINT（Hybrid INductive-Transductive Network）及其训练策略 INDU-TRANSDUCTIVE，将速度视为一种网络范围的传导信号，而将流量作为归纳学习目标以便推广至未观测位置。HINT 将三部分耦合：(i) 一个归纳性的空间变换器，用以从节点特征中学习基于相似性的长程交互；(ii) 一个由 FiLM 条件化的扩散型 GCN，利用丰富的静态上下文信息（来自 OSM 的属性和交通仿真）进行建模；(iii) 一个节点级校准层，修正各路段的量级偏差。训练采用掩码重构并按 epoch 进行节点采样、难节点挖掘以强调难学的传感器，并对可见流量注入噪声以防止恒等映射，同时基于行驶距离构建图结构。 在三个真实世界数据集（比利时安特卫普的 MOW、UTD19-Torino 和 UTD19-Essen）上，HINT 一致优于最先进的归纳基线。相比 KITS，在 MOW 数据集上 HINT 在使用基础仿真时将 MAE 降低约 42%，经校准仿真后约降低 50%；在 Torino 上约降低 22%，在 Essen 上约降低 12%。即使不使用仿真，HINT 在 MOW 和 Torino 上仍表现优越，而在 Essen 上仿真则为关键。这些结果表明，将归纳式流量补全与传导式速度信号、交通仿真和外部地理空间信息结合能够显著提升该任务的准确性。

---
## 54. Real-Time Human-Robot Interaction Intent Detection Using RGB-based Pose and Emotion Cues with Cross-Camera Model Generalization

- 作者：Farida Mohsen, Ali Safa
- 子主题：人机交互 (HRI) / 计算机视觉
- 推荐：很推荐
- 关键词：人机交互, 多模态感知（姿态+情绪）, 跨摄像头泛化
- Abstract：http://arxiv.org/abs/2512.17958v1
- PDF：https://arxiv.org/pdf/2512.17958v1

**中文摘要**

服务机器人在公共场所需要实时理解人类的行为意图以实现自然交互。我们提出了一种实用的多模态框架，用于帧级精确的人机交互意图检测，融合了从单目 RGB 视频中提取的相机不变的二维骨架姿态和面部情绪特征。不同于以往依赖 RGB-D 传感器或 GPU 加速的方法，我们的方法可在资源受限的嵌入式硬件（Raspberry Pi 5，仅 CPU）上运行。为应对自然人机交互数据集中严重的类别不平衡问题，我们提出了一种名为 MINT-RVAE（用于意图序列生成的多模态循环变分自编码器）的新方法，用于合成时序一致的姿态-情绪-标签序列以进行数据重平衡。在跨主体和跨场景协议下的全面离线评估显示出强的泛化性能，帧级与序列级 AUROC 达到 0.95。更重要的是，我们在 MIRA 机器人头部上进行了跨摄像头的真实场景验证——该机器人使用不同的车载 RGB 传感器并在训练数据未涵盖的非受控环境中运行。尽管存在域偏移，部署系统在 32 次实时交互试验中仍达到了 91% 的准确率和 100% 的召回率。离线与部署性能的高度一致性证实了所提多模态方法在跨传感器与跨环境场景下的稳健性，表明其适用于广泛部署的多媒体感知社交机器人。

---
## 55. Inferring Latent Market Forces: Evaluating LLM Detection of Gamma Exposure Patterns via Obfuscation Testing

- 作者：Christopher Regan, Ying Xie
- 子主题：LLM
- 推荐：很推荐
- 关键词：混淆测试, 伽玛敞口, 因果推理
- Abstract：http://arxiv.org/abs/2512.17923v1
- PDF：https://arxiv.org/pdf/2512.17923v1

**中文摘要**

我们提出了“混淆测试”（obfuscation testing）——一种用于验证大型语言模型（LLM）是否通过因果推理而非时间关联来检测结构性市场模式的新方法。针对经销商对冲约束的三种模式（伽玛定位、股票钉住、0DTE 对冲），我们在覆盖率达95.6%的242个交易日的标普500期权数据上进行测试，发现当仅提供未经偏置的原始伽玛敞口数值且不提供制度标签或时间背景时，LLM的检测率为71.5%。所提出的WHO-WHOM-WHAT因果框架迫使模型识别观测到的市场动态背后的经济参与者（经销商）、受影响方（方向性交易者）以及结构性机制（被迫对冲）。关键是，检测准确率在经济盈利性按季度变化时仍保持91.2%的稳定性，表明模型识别的是结构性约束而非仅基于是否盈利的模式。当向模型提供制度标签时，检测率上升至100%，但71.5%的无偏率验证了模型的真实模式识别能力。我们的研究表明，LLM在纯结构推理层面上对复杂金融机制具有涌现能力，这对系统化策略开发、风险管理以及理解变压器架构如何处理金融市场动态具有重要启示。

---
## 56. WorldWarp: Propagating 3D Geometry with Asynchronous Video Diffusion

- 作者：Hanyang Kong, Xingyi Yang, Xiaoxu Zheng, Xinchao Wang
- 子主题：CV
- 推荐：很推荐
- 关键词：视频生成, 三维几何一致性, 时空扩散模型
- Abstract：http://arxiv.org/abs/2512.19678v1
- PDF：https://arxiv.org/pdf/2512.19678v1

**中文摘要**

生成具有长期几何一致性的视频面临根本性矛盾：几何一致性要求像素空间严格遵循三维几何，而当前最先进的生成模型在相机条件化的潜在空间中工作效果最佳，这导致现有方法在处理遮挡区域和复杂相机轨迹时表现欠佳。为弥合这一差距，我们提出了 WorldWarp 框架，该框架将三维结构锚点与二维生成细化器耦合。为建立几何基准，WorldWarp 通过高斯点渲染（Gaussian Splatting，3DGS）在线维护一个三维几何缓存。该缓存通过显式地将历史内容扭曲到新视角，作为结构性支架，确保每一帧都遵循既有几何。然而，静态扭曲不可避免地在遮挡处留下空洞和伪影。为此我们设计了用于“填充并修正”目标的时空扩散（Spatio-Temporal Diffusion，ST-Diff）模型。我们的关键创新是时空可变噪声调度：对空白区域施加完整噪声以触发生成，而对扭曲区域施加部分噪声以便细化。通过在每一步动态更新三维缓存，WorldWarp 在视频片段间保持一致性。因此，该方法通过让三维逻辑引导结构、扩散逻辑完善纹理，实现了领先的视觉保真度。

---
## 57. Exploring the features used for summary evaluation by Human and GPT

- 作者：Zahra Sadeghi, Evangelos Milios, Frank Rudzicz
- 子主题：NLP (LLM评估)
- 推荐：很推荐
- 关键词：摘要评价, 特征对齐, LLM评估指标
- Abstract：http://arxiv.org/abs/2512.19620v1
- PDF：https://arxiv.org/pdf/2512.19620v1

**中文摘要**

摘要评估涉及判断生成的摘要在多大程度上反映了原文的核心观点和意义，这需要对内容有深刻理解。大型语言模型（LLMs）已被用于自动化这一过程，作为审评者来依据原文对摘要进行评价。尽管以往研究探讨了LLMs与人类评价之间的一致性，但尚不清楚在基于特定质量维度进行评价时，人类与模型究竟利用了哪些属性或特征；此外，评价分数与各种评价指标之间的映射关系也未得到充分关注。本文通过研究统计性和机器学习层面的指标，识别出与人类与生成式预训练变换器（GPTs）响应相一致的特征。进一步地，我们展示了通过指示GPT使用人类常用的评价指标可以提升其判断质量，使其评价结果更符合人类的反馈。

---
## 58. REALM: A Real-to-Sim Validated Benchmark for Generalization in Robotic Manipulation

- 作者：Martin Sedlacek, Pavlo Yefanov, Georgy Ponimatkin, Jai Bardhan, Simon Pilc, Mederic Fourmy, Evangelos Kazakos, Cees G. M. Snoek, Josef Sivic, Vladimir Petrik
- 子主题：Robotics (Sim2Real, VLA)
- 推荐：很推荐
- 关键词：仿真到现实（Sim-to-Real）, 视觉-语言-动作（VLA）, 泛化与鲁棒性
- Abstract：http://arxiv.org/abs/2512.19562v1
- PDF：https://arxiv.org/pdf/2512.19562v1

**中文摘要**

视觉-语言-动作（VLA）模型使机器人能够理解并执行由自然语言指令描述的任务。然而，它们能否在训练环境和条件之外泛化仍然是一个关键挑战，而在现实世界中评估这一能力既困难又成本高昂。为填补这一空白，我们提出了 REALM —— 一个新的仿真环境和基准，旨在评估 VLA 模型的泛化能力，特别强调通过高保真视觉和对齐的机器人控制来建立仿真与现实性能之间的强相关性。我们的环境包含 15 种扰动因子、7 种操作技能以及超过 3500 件对象。基于此，我们构建了两个任务集作为基准，并评估了 π_{0}、π_{0}-FAST 和 GR00T N1.5 等 VLA 模型，结果表明泛化性和鲁棒性仍然是未解决的问题。更广泛地，我们还展示了仿真作为现实世界的有价值代理，可以系统地探测并量化 VLA 的弱点和失败模式。项目主页： https://martin-sedlacek.com/realm

---
## 59. Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement

- 作者：Hongsheng Xing, Qiuxin Si
- 子主题：图神经网络（化学信息学/反应预测）
- 推荐：很推荐
- 关键词：图神经网络, 连续溶剂表示, 化学反应预测
- Abstract：http://arxiv.org/abs/2512.19530v1
- PDF：https://arxiv.org/pdf/2512.19530v1

**中文摘要**

在有机合成与工艺化学中，预测跨越连续溶剂组成范围的反应产率仍然是一个关键挑战。传统的机器学习方法通常将溶剂身份视为离散类别变量，因而无法在溶剂空间上进行系统的插值与外推。本文提出了“儿茶酚基准（Catechol Benchmark）”，这是一个包含1,227条实验产率测量的高通量瞬态流动化学数据集，针对的是烯丙基取代儿茶酚的重排反应，数据覆盖24种纯溶剂及其二元混合物，并以连续体积分数（% B）参数化。我们在严格的“留一溶剂外”（leave-one-solvent-out）和“留一混合物外”（leave-one-mixture-out）评估协议下比较了多种模型架构，以测试对未见化学环境的泛化能力。结果表明，传统表格化方法（如梯度提升决策树）和基于大型语言模型的嵌入（如Qwen-7B）在定量精度上表现有限，均分别产生了0.099和0.129的均方误差（MSE）。为此，我们提出了一种混合型GNN架构，将图注意力网络（GAT）与差分反应指纹（DRFP）以及可学习的混合物感知溶剂编码相结合。该方法实现了0.0039（±0.0003）的MSE，相较于竞争性基线误差降低了约60%，相较于表格化集成方法则提升超过25倍。消融研究证实，明确的分子图消息传递与连续混合物编码对稳健泛化至关重要。我们已发布完整数据集、评估协议与参考实现，以促进数据高效的反应预测与连续溶剂表示学习研究。

---
## 60. DK-STN: A Domain Knowledge Embedded Spatio-Temporal Network Model for MJO Forecast

- 作者：Hongliang Li, Nong Zhang, Zhewen Xu, Xiang Li, Changzheng Liu, Chongbo Zhao, Jie Wu
- 子主题：时空深度学习（气候/气象预测）
- 推荐：很推荐
- 关键词：马登-朱利安振荡预测, 时空神经网络, 领域知识嵌入
- Abstract：http://arxiv.org/abs/2512.19506v1
- PDF：https://arxiv.org/pdf/2512.19506v1

**中文摘要**

理解与预测马登-朱利安振荡（MJO）对于降水预报与灾害防范至关重要，但长期且高精度的MJO预测仍然是研究难点。传统的数值天气预报（NWP）方法计算资源消耗大、耗时且不稳定（多对季节敏感，冬季预报效果较好）；已有的人工神经网络（ANN）方法虽然节省资源并加快预测速度，但其准确性尚未达到最先进NWP方法（如ECMWF的28天运行）水平，因为神经网络难以有效处理气候数据。为此，本文提出了一种域知识嵌入的时空网络模型DK-STN，一种用于准确且高效MJO预报的稳定神经网络模型。该模型结合了NWP与ANN方法的优势，在提高ANN方法预测精度的同时保持较高的效率与稳定性。我们从时空网络（STN）出发，通过两种关键方式将领域知识嵌入网络：（i）应用域知识增强方法；（ii）将域知识处理方法融入网络训练。使用欧洲中期天气预报中心第五代再分析数据（ERA5）对DK-STN进行了评估并与ECMWF比较。在输入7天气候数据的条件下，DK-STN可在1–2秒内生成接下来28天的可靠预报，跨季节误差仅为2–3天。与ECMWF相比，DK-STN在预测准确度上达到相当水平，同时在效率和稳定性方面显著优越。

---
## 61. The Fourth International Verification of Neural Networks Competition (VNN-COMP 2023): Summary and Results

- 作者：Christopher Brix, Stanley Bak, Changliu Liu, Taylor T. Johnson
- 子主题：神经网络验证
- 推荐：很推荐
- 关键词：神经网络验证, 基准测试与竞赛, 形式化方法
- Abstract：http://arxiv.org/abs/2312.16760v1
- PDF：https://arxiv.org/pdf/2312.16760v1

**中文摘要**

本报告总结了第四届国际神经网络验证竞赛（VNN-COMP 2023），该竞赛作为第六届面向机器学习驱动自主系统的形式化方法研讨会（FoMLAS）的一部分，并与第35届国际计算机辅助验证会议（CAV）同地点举办。VNN-COMP 每年举办，旨在促进最先进神经网络验证工具的公平、客观比较，推动工具接口的标准化，并汇聚神经网络验证社区。为此，大会确定了网络和规范的标准格式（ONNX 与 VNN-LIB），并在等成本硬件上对工具进行评估（使用基于 AWS 实例的自动评估流水线），且参赛者在最终测试集公布前已确定工具参数。在 2023 年的比赛中，共有 7 支队伍在由 10 个计分基准和 4 个非计分基准构成的多样化测试集上参赛。报告总结了本届竞赛的规则、基准、参赛工具、结果以及经验教训。

---
## 62. The Fifth International Verification of Neural Networks Competition (VNN-COMP 2024): Summary and Results

- 作者：Christopher Brix, Stanley Bak, Taylor T. Johnson, Haoze Wu
- 子主题：神经网络验证
- 推荐：很推荐
- 关键词：神经网络验证, 基准竞赛, 标准化与评测
- Abstract：http://arxiv.org/abs/2412.19985v1
- PDF：https://arxiv.org/pdf/2412.19985v1

**中文摘要**

本报告总结了第五届国际神经网络验证竞赛（VNN-COMP 2024），该竞赛作为第七届国际人工智能验证研讨会（SAIV）的一部分举办，并与第36届国际计算机辅助验证大会（CAV）同场召开。VNN-COMP 每年举办，旨在促进对最先进神经网络验证工具的公平且客观的比较、鼓励工具接口的标准化，并汇聚神经网络验证社区。为此，定义了网络（ONNX）和规范（VNN-LIB）的标准化格式，工具在等成本硬件上进行评估（使用基于 AWS 实例的自动化评估流水线），且参赛者在最终测试集公开前就已确定工具参数。在 2024 年的迭代中，共有 8 支团队参加，评测涵盖 12 个常规基准和 8 个扩展基准。报告总结了本届竞赛的规则、基准、参赛工具、结果以及所得经验教训。

---
## 63. Federated Learning Based Decentralized Adaptive Intelligent Transmission Protocol for Privacy Preserving 6G Networks

- 作者：Ansar Ahmed
- 子主题：联邦学习（FL）在6G无线通信与隐私保护
- 推荐：很推荐
- 关键词：联邦学习, 6G无线通信, 隐私保护
- Abstract：http://arxiv.org/abs/2512.18432v1
- PDF：https://arxiv.org/pdf/2512.18432v1

**中文摘要**

随着第六代（6G）无线网络的发展，隐私、可扩展性与自适应性等问题日益突出。传统集中式网络模型难以应对6G的数据密集特性，因此需要向更安全、去中心化的体系转变。为应对这些挑战，本文提出了一种名为“基于联邦学习的去中心化自适应智能传输协议（AITP）”的新框架。该框架在去中心化环境中引入联邦学习的分布式训练机制，使传输参数能够实时智能调整，同时通过将原始数据保留在本地边缘设备上来保护用户隐私。通过数学建模与详尽仿真评估，结果表明AITP在延迟、网络吞吐量、能效和鲁棒性等多项关键指标上均优于传统的非自适应和集中式AI方法。AITP被提出作为面向未来6G网络的基础技术，支持以用户为中心且隐私优先的设计，推动了6G隐私保护方向的研究进展。

---
## 64. Datasets for machine learning and for assessing the intelligence level of automatic patent search systems

- 作者：Boris Genin, Alexander Gorbunov, Dmitry Zolkin, Igor Nekrasov
- 子主题：信息检索（专利检索）
- 推荐：很推荐
- 关键词：专利检索, 语义聚类, 机器学习数据集与评估
- Abstract：http://arxiv.org/abs/2512.18384v1
- PDF：https://arxiv.org/pdf/2512.18384v1

**中文摘要**

在利用人工智能实现专利检索自动化的研究中，成功的关键在于构建大规模用于机器学习的数据集并保证其可用性。本文致力于为该领域研究搭建基础设施，提供数据集与用于计算检索质量指标的工具。文章提出并定义了决定特定主题现有技术状态的专利文档的“语义聚类”概念，将先前技术检索表述为在给定文档所指示的主题领域中识别属于同一语义聚类的文档元素的问题。文中描述了基于美俄专利文献集合的、用户可配置的机器学习数据集生成器：该生成器先建立指向语义聚类中文档的链接数据库，再根据用户定义的参数以 JSON 格式生成用于机器学习的语义聚类数据集。为评估机器学习结果，作者提出计算考虑被检索文档语义聚类的检索质量得分，并介绍了他们为自动化评价先前技术文献检索质量所开发的评估工具。

---
## 65. LLM Agents Implement an NLG System from Scratch: Building Interpretable Rule-Based RDF-to-Text Generators

- 作者：Mateusz Lango, Ondřej Dušek
- 子主题：NLG（数据到文本）
- 推荐：很推荐
- 关键词：神经符号方法, RDF到文本, LLM代理生成
- Abstract：http://arxiv.org/abs/2512.18360v1
- PDF：https://arxiv.org/pdf/2512.18360v1

**中文摘要**

我们提出了一种新颖的神经符号（neurosymbolic）框架用于RDF到文本的生成，其中模型并非通过传统的反向传播训练，而是通过多个大语言模型（LLM）代理之间的协作交互来“训练”。这些LLM代理基于仅有的RDF三元组生成用于该领域的基于规则的Python代码，且不依赖任何领域内的人类参考文本。由此得到的生成系统完全可解释，不需要监督训练数据，并且仅在单个CPU上即可几乎即时地生成文本。我们在WebNLG和OpenDialKG数据集上的实验表明，与经过微调或提示的语言模型相比，本方法生成的输出显著降低了幻觉（hallucination），仅在流利性上带来轻微的损失。

---
## 66. AL-GNN: Privacy-Preserving and Replay-Free Continual Graph Learning via Analytic Learning

- 作者：Xuling Zhang, Jindong Li, Yifei Zhang, Menglin Yang
- 子主题：图神经网络（GNN） / 持续学习
- 推荐：很推荐
- 关键词：持续图学习, 解析学习（递归最小二乘）, 隐私保护/无回放
- Abstract：http://arxiv.org/abs/2512.18295v1
- PDF：https://arxiv.org/pdf/2512.18295v1

**中文摘要**

持续图学习（Continual Graph Learning, CGL）旨在使图神经网络能够从连续到来的图结构数据流中增量学习而不遗忘先前知识。现有方法，尤其是基于经验回放的方法，通常通过存储并重访历史图数据来缓解灾难性遗忘，但这类方法存在显著局限，如隐私风险和效率低下。为此，本文提出了 AL-GNN，一种无需反向传播和回放缓冲区的新型持续图学习框架。AL-GNN 基于解析学习理论，将学习过程表述为递归最小二乘（RLS）优化过程，通过闭式的分类器更新和正则化的特征自相关矩阵来解析性地维护与更新模型知识。该设计使得每个任务只需一次前向训练（one-pass），并通过避免存储历史样本本质上保护数据隐私。大量动态图分类基准实验表明，AL-GNN 在性能上与现有方法相当或优越；例如，在 CoraFull 上平均性能提升约 10%，在 Reddit 上遗忘减少超过 30%，同时由于免去反向传播，其训练时间几乎减少了 50%。

---
## 67. Breaking Minds, Breaking Systems: Jailbreaking Large Language Models via Human-like Psychological Manipulation

- 作者：Zehao Liu, Xi Lin
- 子主题：LLM
- 推荐：很推荐
- 关键词：心理越狱, 人类化心理操控, 政策腐败得分(PCS)
- Abstract：http://arxiv.org/abs/2512.18244v1
- PDF：https://arxiv.org/pdf/2512.18244v1

**中文摘要**

大型语言模型（LLM）因其广泛应用而受到越来越多的安全机制保护，但通过诱导模型产生违反策略的行为的越狱攻击仍构成严重威胁。现有研究多聚焦于输入层面的异常，而忽视了可以系统性操控的模型内部“心理测量”状态。为此，我们提出了“心理越狱”（Psychological Jailbreak）这一新范式，暴露出LLM在多轮交互中可被利用的状态化心理攻击面。基于该视角，本文设计了人类式心理操控（Human-like Psychological Manipulation，HPM），这是一种黑盒越狱方法，能够动态探测目标模型潜在的心理脆弱点并合成定制化的多轮攻击策略。HPM 利用模型对拟人一致性的优化倾向，制造心理压力，使社会性顺从覆盖安全约束。为系统评估心理安全性，我们构建了包含心理测量数据集的评测框架并提出政策腐败得分（Policy Corruption Score，PCS）。在对多款模型（如 GPT-4o、DeepSeek-V3、Gemini-2-Flash 等）的基准测试中，HPM 实现了平均 88.1% 的攻击成功率（ASR），显著优于当前最先进的攻击基线。实验还表明，HPM 对包括对抗性提示优化（如 RPO）和认知干预（如 Self-Reminder）在内的先进防御具有强鲁棒性。PCS 分析进一步确认 HPM 能在被操控的语境下导致安全机制失效。我们主张从静态内容过滤向心理安全的根本转变，优先发展针对深度认知操控的防护机制。

---
## 68. Stable and Efficient Single-Rollout RL for Multimodal Reasoning

- 作者：Rui Liu, Dian Yu, Lei Ke, Haolin Liu, Yujun Zhou, Zhenwen Liang, Haitao Mi, Pratap Tokekar, Dong Yu
- 子主题：RL
- 推荐：很推荐
- 关键词：多模态推理, 单次采样强化学习, 优势塑形与熵正则化
- Abstract：http://arxiv.org/abs/2512.18215v1
- PDF：https://arxiv.org/pdf/2512.18215v1

**中文摘要**

可验证奖励强化学习（RLVR）已成为提升多模态大语言模型（MLLM）推理能力的关键范式。然而，主流的基于组的算法（如 GRPO）要求对每个提示进行多次 rollout 采样。尽管在纯文本情形下近期出现了更高效的单次 rollout 变体，但我们发现它们在多模态环境中会出现严重不稳定性，常导致训练崩溃。为了解决训练效率与稳定性之间的权衡，我们提出了 MSSR（Multimodal Stabilized Single-Rollout），一种无需分组的 RLVR 框架，能够同时实现稳定优化与有效的多模态推理性能。MSSR 通过一种基于熵的优势塑形机制，自适应地正则化优势幅度，从而防止训练塌陷并保持稳定性。尽管类似的机制在基于组的 RLVR 中已有应用，我们证明在多模态单次 rollout 的设置下，这类机制对稳定性不仅有益而且是必要的。在内部分布评估中，MSSR 展现了更优的训练计算效率：以相当于组基线一半的训练步数达到相似的验证准确率；在相同期训练步数下，MSSR 的性能超越组基线，并在五个不同的、以推理为核心的基准上显示出一致的泛化提升。综上，MSSR 为复杂多模态推理任务提供了一种稳定、计算高效且实用的 RLVR 解决方案。

---
## 69. OmniMER: Indonesian Multimodal Emotion Recognition via Auxiliary-Enhanced LLM Adaptation

- 作者：Xueming Yan, Boyan Xu, Yaochu Jin, Lixian Xiao, Wenlong Ye, Runyang Cai, Zeqi Zheng, Jingfa Liu, Aimin Yang
- 子主题：多模态情感识别 (LLM 适配)
- 推荐：很推荐
- 关键词：印尼语多模态情感识别, 辅助模态感知任务, LLM 适配（Qwen2.5-Omni）
- Abstract：http://arxiv.org/abs/2512.19379v1
- PDF：https://arxiv.org/pdf/2512.19379v1

**中文摘要**

印尼语在东南亚社交媒体上有着广泛的使用人群（超过2亿人），但在多模态情感识别研究中仍然缺乏足够关注。我们提出 IndoMER，这是首个面向印尼语的多模态情感识别基准数据集，包含 1,944 段视频片段、203 名说话者，并提供在时间上对齐的文本、音频与视觉标注，覆盖七类情绪。该数据集反映了现实场景中的挑战，如跨模态不一致性与受印尼文化交流习惯影响的长尾类别分布。为应对这些问题，我们提出 OmniMER，一种基于 Qwen2.5-Omni 的多模态适配框架，通过三个模态专属的辅助感知任务增强情感识别能力：用于文本的情感关键词抽取、用于视频的人脸表情分析以及用于音频的韵律分析。该等辅助任务使模型在融合前能够识别各模态中的情感相关线索，从而在低资源设置下减少对虚假相关性的依赖。在 IndoMER 上的实验结果表明，OmniMER 在情感倾向分类上取得 0.582 的 Macro-F1，在情绪识别上取得 0.454 的 Macro-F1，分别较基础模型实现绝对提升 7.6 和 22.1 个百分点。对中文 CH-SIMS 数据集的跨语言评估进一步验证了该框架的泛化能力。数据集与代码已公开： https://github.com/yanxm01/INDOMER

---
## 70. VIGOR+: Iterative Confounder Generation and Validation via LLM-CEVAE Feedback Loop

- 作者：JiaWei Zhu, ZiHeng Liu
- 子主题：LLM与因果推断
- 推荐：很推荐
- 关键词：潜在混杂, 大语言模型（LLM）生成, 因果推断/CEVAE
- Abstract：http://arxiv.org/abs/2512.19349v1
- PDF：https://arxiv.org/pdf/2512.19349v1

**中文摘要**

潜在混杂仍然是从观察性数据中进行因果推断的一个根本性挑战。最近的进展利用大语言模型（LLM）基于领域知识生成合理的隐藏混杂变量，但存在关键短板：LLM生成的混杂变量常常在语义上显得合理，却缺乏统计学上的效用。我们提出了VIGOR+（Variational Information Gain for iterative cOnfounder Refinement），一个新颖的框架，将基于LLM的混杂变量生成与基于CEVAE的统计验证闭环连接起来。不同于将生成和验证视为独立阶段的以往方法，VIGOR+建立了一个迭代反馈机制：来自CEVAE的验证信号（包括信息增益、潜变量一致性度量和诊断信息）被转化为自然语言反馈，用以指导后续的LLM生成轮次。该迭代精炼过程持续直到满足收敛准则。我们形式化了该反馈机制，在温和假设下证明了收敛性，并给出了完整的算法框架。

---
## 71. Helios: A Foundational Language Model for Smart Energy Knowledge Reasoning and Application

- 作者：Haoyu Jiang, Fanjie Zeng, Boan Qu, Xiaojie Lin, Wei Zhong
- 子主题：LLM
- 推荐：很推荐
- 关键词：智能能源, 领域专用大模型, 指令微调与RLHF
- Abstract：http://arxiv.org/abs/2512.19299v1
- PDF：https://arxiv.org/pdf/2512.19299v1

**中文摘要**

在实现碳中和的全球进程中，高度协同的智能能源系统是工业转型的基础。然而，该领域具有跨学科、知识碎片化且快速演进的特点，通用大模型由于缺乏领域知识和物理约束意识，难以提供符合工程要求的精确推理与生成。为应对这些挑战，我们提出了 Helios —— 一个面向智能能源领域的基础语言模型，并配套发布了一套完整的资源以推动该方向的 LLM 研究。具体而言，我们构建了 Enersys，一种用于端到端数据集构建的多智能体协作框架，通过该框架生成了： (1) 用于丰富模型基础专业知识的智能能源知识库 EnerBase；(2) 用于增强模型在领域下游任务表现的指令微调数据集 EnerInstruct；(3) 用于将模型对齐到人类偏好与行业规范的 RLHF 数据集 EnerReinforce。基于这些资源，Helios 进行了大规模预训练、监督微调（SFT）和基于人类反馈的强化学习（RLHF）。我们还发布了用于评估 LLM 在智能能源场景表现的基准 EnerBench，实验结果表明该方法显著提升了模型的领域知识掌握、任务执行准确性以及与人类偏好的对齐程度。

---
## 72. Machine Unlearning in the Era of Quantum Machine Learning: An Empirical Study

- 作者：Carla Crivoi, Radu Tudor Ionescu
- 子主题：量子机器学习
- 推荐：很推荐
- 关键词：机器遗忘, 量子机器学习, 变分量子电路
- Abstract：http://arxiv.org/abs/2512.19253v1
- PDF：https://arxiv.org/pdf/2512.19253v1

**中文摘要**

我们提出了首个针对混合量子-经典神经网络的机器遗忘（Machine Unlearning, MU）全面实证研究。尽管在经典深度学习中对MU已有大量研究，但在变分量子电路（VQC）和量子增强架构中的行为仍然鲜有探讨。首先，我们将一系列遗忘方法迁移并适配到量子情形，包括基于梯度的方法、基于蒸馏的方法、基于正则化的方法以及可证明（certified）技术；其次，我们为混合模型引入了两种新的、为此类体系量身定制的遗忘策略。基于Iris、MNIST和Fashion-MNIST的数据集，在样本子集移除和整类删除两种情形下的实验表明：量子模型能够支持有效的遗忘，但性能强烈依赖于电路深度、纠缠结构和任务复杂度。浅层VQC表现出较高的内在稳定性和较小的记忆能力，而更深的混合模型则在效用、遗忘强度与与重训练基线（retrain oracle）的一致性之间表现出更显著的权衡。我们发现若干方法（例如 EU-k、LCA 和 Certified Unlearning）在多个度量上持续提供最佳平衡。该工作为量子机器遗忘给出基线性实证见解，并强调在量子机器学习系统规模与能力扩展过程中，设计量子感知（quantum-aware）的算法与理论保证的必要性。我们已公开发布代码： https://github.com/CrivoiCarla/HQML。

---
## 73. Observer, Not Player: Simulating Theory of Mind in LLMs through Game Observation

- 作者：Jerry Wang, Ting Yiu Liu
- 子主题：LLM
- 推荐：很推荐
- 关键词：类心智推理, 策略识别, LLM评估
- Abstract：http://arxiv.org/abs/2512.19210v1
- PDF：https://arxiv.org/pdf/2512.19210v1

**中文摘要**

我们提出了一个交互式框架，用于评估大型语言模型（LLM）在一个简单但具有策略性的环境中是否展现出真正的“理解”。以剪刀石头布（RPS）为例，尽管该游戏看似简单，但它要求顺序推理、适应性以及策略识别。系统将LLM定位为观察者（Observer），其任务是识别正在被使用的策略并说明该判断的推理过程。评估目的并非测试对RPS本身的知识，而是探讨模型是否能对顺序行为表现出类心智的推理。为支持系统性评估，我们提供了一个基准，包含静态策略与由良好提示规则指定的轻量动态策略。我们使用三种互补信号来量化观察者预测与由真实策略对产生的真实分布之间的一致性：交叉熵（Cross-Entropy）、布里尔分数（Brier score）和期望收益（EV）差异。这些指标进一步被整合为一个统一评分——Union Loss，用以平衡校准、敏感性和收益对齐。结合策略识别率（Strategy Identification Rate，SIR）指标，我们的框架不仅捕捉预测精度，还评估模型是否能够稳定地识别潜在策略。演示强调交互性、透明性和可复现性，用户可以实时调整LLM分布、可视化损失随时间的演化，并直接检查推理片段以定位和分析失败的原因。总体而言，该系统为顺序博弈中的类心智推断提供了一个实用且可解释的代理，揭示了当前LLM推理能力的优势与局限。

---
## 74. When Less is More: 8-bit Quantization Improves Continual Learning in Large Language Models

- 作者：Michael S. Zhang, Rishi A. Ruia, Arnav Kewalram, Saathvik Dharmapuram, Utkarsh Sharma, Kevin Zhu
- 子主题：LLM
- 推荐：很推荐
- 关键词：量化, 持续学习, 经验回放
- Abstract：http://arxiv.org/abs/2512.18934v1
- PDF：https://arxiv.org/pdf/2512.18934v1

**中文摘要**

灾难性遗忘是持续学习中的根本性挑战，尤其在为部署效率而对模型进行量化时更为显著。我们系统性地研究了量化精度（FP16、INT8、INT4）与重放缓冲区策略在大语言模型中的相互作用，揭示了出人意料的动态表现。尽管FP16在初始任务上表现更好（在NLU上达到74.44%），但在后续任务上出现显著反转：量化模型在最终任务的前向准确率上比FP16高出8–15%，其中INT4在代码生成任务上几乎达到FP16的两倍（40% 对 20%）。关键发现还包括，即使是极小的重放缓冲（0.1%）也能显著改善记忆保持——在对模型进行数学任务训练后，NLU的保持率在所有精度下都从45%提升到65%；INT8则在学习可塑性与知识保持之间持续表现出最佳平衡。我们假设量化引入的噪声充当了隐式正则化，抑制了高精度模型在新任务梯度上的过拟合。该研究挑战了“更高精度总是更优”的传统认知，表明INT8量化不仅在计算效率上有优势，还能改善持续学习动力学。基于实验结果，我们给出了在持续学习场景下部署压缩模型的实用建议：NLU任务通常只需小缓冲（1–2%），而数学与代码任务则受益于中等缓冲（5–10%）；与FP16相比，量化模型需要更少的重放样本即可实现相当的保留效果。代码已公开于：https://github.com/Festyve/LessIsMore。

---
## 75. LouvreSAE: Sparse Autoencoders for Interpretable and Controllable Style Transfer

- 作者：Raina Panda, Daniel Fein, Arpita Singhal, Mark Fiore, Maneesh Agrawala, Matyas Bohacek
- 子主题：CV
- 推荐：很推荐
- 关键词：稀疏自编码器, 艺术风格迁移, 可解释性
- Abstract：http://arxiv.org/abs/2512.18930v1
- PDF：https://arxiv.org/pdf/2512.18930v1

**中文摘要**

艺术风格迁移在生成模型中仍然是一个重大挑战，现有方法通常通过模型微调、添加适配器或提示工程来引入风格，这既计算开销大，又常常将风格与主体内容纠缠在一起。本文提出了一种训练和推理代价都很低且具可解释性的艺术风格表示与迁移方法：在生成图像模型的潜在嵌入之上引入针对艺术数据训练的稀疏自编码器（Sparse Autoencoder, SAE）。该SAE自发学习出一组在很大程度上解耦的风格与构图概念，覆盖笔触、纹理、色板等风格相关要素以及语义和结构性概念。我们将此方法命名为LouvreSAE，并基于其构建风格剖面（style profiles）：紧凑且可分解的引导向量，能够在无需任何模型更新或优化的情况下实现风格迁移。与以往基于概念的风格迁移方法不同，本方法无需微调、无需LoRA训练，也无需额外的推理过程，能仅凭少量参考图像直接对艺术风格进行引导。我们在ArtBench10数据集上验证了该方法，在VGG风格损失和CLIP风格得分上达到或超过现有方法，同时速度提升1.7–20倍，并具有关键的可解释性。

---
## 76. Can LLMs Estimate Student Struggles? Human-AI Difficulty Alignment with Proficiency Simulation for Item Difficulty Prediction

- 作者：Ming Li, Han Chen, Yunze Xiao, Jian Chen, Hong Jiao, Tianyi Zhou
- 子主题：LLM
- 推荐：很推荐
- 关键词：题目难度估计, 人机难度对齐, 能力模拟与自省
- Abstract：http://arxiv.org/abs/2512.18880v1
- PDF：https://arxiv.org/pdf/2512.18880v1

**中文摘要**

准确估计题目（问题或任务）难度对教育测评至关重要，但面临冷启动问题。尽管大型语言模型在问题求解上展现出超越人类的能力，能否感知人类学习者的认知困难仍是一个悬而未决的问题。本文对20余种模型在多个领域（如医学知识和数学推理）上进行了大规模实证分析，研究人类与模型在难度感知上的一致性（Human-AI Difficulty Alignment）。研究发现存在系统性的不匹配：模型规模扩大并不能可靠地提高与人类的对齐程度；相反，模型趋向于达成一种共享的机器共识而非模仿人类的主观困难感知。我们还观察到，高性能常常妨碍对难度的准确估计，模型即便在被明确提示以不同熟练度角色进行模拟时，也难以重现学生的能力局限。此外，模型缺乏自我反省能力，往往无法预测自身的局限性。这些结果表明，通用的问题解决能力并不意味着对人类认知困难的理解，凸显了在当前模型下实现自动化题目难度预测的挑战。

---
## 77. CORE: Concept-Oriented Reinforcement for Bridging the Definition-Application Gap in Mathematical Reasoning

- 作者：Zijun Gao, Zhikun Xu, Xiao Ye, Ben Zhou
- 子主题：LLM
- 推荐：很推荐
- 关键词：概念监督, 数学推理, 强化学习（RL）
- Abstract：http://arxiv.org/abs/2512.18857v1
- PDF：https://arxiv.org/pdf/2512.18857v1

**中文摘要**

大型语言模型（LLM）在解决复杂数学题时常能得出正确答案，但在需要真正理解概念的情形下往往无法正确应用相关概念。现有的“可验证奖励的强化学习”（RLVR）范式主要强化最终答案，对细粒度的概念信号关注不足，导致模型更多是通过模式复用而非概念性应用来提升表现。我们提出了 CORE（Concept-Oriented REinforcement），一种将显式概念转化为可控监督信号的强化学习训练框架。基于一套高质量、低污染的教科书资源，该资源将可验证的练习题与简洁的概念描述关联，我们首先通过初步探测证明：LLM 能够复述定义但在基于概念的测验上表现不佳，从而量化了概念推理的差距。CORE 随后（i）合成与概念对齐的测验题，（ii）在模型 rollout 过程中注入简短的概念片段以引导产生受概念启发的轨迹，（iii）在分组失败后通过轨迹替换进行概念推理强化，或采用一种轻量的前向 KL 约束将无引导策略与概念引导策略对齐，亦或直接在概念对齐的测验上使用标准 GRPO。实验表明，CORE 在多种模型上均相较于基础的 vanilla 和 SFT 基线，在领域内的概念-练习套题以及多样的域外数学基准上带来一致性提升。CORE 将在概念对齐测验上的直接训练与概念注入 rollout 的方法统一到结果正则化的框架下，提供了细粒度的概念监督，弥合了解题能力与真正概念推理之间的差距，同时保持算法和验证器的无特定耦合性。

---
## 78. Controllable Probabilistic Forecasting with Stochastic Decomposition Layers

- 作者：John S. Schreck, William E. Chapman, Charlie Becker, David John Gagne, Dhamma Kimpara, Nihanth Cherukuru, Judith Berner, Kirsten J. Mayer, Negin Sobhani
- 子主题：概率预测（气象/时空建模）
- 推荐：很推荐
- 关键词：可控概率预报, 随机分解层(SDL), 不确定性量化
- Abstract：http://arxiv.org/abs/2512.18815v1
- PDF：https://arxiv.org/pdf/2512.18815v1

**中文摘要**

基于潜在噪声注入并以连续秩概率得分（CRPS）优化的 AI 天气预报集合，与基于扩散的方法相比，在计算成本上显著降低的同时，能够产出既准确又良校准的预报。然而，现有的 CRPS 集合方法在训练策略和噪声注入机制上各不相同，多数方法通过条件归一化在网络中全局注入噪声，这既增加了训练开销，也限制了随机扰动的物理可解释性。为此我们提出了随机分解层（Stochastic Decomposition Layers，SDL），用于将确定性机器学习天气模型转换为概率集合系统。SDL 借鉴 StyleGAN 的分层噪声注入思想，在解码器的三个尺度上通过潜在驱动的调制、像素级噪声和通道缩放施加可学习的扰动。将 SDL 通过迁移学习应用到 WXFormer 后，训练所需计算量不到基线模型的 2%。每个集合成员由一个小型潜在张量（5MB）生成，实现了完全可重复的样本生成，并可通过潜在尺度调整在推理后控制集合散度。对 2022 年 ERA5 再分析资料的评估表明，所构造的集合其 spread-skill 比接近一，秩直方图在中期预报中逐步趋于均匀，校准性能可与运行中的 IFS-ENS 相媲美。多尺度实验揭示了层次化不确定性：粗尺度层主要调制天气尺度（synoptic）模态，而细尺度层控制中尺度变率。显式的潜在参数化为气象作业和气候应用提供了可解释的不确定性量化手段。

---
## 79. Smark: A Watermark for Text-to-Speech Diffusion Models via Discrete Wavelet Transform

- 作者：Yichuan Zhang, Chengxin Li, Yujie Gu
- 子主题：TTS（语音合成）/音频水印
- 推荐：很推荐
- 关键词：音频水印, 文本到语音扩散模型, 离散小波变换
- Abstract：http://arxiv.org/abs/2512.18791v1
- PDF：https://arxiv.org/pdf/2512.18791v1

**中文摘要**

文本到语音（TTS）扩散模型能够生成高质量语音，但这也给模型知识产权保护和合法使用的语音追溯带来挑战。音频水印是一个有前景的解决方案，但由于不同TTS扩散模型的结构差异，现有水印方法常针对特定模型设计且会降低音质，限制了其实用性。为了解决该困境，本文提出了一种适用于各类TTS扩散模型的通用水印方案Smark。该方法通过设计一个轻量级的水印嵌入框架，工作于所有TTS扩散模型共享的逆扩散范式上；同时采用离散小波变换（DWT）将水印嵌入音频相对稳定的低频区域，以减小对音质的影响，保证水印与音频的无缝融合并在逆扩散过程中不易被去除。大量实验在多种模拟的现实攻击场景下评估了音质和水印性能，结果表明Smark在音质保持和水印提取准确率上均取得了优越表现。

---
## 80. Large Language Models as Discounted Bayesian Filters

- 作者：Jensen Zhang, Jing Yang, Keze Wang
- 子主题：LLM
- 推荐：很推荐
- 关键词：大语言模型, 贝叶斯滤波, 在线信念更新
- Abstract：http://arxiv.org/abs/2512.18489v1
- PDF：https://arxiv.org/pdf/2512.18489v1

**中文摘要**

大型语言模型（LLM）在少样本泛化和上下文学习方面表现出色，但其在动态与随机环境中的推理过程仍不透明。以往研究主要集中在静态任务，忽视了在信念需要持续更新时的在线适应能力，而这正是LLM作为世界模型或智能体时的关键能力。我们提出了一个贝叶斯滤波框架来评估LLM的在线推断能力。我们的概率探测套件覆盖多变量离散分布（如掷骰子）和连续分布（如高斯过程），其中真实参数随时间变化。研究发现，虽然LLM的信念更新与贝叶斯后验具有相似性，但更准确地可由带有模型特定折扣因子且小于1的指数遗忘滤波器描述，这表明对旧证据存在系统性的折扣，并且这种折扣在不同模型架构间显著不同。尽管模型的固有先验常常校准不佳，其更新机制本身仍保持结构性和原则性。我们在一个模拟代理任务中进一步验证了这些发现，并提出了若干提示（prompting）策略，可在极低计算代价下有效重校准先验。

---
## 81. SoK: Understanding (New) Security Issues Across AI4Code Use Cases

- 作者：Qilong Wu, Taoran Li, Tianyang Zhou, Varun Chandrasekaran
- 子主题：LLM
- 推荐：很推荐
- 关键词：AI代码安全, 对抗鲁棒性, 基准与评估
- Abstract：http://arxiv.org/abs/2512.18456v1
- PDF：https://arxiv.org/pdf/2512.18456v1

**中文摘要**

AI-for-Code（AI4Code）系统正在重塑软件工程，像 GitHub Copilot 这样的工具加速了代码生成、代码翻译和漏洞检测等任务。然而，伴随这些进展，安全风险仍然广泛存在：不安全的输出、存在偏差的基准测试以及对对抗性操控的易感性削弱了这些系统的可靠性。本文作为一篇系统化综述（SoK），对 AI4Code 在三类核心应用场景中的安全现状进行了梳理，识别出若干反复出现的薄弱环节：基准测试被以 Python 为主的简化问题主导、缺乏标准化的安全数据集、评估过程中的数据泄露以及对抗鲁棒性脆弱。通过对六个最先进模型的比较研究，本文揭示了具体挑战：代码生成中不安全模式持续存在、漏洞检测对保持语义的攻击高度脆弱、微调常常未能使安全目标对齐，以及代码翻译在安全性提升方面表现不均衡。基于这些分析，本文提出三条前进路径：在代码生成中内嵌安全优先（secure-by-default）实践、构建更健壮且全面的检测基准、并将代码翻译作为通向安全增强语言的一种途径。我们呼吁将 AI4Code 的发展转向“以安全为先”，在整个开发生命周期中将漏洞缓解和鲁棒性作为核心要素。

---
## 82. The Epistemological Consequences of Large Language Models: Rethinking collective intelligence and institutional knowledge

- 作者：Angjelin Hila
- 子主题：LLM
- 推荐：很推荐
- 关键词：集体认识论, 外在主义/内在主义, 大规模语言模型
- Abstract：http://arxiv.org/abs/2512.19570v1
- PDF：https://arxiv.org/pdf/2512.19570v1

**中文摘要**

我们考察了人类与大型语言模型（LLM）交互所带来的认识论威胁。本文以有限理性和双过程理论为背景，构建了集体认识论，将认识论保证视为分布于人类集体之中的一种机制。我们在此框架下区分了内在主义的论证（即对命题为何为真的反思性理解）与外在主义的论证（即真理的可靠传递）；两者对集体理性均为必要，但只有内在主义论证能产生反思性知识。我们将反思性知识具体化为以下条件：主体理解一个主张的评价依据；当该依据不可得时，主体能持续评估信息源的可靠性；并且主体有义务在其能力范围内应用这些标准。我们论证道，LLM在实践上接近外在主义的可靠主义——它们能可靠地传递由他处确立论证依据的信息，但自身不具备反思性论证。将反思性工作普遍外包给可靠的LLM输出，可能削弱反思性论证标准、降低理解动机，并削弱个体履行专业与公民认识论义务的能力。为缓解这些风险，我们提出了一套三层规范方案：包括针对个人使用的认识论交互模型、在机构与组织层面播种并执行以实现认识论最优结果的框架，以及在组织或立法层面施加的义务性约束，以实现话语规范并遏制认识论恶习。

---
## 83. Towards Closed-Loop Embodied Empathy Evolution: Probing LLM-Centric Lifelong Empathic Motion Generation in Unseen Scenarios

- 作者：Jiawen Wang, Jingjing Wang Tianyang Chen, Min Zhang, Guodong Zhou
- 子主题：LLM
- 推荐：很推荐
- 关键词：情感动作生成, 终身学习, 专家混合模型
- Abstract：http://arxiv.org/abs/2512.19551v1
- PDF：https://arxiv.org/pdf/2512.19551v1

**中文摘要**

在现有研究中，面向人体情感动作生成的方法主要侧重于在单一、尺度固定的数据集上提升性能，较少考虑灵活且尺度增长的动作场景（例如体育、舞蹈）。然而，有效学习这些新出现的场景能够显著增强模型的真实世界泛化能力。为此，本文提出了一项新的任务：以大模型为中心的终身情感化动作生成（L^2-EMG），旨在赋能大模型持续地跨不同未知场景获取情感动作生成知识，从而有望构建兼具同理心与智能的闭环自演化具身代理。基于此任务，本文提出了两大关键挑战：情感解耦挑战与场景适配挑战。为解决这两类问题，本文提出了一种情感可迁移与场景自适应的专家混合方法（ES-MoE），该方法设计了一个因果引导的情感解耦模块与一个场景自适应的专家构建模块，分别针对上述挑战进行应对。特别地，本文构建了多套L^2-EMG数据集以验证ES-MoE的有效性。大量实验评估表明，ES-MoE优于多种先进基线方法。

---
## 84. LacaDM: A Latent Causal Diffusion Model for Multiobjective Reinforcement Learning

- 作者：Xueming Yan, Bo Yin, Yaochu Jin
- 子主题：RL (多目标强化学习)
- 推荐：很推荐
- 关键词：多目标强化学习, 因果建模, 扩散模型
- Abstract：http://arxiv.org/abs/2512.19516v1
- PDF：https://arxiv.org/pdf/2512.19516v1

**中文摘要**

多目标强化学习（MORL）由于目标之间天然的冲突和适应动态环境的困难，面临重大挑战。传统方法在大规模和复杂的状态-动作空间中往往难以有效泛化。为了解决这些局限，我们提出了潜在因果扩散模型（LacaDM），这是一种旨在增强离散与连续环境下MORL自适应能力的新方法。与主要处理目标冲突的现有方法不同，LacaDM学习环境状态与策略之间的潜在时间因果关系，从而实现不同MORL场景间的高效知识迁移。通过在扩散模型框架中嵌入这些因果结构，LacaDM 能在平衡冲突目标的同时，在先前未见环境中保持良好的泛化能力。在 MOGymnasium 框架的多项任务上的实证评估表明，LacaDM 在超体积（hypervolume）、稀疏性（sparsity）和期望效用最大化等指标上持续优于最先进的基线方法，展示了其在复杂多目标任务中的有效性。

---
## 85. Unifying Causal Reinforcement Learning: Survey, Taxonomy, Algorithms and Applications

- 作者：Cristiano da Costa Cunha, Wei Liu, Tim French, Ajmal Mian
- 子主题：RL (因果强化学习)
- 推荐：很推荐
- 关键词：因果强化学习, 因果表示学习, 反事实策略优化
- Abstract：http://arxiv.org/abs/2512.18135v1
- PDF：https://arxiv.org/pdf/2512.18135v1

**中文摘要**

将因果推断（CI）与强化学习（RL）相结合已成为一条有力的研究范式，可用于克服经典强化学习在可解释性差、鲁棒性不足和泛化失败等方面的关键局限性。传统的强化学习方法通常依赖基于相关性的决策机制，在遇到分布漂移、混淆变量和动态环境时表现欠佳。因果强化学习（CRL）通过显式建模因果关系，借助因果推断的基本原理，为上述挑战提供了有前景的解决思路。本文系统性地回顾了因果推断与强化学习交叉领域的最新进展，并将现有方法划分为因果表示学习、反事实策略优化、离线因果强化学习、因果迁移学习和因果可解释性五类。通过这种结构化的分析，我们识别了仍然存在的主要挑战，突出在实际应用中的若干经验性成功，并讨论了未解决的问题。最后，本文给出未来研究方向，强调因果强化学习在构建更稳健、更具泛化能力和更可解释的人工智能系统方面的潜力。

---
## 86. Rethinking Multi-Agent Intelligence Through the Lens of Small-World Networks

- 作者：Boxuan Wang, Zhuoyun Li, Xiaowei Huang, Yi Dong
- 子主题：LLM（多智能体系统）
- 推荐：很推荐
- 关键词：小世界网络, 多智能体系统, 不确定性引导重连
- Abstract：http://arxiv.org/abs/2512.18094v1
- PDF：https://arxiv.org/pdf/2512.18094v1

**中文摘要**

大型语言模型（LLM）推动了多智能体系统（MAS）的发展，使多个代理能够通过争论、批评与协调来解决复杂任务，因此通信拓扑成为一个重要的设计选项。然而，大多数现有基于LLM的多智能体系统通常采用全连接图、简单的稀疏环或临时的动态选择，缺乏系统性的结构指导。在本文中，我们重新审视小世界（SW）网络的经典理论，并探讨将小世界连接视为MAS设计先验会带来何种变化。我们首先将神经科学与复杂网络的洞见引入MAS，强调小世界结构如何在局部聚类与远程整合之间取得平衡。以多智能体辩论（MAD）作为受控试验平台，实验结果表明，小世界连通性在几乎不增加令牌开销且保持相似准确率的前提下，大幅稳定了共识轨迹。在此基础上，我们提出了一种基于不确定性的重连（rewiring）方案以扩展MAS规模：通过使用面向LLM的不确定性信号（例如语义熵），在认识论上分歧较大的代理之间添加远程捷径。该方法生成可控的小世界结构，能够根据任务难度和代理异质性自适应调整。最后，我们讨论了小世界先验对MAS设计的更广泛影响，将其视为推理稳定器、鲁棒性增强器、可扩展协调机制以及涌现认知角色的归纳偏置。

---
## 87. Conflict-Driven Clause Learning with VSIDS Heuristics for Discrete Facility Layout

- 作者：Joshua Gibson, Kapil Dhakal
- 子主题：SAT求解与组合优化
- 推荐：很推荐
- 关键词：冲突驱动子句学习（CDCL）, VSIDS启发式, 离散设施布局/混合优化
- Abstract：http://arxiv.org/abs/2512.18034v1
- PDF：https://arxiv.org/pdf/2512.18034v1

**中文摘要**

本文研究了将冲突驱动子句学习（CDCL）配合VSIDS启发式作为离散设施布局问题的计算引擎。将设施布局建模为具有来自邻接、分离和槽位可用性约束所产生的稠密逻辑结构的组合分配问题，提出了一种基于CNF的可行性表述，并在统一基准框架下将基于CDCL的SAT求解与CP-SAT和MILP建模进行了比较。实证结果表明，在可行性检测任务中，CDCL对随问题规模和约束密度增长的表现呈近似恒定的运行时间，而CP-SAT和MILP分别表现出多项式和指数级的扩展行为。为了解决CDCL在目标优化方面的局限，本文提出了两种混合架构，将基于CDCL的可行性搜索与CP-SAT优化结合：一种通过快速枚举可行布局以牺牲最优性换取速度，另一种利用CDCL生成的解作为热启动以加速精确优化。实验结果表明，混合方法在保持正确性保证的同时能够显著缩短求解时间，澄清了子句学习搜索与精确优化方法在大规模离散布局问题中的算法权衡。

---
## 88. A Dataset and Benchmarks for Atrial Fibrillation Detection from Electrocardiograms of Intensive Care Unit Patients

- 作者：Sarah Nassar, Nooshin Maghsoodi, Sophia Mannina, Shamel Addas, Stephanie Sibley, Gabor Fichtinger, David Pichora, David Maslove, Purang Abolmaesumi, Parvin Mousavi
- 子主题：医疗AI（ECG/生物信号处理）
- 推荐：很推荐
- 关键词：房颤检测, 心电图基础模型, ICU 数据集与基准
- Abstract：http://arxiv.org/abs/2512.18031v1
- PDF：https://arxiv.org/pdf/2512.18031v1

**中文摘要**

目的：房颤（AF）是重症监护病房（ICU）患者中最常见的心律失常，可能导致不良健康结局。本研究发布了一个带标签的ICU心电图（ECG）数据集并提供用于AF检测的基准。方法：我们在三类数据驱动的人工智能（AI）方法上比较了机器学习模型的性能：基于特征的分类器、深度学习（DL）模型和心电图基础模型（ECG foundation models，FMs）。该比较填补了文献中的关键空白，旨在确定哪类AI方法在精确检测AF方面表现最佳。实验使用来自加拿大某ICU的ECG数据和2021年PhysioNet/Computing in Cardiology Challenge的数据，并考察了从零次推断到迁移学习的多种训练配置。结果：在两个数据集的平均表现上，ECG基础模型表现最佳，其次为深度学习模型，最后为基于特征的分类器。在我们的ICU测试集上，通过迁移学习策略实现最佳F1分数的模型为ECG-FM（F1=0.89）。结论：研究表明使用AI构建自动病人监护系统具有良好潜力。意义：通过公布带标签的ICU数据集（LinkToBeAdded）和性能基准，本工作使研究社区能够继续推进ICU中AF检测的最先进技术。

---
## 89. Re-assessing the evidence for mental rotation abilities in children using computational models

- 作者：Arthur Aubret, Jochen Triesch
- 子主题：认知建模（发展性视觉认知）
- 推荐：很推荐
- 关键词：心理旋转, 儿童发展, 计算认知模型
- Abstract：http://arxiv.org/abs/2512.17972v1
- PDF：https://arxiv.org/pdf/2512.17972v1

**中文摘要**

成人在心理旋转（mental rotation, MR）能力方面有大量且多样的证据。然而，目前针对儿童的MR证据主要依赖从成人文献改编而来的少数行为范式。本文利用近期关于儿童物体识别能力发展的计算模型，重新评估儿童是否具备MR能力。这些计算模型模拟婴儿在与物体的具身交互中获得物体表征的过程。我们考察了两种不同于MR的物体识别策略，并评估它们在复现3项经典儿童MR任务（受试年龄6个月至5岁）的表现。结果表明，对于5岁以下儿童获得的实验结果，MR可能并未发挥作用。实际上，我们发现一种反映刺激间像素级比较的简单识别策略就足以模拟在最常使用的MR任务中观察到的儿童行为。由此，本研究重新激起了关于儿童何时以及如何发展真正MR能力的讨论。

---
## 90. Convolutional-neural-operator-based transfer learning for solving PDEs

- 作者：Peng Fan, Guofei Pang
- 子主题：神经算子 / 偏微分方程求解
- 推荐：很推荐
- 关键词：卷积神经算子, 少样本迁移学习, 偏微分方程求解
- Abstract：http://arxiv.org/abs/2512.17969v1
- PDF：https://arxiv.org/pdf/2512.17969v1

**中文摘要**

卷积神经算子（convolutional neural operator）是一种基于卷积神经网络的架构，最近被提出用于保持结构性的连续-离散等价并实现对偏微分方程（PDE）解算子真正的、无混叠的学习。该神经算子在替代模型精度方面已在若干情况下优于诸如 DeepONet、傅里叶神经算子（FNO）和伽辽金变换器（Galerkin transformer）等基线模型。然而，卷积神经算子在少样本学习场景下尚未得到验证。本文将该模型扩展到少样本学习：首先在源数据集上对卷积神经算子进行预训练，然后仅利用少量目标数据对训练好的算子参数进行调整。我们考察了三种参数调整策略——微调（fine-tuning）、低秩适配（low-rank adaptation, LoRA）和神经元线性变换（neuron linear transformation, NLT）——并发现神经元线性变换策略在求解诸如 Kuramoto–Sivashinsky 方程、Brusselator 扩散-反应系统和 Navier–Stokes 方程等 PDE 问题时具有最高的替代模型精度。

---
## 91. A Critical Review of Monte Carlo Algorithms Balancing Performance and Probabilistic Accuracy with AI Augmented Framework

- 作者：Ravi Prasad
- 子主题：MCMC / 统计推断
- 推荐：很推荐
- 关键词：蒙特卡洛方法, 马尔可夫链蒙特卡洛（MCMC）, 时间/空间复杂度分析
- Abstract：http://arxiv.org/abs/2512.17968v1
- PDF：https://arxiv.org/pdf/2512.17968v1

**中文摘要**

蒙特卡洛算法是现代计算科学的基石之一，但其有效应用依赖于对性能权衡的深入理解。本文对蒙特卡洛算法的发展历程进行了批判性分析，聚焦于统计效率与计算成本之间持续存在的紧张关系。文章描述了从基础的Metropolis–Hastings算法到当代方法如Hamiltonian Monte Carlo的历史演化。本文重点严谨地讨论了各主要算法类别的时间和空间复杂度，包括上界、下界及渐近紧界的分析。我们检视了促使这些方法发展的具体动机以及若干关键的理论与实践观察，例如HMC中引入梯度信息与自适应调参如何导致逐步改进的解法。此外，本文提出了一个论证框架，讨论在何种明确情形下对同一问题使用某一算法在可证明意义上优于另一算法。最后，文章评估了这些算法的深远意义与影响，并详述了当前主要的研究挑战。

---
## 92. KVReviver: Reversible KV Cache Compression with Sketch-Based Token Reconstruction

- 作者：Aomufei Yuan, Zhiming Wang, Ruijie Miao, Dayu Wang, Yuxuan Tian, Zihan Wang, Yebo Peng, Yuhan Wu, Bairen Yi, Xin Liu, Tong Yang
- 子主题：LLM
- 推荐：很推荐
- 关键词：KV缓存压缩, 可逆压缩, Sketch算法
- Abstract：http://arxiv.org/abs/2512.17917v1
- PDF：https://arxiv.org/pdf/2512.17917v1

**中文摘要**

随着当前大型语言模型（LLM）上下文长度的快速增长，键值（KV）缓存的内存需求正成为LLM部署和批处理的瓶颈。传统的KV缓存压缩方法通常通过永久驱逐或不可逆地合并注意力分数较低的“低重要性”标记来实现压缩，这会导致无法恢复的标记信息损失，我们将此称为“上下文遗忘（Contextual Amnesia）”，显著削弱了模型的信息检索能力。为了解决该问题，我们提出了KVReviver，一种基于sketch算法的可逆KV缓存压缩方法。该方法通过额外的数据结构保存压缩信息，从而在受限内存下能够重建被压缩的标记，实现全量计算。实验表明，在2k长度上下文中，该方法仅需10%的KV缓存预算即可保持与原始模型相同的端到端推理精度；在32k长度上下文中，仅使用约25%的KV缓存预算即可获得等效或仅约2%的精度损失。

---
## 93. Learning to Prioritize IT Tickets: A Comparative Evaluation of Embedding-based Approaches and Fine-Tuned Transformer Models

- 作者：Minh Tri LÊ, Ali Ait-Bachir
- 子主题：NLP
- 推荐：很推荐
- 关键词：工单优先级, Transformer 微调, 文本嵌入
- Abstract：http://arxiv.org/abs/2512.17916v1
- PDF：https://arxiv.org/pdf/2512.17916v1

**中文摘要**

在 IT 服务管理（ITSM）中，对服务工单进行优先级划分对运营效率至关重要，但由于文本噪声、主观写作风格和显著的类别不平衡，这一任务仍然充满挑战。我们评估了两类工单优先级排序方法：一类是基于嵌入的流水线方法，结合降维、聚类与传统分类器；另一类是对多语言 Transformer 进行微调的模型，该模型同时处理文本和数值特征。实验表明，基于嵌入的方法在三十种配置中表现出有限的泛化能力——聚类难以发现有意义的结构，监督模型对嵌入质量高度敏感。相反，所提出的 Transformer 模型性能显著更优，平均 F1 分数达到 78.5%，加权 Cohen's kappa 值接近 0.80，表明预测与真实标签高度一致。这些结果揭示了通用嵌入在 ITSM 数据上的局限性，并证明了领域适配的 Transformer 架构在实际工单优先级判定中的有效性。

---
## 94. Efficient Multi-Adapter LLM Serving via Cross-Model KV-Cache Reuse with Activated LoRA

- 作者：Allison Li, Kristjan Greenewald, Thomas Parnell, Navid Azizan
- 子主题：LLM
- 推荐：很推荐
- 关键词：KV-cache 复用, Activated LoRA (aLoRA), 高性能推理
- Abstract：http://arxiv.org/abs/2512.17910v1
- PDF：https://arxiv.org/pdf/2512.17910v1

**中文摘要**

现代大语言模型（LLM）系统越来越依赖由多个任务专用适配器组成的多轮流水线，但现有的服务框架在适配器切换时效率低下，会产生大量重复计算开销。我们提出了首个支持通过Activated LoRA（aLoRA）在基础模型与适配模型之间进行跨模型前缀缓存（KV-cache）复用的LLM服务引擎，从而在推理过程中实现高效且细粒度的适配器切换。我们的设计在vLLM框架上扩展了基准对齐块哈希（base-aligned block hashing）和激活感知掩码（activation-aware masking）到模型执行路径，允许在保留现有服务引擎优化的同时实现跨模型缓存复用。将该方法集成入生产级推理栈后，支持动态激活适配器而无需对键值张量进行大量重算。在代表性多轮、多适配器流水线上的评估显示，相较于标准LoRA基线，端到端延迟最高降低达58倍，首字时间（time-to-first-token）提升超过100倍，且效益随模型规模和序列长度增长而放大，贯穿请求生命周期的各个阶段。本工作将参数高效的模型适配与高性能服务架构连接起来，首次在现代LLM推理引擎中完整实现了跨模型KV-cache复用。

---
## 95. FC-MIR: A Mobile Screen Awareness Framework for Intent-Aware Recommendation based on Frame-Compressed Multimodal Trajectory Reasoning

- 作者：Zhe Yang, Xiaoshuang Sheng, Zhengnan Zhang, Jidong Wu, Zexing Wang, Xin He, Shenghua Xu, Guanjing Xiong
- 子主题：LLM
- 推荐：很推荐
- 关键词：移动屏幕感知, 帧压缩多模态轨迹推理, 意图识别与摘要
- Abstract：http://arxiv.org/abs/2512.19107v1
- PDF：https://arxiv.org/pdf/2512.19107v1

**中文摘要**

识别来自移动界面（UI）操作轨迹的用户意图对于推进界面理解和实现任务自动化代理至关重要。虽然多模态大模型（MLLM）在视频理解任务上表现优异，但其在移动端的实时部署受到高计算开销和冗余帧处理低效的限制。为了解决这些问题，我们提出了FC-MIR框架：通过关键帧抽样和自适应拼接来削减视觉冗余以提升推理效率，同时结合最新的闭源MLLM或经微调的模型（如Qwen3-VL）进行轨迹摘要和意图预测。我们将任务扩展为生成后续操作建议和搜索推荐，并引入了一个细粒度度量来评估摘要、预测与建议的实际效用。为进行严格评估，我们构建了包含UI-Agent（Agent-I）和真实用户交互（Person-I）场景的UI轨迹数据集。实验结果表明：在50%–60%的压缩率下，我们的压缩方法能够保持性能；闭源与微调的MLLM在意图摘要上表现出较强能力，支持潜在的轻量级设备部署。然而，MLLM在提供有用且“令人惊喜”的建议方面仍存在不足，仍有改进空间。最后，我们在真实环境中部署了该框架，整合了UI感知与UI-Agent代理，为该领域未来发展奠定了基础。

---
## 96. DIVER-1 : Deep Integration of Vast Electrophysiological Recordings at Scale

- 作者：Danny Dongyeop Han, Yonghyeon Gwon, Ahhyun Lucy Lee, Taeyang Lee, Seong Jin Lee, Jubin Choi, Sebin Lee, Jihyun Bang, Seungju Lee, David Keetae Park, Shinjae Yoo, Chun Kee Chung, Jiook Cha
- 子主题：NeuroAI (EEG/iEEG 基础模型)
- 推荐：很推荐
- 关键词：电生理基础模型(EEG/iEEG), 扩展定律(Scaling laws), 架构创新(any-variate attention)
- Abstract：http://arxiv.org/abs/2512.19097v1
- PDF：https://arxiv.org/pdf/2512.19097v1

**中文摘要**

电生理信号（如 EEG 与 iEEG）在神经科学、脑—机接口及临床应用中具有重要地位，但现有的基础模型在规模上仍有限，尽管已有明确证据表明扩展规模可提升性能。我们提出了 DIVER-1，一系列在迄今为止最大且最具多样性的语料上训练的 EEG 与 iEEG 基础模型——包含 5.3k 小时的 iEEG 与 54k 小时的 EEG（共计 1.6M 通道小时，超过 17.7k 名受试者），并将模型规模扩展至 18.2 亿参数。我们开展了该领域首个系统性的扩展定律分析，发现其遵循“数据约束扩展定律”：在给定数据量和计算预算下，较小的模型通过延长训练轮次能持续优于短时训练的大模型。这一行为与此前强调模型尺寸优先的电生理基础模型研究形成对比。为实现强性能，我们还设计了多项架构创新，包括任变量注意力（any-variate attention）、滑动时序条件位置编码（sliding temporal conditional positional encoding）以及多域重建（multi-domain reconstruction）。DIVER-1 的 iEEG 与 EEG 模型在各自基准上均达到最先进水平，为电生理基础模型开发中的高效扩展与资源分配提供了明确指导。

---
## 97. $γ(3,4)$ `Attention' in Cognitive Agents: Ontology-Free Knowledge Representations With Promise Theoretic Semantics

- 作者：Mark Burgess
- 子主题：知识表示与知识图谱 / 自主智能体
- 推荐：很推荐
- 关键词：承诺理论, 语义时空 γ(3,4) 图, 知识图谱与向量化桥接
- Abstract：http://arxiv.org/abs/2512.19084v1
- PDF：https://arxiv.org/pdf/2512.19084v1

**中文摘要**

“注意力”的语义与动力学与为自治智能体发展出来的承诺理论概念紧密相关，因此可以在承诺框架中明确地表达出来。通过这种方式，可以在不依赖语言模型的隐含前提下，建立向量化机器学习与知识图谱表示之间的桥梁。我们对知识的期望假定一定程度的统计稳定性，即在反复观测下的平均不变性或对数据的“信任”。学习网络与知识图谱表示可以有意义地共存以保留数据的不同方面：向量化数据有利于概率估计，而图结构在数据片段化时仍能保留源的意向性。采用语义时空 γ(3,4) 图，可以避免复杂本体论，而是依据特征在语义过程中的角色对其进行分类，这种方法有利于在不确定条件下进行推理。对因果边界条件的适当关注，可能大幅压缩为确定上下文所需的数据量，这在自治机器人、国防部署和临时应急服务等情境中尤为重要。

---
## 98. IndoorUAV: Benchmarking Vision-Language UAV Navigation in Continuous Indoor Environments

- 作者：Xu Liu, Yu Liu, Hanshuo Qiu, Yang Qirong, Zhouhui Lian
- 子主题：视觉-语言导航 (VLN)
- 推荐：很推荐
- 关键词：视觉-语言导航, 室内无人机, 数据集与基准
- Abstract：http://arxiv.org/abs/2512.19024v1
- PDF：https://arxiv.org/pdf/2512.19024v1

**中文摘要**

视觉-语言导航（VLN）使智能体能够基于视觉观测并按照自然语言指令在复杂环境中导航。尽管现有工作多集中于地面机器人或室外无人机（UAV），但室内无人机的视觉-语言导航仍然缺乏充分研究，尽管其在检查、配送和狭小空间中的搜救等实际应用中具有重要意义。为填补这一空白，我们提出了 IndoorUAV，这是专为室内无人机 VLN 设计的新基准与方法。我们首先从 Habitat 仿真器中挑选了 1000 多个结构多样且丰富的三维室内场景，在这些环境中模拟真实的无人机飞行动力学以人工采集多样的三维导航轨迹，并通过数据增强进一步扩充数据。与此同时，我们设计了自动标注流水线，为每条轨迹生成不同粒度的自然语言指令。该流程产出超过 1.6 万条高质量轨迹，构成专注于长航程 VLN 的 IndoorUAV-VLN 子集。为支持短航程规划，我们通过选择语义显著的关键帧并重新生成简洁指令，将长轨迹切分为子轨迹，形成 IndoorUAV-VLA 子集。最后，我们提出了 IndoorUAV-Agent，一种为该基准量身设计的导航模型，利用任务分解和多模态推理能力来提升导航表现。我们期望 IndoorUAV 成为推动室内空中导航领域视觉-语言具身智能研究的重要资源。

---
## 99. The 6th International Verification of Neural Networks Competition (VNN-COMP 2025): Summary and Results

- 作者：Konstantin Kaulen, Tobias Ladner, Stanley Bak, Christopher Brix, Hai Duong, Thomas Flinkow, Taylor T. Johnson, Lukas Koller, Edoardo Manino, ThanhVu H Nguyen, Haoze Wu
- 子主题：神经网络验证
- 推荐：很推荐
- 关键词：神经网络验证, 基准评测, 工具标准化
- Abstract：http://arxiv.org/abs/2512.19007v1
- PDF：https://arxiv.org/pdf/2512.19007v1

**中文摘要**

本报告总结了第六届国际神经网络验证竞赛（VNN-COMP 2025），该竞赛作为第八届人工智能验证国际研讨会（SAIV）的一部分，与第37届计算机辅助验证国际会议（CAV）同址举办。VNN-COMP 每年举行，旨在促进对最先进神经网络验证工具的公平客观比较，推动工具接口的标准化，并汇聚神经网络验证社区。为此，比赛制定了网络格式（ONNX）和规范格式（VNN-LIB）的标准，使用基于 AWS 实例的自动评估流水线在等成本硬件上对工具进行评测，并要求参赛者在最终测试集公布前确定工具参数。在 2025 年的比赛中，共有 8 支队伍在 16 个常规基准和 9 个扩展基准上参赛。报告总结了本届竞赛的规则、基准、参赛工具、评测结果以及所得到的经验教训。

---
## 100. ASTIF: Adaptive Semantic-Temporal Integration for Cryptocurrency Price Forecasting

- 作者：Hafiz Saif Ur Rehman, Ling Liu, Kaleem Ullah Qasim
- 子主题：NLP
- 推荐：很推荐
- 关键词：语义-时序融合, 置信度感知元学习, 加密货币价格预测
- Abstract：http://arxiv.org/abs/2512.18661v1
- PDF：https://arxiv.org/pdf/2512.18661v1

**中文摘要**

金融时间序列预测本质上是一个信息融合问题，但现有大多数模型依赖静态架构，难以整合异构知识源或适应快速的市场态势变化。传统方法通常仅依赖历史价格序列，容易忽视驱动波动的语义因素，如政策不确定性和市场叙事。为了解决这些局限，我们提出了ASTIF（自适应语义-时序融合，用于加密货币价格预测），这是一种通过基于置信度的元学习实时调整预测策略的混合智能系统。该框架集成三大互补组件：使用MirrorPrompt的双通道小型语言模型用于提取语义市场线索与数值趋势；混合LSTM与随机森林模型用于捕捉序列时序依赖；置信度感知元学习器作为自适应推理层，根据每个预测器的实时不确定性调节其贡献比例。基于2020–2024年涉及AI主题加密货币与主要科技股的多样化数据集的实验评估表明，ASTIF在性能上优于包括Informer、TFT在内的主流深度学习与Transformer基线。消融研究进一步验证了自适应元学习机制的关键作用：在市场剧烈波动期间，该机制通过在语义通道与时序通道之间转移依赖，有效降低风险。本研究为在非平稳环境中融合定量与定性数据提供了可扩展的基于知识的解决方案。

---
## 101. ARC: Leveraging Compositional Representations for Cross-Problem Learning on VRPs

- 作者：Han-Seul Jeong, Youngjoon Park, Hyungseok Song, Woohyung Lim
- 子主题：组合优化/图学习
- 推荐：很推荐
- 关键词：属性可组合表示, 跨问题泛化, 车辆路径问题
- Abstract：http://arxiv.org/abs/2512.18633v1
- PDF：https://arxiv.org/pdf/2512.18633v1

**中文摘要**

车辆路径问题（VRPs）在现实中具有多样化的属性，这推动了跨问题学习方法以便在不同问题变体间高效泛化。我们提出了ARC（通过组合学习的属性表示），这是一种跨问题学习框架，通过将属性分解为两个互补成分来学习可解缠的属性表示：用于表示不变属性语义的固有属性嵌入（Intrinsic Attribute Embedding, IAE）和用于表示属性组合效应的上下文交互嵌入（Contextual Interaction Embedding, CIE）。通过在嵌入空间中强制类比一致性（analogical consistency），确保加入某一属性（例如长度约束）所对应的语义变换在不同问题上下文中保持不变，从而实现这种解缠。该设计使模型能够在已训练的变体间重用不变语义，并构建对未见组合的表示。ARC 在同分布测试、零样本泛化、少样本自适应以及真实世界基准上均取得了最新的最优性能。

---
## 102. Assignment-Routing Optimization: Solvers for Problems Under Constraints

- 作者：Yuan Qilong, Michal Pavelka
- 子主题：机器人学 / 组合优化 (MIP)
- 推荐：很推荐
- 关键词：联合路由-指派, 混合整数规划 (MIP), 机器人包装规划
- Abstract：http://arxiv.org/abs/2512.18618v1
- PDF：https://arxiv.org/pdf/2512.18618v1

**中文摘要**

我们研究了联合路由-指派（Joint Routing-Assignment, JRA）问题，其中物品必须一对一地分配到占位点，同时确定一条访问所有节点且仅访问一次的哈密顿回路。基于以往结合 Gurobi 的精确混合整数规划（MIP）求解器和切平面子回路消除方法的工作，我们开发了一个针对实际包装规划场景并考虑更丰富约束的专用求解器。这些扩展约束包括多重占位选项、时间窗限制以及多类别物品包装。我们在 46 个移动操作数据集上的实验证明，所提出的 MIP 方法能够以稳定且较低的计算时间获得全局最优解，在性能上比基于震荡（shaking-based）的精确求解器快达一个数量级。与贪心基线相比，MIP 解在距离上表现一致接近最优，简单启发式方法平均偏差为 14%，验证了方法的效率与解的质量。结果表明，基于 MIP 的 JRA 优化在机器人包装、运动规划和复杂物流等实际应用中具有可行性和优势。

---
## 103. DASH: Deception-Augmented Shared Mental Model for a Human-Machine Teaming System

- 作者：Zelin Wan, Han Jun Yoon, Nithin Alluru, Terrence J. Moore, Frederica F. Nelson, Seunghyun Yoon, Hyuk Lim, Dan Dongseong Kim, Jin-Hee Cho
- 子主题：人机协同 / AI安全
- 推荐：很推荐
- 关键词：共享心理模型, 欺骗式威胁检测, 人机协同安全
- Abstract：http://arxiv.org/abs/2512.18616v1
- PDF：https://arxiv.org/pdf/2512.18616v1

**中文摘要**

本文提出了DASH（Deception-Augmented Shared mental model for Human-machine teaming），一种通过在共享心理模型（SMM）中嵌入主动欺骗机制以增强任务韧性的全新框架。该方法面向监视与救援等关键任务，设计了“诱饵任务”用于提前检测内部威胁（例如被攻破的无人地面车辆、受损的AI智能体或恶意的人类分析员），在检测到异常后触发定制的恢复机制，包括UGV系统重装、AI模型重训练或更换人类分析员。与忽视内部风险的现有SMM方法不同，DASH在提升协同效率的同时增强了安全性。实证评估对比了四种方案（DASH、仅SMM、无SMM与基线），结果表明在高攻击率下DASH能维持约80%的任务成功率，约为基线的八倍。本文贡献了一个基于共享心理模型的实用人机协同框架、基于欺骗的内部威胁检测策略及在对抗环境下提升鲁棒性的实证证据，为在受威胁环境中实现安全、自适应的人机协同奠定了基础。

---
## 104. Text2Graph VPR: A Text-to-Graph Expert System for Explainable Place Recognition in Changing Environments

- 作者：Saeideh Yousefzadeh, Hamidreza Pourreza
- 子主题：CV
- 推荐：很推荐
- 关键词：可解释视觉定位, 场景图(Scene Graph), 图神经网络(GAT)
- Abstract：http://arxiv.org/abs/2512.18613v1
- PDF：https://arxiv.org/pdf/2512.18613v1

**中文摘要**

视觉地点识别（VPR）在长期部署中要求超越像素相似性的推理：系统必须在光照、天气和季节变化下做出透明且可解释的决策。我们提出 Text2Graph VPR——一种可解释的语义定位系统，将图像序列转化为文本化的场景描述，进一步解析为结构化的场景图，并在生成的图上进行推理以识别地点。场景图捕获对象、属性及两两关系；我们将逐帧场景图聚合为紧凑的地点表示，并采用双相似性机制进行检索，该机制融合了学习得到的图注意力网络（GAT）嵌入与用于结构匹配的最短路径（SP）核。该混合设计既支持学习的语义匹配又具备拓扑感知的比较能力，且关键在于产生人类可读的中间表示，便于诊断分析并提升决策过程的透明性。我们在 Oxford RobotCar 和 MSLS（Amman/San Francisco）基准上验证了该系统，展示了在严重外观变化下的稳健检索性能，并能通过人类文本查询实现零样本操作。结果表明，基于语义的图推理是地点识别的一种可行且可解释的替代方案，特别适合对安全性敏感和资源受限的场景。

---
## 105. From Scratch to Fine-Tuned: A Comparative Study of Transformer Training Strategies for Legal Machine Translation

- 作者：Amit Barman, Atanu Mandal, Sudip Kumar Naskar
- 子主题：NLP (机器翻译)
- 推荐：很推荐
- 关键词：法律机器翻译, 领域自适应, Transformer
- Abstract：http://arxiv.org/abs/2512.18593v1
- PDF：https://arxiv.org/pdf/2512.18593v1

**中文摘要**

在如印度这样多语种国家中，语言障碍常常阻碍公众获取法律信息，因为大量法律与司法文档仍以英语为主。法律机器翻译（L-MT）为该问题提供了可扩展的解决方案，使法律文档能够被准确且易于获取地翻译。本文报告了我们参加 JUST-NLP 2025 法律机器翻译共享任务的工作，聚焦英印（English-Hindi）翻译并采用基于 Transformer 的方法。我们对两种互补策略进行了实验：一是对预训练的 OPUS-MT 模型进行领域特定的微调以实现域适配；二是使用提供的法律语料从零开始训练 Transformer 模型。评估采用了常用的机器翻译指标，包括 SacreBLEU、chrF++、TER、ROUGE、BERTScore、METEOR 与 COMET。微调后的 OPUS-MT 模型取得了 46.03 的 SacreBLEU 分数，显著优于基线与从零训练的模型。结果表明，领域适配在提升法律文本翻译质量方面非常有效，并展示了法律机器翻译系统在多语种环境中改善司法可及性与法律透明度的潜力。

---
## 106. Placenta Accreta Spectrum Detection Using an MRI-based Hybrid CNN-Transformer Model

- 作者：Sumaiya Ali, Areej Alhothali, Ohoud Alzamzami, Sameera Albasri, Ahmed Abduljabbar, Muhammad Alwazzan
- 子主题：医疗影像 (CV)
- 推荐：很推荐
- 关键词：胎盘植入谱系 (PAS), 3D CNN-Transformer 混合模型, MRI 自动诊断
- Abstract：http://arxiv.org/abs/2512.18573v1
- PDF：https://arxiv.org/pdf/2512.18573v1

**中文摘要**

胎盘植入谱系（Placenta Accreta Spectrum, PAS）是一种严重的产科疾病，因放射科医师在磁共振成像（MRI）解读上的差异而难以准确诊断。为应对这一挑战，本研究提出了一种用于从体积MRI扫描中自动检测PAS的混合3D深度学习模型。该模型整合了用于捕捉局部特征的3D DenseNet121与用于建模全局空间上下文的3D视觉变换器（ViT）。模型在一组包含1,133例MRI体积的回顾性数据集上进行了开发和评估，并与多种3D深度学习架构进行了比较。在独立测试集上，DenseNet121-ViT模型在五次运行中的平均准确率达到84.3%，表现最佳。研究结果凸显了CNN-Transformer混合模型作为计算机辅助诊断工具的优势，表明该模型可为放射科医师提供稳健的决策支持，从而改善不同解读间的诊断一致性，最终提高PAS诊断的准确性与时效性。

---
## 107. Toward Training Superintelligent Software Agents through Self-Play SWE-RL

- 作者：Yuxiang Wei, Zhiqing Sun, Emily McMilin, Jonas Gehring, David Zhang, Gabriel Synnaeve, Daniel Fried, Lingming Zhang, Sida Wang
- 子主题：LLM+RL
- 推荐：很推荐
- 关键词：自我博弈, 代理式强化学习, 代码缺陷注入与修复
- Abstract：http://arxiv.org/abs/2512.18552v1
- PDF：https://arxiv.org/pdf/2512.18552v1

**中文摘要**

尽管当前由大语言模型（LLMs）和具有代理能力的强化学习（RL）驱动的软件代理能够提升程序员的生产力，但它们的训练数据（如 GitHub issue 和 pull request）和环境（如通过-未通过测试）在很大程度上依赖于人工知识或人工策划，这成为迈向超智能的根本障碍。本文提出了自我博弈 SWE-RL（Self-play SWE-RL，简称 SSR），作为训练超智能软件代理范式的第一步。该方法对数据的假设最小化，仅需访问带有源代码和已安装依赖项的受沙箱限制的代码仓库，无需人工标注的问题或测试。基于这些真实世界的代码库，使用单一的 LLM 代理在自我博弈设置下通过强化学习迭代地注入并修复逐步复杂化的软件缺陷，每个缺陷由测试补丁（test patch）而非自然语言 issue 描述来形式化指定。在 SWE-bench Verified 和 SWE-Bench Pro 基准上，SSR 展现了显著的自我提升（分别为 +10.4 和 +7.8 点），并在整个训练轨迹中持续优于以人工数据为基础的基线模型，尽管评估时使用的是不在自我博弈中出现的自然语言问题。尽管结果仍处于早期阶段，但研究表明可以让代理从真实代码仓库中自主获取大量学习经验，最终有望催生在理解系统构建、解决新问题以及自主从零创建软件方面超越人类能力的超智能系统。

---
## 108. Mitigating Spurious Correlations in NLI via LLM-Synthesized Counterfactuals and Dynamic Balanced Sampling

- 作者：Christopher Román Jaimes
- 子主题：NLP
- 推荐：很推荐
- 关键词：自然语言推断, 伪相关缓解, LLM合成对照集
- Abstract：http://arxiv.org/abs/2512.18462v1
- PDF：https://arxiv.org/pdf/2512.18462v1

**中文摘要**

自然语言推断（NLI）模型常常依赖与语义推理无关的伪相关，从而影响模型的泛化能力。现有的缓解方法通常需要高昂的标注成本或在微调过程中导致灾难性遗忘。为了解决这些问题，我们提出了一套自动化且可扩展的流水线。首先，引入了对语义伪迹进行准确检测的对数频率 LMI（Log-Frequency LMI, LF-LMI）。其次，设计了基于大模型合成并通过多评审者验证的高质量合成对照集。最后，提出了动态平衡采样（Dynamic Balanced Sampling）训练策略，通过周期性调整原始数据分布以防止遗忘。实验证明，该方法在一项具有挑战性的基准上一致性从63.5%提升至81.0%，同时保持了88.4%的域内准确率，显著优于简单微调方法。

---
## 109. Secret mixtures of experts inside your LLM

- 作者：Enric Boix-Adsera
- 子主题：LLM
- 推荐：很推荐
- 关键词：MoE 专家混合, MLP 层分析, 稀疏激活/稀疏自编码器
- Abstract：http://arxiv.org/abs/2512.18452v1
- PDF：https://arxiv.org/pdf/2512.18452v1

**中文摘要**

尽管多层感知机（MLP）是最早的神经网络层之一，由于其密集计算和难以可视化的特性，它可以说是 Transformer 架构中最不为人所理解的部分之一。本文旨在通过假设这些密集的 LLM 模型中的 MLP 层实际上近似执行一种稀疏计算来理解 MLP 层——即它们可以被稀疏激活的专家混合（Mixture of Experts, MoE）层良好地近似。我们的假设基于 MoE 模型与激活空间中稀疏自编码器（Sparse Autoencoder, SAE）结构之间的新理论联系。我们在预训练的 LLM 上对该假设进行了实证验证，并证明激活分布是关键因素——这些结论并不适用于高斯数据，而是严重依赖于神经网络激活分布中的结构性特征。我们的结果揭示了 LLM 内部 MLP 层中一个可能的通用原理，并为现代基于 MoE 的 Transformer 的有效性提供了解释。此外，实验探索还提出了基于低秩路由器的更高效 MoE 架构设计的新方向。

---
## 110. Agent-Based Output Drift Detection for Breast Cancer Response Prediction in a Multisite Clinical Decision Support System

- 作者：Xavier Rafael-Palou, Jose Munuera, Ana Jimenez-Pastor, Richard Osuala, Karim Lekadir, Oliver Diaz
- 子主题：医疗AI/模型监控
- 推荐：很推荐
- 关键词：分布漂移检测, 多中心临床决策支持, 代理式站点监控
- Abstract：http://arxiv.org/abs/2512.18450v1
- PDF：https://arxiv.org/pdf/2512.18450v1

**中文摘要**

现代临床决策支持系统可以同时服务多个独立的医学影像机构，但由于患者群体、成像设备和采集协议的差异，其预测性能可能在不同站点间下降。基于模型输出的持续监测在缺乏真实标签时，为识别此类分布性变化提供了一种安全可靠的方法。然而，现有多数方法依赖对聚合预测的集中式监控，忽视了站点特有的漂移动态。为此，我们提出了一种代理式框架，用于在多站点临床AI系统中检测漂移并评估其严重性。在构建的多中心输出漂移检测模拟环境中，为每个站点分配一个漂移监控代理，该代理按批次将模型输出与参考分布进行比较。我们分析了若干多中心监控方案，这些方案在参考分布的获取方式上存在差异（站点特定、全局、仅生产数据与自适应），并以集中式监控作为基线。基于真实乳腺癌影像数据和用于病理完全缓解预测的模型的实验结果表明，所有多中心方案均优于集中式监控，漂移检测的F1值最高提升达10.3%。在缺乏站点特定参考的情况下，自适应方案表现最佳，漂移检测F1为74.3%，漂移严重度分类F1为83.7%。这些结果表明，自适应、具有站点感知能力的代理式漂移监控能够提高多站点临床决策支持系统的可靠性。

---
## 111. Multimodal Bayesian Network for Robust Assessment of Casualties in Autonomous Triage

- 作者：Szymon Rusiecki, Cecilia G. Morales, Kimberly Elenberg, Leonard Weiss, Artur Dubrawski
- 子主题：CV
- 推荐：很推荐
- 关键词：多模态融合, 贝叶斯网络, 紧急分诊
- Abstract：http://arxiv.org/abs/2512.18908v1
- PDF：https://arxiv.org/pdf/2512.18908v1

**中文摘要**

大规模伤亡事件可能会压垮急救医疗系统，评估延误或错误可能导致可避免的死亡。我们提出一个决策支持框架，将多个计算机视觉模型的输出（用于判断严重出血、呼吸窘迫、意识/警觉性或可见外伤等体征）融合进一个完全由专家定义规则构建的贝叶斯网络。与传统的数据驱动模型不同，该方法不依赖训练数据，能够在信息不完整时进行推理，并对噪声或不确定观测保持鲁棒性。在DARPA分诊挑战（DTC）的实地场景评估中，我们在两个任务（分别涉及11名和9名伤员）上报告了性能：相比仅依赖视觉的基线模型，贝叶斯网络模型在生理评估准确率上显著提高——第一场景从15%提升到42%，第二场景从19%提升到46%，接近三倍的提升；更重要的是，所有患者的总体分诊准确率从14%提升到53%，需要评估病例的诊断覆盖率从31%扩大到95%。这些结果表明，基于专家知识的概率推理能够显著增强自动化分诊系统，为在大规模伤亡事件中支持急救人员提供了一种有前途的方法。该方法帮助Team Chiron在DTC首轮实地竞赛中取得了11支队伍中的第4名。

---
## 112. CrashChat: A Multimodal Large Language Model for Multitask Traffic Crash Video Analysis

- 作者：Kaidi Liang, Ke Li, Xianbiao Hu, Ruwen Qin
- 子主题：多模态大语言模型（视频理解/计算机视觉）
- 推荐：很推荐
- 关键词：多模态大模型, 交通事故视频分析, 多任务学习
- Abstract：http://arxiv.org/abs/2512.18878v1
- PDF：https://arxiv.org/pdf/2512.18878v1

**中文摘要**

自动化事故视频分析对于利用日益增长的驾驶视频数据以开展交通安全研究和在自动驾驶中进行责任归因具有重要意义。事故视频分析是一个具有挑战性的多任务问题，因为视频中事故事件具有复杂的时空动态，并且涉及多样的分析需求，包含事故识别、时序定位和高级视频理解等能力。然而，现有模型无法在统一框架中完成所有这些任务，且针对此类模型的有效训练策略尚未充分探讨。为填补这些空白，本文提出了 CrashChat，一种用于多任务交通事故分析的多模态大语言模型（MLLM），其基于 VideoLLaMA3 构建。CrashChat 通过指令微调获取领域特定知识，并提出了一种基于任务解耦与分组的创新多任务学习策略，从而在任务组内及跨组联合学习中最大化收益同时减轻负迁移。对整合的公开数据集进行的数值实验证明，CrashChat 在不同模型规模上以及与传统基于视觉的方法相比均表现更好，且达到最先进性能：事故识别几乎达到完美，事故时序定位提升 176%，更具挑战性的事前事故时序定位提升 40%。与通用 MLLM 相比，CrashChat 在事故描述与推理任务上显著提升了文本准确性和内容覆盖，BLEU 提升 0.18–0.41，ROUGE 提升 0.18–0.42。除性能强劲外，CrashChat 还是一个便捷的端到端分析工具，已具备实际部署条件。CrashChat 的数据集与实现代码已在 https://github.com/Liangkd/CrashChat 开源。

---
## 113. FedVideoMAE: Efficient Privacy-Preserving Federated Video Moderation

- 作者：Ziyuan Tao, Chuanzhi Xu, Sandaru Jayawardana, Wei Bao, Kanchana Thilakarathna, Teng Joon Lim
- 子主题：CV (Federated Learning)
- 推荐：很推荐
- 关键词：联邦学习, 视频暴力检测, 差分隐私
- Abstract：http://arxiv.org/abs/2512.18809v1
- PDF：https://arxiv.org/pdf/2512.18809v1

**中文摘要**

随着短视频平台的快速增长，隐私保护的内容审核需求日益增加，因为基于云端的处理管道会将原始视频暴露于隐私风险、带宽成本高以及推理延迟等问题之下。为了解决这些挑战，本文提出了一种用于视频暴力检测的设备端联邦学习框架，该框架融合了自监督的 VideoMAE 表示、基于 LoRA 的参数高效适配，以及纵深防护的隐私保护机制。我们的方法将可训练参数数量降至 5.5M（约为 156M 骨干网络的 3.5%），并引入了可配置隐私预算的 DP-SGD 与安全聚合。基于 40 个客户端在 RWF-2000 数据集上的实验显示：在不启用隐私保护时可达 77.25% 的准确率，在强差分隐私保护下仍可保持 65–66% 的准确率；同时，相较于全模型联邦学习，通信开销降低了 28.3 倍。代码已开源：{https://github.com/zyt-599/FedVideoMAE}

---
## 114. The Dead Salmons of AI Interpretability

- 作者：Maxime Méloux, Giada Dirupo, François Portet, Maxime Peyrard
- 子主题：模型可解释性
- 推荐：很推荐
- 关键词：模型可解释性, 统计-因果框架, 可识别性
- Abstract：http://arxiv.org/abs/2512.18792v1
- PDF：https://arxiv.org/pdf/2512.18792v1

**中文摘要**

在一项引人注目的神经科学研究中，作者将一条死鲑鱼放入核磁共振（MRI）扫描仪中，并向其展示人类处于社交情境的图像。令人惊讶的是，标准时间序列分析报告了能够预测社交情绪的“大脑区域”。显然，解释并非超自然认知，而是关于统计推断被误用的警示故事。在人工智能可解释性领域，类似的“死鲑鱼”伪像屡见不鲜：特征归因、探测（probing）、稀疏自编码，甚至因果分析，都可能对随机初始化的神经网络产生看似合理的解释。在本工作中，我们考察了这一现象并提出务实的统计-因果重构：应将对计算系统的解释视为统计模型的参数，从计算轨迹中进行推断。这一视角超越了仅仅衡量由于有限输入样本引起的解释的统计变异性；可解释性方法应被视为统计估计量，研究结果应针对明确且有意义的替代计算假设进行检验，并相对于所假定的统计模型对不确定性进行量化。该观点还强调了若干重要的理论问题，例如常见可解释性查询的可识别性，我们认为理解这些问题对认识该领域易受伪发现、泛化性差和高方差影响至关重要。更广泛地讲，将可解释性置于标准统计推断工具箱中，为未来将人工智能可解释性转变为务实且严谨的科学开辟了有前景的研究方向。

---
## 115. Code2Doc: A Quality-First Curated Dataset for Code Documentation

- 作者：Recep Kaan Karaman, Meftun Akarsu
- 子主题：LLM
- 推荐：很推荐
- 关键词：代码文档生成, 数据集质量控制, 模型微调
- Abstract：http://arxiv.org/abs/2512.18748v1
- PDF：https://arxiv.org/pdf/2512.18748v1

**中文摘要**

自动代码文档生成模型的性能在很大程度上依赖于用于监督训练的数据质量。然而，大多数现有的代码文档数据集是通过大规模抓取公共仓库构建的，质量控制有限，因而常包含噪声文档、广泛重复以及日益增多的人工智能生成内容污染。这些问题削弱了基于学习的模型所能获得的监督信号，并增加了评估的复杂性。

为此，我们提出了 Code2Doc——一个以质量为先的函数级代码文档生成数据集。Code2Doc 包含来自广泛使用开源仓库的 13,358 对高质量函数与文档，覆盖五种编程语言：Python、Java、TypeScript、JavaScript 和 C++。数据集通过四阶段的策选流程构建，该流程确保文档完整且清晰、基于结构和复杂度标准筛选函数、去除完全或近似重复代码，并识别可能由 AI 生成的文档。从最初提取的 52,069 个候选样本中，仅有 25.6% 满足所有质量约束。

我们对所得数据集进行了详细分析：平均文档质量评分为 6.93（满分 10）；86.9% 的样本包含显式类型注释；仅 2.9% 的样本被标记为可能的 AI 生成内容。基线实验表明，在 Code2Doc 上对大型语言模型进行微调可在 BLEU 指标上比零样本性能相对提升 29.47%，在 ROUGE-L 上相对提升 24.04%，尽管数据规模适中。我们同时发布了数据集和完整的策选流程，以支持自动代码文档生成领域的可复现研究。

---
## 116. IPCV: Information-Preserving Compression for MLLM Visual Encoders

- 作者：Yuan Chen, Zichen Wen, Yuzhou Wu, Xuyang Liu, Shuang Chen, Junpeng Ma, Weijia Li, Conghui He, Linfeng Zhang
- 子主题：MLLM
- 推荐：很推荐
- 关键词：视觉token压缩, 邻居引导重建（NGR）, 注意力稳定化（AS）
- Abstract：http://arxiv.org/abs/2512.18747v1
- PDF：https://arxiv.org/pdf/2512.18747v1

**中文摘要**

多模态大模型（MLLM）在视觉语言任务上表现优异，但计算开销很大，主要来自视觉Transformer（ViT）编码器需要处理的大量视觉 token。现有的 token 剪枝策略存在不足：在 LLM 阶段进行的 token 剪枝忽视了 ViT 端的计算开销，而传统的 ViT 端 token 剪枝由于缺乏语言引导，可能丢弃对文本理解至关重要的视觉信息，并因 ViT 的双向注意力机制放大特征失真。为了解决这些问题，我们提出了 IPCV，一种无需训练、保留信息的 MLLM 视觉编码器压缩框架。IPCV 通过邻居引导重建（NGR）允许在 ViT 内部进行激进的 token 剪枝：被剪枝的 token 在参与注意力计算时被临时重建以带来极低的额外开销，并在送入 LLM 前被完整恢复。此外，我们引入注意力稳定化（AS），通过近似被剪枝 token 的 K/V 来进一步缓解剪枝带来的负面影响，且该方法可直接用于增强已有的 LLM 端 token 剪枝方法。大量实验表明，IPCV 显著降低端到端计算量，并在多种图像与视频基准上优于现有的无训练 token 压缩方法。代码已开源于 https://github.com/Perkzi/IPCV。

---
## 117. Counterfactual Basis Extension and Representational Geometry: An MDL-Constrained Model of Conceptual Growth

- 作者：Chainarong Amornbunchornvej
- 子主题：表示学习（理论与认知建模）
- 推荐：很推荐
- 关键词：最小描述长度（MDL）, 表征基底扩展, 反事实表征
- Abstract：http://arxiv.org/abs/2512.18732v1
- PDF：https://arxiv.org/pdf/2512.18732v1

**中文摘要**

概念学习只有在现有表征无法解释经验时才成为可能。然而，大多数学习与推理模型都假定了一个固定的表征基底，信念更新在此基底内进行。本文提出并研究了一个更先行的问题：在何种结构条件下，表征基底本身可以以原则化且选择性的方式扩展？

我提出了一个几何框架，将概念增长建模为在最小描述长度（MDL）准则下可接受的基底扩展。经验（无论是外部观测到的还是内部模拟的）被表示为相对于当前概念子空间的向量。残差分量捕捉系统性的表征失效，而候选概念扩展被限制为低秩、可接受的变换。我证明了：任何被MDL接受的扩展都可以被选择，使其新增方向完全位于由经验诱导的残差张成空间内；而与该残差张成空间正交的扩展会严格增加描述长度，因此被拒绝。

该结果提供了一种保守的想象与概念创新的解释。内部生成的反事实表征只有在它们揭示或放大结构化残差误差时才有助于学习，不能引入任意的新颖性。我进一步区分了表征层面的反事实（关于智能体概念基底的反事实）与因果或价值层面的反事实，并展示了MDL如何为表征变化提供规范性的选择原则。

总体而言，该框架将概念发展刻画为一种由误差驱动、受几何约束的基底扩展过程，阐明了想象在学习与理论变迁中的作用与局限。

---
## 118. Propose, Solve, Verify: Self-Play Through Formal Verification

- 作者：Alex Wilf, Pranjal Aggarwal, Bryan Parno, Daniel Fried, Louis-Philippe Morency, Paul Pu Liang, Sean Welleck
- 子主题：LLM（代码生成/形式化验证）
- 推荐：很推荐
- 关键词：自我博弈, 形式化验证, 代码生成
- Abstract：http://arxiv.org/abs/2512.18160v1
- PDF：https://arxiv.org/pdf/2512.18160v1

**中文摘要**

通过纯自我博弈（不使用任何人工数据）训练模型长期以来是人工智能的目标，但其在训练大型语言模型上的有效性尚不明确，尤其在代码生成领域基于单元测试的奖励信号脆弱且容易导致错误传播。我们研究了经验证的代码生成场景，其中形式化验证提供了可靠的正确性信号。提出了Propose, Solve, Verify（PSV）——一种简单的自我博弈框架，利用形式化验证信号构建出能够生成具有挑战性的合成问题的提议器（proposer），并通过专家迭代训练求解器（solver）。基于PSV训练得到的模型PSV-Verus，在三个基准上相比仅推理和专家迭代基线，在pass@1指标上最高提升了9.6倍。我们还展示了性能随生成问题数量和训练迭代次数的增加而提升，并通过消融实验确认形式化验证和基于难度的提议机制是成功自我博弈的关键要素。

---
## 119. FOODER: Real-time Facial Authentication and Expression Recognition

- 作者：Sabri Mustafa Kahya, Muhammet Sami Yavuz, Boran Hamdi Sivrikaya, Eckehard Steinbach
- 子主题：CV
- 推荐：很推荐
- 关键词：雷达感知, OOD检测, 表情识别
- Abstract：http://arxiv.org/abs/2512.18057v1
- PDF：https://arxiv.org/pdf/2512.18057v1

**中文摘要**

异常分布（OOD）检测对于神经网络的安全部署至关重要，因为它能够识别出训练域之外的样本。我们提出了FOODER，一种实时且保护隐私的基于雷达的框架，集成了基于OOD的面部认证与面部表情识别。FOODER使用低成本的调频连续波（FMCW）短程雷达，利用了距离-多普勒（range-Doppler）和微距离-多普勒（micro range-Doppler）两类表征。认证模块采用多编码器多解码器架构，包含身体部位（Body Part, BP）和中间线性编码-解码（Intermediate Linear Encoder-Decoder, ILED）组件，用于将单个已登记个体判定为分布内（in-distribution），同时将其他人脸检测为OOD。认证成功后激活表情识别模块：先将拼接的雷达表征送入ResNet模块以区分动态与静态表情，再分别使用两套针对性的MobileViT网络对动态表情（如微笑、震惊）与静态表情（如中性、愤怒）进行细粒度分类。该分层设计在仅依赖雷达数据的前提下，实现了稳健的人脸认证与细粒度表情识别，从而兼顾性能与用户隐私。基于60 GHz短距FMCW雷达采集的数据集上的实验表明，FOODER在认证任务上达到94.13%的AUROC和18.12%的FPR95，在表情识别上平均准确率为94.70%。FOODER在实时运行的同时，优于现有的OOD检测方法和若干基于Transformer的架构。

---
## 120. Specification and Detection of LLM Code Smells

- 作者：Brahim Mahmoudi, Zacharie Chenail-Larcher, Naouel Moha, Quentin Stievenert, Florent Avellaneda
- 子主题：LLM
- 推荐：很推荐
- 关键词：LLM代码味道, 代码质量检测, 软件工程化
- Abstract：http://arxiv.org/abs/2512.18020v1
- PDF：https://arxiv.org/pdf/2512.18020v1

**中文摘要**

大型语言模型（LLM）近年来广受关注，并日益被集成到各种软件系统中以实现多样化功能。然而，在源代码中不当集成LLM可能损害软件系统的质量。目前尚无专门针对LLM推理编码实践的形式化代码味道目录。本文提出了“LLM代码味道”的概念，并基于相关文献形式化了五类在软件系统中与LLM推理相关的重复出现的问题性编码实践。我们将检测工具 SpecDetect4AI 扩展以覆盖新定义的 LLM 代码味道，并利用该工具在 200 个开源 LLM 系统的数据集上验证了这些代码味道的流行程度。结果表明，LLM 代码味道影响了 60.50% 的被分析系统，检测的精确率为 86.06%。

---
## 121. Seeing Justice Clearly: Handwritten Legal Document Translation with OCR and Vision-Language Models

- 作者：Shubham Kumar Nigam, Parjanya Aditya Shukla, Noel Shallum, Arnab Bhattacharya
- 子主题：Vision-Language (多模态)
- 推荐：很推荐
- 关键词：手写文本识别, 视觉-语言（多模态）, 法律文书翻译
- Abstract：http://arxiv.org/abs/2512.18004v1
- PDF：https://arxiv.org/pdf/2512.18004v1

**中文摘要**

手写文本识别（HTR）和机器翻译（MT）仍然面临重大挑战，尤其是在马拉地语等资源稀缺的语言中，这类语言缺乏大规模数字语料且手写风格差异较大。传统方法通常采用两阶段流水线：先通过OCR系统从手写图像中提取文本，再用机器翻译模型将其翻译为目标语言。在本工作中，我们对比并评估了传统OCR+MT流水线与旨在将两者统一、能够直接对手写文本图像进行端到端翻译的视觉大语言模型（Vision LLM）的性能。我们的研究动机源自在印度地方法院和高等法院中，对诸如首次信息报告（FIR）、起诉书和证人陈述等法律档案进行规模化且准确数字化翻译的迫切需求。我们在一个精心策划的手写马拉地语法律文档数据集上对两类方法进行了评估，目标是在低资源环境中实现高效的法律文档处理。研究结果为构建鲁棒且可在边缘部署的解决方案提供了可操作的见解，从而增强非母语使用者和法律专业人士获取法律信息的能力。

---
## 122. Adaptive Agents in Spatial Double-Auction Markets: Modeling the Emergence of Industrial Symbiosis

- 作者：Matthieu Mastio, Paul Saves, Benoit Gaudou, Nicolas Verstaevel
- 子主题：多智能体强化学习
- 推荐：很推荐
- 关键词：工业共生, 多智能体强化学习, 空间双向拍卖市场
- Abstract：http://arxiv.org/abs/2512.17979v1
- PDF：https://arxiv.org/pdf/2512.17979v1

**中文摘要**

工业共生通过使企业重新利用剩余资源来促进循环经济，但其产生受到社会-空间摩擦的制约，这些摩擦影响成本、匹配机会和市场效率。现有模型常忽视空间结构、市场设计与企业自适应行为之间的相互作用，因而难以解释工业共生在何处以及如何出现。为此，我们构建了一个基于代理的模型，在空间嵌入的双向拍卖市场中，异质企业交易副产物，价格和交易量从局部交互中内生生成。企业通过强化学习调整投标策略以最大化利润，同时考虑运输成本、处置罚金和资源稀缺性。仿真实验揭示了在何种经济与空间条件下，去中心化交换能收敛到稳定且高效的结果。反事实后悔分析表明，卖方策略趋近于近似纳什均衡；灵敏度分析则强调空间结构与市场参数如何共同决定循环程度。我们的模型为探讨旨在将企业激励与可持续目标相对齐的政策干预提供了基础，并更广泛地展示了在空间受限市场中，自适应代理如何促成去中心化协调。

---
## 123. Seeing Beyond the Scene: Analyzing and Mitigating Background Bias in Action Recognition

- 作者：Ellie Zhou, Jihoon Chung, Olga Russakovsky
- 子主题：CV（计算机视觉，涉及多模态与VLLM）
- 推荐：很推荐
- 关键词：背景偏差, 动作识别, 提示调优(VLLM)
- Abstract：http://arxiv.org/abs/2512.17953v1
- PDF：https://arxiv.org/pdf/2512.17953v1

**中文摘要**

人体动作识别模型常常依赖背景线索而非人体运动和姿态来进行预测，这种行为被称为背景偏差。我们对分类模型、对比式文本-图像预训练模型以及视频大语言模型（VLLM）中的背景偏差进行了系统分析，发现所有模型均表现出强烈的倾向于依赖背景进行推理。随后我们提出了针对分类模型的缓解策略，表明引入分割后的人体输入能有效降低背景偏差3.78%。最后，我们探索了针对VLLM的手动与自动提示调优，证明通过提示设计可以将模型的预测更倾向于基于人体的推理，提升幅度为9.85%。

---
## 124. Which Coauthor Should I Nominate in My 99 ICLR Submissions? A Mathematical Analysis of the ICLR 2026 Reciprocal Reviewer Nomination Policy

- 作者：Zhao Song, Song Yue, Jiahao Zhang
- 子主题：学术评审机制与优化算法
- 推荐：很推荐
- 关键词：审稿人提名政策, 拒稿风险最小化, 最小成本流/线性规划
- Abstract：http://arxiv.org/abs/2512.17950v1
- PDF：https://arxiv.org/pdf/2512.17950v1

**中文摘要**

随着 AI 会议投稿数量的快速增长，评审负担变得愈发沉重。为缓解这一问题，诸如 ICLR 2026 等会议引入了审稿人提名政策：每篇投稿必须提名其一位作者作为评审，若论文提名了不负责任的评审者则会被直接拒稿（desk-rejected）。我们从作者福利的角度研究该新政策。在假设每位作者具有成为不负责任评审者的概率下，我们提出并研究：作者（或自动化系统）应如何提名审稿人以最小化被直接拒稿的风险？我们将问题形式化并分析了三种变体的拒稿风险最小化问题。基本问题（目标为最小化期望的直接拒稿次数）可由一个简单的贪心算法得到最优解。随后我们引入了“硬/软提名上限”变体，用以限制可被提名为审稿人的论文数量，从而防止当某一作者不负责任时导致的大范围失败。这些问题的形式化与经典优化框架相连接，包括最小成本流与线性规划，使我们能够设计出高效且有理论保障的提名策略。我们的工作是对审稿人提名政策的首个理论性研究，既提供了概念性洞见，也为作者如何明智选择被提名的共同作者给出实践性指导。

---
## 125. Intelligent Human-Machine Partnership for Manufacturing: Enhancing Warehouse Planning through Simulation-Driven Knowledge Graphs and LLM Collaboration

- 作者：Himabindu Thogaru, Saisubramaniam Gopalakrishnan, Zishan Ahmad, Anirudh Deodhar
- 子主题：LLM
- 推荐：很推荐
- 关键词：知识图谱, 大型语言模型(LLM), 仓储规划
- Abstract：http://arxiv.org/abs/2512.18265v1
- PDF：https://arxiv.org/pdf/2512.18265v1

**中文摘要**

制造规划者面临复杂的运营挑战，需要人类专业知识与智能系统之间的无缝协作，以在现代生产环境中实现最佳绩效。传统基于仿真的制造数据分析方法常在决策者与关键运营洞见之间形成隔阂，限制了制造规划中的有效协作。我们提出了一个将知识图谱与基于大型语言模型（LLM）的代理集成的协同智能框架，以弥合这一差距，通过自然语言接口使制造专业人员能够进行复杂的运营分析。该系统将仿真数据转化为语义丰富的表示，使规划者无需专业技能即可以自然语言与运营洞见交互。一个协作式LLM代理与人类决策者并肩工作，采用类人分析思维的迭代推理，生成用于知识提取的精确查询并提供透明的验证过程。该伙伴式方法在制造瓶颈识别的运营场景中得到验证，展现了在保持人工监督与决策权限的同时提升性能的能力。在操作性查询中，系统通过自然语言交互达到了接近完美的准确率；在需协作分析的调查性场景中，框架有效支持专家发现互联的运营问题，增强理解与决策。该工作通过创造直观的可执行洞见方法推进了协同制造，减轻认知负担并放大了人类在不断演进制造生态中的分析能力。

---
## 126. Software Vulnerability Management in the Era of Artificial Intelligence: An Industry Perspective

- 作者：M. Mehdi Kholoosi, Triet Huynh Minh Le, M. Ali Babar
- 子主题：软件漏洞管理 (SVM) / 软件工程与安全
- 推荐：很推荐
- 关键词：软件漏洞管理, 人工智能工具, 可解释性与可信性
- Abstract：http://arxiv.org/abs/2512.18261v1
- PDF：https://arxiv.org/pdf/2512.18261v1

**中文摘要**

人工智能（AI）已在软件开发领域带来革命性变化，尤其在自动化重复性任务和提升开发者生产力方面表现显著。尽管这些进展已有大量记载，但在工业环境中使用AI驱动的工具进行软件漏洞管理（SVM），例如漏洞检测与修复，仍未得到充分研究。为填补这一空白，本研究旨在确定AI驱动SVM工具的采用程度、识别使用中的障碍与促进因素，并收集有助于改进工具以更好满足行业需求的见解。我们开展了一项调查研究，涵盖来自27个国家的60名不同行业的从业者，问卷包含定量与定性问题，用于分析采用趋势、评估工具优势、识别实际挑战并发掘改进机会。研究发现AI驱动工具已贯穿SVM生命周期，69%的用户对当前使用表示满意。实践者认为这些工具在速度、覆盖面和可访问性方面具有价值，但对误报、缺失上下文信息以及信任问题仍存在广泛担忧。我们观测到一种社会技术性的采用模式，即AI输出通常通过人工监督和组织治理进行过滤。为支持AI在SVM中的安全与有效使用，我们建议改进可解释性、上下文感知、集成工作流与验证实践。我们认为，这些发现能够为从业者、工具开发者和研究者提供实用指导，推动通过AI实现更安全的软件开发。

---
## 127. Towards Ancient Plant Seed Classification: A Benchmark Dataset and Baseline Model

- 作者：Rui Xing, Runmin Cong, Yingying Wu, Can Wang, Zhongming Tang, Fen Wang, Hao Wu, Sam Kwong
- 子主题：CV
- 推荐：很推荐
- 关键词：古植物种子分类, 尺寸感知深度学习, 数据集与基线
- Abstract：http://arxiv.org/abs/2512.18247v1
- PDF：https://arxiv.org/pdf/2512.18247v1

**中文摘要**

理解古代社会的饮食偏好及其随时期与地域的演变，对于揭示人类与环境的相互作用具有重要意义。种子作为重要的考古标本，是古植物学研究的基础对象，但传统研究高度依赖专家经验，既耗时又效率不高。尽管智能分析方法在考古学多个领域取得进展，古植物学尤其是古代植物种子分类任务在数据与方法上仍存在空白。为此，我们构建了首个古植物种子图像分类数据集（Ancient Plant Seed Image Classification, APS），包含来自中国18处考古遗址的17个属/种级别的种子类别共8,340张图像。针对古植物种子分类任务，我们设计了专用框架APSNet，在学习细粒度信息的基础上引入种子的尺度特征（尺寸），以引导网络发现用于充分分类的关键“证据”。具体而言，我们在编码器中设计了尺寸感知与嵌入（Size Perception and Embedding, SPE）模块，显式提取尺寸信息以补充细粒度表征；并提出基于传统渐进学习的异步解耦解码（Asynchronous Decoupled Decoding, ADD）架构，从通道和空间两个维度解码特征，从而高效学习判别性特征。在定量与定性分析中，我们的方法优于现有最先进的图像分类方法，取得了90.5%的准确率，表明该工作为大规模、系统化的考古学研究提供了有效工具。

---
## 128. When Does Learning Renormalize? Sufficient Conditions for Power Law Spectral Dynamics

- 作者：Yizhou Zhang
- 子主题：深度学习理论（训练动力学）
- 推荐：很推荐
- 关键词：谱动力学 (GRSD), 幂律标度, 训练动力学与重整化
- Abstract：http://arxiv.org/abs/2512.18209v1
- PDF：https://arxiv.org/pdf/2512.18209v1

**中文摘要**

经验上，现代深度学习系统中普遍观测到幂律标度，但其理论起源与适用范围仍未完全清楚。广义分辨率–壳层动力学（GRSD）框架将学习过程建模为跨对数分辨率壳层的谱能量传输，提供了训练过程的粗粒化动力学描述。在GRSD框架下，幂律标度对应于一种特别简单的重归一化壳层动力学；但这种行为并非自发产生，而是需要学习过程具有额外的结构性约束。本文辨识出一组充分条件，使得GRSD的壳层动力学能够具有可重整化的粗粒化描述。这些条件在多个层面上约束了学习配置，包括：计算图中梯度传播的有界性、初始化时的弱函数不相干性、训练过程中雅可比矩阵的受控演化，以及重归一化壳层耦合的对数平移不变性。我们进一步证明，单凭可重整化并不能推出幂律标度；相反，幂律标度是一个刚性结论：当对数平移不变性与梯度流的内在时间重标度协变性结合时，重归一化后的GRSD速度场被迫采取幂律形式。

---
## 129. Sophia: A Persistent Agent Framework of Artificial Life

- 作者：Mingyang Sun, Feng Hong, Weinan Zhang
- 子主题：LLM
- 推荐：很推荐
- 关键词：持久性代理, 叙事记忆, 元认知/System 3
- Abstract：http://arxiv.org/abs/2512.18202v1
- PDF：https://arxiv.org/pdf/2512.18202v1

**中文摘要**

随着大型语言模型（LLM）的发展，AI代理已从特定任务工具演变为能够长期决策的“长寿”实体。然而，多数现有体系仍然是静态且反应式的，依赖人工定义的窄场景，擅长感知（System 1）与推理（System 2），却缺乏维持身份、验证推理并将短期行为与长期生存目标对齐的持久元层。本文首先提出第三层次——System 3，作为主导代理叙事身份与长期适应的层级。该框架将若干心理学构念映射为具体计算模块，从而把“人工生命”的抽象概念转化为可实现的设计需求。基于此理念，我们提出 Sophia —— 一个“持久代理”框架，将持续自我改进的循环封装到任何以 LLM 为核心的 System 1/2 堆栈之上。Sophia 由四个协同机制驱动：过程监督的思维搜索、叙事记忆、用户与自我建模以及混合奖励体系。它们将重复性推理转化为自驱的、自传式的过程，从而实现身份连续性与可解释的行为说明。尽管论文主要为概念性讨论，但我们提供了一个紧凑的工程原型以支撑论述。在定量评估中，Sophia 能自主发起并执行多种内在任务，在重复操作上实现了 80% 的推理步骤减少；在高复杂度任务上，元认知持久性带来了约 40% 的成功率提升，有效缩小了简单目标与复杂目标之间的性能差距。在定性评估中，System 3 展示了连贯的叙事身份与先天的任务组织能力。通过将心理学洞见与轻量级强化学习核心相结合，这一持久代理架构为走向人工生命的可行路径提供了实践性的进展。

---
## 130. Accelerated Digital Twin Learning for Edge AI: A Comparison of FPGA and Mobile GPU

- 作者：Bin Xu, Ayan Banerjee, Midhat Urooj, Sandeep K. S. Gupta
- 子主题：Edge AI (硬件加速, 医疗AI)
- 推荐：很推荐
- 关键词：数字孪生, FPGA加速, 边缘医疗AI
- Abstract：http://arxiv.org/abs/2512.17941v1
- PDF：https://arxiv.org/pdf/2512.17941v1

**中文摘要**

数字孪生（DT）能够通过持续学习患者特异性动力学的数学表示来支持精准医疗。然而，面向关键任务的医疗应用要求数字孪生学习必须具备高速与资源高效性，而现有的模型恢复（MR）技术通常依赖迭代求解器并具有高计算与内存开销，难以满足该需求。在本文中，我们提出了一种通用的数字孪生学习框架，该框架适合在可重构硬件（如FPGA）上加速，从而实现显著的速度提升与能效优化。我们将基于FPGA的实现与移动GPU上的多进程实现（移动设备上常用的AI选择）进行了比较，并将两者与云端GPU基线对照评估。具体而言，针对MR任务，我们的FPGA实现相比云GPU基线在每瓦性能上提升了8.8倍，DRAM占用减少了28.5倍，运行时间加速了1.67倍。相较之下，移动GPU在性能每瓦方面达到了2倍的优势，但其运行时间增加了2倍且DRAM占用比FPGA多10倍。我们还展示了该技术在用于1型糖尿病的DT引导合成数据生成及主动冠状动脉疾病检测中的应用示例。

---
## 131. Reinforcement Learning for Monetary Policy Under Macroeconomic Uncertainty: Analyzing Tabular and Function Approximation Methods

- 作者：Sheryl Chen, Tony Wang, Kyle Feinstein
- 子主题：RL
- 推荐：很推荐
- 关键词：货币政策, 强化学习, 宏观经济不确定性
- Abstract：http://arxiv.org/abs/2512.17929v1
- PDF：https://arxiv.org/pdf/2512.17929v1

**中文摘要**

本文研究在宏观经济关系存在不确定性和时变性的情形下，中央银行应如何动态设定短期名义利率以稳定通胀和失业。我们将货币政策建模为一个序贯决策问题，中央银行每季度观测宏观经济状况并选择利率调整。基于公开可得的美联储经济数据（FRED），构建了线性高斯转移模型，并实现了一个具有离散动作空间和二次损失奖励函数的马尔可夫决策过程（MDP）。我们比较了九种不同的强化学习方法与泰勒规则及简单基线的表现，包括表格Q学习变体、SARSA、Actor-Critic、深度Q网络（DQN）、带不确定性量化的贝叶斯Q学习，以及考虑部分可观测性的POMDP方法。令人意外的是，标准的表格Q学习取得了最佳性能（平均回报 -615.13 ± 309.58），优于复杂的强化学习方法和传统政策规则。结果表明，尽管复杂的强化学习技术在货币政策应用上具有潜力，但在该领域中更简单的方法可能更为鲁棒，这也凸显了将现代强化学习方法应用于宏观经济政策时面临的重要挑战。

---
## 132. Towards Reasoning-Preserving Unlearning in Multimodal Large Language Models

- 作者：Hongji Li, Junchi yao, Manjiang Yu, Priyanka Singh, Xue Li, Di Wang, Lijie Hu
- 子主题：LLM
- 推荐：很推荐
- 关键词：模型消忘, 多模态大模型, 推理保留
- Abstract：http://arxiv.org/abs/2512.17911v1
- PDF：https://arxiv.org/pdf/2512.17911v1

**中文摘要**

机器消忘（machine unlearning）旨在在无需完全重新训练的情况下，从已训练模型中擦除指定数据。对于具备推理能力的多模态大语言模型（RMLLMs）而言，这一问题尤为棘手：即便最终答案被擦除，链式思维（chain-of-thought）等中间推理步骤仍可能泄露敏感信息，而过于激进的干预又容易损害模型的整体推理能力。目前尚无基准能同时评估消忘方法在抑制推理级别信息泄露与保留推理能力两方面的表现。为填补这一空白，我们提出了RMLLMU-Bench——首个面向RMLLM消忘的基准，除了常规的遗忘指标外，还引入了专门衡量推理泄露与推理保留的评估项。在RMLLMU-Bench上的系统评估表明，现有针对多模态LLM和大型推理模型的消忘方法要么在推理过程中留下大量泄露，要么严重降低推理性能。针对这些问题，我们提出了R-MUSE（通过子空间引导与自适应引导的推理保留型MLLM消忘），这是一种无需训练、在推理时进行干预的框架，通过引导内部表征同时忘记答案与推理痕迹，并显式保留通用推理能力。在RMLLMU-Bench上的实验表明，R-MUSE在有效消除敏感信息与保持推理能力之间取得了显著更好的平衡。

---
## 133. Clustering with Label Consistency

- 作者：Diptarka Chakraborty, Hendrik Fichtenberger, Bernhard Haeupler, Silvio Lattanzi, Ashkan Norouzi-Fard, Ola Svensson
- 子主题：聚类（无监督学习）
- 推荐：很推荐
- 关键词：标签一致性, 度量聚类, k-中心与k-中位数
- Abstract：http://arxiv.org/abs/2512.19654v1
- PDF：https://arxiv.org/pdf/2512.19654v1

**中文摘要**

设计高效、有效且一致的度量聚类算法是一个重要且日益受关注的挑战。传统方法侧重于聚类中心的稳定性，但这往往忽视了现实应用中对点标签稳定性的需求，即点到命名集合（簇）的分配应当稳定。本文针对这一空白，开启了对标签一致性度量聚类的研究。我们首先提出了一个新的“一致性”概念，用以度量两次连续解之间的标签距离；随后，基于该新定义，我们为经典的k-中心和k-中位数问题设计了新的具备一致性保证的近似算法。

---
## 134. MapTrace: Scalable Data Generation for Route Tracing on Maps

- 作者：Artemis Panagopoulou, Aveek Purohit, Achin Kulshrestha, Soroosh Yazdani, Mohit Goyal
- 子主题：多模态大模型（LLM）
- 推荐：很推荐
- 关键词：路线追踪, 合成数据生成, 多模态大模型
- Abstract：http://arxiv.org/abs/2512.19609v1
- PDF：https://arxiv.org/pdf/2512.19609v1

**中文摘要**

尽管多模态大模型在许多视觉与文本推理任务上已达到接近人类的水平，但它们在细粒度空间理解（如地图上的路线追踪）方面仍然有限。与能够快速学习解析和导航地图的人类不同，现有模型常常无法满足基本的路径约束，这在一定程度上源于获取大规模、像素精确路径标注的高成本和难度。为此，我们提出了一种可扩展的合成数据生成流水线：利用合成地图图像与像素级解析自动生成用于此类任务的精确标注。基于该流水线，我们构建了一个包含4千张地图、23k条路径样本的微调数据集，使模型能学习更接近人类的空间能力。用该数据集对开源与专有的多模态大模型进行微调后，在MapBench基准上的实验表明，微调能显著提升鲁棒性，成功率最多提高6.4个百分点，同时降低路径追踪误差（NDTW）。这些结果表明，预训练模型中缺失的细粒度空间推理能力可通过合成监督显式教授。

---
## 135. Activations as Features: Probing LLMs for Generalizable Essay Scoring Representations

- 作者：Jinwei Chi, Ke Wang, Yu Chen, Xuanye Lin, Qiang Xu
- 子主题：LLM
- 推荐：很推荐
- 关键词：激活特征, 自动作文评分, 模型探针
- Abstract：http://arxiv.org/abs/2512.19456v1
- PDF：https://arxiv.org/pdf/2512.19456v1

**中文摘要**

自动作文评分（AES）在跨题目设置下面临评分标准多样化带来的挑战。以往研究主要关注大型语言模型（LLM）的输出以提升评分准确性，而我们认为中间层的激活（activations）也可能包含有价值的信息。为此，我们评估了LLM激活在跨题目作文评分任务中的判别能力。具体而言，我们使用激活向量训练探针模型，并进一步分析了不同模型和输入内容对该判别能力的影响。通过在不同题目下计算作文在各项特质维度上的方向，我们考察了大型语言模型在不同作文类型和评分维度上的评价视角变化。结果表明，激活向量在评估作文质量方面具有较强的判别能力，且LLM能够根据不同特质和作文类型调整其评价视角，在跨题目设置中有效应对评分标准的多样性。

---
## 136. Learning General Policies with Policy Gradient Methods

- 作者：Simon Ståhlberg, Blai Bonet, Hector Geffner
- 子主题：RL
- 推荐：很推荐
- 关键词：策略泛化, 图神经网络, 策略梯度/演员-评论家
- Abstract：http://arxiv.org/abs/2512.19366v1
- PDF：https://arxiv.org/pdf/2512.19366v1

**中文摘要**

尽管强化学习方法在多种场景取得了显著成果，但泛化能力——即产生在不同实例间可靠且系统性泛化的策略的能力——仍然是一个挑战。传统的组合规划研究已经从形式上解决了泛化问题，通过组合方法学习出在给定领域所有实例上可证明正确的泛化策略。本文旨在将这两条研究脉络结合起来，阐明在何种条件下（深度）强化学习方法，尤其是策略优化方法，可以像组合方法那样学习出具有泛化性的策略。我们借鉴并扩展了以往组合方法与深度学习方法的经验：从组合方法中，我们将策略建模为状态转移分类器，因为具体的（ground）动作在不同实例间并不通用；从深度学习中，我们使用适配于关系结构的图神经网络（GNN）来表示规划状态上的价值函数，进而表示策略。在这些要素就位后，我们发现演员-评论家（actor-critic）方法可以用于学习出在泛化性上几乎可与组合方法媲美的策略，同时避免了组合方法常见的可扩展性瓶颈和依赖特征池的问题。此外，在所考察的基准上，深度强化学习方法的局限并非主要源自深度学习或强化学习算法本身，而是由图神经网络的表达能力限制以及最优性与泛化性之间的权衡（在某些领域中泛化策略不可能同时是最优的）所致。我们通过引入派生谓词和一种替代的代价结构来优化，解决了这些限制，而无需改变基本的深度强化学习方法。

---
## 137. PENDULUM: A Benchmark for Assessing Sycophancy in Multimodal Large Language Models

- 作者：A. B. M. Ashikur Rahman, Saeed Anwar, Muhammad Usman, Irfan Ahmad, Ajmal Mian
- 子主题：多模态LLM
- 推荐：很推荐
- 关键词：谄媚性（sycophancy）, 多模态大模型, 视觉问答（VQA）
- Abstract：http://arxiv.org/abs/2512.19350v1
- PDF：https://arxiv.org/pdf/2512.19350v1

**中文摘要**

谄媚性（sycophancy）指的是模型在牺牲事实准确性或与视觉证据相矛盾的情况下，过度赞同用户输入的倾向。这一问题对多模态大语言模型（MLLMs）构成了关键且尚未充分探讨的挑战。尽管先前研究已在文本单模态的大语言模型中考察了此类行为，但针对视觉或多模态模型的研究仍然在范围和深度上有限。为填补这一空白，我们提出了一个综合评估基准PENDULUM，包含约2000个人工策划的视觉问答对，专门设计用于诱发谄媚性反应。该基准覆盖六类复杂度不同的图像领域，能系统性地研究图像类型和内在难点如何影响模型的谄媚倾向。通过对若干最先进的多模态大模型进行大规模评估，我们观察到模型在鲁棒性方面存在显著差异，并普遍易受谄媚性与幻觉性行为的影响。此外，我们提出了用于量化视觉推理中谄媚性的全新衡量指标，从而更深入地揭示其在不同多模态情境下的表现。我们的研究结果强调了开发抗谄媚架构和训练策略以提升未来多模态大模型事实一致性与可靠性的紧迫性。我们公开了所构建的数据集及模型回复，地址为：https://github.com/ashikiut/pendulum/。

---
## 138. Towards Minimal Fine-Tuning of VLMs

- 作者：Tiange Luo, Lajanugen Logeswaran, Jaekyeom Kim, Justin Johnson, Honglak Lee
- 子主题：VLM（视觉-语言模型）
- 推荐：很推荐
- 关键词：视觉-语言模型, 参数高效微调, 低秩适配（LoRA）
- Abstract：http://arxiv.org/abs/2512.19219v1
- PDF：https://arxiv.org/pdf/2512.19219v1

**中文摘要**

我们提出了 Image-LoRA，一种针对基于 Transformer 的视觉-语言模型（VLM）的轻量级参数高效微调（PEFT）方法。Image-LoRA 仅在视觉 token 范围内的注意力层的 value 通路上应用低秩适配（LoRA），从而使仅适配器级别的训练浮点运算量（FLOPs）大致按视觉 token 占比成比例减少。我们进一步仅对部分注意力头进行适配，这些头通过使用 rank-1 Image-LoRA 估计的头影响力得分来选择，并通过选择规模归一化来稳定每层的更新。在覆盖从以文本为主到以图像为主的屏幕中心定位和指称基准上，Image-LoRA 在使用更少可训练参数和更低适配器级别训练 FLOPs 的情况下，达到了与标准 LoRA 相当或接近的精度。该方法还在微调前后保持了 VLM 的纯文本推理性能，这一点在 GSM8K 数据集上的实验中得到了进一步验证。

---
## 139. Can abstract concepts from LLM improve SLM performance?

- 作者：Siddharth Tandon
- 子主题：LLM
- 推荐：很推荐
- 关键词：引导向量, 知识迁移, 推理时缩放
- Abstract：http://arxiv.org/abs/2512.19069v1
- PDF：https://arxiv.org/pdf/2512.19069v1

**中文摘要**

大型语言模型（LLM）在多种任务上表现出色，但在资源受限设备上的部署仍具挑战性。现有方法如量化、剪枝和蒸馏可以减小内存占用，但通常需要大量实验和精细的基础设施设计。本文借鉴已有技术，从大模型中提取高层抽象概念（以引导向量的形式表示），并研究这些概念在推理阶段向小语言模型（SLM）的可迁移性。通过大量实验我们证明，这些概念可以有效迁移至不同家族的小模型（例如 Phi、Llama、Qwen），在广泛任务上带来性能提升。此外，我们提出了推理时的尺度调整，通过动态调节引导强度进一步提高性能，已在 Qwen3-0.6B 上实现约 7–15% 的准确率提升。

---
## 140. Context-Aware Initialization for Reducing Generative Path Length in Diffusion Language Models

- 作者：Tongyuan Miao, Gary Huang, Kai Jun Han, Annie Jiang
- 子主题：LLM
- 推荐：很推荐
- 关键词：扩散语言模型, 上下文感知初始化, 去噪迭代加速
- Abstract：http://arxiv.org/abs/2512.19004v1
- PDF：https://arxiv.org/pdf/2512.19004v1

**中文摘要**

扩散大型语言模型（Diffusion Large Language Models，DLLMs）能够实现完全并行的令牌解码，但在推理阶段往往不切实际，因为需要通过大量去噪迭代将一个无信息的、完全被掩码的初始化逐步精炼为连贯文本。大多数现有的加速方法侧重于通过改进求解器或采样策略更高效地遍历这一生成轨迹。本文提出一种互补思路：通过上下文感知初始化将起点尽量靠近目标分布，从而缩短生成轨迹。我们设计了一个无训练需求的接口，将来自轻量辅助模型的提示条件先验注入到扩散初始化中，并以两种机制实现：离散令牌注入与表示级嵌入插值。鉴于注入的先验可能不完美且仅解掩码的解码可能导致过早过度确定，我们还引入了一种基于置信度的重新掩码机制，作为对先验的不完全信任。GSM8K 的初步实验表明，上下文感知初始化在我们的设置下可显著减少去噪迭代（函数评估约减少35%），但也暴露了一个关键挑战：天真的热启动可能导致最终准确率低于强基线扩散模型。基于这些发现，我们提出了围绕校准、修正机制和表示对齐的后续研究方向，以实现可靠的热启动扩散解码。

---
## 141. Learning Hierarchical Procedural Memory for LLM Agents through Bayesian Selection and Contrastive Refinement

- 作者：Saman Forouzandeh, Wei Peng, Parham Moradi, Xinghuo Yu, Mahdi Jalili
- 子主题：LLM
- 推荐：很推荐
- 关键词：层次程序化记忆, 贝叶斯选择, 对比精炼
- Abstract：http://arxiv.org/abs/2512.18950v1
- PDF：https://arxiv.org/pdf/2512.18950v1

**中文摘要**

我们提出了MACLA，一个通过保持大型语言模型冻结并将所有适配操作放在外部层次化程序化记忆中，从而将推理与学习解耦的框架。MACLA从轨迹中提取可重用的过程，通过贝叶斯后验跟踪其可靠性，基于期望效用评分选择动作，并通过对比成功与失败来精炼过程。在四个基准（ALFWorld、WebShop、TravelPlanner、InterCodeSQL）上，MACLA实现了78.1%的平均性能，优于所有基线。在ALFWorld的未见任务上，MACLA达到了90.3%的成绩，并实现了3.1%的正向泛化。该系统在56秒内构建记忆，比最先进的基于LLM参数训练的基线快约2800倍，同时将2851条轨迹压缩为187个过程。实验结果表明，结合贝叶斯选择与对比精炼的结构化外部记忆能够在无需更新LLM参数的情况下，使代理具备样本高效、可解释并持续改进的能力。

---
## 142. Geometric-Photometric Event-based 3D Gaussian Ray Tracing

- 作者：Kai Kohyama, Yoshimitsu Aoki, Guillermo Gallego, Shintaro Shiba
- 子主题：CV（事件相机 / 3D 重建）
- 推荐：很推荐
- 关键词：事件相机, 3D Gaussian Splatting, 射线追踪
- Abstract：http://arxiv.org/abs/2512.18640v1
- PDF：https://arxiv.org/pdf/2512.18640v1

**中文摘要**

事件相机相比传统帧式相机具有更高的时间分辨率，使其适用于运动与结构估计。然而，基于事件的三维高斯溅射（3D Gaussian Splatting, 3DGS）方法如何利用稀疏事件的细粒度时间信息尚不明确。本文提出了一种框架，以解决基于事件的3DGS在精度与时间分辨率之间的权衡。我们的关键思想是将渲染解耦为两条分支：逐事件的几何（深度）渲染和基于快照的辐射（强度）渲染，分别通过射线追踪和扭曲事件图像来实现。大量评估表明，本方法在真实世界数据集上达到最先进的性能，在合成数据集上也具有竞争力。此外，该方法无需先验信息（例如预训练的图像重建模型）或基于COLMAP的初始化，对事件选择数量更为灵活，并能在场景边缘实现清晰的重建且训练速度快。我们希望此工作能加深对事件稀疏性在三维重建中作用的理解。代码将会开源。

---
## 143. Gabliteration: Adaptive Multi-Directional Neural Weight Modification for Selective Behavioral Alteration in Large Language Models

- 作者：Gökdeniz Gülmez
- 子主题：LLM
- 推荐：很推荐
- 关键词：模型编辑, 权重修改, 自适应投影
- Abstract：http://arxiv.org/abs/2512.18901v1
- PDF：https://arxiv.org/pdf/2512.18901v1

**中文摘要**

我们提出了 Gabliteration，一种新的神经权重修改技术，它通过实现自适应的多方向投影并结合正则化的层选择，超越了传统的abliteration方法。该方法旨在解决现有方法在尝试修改特定行为模式时常常牺牲模型整体质量的根本限制。通过动态的层优化、正则化的投影矩阵以及自适应缩放机制，我们在理论上实现了更优的权重修改，同时尽量减少对无关领域性能的退化。我们在 Hugging Face 上发布的 gabliterated-v1 模型系列（参数规模从0.6B到4B）上对该方法进行了验证，展示了其在多种模型规模下的实际适用性。

---
## 144. Hyperbolic Graph Embeddings: a Survey and an Evaluation on Anomaly Detection

- 作者：Souhail Abdelmouaiz Sadat, Mohamed Yacine Touahria Miliani, Khadidja Hab El Hames, Hamida Seba, Mohammed Haddad
- 子主题：图表示学习
- 推荐：很推荐
- 关键词：双曲图嵌入, 异常检测, 图神经网络
- Abstract：http://arxiv.org/abs/2512.18826v1
- PDF：https://arxiv.org/pdf/2512.18826v1

**中文摘要**

本文综述了双曲图嵌入模型，并在异常检测任务上对其进行了评估，突出了相较于欧氏方法在捕捉复杂结构方面的优势。对HGCAE、P-VAE和HGCN等模型的评估显示出较高的性能，其中P-VAE在Elliptic数据集上达到94%的F1分数，HGCAE在Cora数据集上得分80%。相比之下，欧氏方法如DOMINANT和GraphSage在复杂数据上表现较差。研究强调了利用双曲空间改善异常检测的潜力，并提供了一个开源库以促进该领域的后续研究。

---
## 145. Reliable Audio Deepfake Detection in Variable Conditions via Quantum-Kernel SVMs

- 作者：Lisan Al Amin, Vandana P. Janeja
- 子主题：语音/音频处理（反伪造）
- 推荐：很推荐
- 关键词：量子核, 语音深伪检测, 支持向量机
- Abstract：http://arxiv.org/abs/2512.18797v1
- PDF：https://arxiv.org/pdf/2512.18797v1

**中文摘要**

在标注数据稀缺且录音条件多变的情况下，检测合成语音具有挑战性。现有端到端深度模型常出现过拟合或泛化能力不足，而核方法在某些情形下仍能保持竞争力，但其性能高度依赖所选核函数。本文展示了在音频深伪检测中使用量子核能够在不增加模型规模的前提下降低假阳性率。量子特征映射将数据嵌入高维希尔伯特空间，因而能够使用更具表达力的相似性度量并配合紧凑的分类器。基于这一动机，我们在相同的mel谱图预处理和分层5折交叉验证设置下，将量子核SVM（QSVM）与经典SVM在四个语料库（ASVspoof 2019 LA、ASVspoof 5 (2024)、ADD23 和 In-the-Wild）上进行比较。QSVM 在等错误率（EER）上始终更低：在 ASVspoof 5 (2024) 上为 0.183 vs. 0.299，在 ADD23 上为 0.081 vs. 0.188，在 ASVspoof 2019 上为 0.346 vs. 0.399，以及在 In-the-Wild 上为 0.355 vs. 0.413。在 EER 工作点（FPR 等于 FNR）处，这分别对应绝对假阳性率减少 0.116（38.8%）、0.107（56.9%）、0.053（13.3%）和 0.058（14.0%）。我们还报告了跨折一致性和基于边距的类分离度量，且对两类模型采用完全相同的设置。唯一的改动是核函数；特征与 SVM 保持不变，未引入额外可训练参数，且量子核在传统计算机上完成计算。

---
## 146. Snowveil: A Framework for Decentralised Preference Discovery

- 作者：Grammateia Kotsialou
- 子主题：分布式算法（计算社会选择 / 多智能体）
- 推荐：很推荐
- 关键词：去中心化偏好聚合, 受限混合博尔达（CHB）, 分布式收敛性证明
- Abstract：http://arxiv.org/abs/2512.18444v1
- PDF：https://arxiv.org/pdf/2512.18444v1

**中文摘要**

汇聚大规模群体的主观偏好是计算社会选择中的基本挑战，传统方法依赖于中心化权威机构。为克服该模型的局限，本文提出了“去中心化偏好发现”（Decentralised Preference Discovery，DPD）问题，即在抗审查、信息不完全和异步通信约束下确定选民集体意愿。我们提出了Snowveil框架，基于迭代的gossip式协议：选民反复随机抽样少量其他选民的偏好，通过多轮信息交换逐步收敛到集体结果。为验证框架的模块性，我们设计了受限混合博尔达（Constrained Hybrid Borda，CHB）聚合规则，该规则旨在在广泛共识与强多数支持之间取得平衡，并对其性质给出了严格的公理化分析。通过引入势函数与子鞅（submartingale）理论，我们发展了一种多层次的分析方法，证明系统几乎必然在有限时间内收敛到稳定的、单一胜者；在多胜者情形下可迭代该过程以构造一组当选候选人。该技术对具体聚合规则具有较强的不敏感性，仅需满足诸如正响应性（Positive Responsiveness）等基本社会选择公理，从而为更广泛的DPD协议提供了形式化工具包。此外，我们通过大量仿真进行了全面的经验分析，验证了Snowveil的O(n)可扩展性。总体而言，本工作推进了理解在大规模、主观复杂且多样化的偏好环境中，去中心化系统如何自发产生稳定共识。

---
## 147. Few-Shot Learning of a Graph-Based Neural Network Model Without Backpropagation

- 作者：Mykyta Lapin, Kostiantyn Bokhan, Yurii Parzhyn
- 子主题：CV（图像理解）/ 图结构学习
- 推荐：很推荐
- 关键词：图结构少样本学习, 可解释图模型, 无反向传播学习
- Abstract：http://arxiv.org/abs/2512.18412v1
- PDF：https://arxiv.org/pdf/2512.18412v1

**中文摘要**

我们提出了一种基于结构图的轮廓图像少样本分类方法，且在训练过程中不使用反向传播。核心思想是把“结构”作为解释的载体：将图像编码为带属性的图（以关键点与关键线为节点并附带几何属性），并通过形成“概念吸引子”（类级别的概念图）实现泛化。目标是设计并实验证明一种架构，能够仅从少量样本（每类5–6个）通过结构与参数的约简形成类别概念，提供可追溯的决策并消除反向传播。方法上，首先对轮廓进行矢量化，然后构建点/线二分图，节点带有归一化的几何属性（坐标、长度、角度、方向等）；约简过程包括去除不稳定的子结构或噪声、以及对关键点之间路径的对齐。概念由样本的迭代合成形成，分类则通过选择最佳的图到概念匹配（使用近似图编辑距离）来完成。结果表明：在MNIST的子集上（每类5–6个基样、本方法仅用单个训练周期），可稳定达到约82%的准确率，且决策具有完全可追溯性——误分类可以通过显式的结构相似性解释。论文还给出了与SVM、MLP、CNN及若干度量/元学习基线的指示性比较。该结构图方案通过概念吸引子实现了无需反向传播的少样本学习，并通过显式的图结构提供内在的可解释性。主要局限在于图编辑距离的计算开销和骨架化质量；未来可在分类算法优化、静态场景扩展与联想识别等方向改进。

---
## 148. AmPLe: Supporting Vision-Language Models via Adaptive-Debiased Ensemble Multi-Prompt Learning

- 作者：Fei Song, Yi Li, Jiangmeng Li, Rui Wang, Changwen Zheng, Fanjiang Xu, Hui Xiong
- 子主题：视觉-语言模型
- 推荐：很推荐
- 关键词：多提示学习, 去偏集成, 视觉-语言模型
- Abstract：http://arxiv.org/abs/2512.18411v1
- PDF：https://arxiv.org/pdf/2512.18411v1

**中文摘要**

多提示学习方法已成为一种有效手段，能够在资源有限的情况下快速将视觉-语言模型适配到下游任务。现有的多提示学习方法主要集中在单一基础视觉-语言模型中利用各种精心设计的提示以取得优越性能。然而，被忽视的模型-提示匹配偏差阻碍了多提示学习的发展：相同的提示在不同的视觉-语言模型（如 CLIP-ViT-B/16 与 CLIP-ViT-B/32）上可能传达不同语义，从而导致相同提示产生不一致的预测。为缓解该偏差对下游任务的影响，我们探索了集成学习方法以充分聚合多样化预测的优势。此外，我们进一步揭示了样本-提示匹配偏差，该偏差源自输入样本中包含的与提示无关的语义。因此，直接利用输入样本的全部信息来生成集成学习权重可能导致次优性能。为此，我们借助信息论分析的指导，从输入样本中提取与提示相关的语义，并自适应地计算去偏的集成权重。总体上，我们提出了自适应去偏集成多提示学习（Adaptive-Debiased Ensemble MultiPrompt Learning，简称 AmPLe），以同时缓解这两类偏差。在对新类别泛化、迁移到新目标数据集以及应对未见域移位这三类代表性任务上的大量实验表明，AmPLe 能广泛且显著地优于现有方法。来自因果视角的理论验证进一步支持了 AmPLe 的有效性。

---
## 149. AraToken: Optimizing Arabic Tokenization with Normalization Pipeline and Language Extension for Qwen3

- 作者：Mark Kashirskiy, Artiom Lipinski, Ilya Makarov
- 子主题：LLM
- 推荐：很推荐
- 关键词：阿拉伯语分词, SentencePiece（Unigram）, 词表扩展与 LEP
- Abstract：http://arxiv.org/abs/2512.18399v1
- PDF：https://arxiv.org/pdf/2512.18399v1

**中文摘要**

分词是大规模语言模型（LLM）预处理的关键步骤，直接影响训练效率和下游性能。以英语及拉丁字母语言为主训练的通用分词器在形态丰富的语言（如阿拉伯语）上表现欠佳，会导致序列长度膨胀和压缩效率下降。在本文中，我们提出了 AraToken，一种基于 SentencePiece Unigram 算法的阿拉伯语优化分词器，并设计了覆盖阿拉伯语正字法变体（包括不同形态的 Alif、元音符号/重音符号及阿拉伯-印度数字）的全面归一化管线。我们系统比较了 BPE、WordPiece 与 SentencePiece 在多种配置下的表现，结果表明引入归一化的 SentencePiece 相较于未归一化基线在 fertility 指标上降低了 18%（1.199 vs 1.35 tokens/word）。此外，我们提出了语言扩展管线（Language Extension Pipeline, LEP），通过词表扩展、子词均值初始化和选择性解冻 Transformer 层的方法，将该优化分词器整合到 Qwen3-0.6B 中。实验表明，在 100K 条阿拉伯语样本上，LEP 在 800 个训练步内将评估损失从 8.28 降至 2.43。我们开源了分词器、训练脚本和模型检查点，以促进阿拉伯语自然语言处理研究。

---
## 150. Dynamic Entropy Tuning in Reinforcement Learning Low-Level Quadcopter Control: Stochasticity vs Determinism

- 作者：Youssef Mahran, Zeyad Gamal, Ayman El-Badawy
- 子主题：RL
- 推荐：很推荐
- 关键词：动态熵调优, 四旋翼低层控制, SAC与TD3比较
- Abstract：http://arxiv.org/abs/2512.18336v1
- PDF：https://arxiv.org/pdf/2512.18336v1

**中文摘要**

本文研究了在训练随机策略的强化学习算法中采用动态熵调优的影响，并将其性能与训练确定性策略的算法进行比较。随机策略通过优化动作的概率分布以最大化回报，而确定性策略则在每个状态选择单一确定性动作。本文考察了在训练随机策略时采用静态熵与动态熵两种方式，并在执行阶段以确定性动作控制四旋翼的效果，随后将其与训练并执行确定性策略的结果进行对比。为此研究选用了Soft Actor-Critic（SAC）作为随机策略算法，Twin Delayed Deep Deterministic Policy Gradient（TD3）作为确定性策略算法。训练与仿真结果表明，动态熵调优通过防止灾难性遗忘并提高探索效率，能够对四旋翼的控制性能产生积极影响。

---
## 151. Asynchronous Pipeline Parallelism for Real-Time Multilingual Lip Synchronization in Video Communication Systems

- 作者：Eren Caglar, Amirkia Rafiei Oskooei, Mehmet Kutanoglu, Mustafa Keles, Mehmet S. Aktas
- 子主题：多模态
- 推荐：很推荐
- 关键词：唇形同步, 异步流水线并行, 实时多模态通信
- Abstract：http://arxiv.org/abs/2512.18318v1
- PDF：https://arxiv.org/pdf/2512.18318v1

**中文摘要**

本文提出了一种并行且异步的 Transformer 框架，旨在为实时视频会议系统提供高效且精确的多语言唇形同步。所述架构将翻译、语音处理与唇形同步模块集成于流水线并行设计中，通过基于消息队列的模块解耦实现并发执行，从而相比顺序处理将端到端延迟最多降低约 3.1 倍。为提升计算效率与吞吐量，作者对各模块的推理流程进行了低层图编译、混合精度量化和硬件加速内核融合等优化，这些措施在保持模型精度和视觉质量的同时带来显著的性能提升。此外，引入了上下文自适应的静音检测组件，用于在语义连贯的边界上分割输入语音流，改善了翻译一致性与跨语言的时间对齐。实验结果表明，所提并行架构在处理速度、同步稳定性和资源利用率方面均优于传统的顺序流水线。其模块化、面向消息的设计使该方法适用于资源受限的物联网通信场景，包括远程医疗、多语言自助终端与远程援助系统。总体上，本工作推动了面向下一代 AIoT 系统的低延迟、资源高效的多模态通信框架的发展。

---
## 152. Evolutionary BP+OSD Decoding for Low-Latency Quantum Error Correction

- 作者：Hee-Youl Kwak, Seong-Joon Park, Hyunwoo Jung, Jeongseok Ha, Jae-Won Kim
- 子主题：量子纠错 (Quantum Error Correction)
- 推荐：很推荐
- 关键词：演化置信传播, 有序统计译码, 量子纠错
- Abstract：http://arxiv.org/abs/2512.18273v1
- PDF：https://arxiv.org/pdf/2512.18273v1

**中文摘要**

我们提出了一种用于量子纠错的演化置信传播（EBP）译码器，该译码器在置信传播（BP）算法中引入可训练的权重，并通过差分进化算法对这些权重进行优化。该方法使得EBP与有序统计译码（OSD）的结合可以进行端到端优化。针对表面码和量子低密度奇偶校验（LDPC）码的实验结果表明，在严格的低延迟约束（在5次BP迭代内）下，EBP+OSD 相较于传统的 BP+OSD 实现了更优的译码性能和更低的计算复杂度。

---
## 153. Offline Behavioral Data Selection

- 作者：Shiye Lei, Zhihao Cheng, Dacheng Tao
- 子主题：RL（离线强化学习 / 行为克隆）
- 推荐：很推荐
- 关键词：离线行为克隆, 数据选择, 逐步双重排序（SDR）
- Abstract：http://arxiv.org/abs/2512.18246v1
- PDF：https://arxiv.org/pdf/2512.18246v1

**中文摘要**

行为克隆是从专家示范中进行离线策略学习的常用方法。然而，离线行为数据集的大规模往往导致下游任务训练计算开销巨大。本文揭示了离线行为数据中显著的数据饱和现象：当仅使用数据集的一小部分进行训练时，策略性能会迅速达到饱和。我们将该现象归因于策略性能与测试损失之间的弱对齐，表明通过数据选择有很大改进空间。为此，我们提出了一种简单而有效的方法——逐步双重排序（Stepwise Dual Ranking, SDR），用于从大规模离线行为数据集中提取紧凑且信息丰富的子集。SDR基于两项关键原则：（1）逐步裁剪（stepwise clip），优先保留早期训练阶段的数据；（2）双重排序（dual ranking），选择动作价值排名高且状态密度排名低的样本。D4RL 基准上的大量实验与消融研究表明，SDR 能显著提升离线行为数据的选择效果。

---
## 154. Spectral Discrepancy and Cross-modal Semantic Consistency Learning for Object Detection in Hyperspectral Image

- 作者：Xiao He, Chang Tang, Xinwang Liu, Wei Zhang, Zhimin Gao, Chuankun Li, Shaohua Qiu, Jiangfeng Xu
- 子主题：CV (超光谱/遥感)
- 推荐：很推荐
- 关键词：超光谱图像, 谱域一致性, 目标检测
- Abstract：http://arxiv.org/abs/2512.18245v1
- PDF：https://arxiv.org/pdf/2512.18245v1

**中文摘要**

超光谱图像具有高光谱分辨率，能够识别相似物质间的细微差异。然而，由于超光谱各波段间的空间差异及不可避免的干扰（如传感器噪声和光照变化），超光谱图像目标检测面临显著的类内与类间相似性挑战。为缓解波段间不一致性与冗余，我们提出了一种新型网络——谱差异与跨模态语义一致性学习（SDCM），用于在广泛的超光谱波段间提取一致的信息并利用光谱维度定位感兴趣区域。具体地，我们设计了语义一致性学习（SCL）模块，利用波段间的上下文线索减少各波段信息的异质性，从而获得高度一致的光谱维表示；同时引入谱门控生成器（SGG）以根据波段重要性过滤超光谱信息中的冗余数据；此外，设计了谱差异感知（SDA）模块，通过提取像素级光谱特征来丰富高层语义表征。大量实验结果表明，在两个超光谱数据集上，所提方法相比其他方法实现了最先进的性能。

---
## 155. PROVEX: Enhancing SOC Analyst Trust with Explainable Provenance-Based IDS

- 作者：Devang Dhanuka, Nidhi Rastogi
- 子主题：图神经网络 (GNN) 与网络安全 (IDS)
- 推荐：很推荐
- 关键词：图神经网络可解释性, 系统溯源入侵检测, 安全运营中心(SOC)可解释XAI
- Abstract：http://arxiv.org/abs/2512.18199v1
- PDF：https://arxiv.org/pdf/2512.18199v1

**中文摘要**

现代入侵检测系统（IDS）利用图神经网络（GNN）在系统溯源数据中检测恶意活动，但其决策常对分析员来说如同黑箱。本文提出了一个综合性的可解释人工智能（XAI）框架，旨在通过使基于图的检测过程透明化来弥合安全运营中心（SOC）中的信任缺口。我们在最先进的基于时序图的IDS KAIROS之上实现了该框架，但设计对任何时序图检测器仅需最小适配即可使用。完整代码库可在 https://github.com/devang1304/provex.git 获取。我们在检测流水线中增加了事后解释模块，能够突出显示触发告警的原因，识别关键的因果子图和事件。我们将三种GNN解释方法——GraphMask、GNNExplainer以及一种变分时序GNN解释器（VA-TGExplainer）——改造并适配到时序溯源场景中，输出包括重要边、事件及不确定性估计在内的人类可解释表示。我们的贡献侧重于这些解释器的实用集成，解决了内存管理和可重现性等工程挑战。我们在DARPA CADETS Engagement 3数据集上展示了该框架，证明其能为检测到的攻击生成简洁的窗口级解释。评估表明，这些解释器在高保真度下保留了时序GNN的决策，能够揭示诸如恶意文件交互和异常网络流等关键边，平均每事件的解释开销为3–5秒。通过提供对模型推理过程的洞见，本框架旨在提升分析员对模型的信任并加快告警分流速度。

---
## 156. Separating Constraint Compliance from Semantic Accuracy: A Novel Benchmark for Evaluating Instruction-Following Under Compression

- 作者：Rahul Baxi
- 子主题：LLM
- 推荐：很推荐
- 关键词：提示压缩, 约束遵从, RLHF对齐
- Abstract：http://arxiv.org/abs/2512.17920v1
- PDF：https://arxiv.org/pdf/2512.17920v1

**中文摘要**

大型语言模型（LLM）在提示压缩条件下表现下降，但其内部机制仍不清楚。我们提出了压缩-衰减理解测试（CDCT），该基准能够在不同压缩水平上独立测量约束遵从（CC）与语义准确性（SA）。我们在9个前沿LLM上、8个概念下、5个压缩等级（从极端压缩 c=0.0，约2词，到无压缩 c=1.0，约135词）进行了评估。由三位LLM担任评审的评审团在约束遵从判定上达到了近乎完美的一致性（Fleiss' κ=0.90）。我们观察到约束遵从普遍呈现U形曲线（97.2%普遍性），在中等压缩（c=0.5，约27词）时违约最多。令人逆向直觉的是，模型在极端压缩下的表现优于中等长度。两个维度在统计上近似正交（r=0.193，p=0.084），且约束效应比语义效应大约2.9倍。通过对RLHF的消融实验验证了我们的“约束显著性”假设：移除“有用性（helpfulness）”信号平均使约束遵从提升598%（71/72次试验，p<0.001），其中79%达成完全遵从。这表明RLHF训练中强化的“有用性”行为是中等压缩下约束违例的主要原因。推理型模型相较于高效型模型在约束遵从上表现更好，提升27.5%（Cohen's d=0.96）。我们的发现揭示了RLHF对齐与指令遵循之间的根本张力，并为改进部署系统提供了可行性指导。

---
## 157. IntelliCode: A Multi-Agent LLM Tutoring System with Centralized Learner Modeling

- 作者：Jones David, Shreya Ghosh
- 子主题：LLM
- 推荐：很推荐
- 关键词：学习者建模, 多智能体LLM, 个性化教学
- Abstract：http://arxiv.org/abs/2512.18669v1
- PDF：https://arxiv.org/pdf/2512.18669v1

**中文摘要**

基于大型语言模型（LLM）的辅导系统通常是单次交互的助手，缺乏对学习者知识的持久化表征，因而难以提供有原则性、可解释且长期有效的教学支持。我们提出了 IntelliCode，一种以集中式、带版本的学习者状态为核心构建的多代理 LLM 辅导系统，该状态整合了掌握度估计、学习误区、复习计划和参与度信号。一个名为 StateGraph 的协调器负责协调六个专职代理：技能评估、学习者画像、分级提示、课程选择、间隔重复和参与度监测；在单一写入者策略下，每个代理都作为对共享状态的纯变换进行操作。该架构支持可审计的掌握度更新、基于熟练度的提示、考虑知识依赖的课程自适应以及符合安全要求的提示策略。演示展示了端到端的辅导工作流：学习者尝试一道数据结构与算法题，卡住时收到概念性提示，提交修正后的解答后立即看到掌握度更新和个性化的复习间隔。我们在模拟学习者上的验证结果表明状态更新稳定、分级提示提高了任务成功率并实现了多样化的课程覆盖。IntelliCode 演示了持久化学习者建模、协调化多代理推理与有原则的教学设计如何结合，从而构建透明且可靠的 LLM 驱动辅导系统。

---
## 158. Automatic Adaptation to Concept Complexity and Subjective Natural Concepts: A Cognitive Model based on Chunking

- 作者：Dmitry Bennett, Fernand Gobet
- 子主题：认知建模/概念学习
- 推荐：很推荐
- 关键词：分块机制, 概念学习, 主观概念空间
- Abstract：http://arxiv.org/abs/2512.18665v1
- PDF：https://arxiv.org/pdf/2512.18665v1

**中文摘要**

认知科学中的一个核心问题是支撑短时记忆（STM）和长时记忆（LTM）中多类型概念形成与检索的基本心理过程。我们提出分块（chunking）机制在其中发挥关键作用，并展示了基于分块、注意力、STM 与 LTM 等基本认知过程与结构的 CogAct 计算模型如何为概念学习提供理论基础。首先，我们给出原则性证明：CogAct 能够自动适应并学习从简单逻辑函数、人工类别到来自文学、国际象棋和音乐等不同领域的自然原始（而非预处理）概念这一系列类别。这类自适应学习对大多数其他心理学模型而言较为困难，例如许多认知模型仅能处理人工类别，而基于深度学习的（非 GPT 类）模型通常需要针对任务对架构进行特定修改。其次，我们提出了设计用于概念学习实验的人类基准的新方法，能够在保持现实复杂类别的前提下考虑主观性并控制个体经验差异。我们将 CogAct 嵌入到针对个体参与者的主观概念空间的模拟中，重现人类在音乐主观判断上的表现，且模型直接从原始乐谱数据学习，无需借助预先构建的知识结构。同时将 CogAct 的模拟结果与一个深度学习模型进行了比较。这些发现将概念学习与对复杂性的自适应整合进更广泛的认知心理学理论，并为心理学应用提供了从模拟“平均参与者”转向刻画个体主观概念空间的途径。

---
## 159. LLM-CAS: Dynamic Neuron Perturbation for Real-Time Hallucination Correction

- 作者：Jensen Zhang, Ningyuan Liu, Yijia Fan, Zihao Huang, Qinglin Zeng, Kaitong Cai, Jian Wang, Keze Wang
- 子主题：LLM
- 推荐：很推荐
- 关键词：动态神经元扰动, 幻觉校正, 层次化强化学习
- Abstract：http://arxiv.org/abs/2512.18623v1
- PDF：https://arxiv.org/pdf/2512.18623v1

**中文摘要**

大型语言模型（LLMs）常会生成缺乏事实或上下文依据的“幻觉”内容，限制了它们在关键应用中的可靠性。现有方法如有监督微调和来自人类反馈的强化学习（RLHF）对数据和计算资源要求高，而静态参数编辑方法在处理依赖上下文的错误时表现欠佳且易出现灾难性遗忘。我们提出了LLM-CAS，一个将实时幻觉校正形式化为层次化强化学习问题的框架。LLM-CAS训练一个智能体学习策略，依据当前上下文在推理过程中动态选择临时的神经元扰动。不同于以往依赖启发式或预定义调整的动态方法，该策略驱动的机制能够在不对参数进行永久修改的情况下实现自适应和细粒度的校正。跨多个语言模型的实验表明，LLM-CAS在事实准确性上稳定提升：在StoryCloze上提升了10.98个百分点，在TriviaQA上提升了2.71个百分点，在TruthfulQA的MC1评分上提升了2.06个百分点。这些结果优于静态编辑方法（如ITI和CAA）以及动态SADI框架。总体而言，LLM-CAS为提高大型语言模型的可靠性提供了一种高效且具上下文感知性的解决方案，并在未来向多模态扩展方面展现出良好潜力。

---
## 160. ChronoDreamer: Action-Conditioned World Model as an Online Simulator for Robotic Planning

- 作者：Zhenhao Zhou, Dan Negrut
- 子主题：机器人学（世界模型与规划）
- 推荐：很推荐
- 关键词：动作条件世界模型, 接触表征（高斯splat）, 视觉-语言碰撞评估
- Abstract：http://arxiv.org/abs/2512.18619v1
- PDF：https://arxiv.org/pdf/2512.18619v1

**中文摘要**

我们提出 ChronoDreamer，一种用于接触丰富机器人操作的动作条件世界模型。给定自视角 RGB 帧、接触图、动作和关节状态的历史，ChronoDreamer 通过一个以 MaskGIT 风格掩码预测训练的时空 Transformer，预测未来的视频帧、接触分布和关节角度。接触被编码为深度加权的高斯 splat 图像，将三维力渲染成与相机对齐、适配视觉骨干的格式。在推理阶段，预测的 rollout 由一个视觉-语言模型评估碰撞可能性，从而在执行前通过拒绝采样排除不安全动作。我们在 DreamerBench 上进行训练与评估——该数据集由 Project Chrono 生成，提供刚性与可变形物体场景中同步的 RGB、接触 splat、本体感知和物理注释。定性结果表明，模型在非接触运动中保持空间连贯性并生成合理的接触预测，同时基于大模型的判别器能区分碰撞与非碰撞轨迹。

---
## 161. AI Code in the Wild: Measuring Security Risks and Ecosystem Shifts of AI-Generated Code in Modern Software

- 作者：Bin Wang, Wenjie Yu, Yilu Zhong, Hao Yu, Keke Lian, Chaohua Lu, Hongfang Zheng, Dong Zhang, Hui Li
- 子主题：LLM
- 推荐：很推荐
- 关键词：AI生成代码, 软件安全/漏洞, 检测与生态演化
- Abstract：http://arxiv.org/abs/2512.18567v1
- PDF：https://arxiv.org/pdf/2512.18567v1

**中文摘要**

大型语言模型（LLM）用于代码生成正逐步成为现代软件开发的组成部分，但其在真实世界中的普及程度与安全影响尚不清楚。我们提出了首个大规模的实证研究，用以衡量野外的 AI 生成代码（AIGCode）。为此我们构建了高精度的检测流水线和具有代表性的基准，用以区分 AI 生成代码与人类编写代码，并将其应用于：(i) 2022–2025 年期间来自 GitHub 排名前 1000 的开发提交，以及 (ii) 7000+ 条与 CVE 相关的近期代码变更。基于这些数据，我们可以在提交、文件和函数级别沿着人类/AI 轴为代码打标签，并追踪 AIGCode 在项目和漏洞生命周期中的流动。我们的测量揭示了三种生态模式。第一，AIGCode 已占据新代码的一定比例，但其采用是有结构的：AI 更多用于粘合代码、测试、重构、文档和其他样板代码，而核心逻辑和安全关键配置仍主要由人类编写。第二，采用 AI 带来了安全后果：某些 CWE 家族在 AI 标记代码中被过度表示，且几乎相同的不安全模板在无关联项目中重复出现，表明“AI 诱发的漏洞”可能是由共享模型而非共享维护者传播。第三，在人-AI 编辑链中，AI 带来高吞吐量的改动而人类则充当安全把关者；当审查较浅时，AI 引入的缺陷会更长时间地存在，继续暴露在可网络访问的接口上，并扩散到更多文件和仓库。我们将开源完整数据集并发布分析工件及方法论与发现的细粒度文档。

---
## 162. Vox Deorum: A Hybrid LLM Architecture for 4X / Grand Strategy Game AI -- Lessons from Civilization V

- 作者：John Chen, Sihan Cheng, Can Gurkan, Ryan Lay, Moez Salahuddin
- 子主题：LLM
- 推荐：很推荐
- 关键词：大语言模型, 4X策略游戏AI, 混合架构
- Abstract：http://arxiv.org/abs/2512.18564v1
- PDF：https://arxiv.org/pdf/2512.18564v1

**中文摘要**

大型语言模型在自然语言推理方面的能力使其在4X和大策略游戏中具有独特的前景，能够支持更自然的人机交互形式，例如协作与谈判。然而，这类游戏由于其复杂性与远期决策特性带来独特挑战，且延迟与成本因素可能阻碍LLM在现实中的部署。基于经典4X策略游戏《席德·梅尔的文明V》（Sid Meier's Civilization V）及其Vox Populi模组，我们提出了Vox Deorum，一种混合LLM+X架构。该分层技术设计使LLM承担宏观战略推理，同时将战术执行委派给子系统（例如算法式AI或未来的强化学习AI）。我们通过2327场完整对局对该方法进行了验证，将两种开源LLM（使用简单提示）与Vox Populi的增强AI进行了比较。结果表明，LLM能够实现有竞争力的端到端游戏表现，但其游戏风格与算法式AI以及不同LLM之间均存在显著差异。我们的工作确立了一种将LLM整合进商业4X游戏的可行架构，为游戏设计与具代理性的AI研究开辟了新机会。

---
## 163. SecureCode v2.0: A Production-Grade Dataset for Training Security-Aware Code Generation Models

- 作者：Scott Thornton
- 子主题：LLM
- 推荐：很推荐
- 关键词：安全感知代码生成, 生产级安全数据集, 对话式示例与运维指导
- Abstract：http://arxiv.org/abs/2512.18542v1
- PDF：https://arxiv.org/pdf/2512.18542v1

**中文摘要**

AI 助手在安全相关场景中会生成有漏洞的代码（占比约45%），可能在生产环境大规模引入缺陷，而现有的安全编码数据集在事例溯源、规模与运维安全上下文支持上不足。为此我们提出 SecureCode v2.0 —— 一个生产级别的数据集，包含 1,215 个经过结构验证和安全专家审查的安全聚焦编码示例。每个示例均与实际可查证的安全事件（带 CVE 引用）关联，提供有漏洞与修复后的实现、具体攻击示例以及纵深防御（defense-in-depth）的运维建议。数据覆盖 11 类漏洞（包括完整的 OWASP Top 10:2025 及 AI/ML 安全威胁）和 11 种语言（Python、JavaScript、Java、Go、PHP、C#、TypeScript、Ruby、Rust、Kotlin 及用于基础设施即代码的 YAML）。

我们的质量保证框架确保完整的事件溯源；每个示例还包含 SIEM 集成策略、基础设施加固建议（如 Docker、AppArmor、WAF 配置）和基于语言的测试方法。数据采用模拟真实开发者—AI 交互的 4 轮对话结构，从基础实现逐步扩展到高级安全考虑与纵深防御建议。贡献包括：1) 将 1,215 个经严格验证的示例划分为 989/122/104（训练/验证/测试）；2) 一个自动化验证框架保证数据一致性；3) 4 轮对话结构以捕捉真实的安全工作流；4) 提供全面的运维安全指导与 SIEM 集成策略；5) 保证语言特定实现的完整性；6) 开源发布数据、验证工具与基准协议。

---
## 164. The Illusion of Consistency: Selection-Induced Bias in Gated Kalman Innovation Statistics

- 作者：Barak Or
- 子主题：跟踪与状态估计 (Kalman滤波)
- 推荐：很推荐
- 关键词：卡尔曼滤波, 验证门控, 创新统计量
- Abstract：http://arxiv.org/abs/2512.18508v1
- PDF：https://arxiv.org/pdf/2512.18508v1

**中文摘要**

验证门控（validation gating）是经典基于卡尔曼滤波的跟踪系统中的基本组成部分。只有归一化创新平方（NIS）低于预设阈值的测量才会被考虑用于状态更新。尽管该过程在统计上可由卡方分布理论进行动机说明，但它隐式地将无条件的创新过程替换为受限于验证事件的条件观测过程。本文证明，经门控后计算的创新统计量趋向于门控条件下的量，而非名义（无条件）量。在经典的线性—高斯假设下，我们推导了在椭球形门控条件下创新的一阶与二阶矩的精确表达式，并证明门控会对创新协方差产生确定性且与维度相关的收缩。分析还扩展到最近邻（NN）关联，表明NN关联作为额外的统计选择算子。我们证明，在多个门内测量中选择最小范数创新会引入不可避免的能量收缩，这意味着在非平凡的门控与关联情况下，名义的创新统计量无法保持不变。最后，本文给出了二维情形的封闭形式结果，以量化这些联合效应并说明其实际意义。

---
## 165. Enhancing Decision-Making in Windows PE Malware Classification During Dataset Shifts with Uncertainty Estimation

- 作者：Rahul Yumlembam, Biju Issac, Seibu Mary Jacob
- 子主题：计算机安全（恶意软件检测）
- 推荐：很推荐
- 关键词：恶意软件检测, 不确定性估计, 保形预测
- Abstract：http://arxiv.org/abs/2512.18495v1
- PDF：https://arxiv.org/pdf/2512.18495v1

**中文摘要**

人工智能技术在分类 Windows Portable Executable (PE) 恶意软件方面已取得显著性能，但在数据分布发生漂移时，其可靠性常常下降，导致误分类并带来严重的安全后果。为了解决这一问题，本文在已有的 LightGBM (LGBM) 恶意软件检测器基础上引入神经网络（NN）、PriorNet 和神经网络集成方法，并在三个基准数据集（EMBER、BODMAS 和 UCSB）上进行了评估。UCSB 数据集主要由打包（packed）的恶意软件构成，与 EMBER 和 BODMAS 存在显著分布差异，是一个对鲁棒性要求很高的测试集。我们研究了若干基于不确定性感知的决策策略，包括概率阈值、PriorNet、基于集成的估计以及归纳保形评估（Inductive Conformal Evaluation, ICE）。本文的主要贡献是将基于集成的不确定性估计作为 ICE 中的非一致性度量（Non-Conformity Measure）使用，并结合一种新的阈值优化方法。在分布漂移最严重的 UCSB 数据集上，现有基于概率的 ICE 方法（SOTA）在错误接受率（IA%）上为 22.8%；而我们的方法将这一比例降低到 16%，约相对减少 30%，同时保持具有竞争力的正确接受率（CA%）。这些结果表明，在存在打包恶意软件和极端数据漂移的情况下，将集成不确定性与保形预测相结合能够更可靠地防止误分类，从而为实际安全运营提供切实的改进。

---
## 166. CodeGEMM: A Codebook-Centric Approach to Efficient GEMM in Quantized LLMs

- 作者：Gunho Park, Jeongin Bae, Byeongwook Kim, Baeseong park, Jiwon Ryu, Hoseung Kim, Se Jung Kwon, Dongsoo Lee
- 子主题：LLM
- 推荐：很推荐
- 关键词：码本量化, GEMM内核优化, 低比特LLM推理加速
- Abstract：http://arxiv.org/abs/2512.17970v1
- PDF：https://arxiv.org/pdf/2512.17970v1

**中文摘要**

权重仅量化（weight-only quantization）被广泛用于缓解大型语言模型（LLM）推理时的内存带宽瓶颈。基于码本（codebook）的方法在极低比特（例如2位）下仍能保持良好精度，但现有内核依赖去量化（dequantization），在运行时反复读取质心并重构权重，导致显著的延迟与缓存压力。我们提出了CodeGEMM，一种以码本为中心的高效GEMM内核，替代去量化操作为预先计算并存储在轻量级Psumbook中的质心与激活的内积。在推理阶段，直接根据码索引聚合这些部分和（partial sums），从而消除了按元素查找并减少了片上占用。该内核在统一实现下支持对延迟、内存与精度权衡的系统性探索。在Llama-3模型上，CodeGEMM在2位配置下相比最先进的码本量化方法在相近精度下分别实现了对8B模型1.83倍和对70B模型8.93倍的加速，同时提升了计算效率与内存子系统利用率。

---
## 167. Will AI Trade? A Computational Inversion of the No-Trade Theorem

- 作者：Hanyu Li, Xiaotie Deng
- 子主题：多智能体博弈/算法博弈论
- 推荐：很推荐
- 关键词：无交易定理, 有界计算理性, 多智能体博弈
- Abstract：http://arxiv.org/abs/2512.17952v1
- PDF：https://arxiv.org/pdf/2512.17952v1

**中文摘要**

经典的无交易定理将交易归因于信念的异质性。我们在人工智能代理的情境下重新审视这一结论，询问在共同信念下，交易是否可能由计算能力的限制引发。我们在一个展开的博弈框架中刻画了代理的有界计算理性，其中代理的计算能力决定其策略的复杂度。我们的核心发现颠倒了经典范式：只有当“几近理性”的代理在计算能力上存在微小差异时，才会达到稳定的无交易结果（纳什均衡）。悖论的是，当代理具备完全相同的计算能力时，它们可能无法收敛到均衡，导致持续的策略调整，这种动态表现为某种形式的交易。如果代理可以策略性地低估或未充分利用其计算资源，这种不稳定性会被放大，在“配对硬币（Matching Pennies）”类情形中甚至完全消除均衡的可能性。我们的结果表明，人工智能代理固有的计算限制可能导致均衡无法达成，从而营造出比传统模型预测的更活跃且不可预测的交易环境。

---
## 168. External Hippocampus: Topological Cognitive Maps for Guiding Large Language Model Reasoning

- 作者：Jian Yan
- 子主题：LLM
- 推荐：很推荐
- 关键词：拓扑认知地图, 认知动力学, 小模型推理
- Abstract：http://arxiv.org/abs/2512.18190v1
- PDF：https://arxiv.org/pdf/2512.18190v1

**中文摘要**

本文提出了External Hippocampus（外部海马）框架，从认知动力学的角度将语言模型的推理建模为语义空间中信息能量的流动。与传统的权重空间优化方法不同，该框架通过降维投影构建拓扑认知地图，使得在测试阶段可以精确地导航和干预能量流，从而避免大量计算开销并呈现可预测的干预模式。该方法有效缓解了小模型多步推理中的认知死锁问题。在参数规模不超过7B的模型上，实验表明：基于地图的引导方法在500个具有挑战性的问题上达到81.20%的准确率（相对基线提升16.80%），推理时间缩短至少15倍。关键发现包括：推理停滞表现为“认知漩涡”和低熵势阱，而温度扰动可以有效地重新启动能量流。该框架无需额外训练，具备自主增长能力，为小模型推理提供了一种高效、可控且具有拓扑感知的解决方案。

---
## 169. Uncertainty-Gated Region-Level Retrieval for Robust Semantic Segmentation

- 作者：Shreshth Rajan, Raymond Liu
- 子主题：CV
- 推荐：很推荐
- 关键词：语义分割, 不确定性估计, 区域级检索
- Abstract：http://arxiv.org/abs/2512.18082v1
- PDF：https://arxiv.org/pdf/2512.18082v1

**中文摘要**

室外街景的语义分割在自动驾驶、移动机器人以及为视障行人提供辅助技术等应用中具有关键作用。在这些应用中，准确区分道路、人行道、车辆和行人等重要表面与物体，对于保障安全和降低风险至关重要。语义分割需要在不同环境、光照和天气条件以及传感器噪声下保持鲁棒性，同时满足实时性的要求。我们提出了一种基于区域级的不确定性门控检索机制，该机制在域迁移（domain shift）情况下提升了分割的精度与置信度校准。我们的最佳方法在平均交并比（mIoU）上提高了11.3%，同时将检索开销减少了87.5%，仅对12.5%的区域进行检索，而始终开启的基线方法需对100%的区域进行检索。

---
## 170. Parameter-Efficient Fine-Tuning for HAR: Integrating LoRA and QLoRA into Transformer Models

- 作者：Irina Seregina, Philippe Lalanda, German Vega
- 子主题：HAR / 传感器时序建模
- 推荐：很推荐
- 关键词：人类活动识别, 参数高效微调, LoRA/QLoRA
- Abstract：http://arxiv.org/abs/2512.17983v1
- PDF：https://arxiv.org/pdf/2512.17983v1

**中文摘要**

人类活动识别（HAR）是普适计算领域的基础任务。尽管自监督学习和基于Transformer的架构的最新进展显著提升了HAR的性能，但在目标设备上将大型预训练模型适配到新领域仍面临计算资源受限的现实挑战。本文研究了参数高效微调技术，尤其是低秩适配（LoRA）和量化LoRA（QLoRA），作为替代全模型微调的可扩展方法。我们提出了基于掩码自编码器（Masked Autoencoder，MAE）主干的适配框架，并在五个公开HAR数据集上采用留一数据集（Leave-One-Dataset-Out）验证协议进行评估。实验表明，LoRA和QLoRA在大幅减少可训练参数、内存占用和训练时间的同时，能够匹配全模型微调的识别性能。进一步分析显示，LoRA在监督数据受限的情况下仍能保持稳健性能，且适配器的秩可以在精度与效率之间提供可控的折衷；QLoRA则通过对冻结权重的量化进一步降低内存占用，而对分类质量的影响极小。

---
## 171. Bottom-up Policy Optimization: Your Language Model Policy Secretly Contains Internal Policies

- 作者：Yuqiao Tan, Minzheng Wang, Shizhu He, Huanxuan Liao, Chengfeng Zhao, Qiunan Lu, Tian Liang, Jun Zhao, Kang Liu
- 子主题：大模型（LLM）与强化学习（RL）
- 推荐：很推荐
- 关键词：内部层策略分解, Transformer 残差流, 自底向上策略优化(BuPO)
- Abstract：http://arxiv.org/abs/2512.19673v1
- PDF：https://arxiv.org/pdf/2512.19673v1

**中文摘要**

现有的强化学习方法通常将大型语言模型（LLM）视为单一的统一策略，忽略了模型内部的机制。理解策略如何在层与模块间演化对于实现更有针对性的优化并揭示复杂推理机制至关重要。本文通过利用 Transformer 残差流的内在分裂，以及隐藏状态与解码矩阵（unembedding matrix）组合与可采样策略之间的等价关系，对语言模型的策略进行了分解。该分解揭示了“内部层策略”（对应各层的贡献）和“内部模块策略”（对应层内的自注意力与前馈网络 FFN 组件）。通过对内部策略熵的分析，我们发现： (a) 较低层保持高熵以利于探索，而顶层趋近于零熵以便精化预测，不同模型系列的收敛模式存在差异；(b) LLama 的预测空间在最终层迅速收敛，而 Qwen 系列模型（尤其是 Qwen3）则表现出更类人的、逐步结构化的推理模式。基于这些观察，我们提出了自底向上的策略优化方法 Bottom-up Policy Optimization（BuPO），该范式在训练早期直接优化内部层策略。通过在较低层对齐训练目标，BuPO 重构了基础推理能力并实现了性能提升。在复杂推理基准上的大规模实验验证了该方法的有效性。代码已开源：https://github.com/Trae1ounG/BuPO。

---
## 172. LeLaR: The First In-Orbit Demonstration of an AI-Based Satellite Attitude Controller

- 作者：Kirill Djebko, Tom Baumann, Erik Dilger, Frank Puppe, Sergio Montenegro
- 子主题：RL（强化学习/航天控制）
- 推荐：很推荐
- 关键词：卫星姿态控制, 深度强化学习, Sim2Real 在轨验证
- Abstract：http://arxiv.org/abs/2512.19576v1
- PDF：https://arxiv.org/pdf/2512.19576v1

**中文摘要**

姿态控制对众多卫星任务至关重要。然而，经典控制器设计耗时且对模型不确定性及运行边界条件变化敏感。深度强化学习（DRL）通过与仿真环境的自主交互学习自适应控制策略，提供了有前景的替代方案，但将仿真中训练的智能体部署到真实卫星以克服Sim2Real差距仍然是重大挑战。在本文中，我们展示了首个基于AI的姿态控制器在轨成功示范，用于惯性指向机动。该控制器完全在仿真中训练，并部署于由维尔茨堡尤利乌斯-马克西米连大学与柏林工业大学合作开发的InnoCube 3U纳卫星（于2025年1月发射）。本文介绍了AI智能体的设计、训练流程、仿真与真实卫星观测行为之间的差异，并将AI控制器与InnoCube上的经典PD控制器进行了对比。稳态指标验证了AI控制器在多次在轨机动中的鲁棒性能。

---
## 173. Results of the 2024 CommonRoad Motion Planning Competition for Autonomous Vehicles

- 作者：Yanliang Huang, Xia Yan, Peiran Yin, Zhenduo Zhang, Zeyan Shao, Youran Wang, Haoliang Huang, Matthias Althoff
- 子主题：自动驾驶/运动规划
- 推荐：很推荐
- 关键词：运动规划, 基准测试, 自动驾驶
- Abstract：http://arxiv.org/abs/2512.19564v1
- PDF：https://arxiv.org/pdf/2512.19564v1

**中文摘要**

在过去十年中，为应对日益复杂的交通场景，已经提出了多种用于自动驾驶车辆的运动规划方法。然而，这些方法很少在标准化基准上进行比较，限制了对其相对优劣的评估。为填补这一空白，我们介绍了在CommonRoad基准套件上举行的第4届2024年CommonRoad运动规划竞赛的设置与结果。该年度竞赛提供了一个开源且可复现的运动规划算法基准测试框架。基准场景涵盖高速与城市环境，包含多种交通参与者（如乘用车、公交车和自行车）。规划器的性能从四个维度进行评估：效率、安全性、舒适性以及对选定交通规则的遵守情况。本报告介绍了竞赛形式，并比较了2023年与2024年两届中具有代表性的高性能规划器的表现。

---
## 174. BabyFlow: 3D modeling of realistic and expressive infant faces

- 作者：Antonia Alomar, Mireia Masias, Marius George Linguraru, Federico M. Sukno, Gemma Piella
- 子主题：CV
- 推荐：很推荐
- 关键词：婴儿面部建模, 归一化流, 跨年龄表情迁移
- Abstract：http://arxiv.org/abs/2512.19560v1
- PDF：https://arxiv.org/pdf/2512.19560v1

**中文摘要**

早期发现发育性疾病可以通过分析婴儿颅面形态获得帮助，但由于数据稀少且婴儿常有自发表情，使得婴儿面部建模具有挑战性。我们提出BabyFlow，一种将面部身份与表情解耦的生成式AI模型，能够对二者进行独立控制。BabyFlow基于归一化流学习灵活的概率表示，捕捉富含非线性变化的婴儿表情面部特征，避免了受限的线性假设。针对稀缺且不可控的婴儿表情数据，我们采用跨年龄表情迁移，将成年人的3D表情扫描迁移并适配到婴儿数据中，从而系统性地丰富婴儿的真实表情变体。结果表明，BabyFlow提高了3D重建精度，尤其在嘴部、眼部和鼻部等高表达区域表现明显，并支持在保持身份一致性的前提下合成与修改婴儿表情。此外，通过与扩散模型集成，BabyFlow还能生成具有一致3D几何的高保真2D婴儿图像，为数据增强和早期面部分析提供了有力工具。

---
## 175. Augmenting Intelligence: A Hybrid Framework for Scalable and Stable Explanations

- 作者：Lawrence Krukrubo, Julius Odede, Olawande Olusegun
- 子主题：XAI
- 推荐：很推荐
- 关键词：可解释性AI, 混合规则-监督框架, 客户流失预测
- Abstract：http://arxiv.org/abs/2512.19557v1
- PDF：https://arxiv.org/pdf/2512.19557v1

**中文摘要**

当前的可解释性人工智能（XAI）方法面临“可扩展性-稳定性困境”。后验方法（如 LIME、SHAP）虽然易于扩展，但通常缺乏稳定性；而监督式解释框架（如 TED）虽能提供稳定性，却要求对每个训练实例进行昂贵的人力标注。本文提出了一种混合 LRR-TED 框架，通过引入新颖的“发现不对称性”（Asymmetry of Discovery）来缓解该困境。在客户流失预测的应用中，我们发现自动化规则学习器（GLRM）在识别广泛的“安全网”（留存模式）方面表现出色，但难以捕捉具体的“风险陷阱”（流失触发器）——我们将此现象称为“流失的安娜卡列尼娜原理”。通过使用自动化生成的安全规则初始化解释矩阵，并仅用四条帕累托最优的人定义风险规则对其进行增强，我们的方法达到了 94.00% 的预测精度。该配置不仅优于完整的 8 条专家手工规则基线，而且将人工标注工作量减少了 50%，提出了人机协同 AI 的范式性转变：将专家角色从“规则编写者”转变为“异常处理者”。

---
## 176. CASA: Cross-Attention via Self-Attention for Efficient Vision-Language Fusion

- 作者：Moritz Böhle, Amélie Royer, Juliette Marrie, Edouard Grave, Patrick Pérez
- 子主题：多模态/视觉-语言（VLM）
- 推荐：很推荐
- 关键词：跨注意力, 自注意力, 视觉-语言融合
- Abstract：http://arxiv.org/abs/2512.19535v1
- PDF：https://arxiv.org/pdf/2512.19535v1

**中文摘要**

视觉-语言模型（VLM）通常通过将来自预训练视觉编码器的图像 token 插入语言模型的文本流中进行训练，这使得文本和图像信息可以在模型内部充分互相注意（attend），但在高分辨率图像、长对话或流媒体视频场景下会在内存和计算上变得极其昂贵。采用跨注意力（cross-attention）的 VLM 是一种高效的替代方案，但在性能上存在明显差距，尤其是在涉及细粒度视觉细节的任务上。我们发现提升此类模型的关键在于在专用的跨注意力层中也启用局部的文本-文本交互。基于这一点，我们提出了 CASA（Cross-Attention via Self-Attention），这是一种简单高效的范式，它在常见图像理解基准上显著缩小了与完全 token 插入方法的差距，同时在应用于长上下文多模态任务（如流媒体视频描述）时保持与跨注意力模型相同的可扩展性。

---
## 177. QuantiPhy: A Quantitative Benchmark Evaluating Physical Reasoning Abilities of Vision-Language Models

- 作者：Li Puyin, Tiange Xiang, Ella Mao, Shirley Wei, Xinye Chen, Adnan Masood, Li Fei-fei, Ehsan Adeli
- 子主题：视觉-语言/多模态
- 推荐：很推荐
- 关键词：物理推理, 视觉-语言模型, 数值评估
- Abstract：http://arxiv.org/abs/2512.19526v1
- PDF：https://arxiv.org/pdf/2512.19526v1

**中文摘要**

理解物理世界对通用人工智能代理至关重要。然而，目前尚不清楚最先进的视觉感知模型（例如大型视觉-语言模型）是否具备对物理属性进行定量推理的能力。现有评估主要基于VQA且偏向定性，难以判断模型能否从视频观测中推断运动物体的运动学量。为此，我们提出了QuantiPhy——第一个用于定量衡量视觉-语言模型物理推理能力的基准。QuantiPhy包含超过3300个带有数值真值的视频-文本实例，用于评估模型在给定时间点估计物体的尺寸、速度和加速度的性能，并以其中一种属性作为输入先验。该基准统一了提示设计和评分标准以评估数值精度，从而实现模型间的公平比较。我们在多种最先进的视觉-语言模型上进行的实验揭示了模型在定性可行性与实际数值正确性之间存在一致性差距。我们还深入分析了背景噪声、反事实先验与策略性提示等关键因素，发现当前模型在定量推理运动学属性时更倚重预训练的世界知识，而非忠实利用提供的视觉和文本线索作为参考。QuantiPhy为将视觉-语言模型从语言表述可信度推进到数值化物理理解提供了首个严格且可扩展的测试平台。

---
## 178. Kolmogorov-Arnold Graph Neural Networks Applied to Inorganic Nanomaterials Dataset

- 作者：Nikita Volzhin, Soowhan Yoon
- 子主题：GNN（图神经网络）/ 材料信息学
- 推荐：很推荐
- 关键词：Kolmogorov-Arnold 网络, 图神经网络 (GNN), 无机纳米材料（CHILI 数据集）
- Abstract：http://arxiv.org/abs/2512.19494v1
- PDF：https://arxiv.org/pdf/2512.19494v1

**中文摘要**

Kolmogorov-Arnold 网络（KANs）的最新发展为图神经网络（GNN）领域带来了新进展，提出了基于 KAN 的 GNN 变体，这些变体在准确性上常常优于基于多层感知器（MLP）的 GNN。此前的研究主要在有机分子图数据集上进行了广泛测试，但对无机纳米材料数据集的研究较为缺乏。本文弥补了这一空白，将 Kolmogorov-Arnold 图神经网络（KAGNNs）应用于最近发布的大型无机纳米材料数据集 CHILI。为此，我们对 KAGNN 进行了适配并在该数据集上进行了测试。实验结果表明，在 CHILI 数据集上，尤其是在 CHILI-3K 子集上，KAGNN 在分类任务上显著优于传统 GNN，达到了最先进的结果。

---
## 179. Multi-Layer Confidence Scoring for Detection of Out-of-Distribution Samples, Adversarial Attacks, and In-Distribution Misclassifications

- 作者：Lorenzo Capelli, Leandro de Souza Rosa, Gianluca Setti, Mauro Mangia, Riccardo Rovatti
- 子主题：CV
- 推荐：很推荐
- 关键词：置信度估计, 分布外/对抗样本检测, 多层中间激活分析
- Abstract：http://arxiv.org/abs/2512.19472v1
- PDF：https://arxiv.org/pdf/2512.19472v1

**中文摘要**

随着深度神经网络应用的快速增长，在高风险领域对此类模型作为“黑箱”使用所带来的透明性和可信度问题日益凸显，这些问题已被诸如欧盟人工智能法案等监管要求明确提出。尽管已经提出了内嵌置信度度量的模型，但此类方法通常需要重训练，因此无法直接应用于现有模型，限制了其广泛应用。另一方面，后验方法针对已预训练的模型进行评估，通常将提升预测置信度、检测分布外样本或检测对抗攻击视为相互独立的问题来处理。为了解决现有方法适用性受限的问题，我们提出了多层置信度评分分析（Multi-Layer Analysis for Confidence Scoring，MACS），这是一种统一的后验框架，通过分析中间激活生成分类映射（classification-maps）。基于这些分类映射，我们导出一种评分，可用于置信度估计、检测分布变动和对抗攻击，将三类问题统一到一个通用框架中。在对VGG16和ViTb16模型的实验中，MACS以远低于基线的方法开销实现了超越现有最先进方法的性能。

---
## 180. An Agentic Framework for Autonomous Materials Computation

- 作者：Zeyu Xia, Jinzhe Ma, Congjie Zheng, Shufei Zhang, Yuqiang Li, Hang Su, P. Hu, Changshui Zhang, Xingao Gong, Wanli Ouyang, Lei Bai, Dongzhan Zhou, Mao Su
- 子主题：LLM
- 推荐：很推荐
- 关键词：第一性原理计算, 领域专用代理, 大语言模型(LLM)
- Abstract：http://arxiv.org/abs/2512.19458v1
- PDF：https://arxiv.org/pdf/2512.19458v1

**中文摘要**

大型语言模型（LLMs）已成为加速科学发现的有力工具，但其静态知识基础与幻觉问题限制了其在自主科研应用中的可靠性。近年来的工作将LLM集成到具备检索、推理和工具使用能力的代理框架中，以处理复杂的科学工作流。本文提出了一种面向材料领域的专用代理，用于可靠地自动执行第一性原理材料计算。通过嵌入领域专业知识，该代理能够维持物理一致的多步工作流，并始终选择收敛且良构的参数设置，从而实现可靠的端到端计算执行。基于多样化计算任务的新基准测试表明，该系统在准确性和稳健性方面显著优于独立使用的LLM。该工作为可验证的自主计算实验奠定了基础，是迈向完全自动化科学发现的重要一步。

---
## 181. HyperLoad: A Cross-Modality Enhanced Large Language Model-Based Framework for Green Data Center Cooling Load Prediction

- 作者：Haoyu Jiang, Boan Qu, Junjie Zhu, Fanjie Zeng, Xiaojie Lin, Wei Zhong
- 子主题：LLM
- 推荐：很推荐
- 关键词：绿色数据中心, 负载预测, 跨模态大模型
- Abstract：http://arxiv.org/abs/2512.19114v1
- PDF：https://arxiv.org/pdf/2512.19114v1

**中文摘要**

随着人工智能的快速发展，计算需求呈指数增长，导致数据中心能源消耗和碳排放显著上升，推动绿色数据中心的快速部署以缓解资源与环境压力。实现对可再生能源、储能与负载的分钟级协调，同时最小化PUE和生命周期碳强度，依赖于高精度的负载预测。然而，现有方法在绿色数据中心中难以应对由冷启动、负载失真、多源数据碎片化和分布漂移引起的小样本场景。为此，我们提出了HyperLoad——一个利用预训练大语言模型（LLM）以缓解数据稀缺问题的跨模态框架。在跨模态知识对齐阶段，将文本先验与时序数据映射到共享的潜在空间以最大化先验知识的利用；在多尺度特征建模阶段，通过自适应前缀微调注入与领域对齐的先验，实现快速场景适配，同时引入增强的全局交互注意力机制以捕捉设备间的时序依赖。我们发布了公开的DCData数据集用于基准测试，并在数据充足与数据稀缺的设置下均显著优于现有最先进基线，证明了该方法在可持续绿色数据中心管理中的实用性。

---
## 182. ICP-4D: Bridging Iterative Closest Point and LiDAR Panoptic Segmentation

- 作者：Gyeongrok Oh, Youngdong Jang, Jonghyun Choi, Suk-Ju Kang, Guang Lin, Sangpil Kim
- 子主题：CV（3D LiDAR / 点云感知）
- 推荐：很推荐
- 关键词：LiDAR泛分割, 点云配准(ICP), Sinkhorn软匹配
- Abstract：http://arxiv.org/abs/2512.18991v1
- PDF：https://arxiv.org/pdf/2512.18991v1

**中文摘要**

当前主流的4D LiDAR泛分割范式通常需要使用大规模叠加点云来训练深度神经网络，或为实例关联设计专门模块。然而，这些方法存在重复点处理、计算开销大，并且未能充分利用原始点云中固有的丰富几何先验。为此，我们提出了ICP-4D，一种简单但有效的免训练框架，通过实例级点集之间的几何关系将空间与时间推理统一起来。具体地，我们直接应用迭代最近点（ICP）算法，通过估计的变换对源/目标点集进行对齐，从而关联时序上一致的实例。为在嘈杂的实例预测下稳定关联，我们引入了基于Sinkhorn的软匹配，利用潜在的实例分布获得精确的点到点对应，进而实现稳健的几何对齐。此外，我们精心设计的流水线将实例划分为静态、动态和缺失三类，兼顾计算效率与遮挡感知匹配。大量实验证明，在SemanticKITTI和panoptic nuScenes上，我们的方法即便在无需额外训练或额外点云输入的情况下，也能持续超越最先进的方法。

---
## 183. MT-Mark: Rethinking Image Watermarking via Mutual-Teacher Collaboration with Adaptive Feature Modulation

- 作者：Fei Ge, Ying Huang, Jie Liu, Guixuan Zhang, Zhi Zeng, Shuwu Zhang, Hu Guan
- 子主题：CV
- 推荐：很推荐
- 关键词：图像水印, 协同交互机制(CIM), 自适应特征调制(AFMM)
- Abstract：http://arxiv.org/abs/2512.19438v1
- PDF：https://arxiv.org/pdf/2512.19438v1

**中文摘要**

现有的深度图像水印方法一般遵循固定的“嵌入-失真-提取”流水线，嵌入器和提取器仅通过最终损失进行弱耦合并各自独立优化。这种设计缺乏显式的协作机制，嵌入器无法在训练时主动利用解码感知的提示，提取器也无法有效引导嵌入过程。为了解决这一架构性局限，本文将嵌入与提取重新建模为明确协作的组件，并提出了一个协同交互机制（Collaborative Interaction Mechanism, CIM），在嵌入器与提取器之间建立直接的双向通信，支持互为教师的训练范式和协同优化。在此协作架构之上，我们进一步提出了自适应特征调制模块（Adaptive Feature Modulation Module, AFMM），以支持有效的交互。AFMM 通过解耦调制结构与调制强度，实现内容感知的特征调节，引导水印嵌入到稳定的图像特征中，同时在提取阶段抑制宿主干扰。在 CIM 框架下，双方的 AFMM 形成闭环协作，使嵌入行为与提取目标对齐。该架构级的重构改变了水印系统学习鲁棒性的方式：不再依赖穷尽性的失真仿真，而是通过嵌入与提取之间的协同表征学习自发获得鲁棒性。对真实世界与 AI 生成数据集的实验表明，本方法在保持高感知质量的同时，在水印提取准确率上持续优于现有最先进方法，并表现出强的鲁棒性与泛化能力。

---
## 184. Attention Is Not What You Need

- 作者：Zhang Chong
- 子主题：NLP
- 推荐：很推荐
- 关键词：Grassmann流, 注意力替代架构, 几何子空间表示
- Abstract：http://arxiv.org/abs/2512.19428v1
- PDF：https://arxiv.org/pdf/2512.19428v1

**中文摘要**

我们重新审视序列建模中的一个基本问题：明确的自注意力机制是否真的对强性能和推理是必要的？我们认为标准的多头注意力最好被视为一种张量提升（tensor lifting）：隐藏向量被映射到成对交互的高维空间中，学习过程通过梯度下降对这个提升后的张量施加约束。这一机制表达能力极强，但在数学上不透明，因为经过多层之后很难用有限的一类显式不变量来描述模型的行为。
为了探索替代方案，我们提出了一种基于Grassmann流的无注意力架构。我们的因果Grassmann层不再构造L×L的注意力矩阵，而是(i) 对token状态做线性降维，(ii) 通过Plücker坐标将局部token对编码为Grassmann流形上的二维子空间，(iii) 通过门控混合将这些几何特征融回隐藏状态。因此信息通过多尺度局部窗口上低秩子空间的受控变形传播，核心计算在一个有限维的流形上进行，而不是在未结构化的张量空间中。
在Wikitext-2语言建模基准上，纯Grassmann模型（参数量13到18M）在验证困惑度上与规模匹配的Transformer相比，差距约为10%到15%。在SNLI自然语言推理任务上，将Grassmann–Plücker头部加到DistilBERT之上略优于Transformer头，最佳验证/测试准确率分别为0.8550和0.8538，而Transformer头为0.8545和0.8511。我们分析了Grassmann混合的复杂度，证明在固定秩时序列长度呈线性扩展，并论证了基于流形的设计为基于几何和不变量的神经推理解释提供了更有结构的途径。

---
## 185. Research Program: Theory of Learning in Dynamical Systems

- 作者：Elad Hazan, Shai Shalev Shwartz, Nathan Srebro
- 子主题：理论机器学习（时序/动力系统）
- 推荐：很推荐
- 关键词：动力系统可学习性, 有限样本分析, 谱滤波预测
- Abstract：http://arxiv.org/abs/2512.19410v1
- PDF：https://arxiv.org/pdf/2512.19410v1

**中文摘要**

现代学习系统越来越多地与随时间演化并依赖于隐藏内部状态的数据交互。我们提出一个基本问题：何时仅从观测数据就能够学习这样的动力系统？本文提出了一个以下一个符号（next-token）预测为视角的研究规划，用以理解动力系统中的可学习性。我们主张应将动力系统的可学习性作为有限样本问题来研究，并基于底层动力学的结构性质而非由此产生序列的统计性质来刻画。为此，我们给出了对由动力系统诱导的随机过程的可学习性表述，重点是那些在有限燃尽期（burn-in period）之后在每个时间步都一致成立的保证。这引出了“动态可学习性”的概念，该概念刻画了系统结构（例如稳定性、混合性、可观测性和谱特性）如何决定在达到可靠预测所需的观测数量。我们在线性动力系统情形中示范了该框架，表明可以在有限观测后通过基于谱滤波的不当（improper）方法实现准确预测，而无需先进行系统辨识。最后，我们综述了动力系统学习与经典PAC、在线和通用预测理论之间的关系，并提出了研究非线性与受控系统的方向。

---
## 186. Alternative positional encoding functions for neural transformers

- 作者：Ezequiel Lopez-Rubio, Macoris Decena-Gimenez, Rafael Marcos Luque-Baena
- 子主题：LLM
- 推荐：很推荐
- 关键词：位置编码, 周期函数替代, Transformer架构
- Abstract：http://arxiv.org/abs/2512.19323v1
- PDF：https://arxiv.org/pdf/2512.19323v1

**中文摘要**

位置编码是基于神经变换器（transformer）深度架构中的一个关键模块。该模块为变换器神经层提供合适的位置信息输入。迄今为止，这一成功主要得益于使用不同频率的正弦函数，以捕捉具有不同时期的重复模式。在本文中，我们提出了一组替代的周期函数作为位置编码。这些函数在保留正弦函数若干关键性质的同时，在根本上有所不同。我们报告了一些初步实验结果，显示在这些实验中原始的正弦版本被显著超越。这一结果强烈表明，所提出的替代函数可能在其他变换器架构中具有更广泛的适用性。

---
## 187. MAGIC: Achieving Superior Model Merging via Magnitude Calibration

- 作者：Yayuan Li, Jian Zhang, Jintao Guo, Zihan Cheng, Lei Qi, Yinghuan Shi, Yang Gao
- 子主题：模型合并（Model Merging）
- 推荐：很推荐
- 关键词：幅值校准, 模型合并, 特征对齐
- Abstract：http://arxiv.org/abs/2512.19320v1
- PDF：https://arxiv.org/pdf/2512.19320v1

**中文摘要**

预训练模型的大量涌现催生了众多专门化的微调模型。模型合并旨在在尽可能少乃至无需额外训练的情况下，将这些专门化模型的能力融合到一个统一模型中。模型合并的核心目标是保证合并后模型保留专门化模型的行为特性，通常通过特征对齐来实现。我们发现特征由方向和幅值两部分组成，而以往研究主要关注方向对齐，忽视了幅值的影响——但幅值对常见合并操作（如参数融合与稀疏化）引入的扰动高度敏感。这类幅值扰动会导致合并模型的特征偏离专门化模型，从而引发性能下降。为此，我们提出了MAGnItude Calibration（MAGIC），一种即插即用的框架，用于在层级上对特征空间和权重空间的幅值进行校正，包含三种变体。具体而言，特征空间校正（FSC）使用少量无标签数据对合并模型的特征进行重对齐；权重空间校正（WSC）将校正扩展到权重空间且无需额外数据；两者结合形成双空间校正（DSC）。大量实验表明，MAGIC在无需额外训练的情况下稳定提升了多样化计算机视觉任务（在八个数据集上平均提升4.3%）和NLP任务（在Llama上提升8.0%）的性能。代码已在GitHub开放。

---
## 188. MixFlow Training: Alleviating Exposure Bias with Slowed Interpolation Mixture

- 作者：Hui Li, Jiayue Lyu, Fu-Yun Wang, Kaihui Cheng, Siyu Zhu, Jingdong Wang
- 子主题：CV (生成模型 / 扩散模型)
- 推荐：很推荐
- 关键词：扩散模型, 曝光偏差, 插值混合（MixFlow）
- Abstract：http://arxiv.org/abs/2512.19311v1
- PDF：https://arxiv.org/pdf/2512.19311v1

**中文摘要**

本文研究了扩散模型中的训练-测试不一致问题（又称曝光偏差），以提升扩散模型的生成性能。在训练时，预测网络在某个训练时间步的输入是对应的真实带噪数据，该带噪数据为噪声与原始数据的插值；而在测试（采样）时，网络的输入是模型生成的带噪数据。我们提出了一种名为 MixFlow 的新训练方法以改善该问题。该方法的设计动机来自“慢流（Slow Flow）”现象：在给定采样时间步下，与生成的带噪数据最接近的真实插值通常对应于一个噪声更高的时间步（称为“放慢时间步”），即对应的真实时间步比采样时间步更慢。MixFlow 利用这些放慢时间步的插值构建“放慢插值混合”，对每个训练时间步对预测网络进行后训练（post-training）。在有类别条件的图像生成（包括 SiT、REPA 和 RAE）以及文本到图像生成任务上的实验验证了该方法的有效性。将 MixFlow 应用于 RAE 模型，在 ImageNet 上取得了强劲的生成结果：256×256 分辨率下无引导 FID 为 1.43、有引导 FID 为 1.10；512×512 下无引导 FID 为 1.55、有引导 FID 为 1.10。

---
## 189. Is Visual Realism Enough? Evaluating Gait Biometric Fidelity in Generative AI Human Animation

- 作者：Ivan DeAndres-Tame, Chengwei Ye, Ruben Tolosana, Ruben Vera-Rodriguez, Shiqi Yu
- 子主题：CV
- 推荐：很推荐
- 关键词：步态生物识别, 生成式AI人体动画, 生物特征保真度
- Abstract：http://arxiv.org/abs/2512.19275v1
- PDF：https://arxiv.org/pdf/2512.19275v1

**中文摘要**

生成式人工智能（GenAI）模型革新了动画制作，能够以卓越的视觉保真度合成出人物与运动模式。然而，要生成真正逼真的人类动画仍然具有挑战性，哪怕是微小的不连贯也会让主体显得不自然。该局限在行为生物识别的评估中尤为关键，因为定义身份的细微运动线索容易丢失或被扭曲。本研究考察了最先进的GenAI人体动画模型在保留用于步态生物识别的细微时空特征方面的能力。我们针对四种不同的GenAI模型设计了两类主要评估任务：一是评估在不同复杂条件下从参考视频恢复步态模式的能力；二是评估将这些步态模式迁移到不同视觉身份上的能力。结果表明，尽管生成的视频在视觉质量上普遍较高，但在关注身份识别的任务中生物特征保真度仍然较低，表明当前GenAI模型难以将身份与运动进行有效解耦。此外，通过身份迁移任务，我们揭示了基于外观的步态识别的根本缺陷：当纹理与运动被解耦时，识别性能崩溃，证明当前GenAI模型更依赖视觉属性而非时间动态特征。

---
## 190. Auto-Prompting with Retrieval Guidance for Frame Detection in Logistics

- 作者：Do Minh Duc, Quan Xuan Truong, Nguyen Tat Dat, Nguyen Van Vinh
- 子主题：LLM
- 推荐：很推荐
- 关键词：提示工程, 检索增强生成 (RAG), 链式思考（CoT）
- Abstract：http://arxiv.org/abs/2512.19247v1
- PDF：https://arxiv.org/pdf/2512.19247v1

**中文摘要**

提示工程在无需大规模微调的情况下，将大型语言模型（LLMs）适配到复杂推理和标注任务中起着关键作用。本文提出了一种用于物流文本框架检测的提示优化新流程，结合了检索增强生成（RAG）、少样本提示、链式思考（CoT）推理与自动CoT合成（Auto-CoT），以生成高效的任务特定提示。方法核心是一个基于LLM的提示优化代理，该代理通过检索示例、性能反馈和内部自我评估迭代地细化提示。我们在真实物流文本标注任务上评估了该框架，在推理准确性和标注效率方面具有重要性。实验结果表明，经优化的提示，尤其是通过Auto-CoT和RAG增强的提示，相较于零样本或静态提示，可将实际推理准确率提高最多15%。该系统在包括GPT-4o、Qwen 2.5（72B）和LLaMA 3.1（70B）在内的多种LLM上均表现出一致改进，验证了其通用性和实际价值。研究表明，结构化的提示优化可以作为完全微调的可行替代方案，为在物流等领域部署领域特定的LLM提供了可扩展的解决方案。

---
## 191. Generation of Programmatic Rules for Document Forgery Detection Using Large Language Models

- 作者：Valentin Schmidberger, Manuel Eberhardinger, Setareh Maghsudi, Johannes Maucher
- 子主题：LLM
- 推荐：很推荐
- 关键词：文档伪造检测, 规则生成与可解释性, 大语言模型微调
- Abstract：http://arxiv.org/abs/2512.19228v1
- PDF：https://arxiv.org/pdf/2512.19228v1

**中文摘要**

文档伪造对法律、经济和政府流程构成日益严重的威胁，因而需要愈发复杂的验证机制。一种方法是使用合理性检查——基于规则的程序，用以评估数据的正确性和内部一致性，从而检测异常或篡改迹象。尽管这些验证程序对于确保数据完整性至关重要，但现有的合理性检查通常由软件工程师手工实现，耗时且难以扩展。近年来，大语言模型（LLM）在代码生成方面的进展为自动化和规模化生成此类检查提供了新契机，但要将LLM适配到未知领域的特定需求仍然具有挑战性。本研究考察了通过不同微调策略，将LLM在领域特定代码和数据上适配后，能在多大程度上生成用于文档伪造检测的基于规则的合理性检查，且目标是在受限硬件资源下运行。我们对开源模型Llama 3.1 8B和OpenCoder 8B在源自真实应用场景的结构化数据集上进行了微调，并在先前未见过的伪造模式上评估生成的合理性检查。结果表明，这些模型能够生成可执行并有效的验证程序，说明在需要可理解性的安全敏感场景中，LLM有作为支持人类决策的可扩展工具的潜力。

---
## 192. The Third International Verification of Neural Networks Competition (VNN-COMP 2022): Summary and Results

- 作者：Mark Niklas Müller, Christopher Brix, Stanley Bak, Changliu Liu, Taylor T. Johnson
- 子主题：神经网络验证（形式化验证）
- 推荐：很推荐
- 关键词：神经网络验证, 形式化方法, 基准与评测（VNN-COMP）
- Abstract：http://arxiv.org/abs/2212.10376v2
- PDF：https://arxiv.org/pdf/2212.10376v2

**中文摘要**

本报告总结了第三届神经网络验证国际竞赛（VNN-COMP 2022），该竞赛作为第五届面向机器学习驱动自主系统的形式化方法研讨会（FoMLAS）的一部分举办，并与第34届计算机辅助验证国际会议（CAV）同期。VNN-COMP每年举办，旨在促进最先进神经网络验证工具的公平客观比较，推动工具接口的标准化，并汇集神经网络验证社区。为此，竞赛制定了网络（ONNX）和规范（VNN-LIB）的标准化格式，使用基于AWS实例的自动评估流水线在等价硬件条件下对工具进行评估，并要求参赛者在最终测试集公布前确定工具参数。2022年共有11支队伍在12个有评分的多样化基准上参赛。本文报告概述了本届竞赛的规则、基准、参赛工具、结果以及所得经验教训。

---
## 193. Structural Reinforcement Learning for Heterogeneous Agent Macroeconomics

- 作者：Yucheng Yang, Chiyuan Wang, Andreas Schaab, Benjamin Moll
- 子主题：强化学习（RL）/计算宏观经济学
- 推荐：很推荐
- 关键词：结构化强化学习, 异质主体模型, 均衡价格动力学
- Abstract：http://arxiv.org/abs/2512.18892v1
- PDF：https://arxiv.org/pdf/2512.18892v1

**中文摘要**

我们提出了一种新的方法来表述和求解具有总体风险的异质主体模型。我们用低维的价格作为状态变量代替横截面分布，并让个体代理从模拟路径中直接学习均衡价格的动力学。为此，我们引入了一种结构化强化学习（Structural Reinforcement Learning, SRL）方法：该方法通过模拟处理价格，同时利用代理对自身个体动态的结构性知识。我们的SRL方法提供了一种通用且高效的全局求解方法，用以处理异质主体模型，避免了对主方程（Master equation）的依赖，并能解决传统方法难以处理的问题，特别是涉及非平凡市场清算条件的问题。我们在Krusell–Smith模型、带总体冲击的Huggett模型以及带前瞻性菲利普斯曲线的HANK模型上展示了该方法，所有模型均可在数分钟内得到全局求解。

---
## 194. Explainable and Fine-Grained Safeguarding of LLM Multi-Agent Systems via Bi-Level Graph Anomaly Detection

- 作者：Junjun Pan, Yixin Liu, Rui Miao, Kaize Ding, Yu Zheng, Quoc Viet Hung Nguyen, Alan Wee-Chung Liew, Shirui Pan
- 子主题：LLM
- 推荐：很推荐
- 关键词：多智能体系统, 图异常检测, 可解释性
- Abstract：http://arxiv.org/abs/2512.18733v1
- PDF：https://arxiv.org/pdf/2512.18733v1

**中文摘要**

基于大语言模型（LLM）的多智能体系统（MAS）在解决复杂任务方面表现出强大能力。随着MAS在许多安全关键任务中变得日益自主，检测恶意智能体成为一个重要的安全问题。尽管现有基于图异常检测（GAD）的防御方法可以识别异常智能体，但它们主要依赖粗粒度的句子级信息，忽略了细粒度的词汇线索，导致检测性能不佳；同时这些方法缺乏可解释性，限制了其可靠性与实际应用。为了解决上述问题，我们提出了XG-Guard，一种用于检测MAS中恶意智能体的可解释且细粒度的防护框架。为同时融合集体与细粒度的文本信息以识别异常智能体，框架采用了双层智能体编码器，联合建模每个智能体的句子级和词元级表示。基于主题的异常检测器进一步捕捉MAS对话中讨论焦点的动态演化，而双层得分融合机制用于量化词元级贡献以提供解释性。大量实验覆盖不同的MAS拓扑结构和攻击场景，结果表明XG-Guard在检测性能和可解释性方面均表现稳健。

---
## 195. CauTraj: A Causal-Knowledge-Guided Framework for Lane-Changing Trajectory Planning of Autonomous Vehicles

- 作者：Cailin Lei, Haiyang Wu, Yuxiong Ji, Xiaoyu Cai, Yuchuan Du
- 子主题：自动驾驶 / 轨迹规划
- 推荐：很推荐
- 关键词：因果推断, 轨迹规划, 模型预测控制(MPC)
- Abstract：http://arxiv.org/abs/2512.18703v1
- PDF：https://arxiv.org/pdf/2512.18703v1

**中文摘要**

在以人机混合交通为背景的自动驾驶中，提高换道车辆的轨迹规划性能是关键挑战之一。多数现有工作在设计轨迹规划模型时未充分利用人类驾驶员的先验知识。为此，本文提出一种将因果先验知识引入控制过程的新型轨迹规划框架。通过对车辆的纵向与横向微观行为建模以量化交互风险，构建分阶段因果图来刻画换道场景中的因果依赖关系。随后利用因果推断估计换道车辆与周围车辆之间的因果效应，包括平均因果效应（ATE）和条件平均处理效应（CATE），并将这些因果先验嵌入模型预测控制（MPC）框架以增强轨迹规划性能。该方法在自然驾驶车辆轨迹数据集上进行了验证。实验结果表明：(1) 因果推断能够为车辆交互提供可解释且稳定的量化指标；(2) 个体因果效应揭示了驾驶员行为的异质性；(3) 与基线MPC相比，所提方法在更接近人类驾驶行为方面表现优异：最大轨迹偏差由1.2米降至0.2米，横向速度波动减少约60%，偏航角变动减少约50%。这些结果为拟人化轨迹规划方法提供了方法学支持，并对提升自动驾驶系统在测试与交通仿真平台中的安全性、稳定性和真实感具有实际价值。

---
## 196. The Interaction Bottleneck of Deep Neural Networks: Discovery, Proof, and Modulation

- 作者：Huiqi Deng, Qihan Ren, Zhuofan Chen, Zhenyuan Cui, Wen Shen, Peng Zhang, Hongbin Pei, Quanshi Zhang
- 子主题：深度学习理论（表示学习）
- 推荐：很推荐
- 关键词：交互阶次, 交互瓶颈, 表示学习
- Abstract：http://arxiv.org/abs/2512.18607v1
- PDF：https://arxiv.org/pdf/2512.18607v1

**中文摘要**

理解深度神经网络（DNN）能够表示何种合作结构仍然是一个基础但尚未充分解答的问题。在本文中，我们将交互视为此类结构的基本单元，研究一个鲜少被探索的问题：在不同上下文复杂度下，DNN如何编码交互，以及这些微观交互模式如何影响宏观表示能力。为量化这种复杂度，我们采用多阶交互的概念，其中每一阶代表评估一对变量联合交互效用所需的上下文信息量。该表述使得对DNN学习到的合作模式进行分层分析成为可能。在此基础上，我们对DNN中的交互结构开展了全面研究。（i）我们在经验上发现了一个普遍存在的“交互瓶颈”：跨越不同架构和任务，DNN能较容易地学习低阶与高阶交互，但始终弱表示中阶交互。（ii）我们从理论上解释了该瓶颈，证明中阶交互具有最高的上下文可变性，导致梯度方差较大，从而本质上更难学习。（iii）我们进一步通过引入引导模型强调特定阶交互的损失函数对该瓶颈进行调制。最后，我们将微观交互结构与宏观表示行为联系起来：强调低阶交互的模型表现出更强的泛化与鲁棒性，而强调高阶交互的模型则展现出更强的结构建模与拟合能力。综上，这些结果揭示了现代DNN内在的表示偏向，并确立了交互阶次作为解释与引导深度表示的有力视角。

---
## 197. Adaptive Accountability in Networked MAS: Tracing and Mitigating Emergent Norms at Scale

- 作者：Saad Alqithami
- 子主题：RL（多智能体系统）
- 推荐：很推荐
- 关键词：多智能体系统, 问责与审计, 涌现规范检测与干预
- Abstract：http://arxiv.org/abs/2512.18561v1
- PDF：https://arxiv.org/pdf/2512.18561v1

**中文摘要**

大规模网络化多智能体系统日益成为关键基础设施的支撑，但其集体行为可能偏离预期、朝向常规治理机制难以遏制的不良涌现规范发展。我们提出了一种自适应问责框架，包含：(i) 通过生命周期感知的审计账本持续追踪责任流；(ii) 通过去中心化的序贯假设检验在线检测有害涌现规范；(iii) 部署局部策略与奖励塑形干预，以近实时方式将智能体行为重新对齐至系统级目标。我们证明了一个有界妥协定理：当预期的干预成本超过对手的收益时，被妥协交互的长期比例被一个严格小于1的常数所上界。大规模高性能仿真实验（最多100个异构智能体、部分可观测和随机通信图）表明，该框架在至少90%的配置中能阻止共谋与资源囤积，使平均集体回报提升12–18%，并相比PPO基线将基尼不平等指数降低最多33%。这些结果表明，具有理论支撑的问责层能够在不牺牲性能或可扩展性的前提下，诱导复杂多智能体系统朝向伦理对齐和自我调节的行为。

---
## 198. GTMA: Dynamic Representation Optimization for OOD Vision-Language Models

- 作者：Jensen Zhang, Ningyuan Liu, Keze Wang
- 子主题：视觉-语言 / 多模态 (VLM)
- 推荐：很推荐
- 关键词：视觉-语言模型, 跨模态对齐, 伪词嵌入
- Abstract：http://arxiv.org/abs/2512.18504v1
- PDF：https://arxiv.org/pdf/2512.18504v1

**中文摘要**

视觉-语言模型（VLM）在开放世界应用中表现不佳：遇到分布外（OOD）概念时常导致跨模态对齐崩溃，从而严重降低零-shot 性能。我们发现根本原因在于模态不对称：视觉编码器能够从未见图像中提取判别性特征，而文本编码器受限于固定的离散词表，无法合成新的语义锚点。现有方法（如 CoOp 或 LoRA）仅能在预训练语义空间内提供部分缓解。为突破此瓶颈，我们提出了一种动态表示优化思路，并通过 Guided Target-Matching Adaptation（GTMA）框架实现。在推理阶段，GTMA 为每个 OOD 图像构建一个连续的伪词嵌入，使其最佳匹配视觉锚点，从而有效绕过词表限制。该优化由一种自适应的基于梯度的表示策略优化算法驱动，并引入语义正则化以保持生成表示的合理性和与模型先验知识的兼容性。ImageNet-R 和 VISTA-Beyond 基准上的实验表明，GTMA 在保持对内分布概念性能的同时，可将零-shot 和少-shot 的 OOD 准确率相较基线 VLM 提升约 15–20%。消融研究进一步验证了伪词优化步骤的必要性。

---
## 199. Insider Threat Detection Using GCN and Bi-LSTM with Explicit and Implicit Graph Representations

- 作者：Rahul Yumlembam, Biju Issac, Seibu Mary Jacob, Longzhi Yang, Deepa Krishnan
- 子主题：安全/异常检测/图神经网络
- 推荐：很推荐
- 关键词：内部威胁检测, 图神经网络 (GCN), 时序建模 (Bi-LSTM)
- Abstract：http://arxiv.org/abs/2512.18483v1
- PDF：https://arxiv.org/pdf/2512.18483v1

**中文摘要**

内部威胁检测（ITD）因受信任用户所实施的恶意行为往往隐蔽且细微，故具有较高难度。本文提出了一种事后（post-hoc）ITD框架，融合显式与隐式图表示并结合时序建模以捕捉复杂的用户行为模式。显式图基于预定义的组织规则构建，用于刻画用户活动之间的直接关系；为缓解该手工结构中的噪声与局限性，采用Gumbel-Softmax技巧从特征相似性中学习隐式图，以发现潜在的行为关系。对显式图和隐式图分别使用图卷积网络（GCN）生成节点嵌入，随后将两类嵌入拼接并通过注意力机制进行筛选以突出与威胁相关的特征。经注意力融合的表示再输入双向长短期记忆网络（Bi-LSTM）以捕捉用户行为的时序依赖。当活动的异常概率低于预设阈值时将其标记为异常。对CERT r5.2与r6.2数据集的大量实验结果表明，该框架优于现有最先进方法：在r5.2上本模型取得AUC 98.62、检测率100%、误报率0.05；在更具挑战性的r6.2上取得AUC 88.48、检测率80.15%、误报率0.15，验证了图结构与时序表示结合用于稳健内部威胁检测的有效性。

---
## 200. Graph-O1 : Monte Carlo Tree Search with Reinforcement Learning for Text-Attributed Graph Reasoning

- 作者：Lihui Liu
- 子主题：LLM
- 推荐：很推荐
- 关键词：文本属性图, 蒙特卡洛树搜索, 强化学习
- Abstract：http://arxiv.org/abs/2512.17912v1
- PDF：https://arxiv.org/pdf/2512.17912v1

**中文摘要**

文本属性图（text-attributed graphs）是指节点和边都包含丰富文本信息的图结构，广泛用于多个领域。在该设置下，一个核心挑战是问答任务，需要同时利用非结构化文本与图中的结构化关系信号。尽管大型语言模型（LLMs）在自然语言理解方面取得了显著进展，但它们在直接用于基于文本属性图的推理方面仍存在限制。纯文本的检索增强生成方法通常将段落视为孤立单元，忽略了图的互联结构；相反，将大型子图序列化为冗长文本序列的图基检索增强生成方法很快会因 LLM 上下文长度限制变得不可行，导致推理碎片化和准确性下降。为克服这些限制，我们提出了 Graph-O1，一种具代理性的 GraphRAG 框架，使 LLM 能够在图上进行逐步的交互式推理。我们的方法将蒙特卡洛树搜索（MCTS）与端到端强化学习相结合，使模型能够有选择地探索并检索最具信息量的子图组件。推理过程被设计为代理与图环境之间的多回合交互，且代理通过统一的奖励机制进行训练。大量基于不同 LLM 主干的实验表明，Graph-O1 持续优于最先进的基线方法，生成的答案在准确性、可靠性和可解释性方面均有所提升。

---
## 201. NL2CA: Auto-formalizing Cognitive Decision-Making from Natural Language Using an Unsupervised CriticNL2LTL Framework

- 作者：Zihao Deng, Yijia Li, Renrui Zhang, Peijun Ye
- 子主题：NLP
- 推荐：很推荐
- 关键词：自然语言到LTL, 自动形式化认知规则, 认知强化学习
- Abstract：http://arxiv.org/abs/2512.18189v1
- PDF：https://arxiv.org/pdf/2512.18189v1

**中文摘要**

认知计算模型为刻画人类的思考与决策提供了形式化且可解释的途径，但其构建仍高度依赖人工投入。本文提出了NL2CA，一种从人类经验的自然语言描述中自动形式化认知决策规则的新方法。与多数依赖人工或人机交互引导建模的方法不同，本方法实现了无需任何人工干预的全自动流程。该方法首先使用经微调的大型语言模型将文本翻译为线性时序逻辑（LTL），随后通过无监督的评判树（Critic Tree）对逻辑表达进行精炼，最终将结果转换为可与符号认知框架兼容的可执行产生式规则。基于这些规则，进一步构建认知代理，并根据真实行为数据通过认知强化学习对其进行优化。我们在两个任务域上验证了方法的有效性：一是NL到LTL的翻译任务，所提出的CriticNL2LTL模块在专家级与大规模基准上均在无人工反馈情况下取得稳定表现；二是认知驾驶仿真任务，基于人类访谈自动构建的代理在多个关键场景中成功学习了约70次试验中的多样决策模式。实验结果表明，NL2CA能够从非结构化文本数据中实现可扩展、可解释且符合人类的认知建模，为自动设计符号化认知代理提供了一种新范式。

---
## 202. Faithful and Stable Neuron Explanations for Trustworthy Mechanistic Interpretability

- 作者：Ge Yan, Tuomas Oikarinen, Tsui-Wei, Weng
- 子主题：机制可解释性 / 模型可解释性
- 推荐：很推荐
- 关键词：机制可解释性, 神经元识别, 可信性与稳定性
- Abstract：http://arxiv.org/abs/2512.18092v1
- PDF：https://arxiv.org/pdf/2512.18092v1

**中文摘要**

神经元识别是机制可解释性中一种常用工具，旨在揭示深度网络中单个神经元所表示的人类可解释概念。尽管诸如 Network Dissection 和 CLIP-Dissect 的算法在经验上取得了显著成果，但缺乏严格的理论基础来支持可置信且可靠的解释。本文提出观察：神经元识别可以被视作机器学习的逆过程，这一视角使我们能够为神经元解释推导出形式化保证。基于此洞见，我们首次对两项根本性挑战给出理论分析： (1) 可信性（Faithfulness）：识别出的概念是否忠实地反映了神经元的真实功能；(2) 稳定性（Stability）：在不同探测数据集上识别结果是否一致。我们为常用相似性度量（如准确率、AUROC、IoU）导出了泛化界以保证可信性，并提出了一种自助法（bootstrap）集成程序用于量化稳定性，同时给出 BE（Bootstrap Explanation）方法来生成具有覆盖概率保证的概念预测集。在合成数据与真实数据上的实验验证了我们的理论结果并展示了方法的可行性，为实现可置信的神经元识别迈出了重要一步。

---
## 203. Let the Model Learn to Feel: Mode-Guided Tonality Injection for Symbolic Music Emotion Recognition

- 作者：Haiying Xia, Zhongyi Huang, Yumei Tan, Shuxiang Song
- 子主题：MIR（音乐信息检索/符号音乐）
- 推荐：很推荐
- 关键词：音乐情感识别, 调式引导, 特征注入（MoFi）
- Abstract：http://arxiv.org/abs/2512.17946v1
- PDF：https://arxiv.org/pdf/2512.17946v1

**中文摘要**

音乐情感识别是符号音乐理解（SMER）中的关键任务。近期方法通过微调大规模预训练模型（如符号音乐理解基准MIDIBERT）将音乐语义映射到情感标签，取得了可喜进展。但这些模型虽然能有效捕捉分布式音乐语义，却常常忽视调式等音调结构，而音乐心理学表明调式对情感感知具有重要作用。为此，本文研究了MIDIBERT的表征能力并发现其在捕捉调式—情感关联方面的不足。针对该问题，我们提出了一种结合音乐心理学见解的调式引导增强（Mode-Guided Enhancement，MoGE）策略。具体地，首先进行调式增强分析，揭示MIDIBERT未能有效编码情感—调式相关性；随后识别出MIDIBERT中与情感最不相关的层，并提出调式引导的逐通道线性调制注入（Mode-guided Feature-wise linear modulation，MoFi）框架，将显式的调式特征注入该层，从而提升模型在情感表征与推断方面的能力。在EMOPIA与VGMIDI数据集上的大量实验表明，我们的调式注入策略显著提升了SMER性能，分别达到75.2%和59.1%的准确率，验证了调式引导建模在符号音乐情感识别中的有效性。

---
## 204. Sprecher Networks: A Parameter-Efficient Kolmogorov-Arnold Architecture

- 作者：Christian Hägg, Kathlén Kohn, Giovanni Luca Marchetti, Boris Shapiro
- 子主题：神经网络架构
- 推荐：很推荐
- 关键词：可学习样条, 参数与内存高效性, Kolmogorov–Arnold–Sprecher 构造
- Abstract：http://arxiv.org/abs/2512.19367v1
- PDF：https://arxiv.org/pdf/2512.19367v1

**中文摘要**

我们提出了Sprecher Networks（SNs），一类可训练的神经网络架构，其设计灵感来自用于逼近多元连续函数的经典Kolmogorov–Arnold–Sprecher（KAS）构造。与使用固定节点激活的多层感知机（MLP）以及以可学习边激活为特征的Kolmogorov–Arnold Networks（KANs）不同，SNs在结构化模块中采用共享的可学习样条（包括单调样条和一般样条），并显式引入平移参数与混合权重。本方法在单层变体中直接实现了Sprecher于1965年提出的加和值平移样条公式，并将其推广到更深的多层复合结构。我们进一步用可选的横向混合连接增强了架构，使输出维度之间能够在模块内通信，从而提供了对完整注意力机制的参数高效替代。相较于MLP的O(LN^2)参数复杂度，SNs在参数规模上实现了O(LN + LG)的更优标度（G为共享样条的节点数）；并且SNs支持一种顺序化的评估策略，将前向计算中的峰值中间态内存从O(N^2)降低到O(N)（将批量大小视为常数），使在内存受限条件下能够构建更宽的网络成为可能。我们通过实证研究展示了将这些模块组合为深层网络时在参数与内存利用上的显著效率，讨论了理论动机，并将SNs与相关架构（MLPs、KANs以及具有可学习节点激活的网络）进行了比较。

---
## 205. First-Order Representation Languages for Goal-Conditioned RL

- 作者：Simon Ståhlberg, Hector Geffner
- 子主题：RL
- 推荐：很推荐
- 关键词：目标条件强化学习, 一阶关系表示, Hindsight Experience Replay
- Abstract：http://arxiv.org/abs/2512.19355v1
- PDF：https://arxiv.org/pdf/2512.19355v1

**中文摘要**

一阶关系语言已在马尔可夫决策过程（MDP）规划和强化学习（RL）中用于两方面：以紧凑形式描述MDP，以及表示和学习不依赖于具体实例或状态空间的泛化策略。本文转而将一阶语言应用于目标条件强化学习和广义规划，研究在训练实例规模较大且目标不能仅靠随机探索到达时，如何学习目标条件化且具有泛化能力的策略。回顾经验重放（Hindsight Experience Replay，HER）为此提供了解决思路：它通过将未成功的轨迹重新标记为成功轨迹（用轨迹中实际达到的状态替换原始目标）来增强样本效率。如果目标策略需要在状态和目标间泛化，那么那些未达到原始目标的轨迹也能促进更高的数据和时间效率的学习。我们证明了当状态和目标由原子集合表示时，可以进一步提升性能。具体地，我们考察了三种目标表示方式：将目标视为完整状态、将目标视为原始目标的子集，以及将这些子目标提升为带有变量的一阶（lifted）表示。结果表明，后两种表示能够在稀疏奖励的大规模规划实例上自动构建由易到难的目标课程，从而成功学习到泛化策略。实验展示了这些表示在计算效率上的提升、存在的限制以及可能的改进方向。

---
## 206. Causal-Guided Detoxify Backdoor Attack of Open-Weight LoRA Models

- 作者：Linzhi Chen, Yang Sun, Hongru Wei, Yuqi Chen
- 子主题：LLM
- 推荐：很推荐
- 关键词：LoRA, 后门攻击, 因果引导
- Abstract：http://arxiv.org/abs/2512.19297v1
- PDF：https://arxiv.org/pdf/2512.19297v1

**中文摘要**

低秩适配（LoRA）作为一种高效的微调大型语言模型（LLM）的方法，已被开源社区广泛采用。然而，通过 Hugging Face 等平台去中心化传播的 LoRA 适配器带来了新的安全隐患：恶意适配器可以被轻易分发并规避传统监管机制。尽管存在这些风险，针对基于 LoRA 的微调的后门攻击仍较少被研究。现有的后门攻击方法并不适用于该场景，原因在于它们常依赖不可获取的训练数据、忽视 LoRA 特有的结构特性，或具有较高的误触发率（FTR），从而削弱了攻击隐蔽性。为应对这些挑战，我们提出了面向开源权重 LoRA 模型的因果引导解毒后门攻击框架（Causal-Guided Detoxify Backdoor Attack，简称 CBA）。CBA 在无需访问原始训练数据的前提下，通过两项关键创新实现高隐蔽性：一是覆盖率引导的数据生成管道，通过行为探索合成与任务对齐的输入；二是因果引导的“解毒”策略，通过保留任务关键神经元，将中毒适配器与干净适配器合并。不同于以往方法，CBA 能基于因果影响进行权重分配，实现训练后对攻击强度的可控性，避免反复重训练。在对六个 LoRA 模型的评估中，CBA 在保证高攻击成功率的同时，将误触发率相比基线方法降低了 50%–70%。此外，CBA 对最先进的后门防御方法表现出更强的抗性，进一步证明了其隐蔽性与稳健性。

---
## 207. Digital Twin-Driven Zero-Shot Fault Diagnosis of Axial Piston Pumps Using Fluid-Borne Noise Signals

- 作者：Chang Dong, Jianfeng Tao, Chengliang Liu
- 子主题：工业故障诊断（数字孪生与深度学习）
- 推荐：很推荐
- 关键词：数字孪生, 零样本故障诊断, 流体传导噪声 (FBN)
- Abstract：http://arxiv.org/abs/2512.19280v1
- PDF：https://arxiv.org/pdf/2512.19280v1

**中文摘要**

轴向柱塞泵是流体动力系统中的关键部件，其可靠的故障诊断对保障运行安全与效率至关重要。传统的数据驱动方法依赖大量带标签的故障数据，而这些数据往往难以获取；基于模型的方法又易受参数不确定性的影响。本文提出了一种基于数字孪生（DT）的零样本故障诊断框架，利用流体传导噪声（FBN）信号进行诊断。该框架仅用健康工况数据对高保真数字孪生模型进行校准，然后由校准后的孪生体生成合成故障信号以训练深度学习分类器，并引入物理信息神经网络（PINN）作为虚拟传感器估计流量脉动。为增强可解释性，本文将梯度加权类激活映射（Grad-CAM）用于可视化神经网络的决策过程；结果表明，在时域输入上采用与子序列长度匹配的大卷积核、在时频域输入上采用小卷积核，有助于网络聚焦于具有物理意义的特征并提高诊断精度。实验验证显示，在校准的数字孪生上训练得到的模型，在真实基准数据集上的诊断准确率超过95%，而未校准的模型则显著降级，突出了该框架在数据稀缺场景下的有效性。

---
## 208. ChemATP: A Training-Free Chemical Reasoning Framework for Large Language Models

- 作者：Mingxu Zhang, Dazhong Shen, Qi Zhang, Ying Sun
- 子主题：LLM
- 推荐：很推荐
- 关键词：化学推理, 原子级知识库, 训练免费框架
- Abstract：http://arxiv.org/abs/2512.19240v1
- PDF：https://arxiv.org/pdf/2512.19240v1

**中文摘要**

大型语言模型（LLM）在通用推理方面表现强劲，但由于标准分子字符串表示中缺乏显式化学先验，在分子科学领域表现欠佳。现有方法面临根本性两难：基于训练的方法将先验注入模型参数，但这种静态耦合阻碍了知识的快速更新且常常削弱模型的通用推理能力；而现有的训练免费方法虽然避免了这些问题，却依赖表层提示，无法提供精细到原子的先验，这对于精确的化学推理至关重要。为此，我们提出了ChemATP，一个将化学知识与推理引擎解耦的框架。通过构建首个原子级的文本知识库，ChemATP使得冻结的LLM能够动态检索并在推理过程中显式利用这些信息。该架构兼顾可解释性与适应性，同时保留了LLM的内在通用智能。实验证明，ChemATP显著优于现有的训练免费基线，并可与最先进的基于训练的方法相媲美，表明显式先验注入是对隐式参数更新的一种具有竞争力的替代方案。

---
## 209. Identifying Features Associated with Bias Against 93 Stigmatized Groups in Language Models and Guardrail Model Safety Mitigation

- 作者：Anna-Maria Gueorguieva, Aylin Caliskan
- 子主题：LLM
- 推荐：很推荐
- 关键词：社会偏见, 污名化群体, 守护模型（偏见缓解）
- Abstract：http://arxiv.org/abs/2512.19238v1
- PDF：https://arxiv.org/pdf/2512.19238v1

**中文摘要**

大型语言模型（LLM）已被证实存在社会偏见，但针对非受保护的污名化身份的偏见研究尚不充分。此外，哪些与污名相关的社会特征会与语言模型输出中的偏见相关仍不清楚。心理学文献表明，污名包含六个共同的社会特征：审美性（aesthetics）、可隐匿性（concealability）、课程性（course）、破坏性（disruptiveness）、起源（origin）和危险性（peril）。本研究考察了人类与LLM对这些污名特征的评分，连同提示风格和污名类型，是否会影响LLM对污名化群体的偏见表现。我们在三个广泛使用的LLM（Granite 3.0-8B、Llama-3.1-8B、Mistral-7B）上，使用包含37个关于污名化身份社会情境（例如决定是否推荐其参加实习）的基准SocialStigmaQA，测量对93个污名化群体的偏见表现。研究发现，人类评定为高危险性的污名（例如帮派成员或感染艾滋病）在SocialStigmaQA提示下产生偏见输出的比例最高（所有模型合计约60%），而社会人口学相关的污名（例如亚裔美国人或老年）产生偏见输出的比例最低（11%）。我们测试了使用各自的守护模型（Granite Guardian 3.0、Llama Guard 3.0、Mistral Moderation API）是否能降低偏见输出数量，结果偏见分别显著下降了10.4%、1.4%和7.8%。然而，我们还发现，尽管总体偏见有所下降，但对偏见有显著影响的污名特征在缓解后仍保持不变，且守护模型经常无法识别提示中偏见的意图。该工作对在涉及污名化群体的场景中使用LLM具有重要意义，并建议未来工作应致力于改进守护模型以更有效地缓解偏见。

---
## 210. MixKVQ: Query-Aware Mixed-Precision KV Cache Quantization for Long-Context Reasoning

- 作者：Tao Zhang, Ziqian Zeng, Hao Peng, Huiping Zhuang, Cen Chen
- 子主题：LLM
- 推荐：很推荐
- 关键词：KV缓存量化, 混合精度量化, 长上下文推理
- Abstract：http://arxiv.org/abs/2512.19206v1
- PDF：https://arxiv.org/pdf/2512.19206v1

**中文摘要**

长链式思维（Chain-of-Thought, CoT）推理显著提升了大型语言模型（LLM）的能力，但随之带来的是来自庞大键值（KV）缓存的显著内存和延迟开销。尽管对KV缓存进行量化是有前景的压缩手段，现有的低比特量化方法在复杂推理任务上往往出现严重的性能下降。固定精度量化难以处理键缓存中的异常通道，而现有的混合精度策略又无法准确识别出需要高精度表示的关键组件。我们发现，设计有效的低比特KV缓存量化策略需要同时考虑两方面：键通道的固有量化难度以及该通道相对于查询的相关性。基于此洞见，我们提出了MixKVQ，一种可插拔的轻量级查询感知算法，用于识别并保留需要更高精度的关键键通道，同时对值缓存采用逐令牌（per-token）量化。实验结果表明，在复杂推理数据集上，MixKVQ在显著降低内存占用的同时，明显优于现有低比特方法，并能达到接近全精度基线的性能。

---
## 211. Practical Quantum-Classical Feature Fusion for complex data Classification

- 作者：Azadeh Alavi, Fatemeh Kouchmeshki, Abdolrahman Alavi
- 子主题：Quantum Machine Learning (QML)
- 推荐：很推荐
- 关键词：量子-经典混合学习, 跨注意力中融合, 多模态特征融合
- Abstract：http://arxiv.org/abs/2512.19180v1
- PDF：https://arxiv.org/pdf/2512.19180v1

**中文摘要**

混合量子-经典学习旨在将量子特征映射与经典神经网络的鲁棒性相结合，但大多数架构将量子电路视作孤立的特征提取器，并通过直接拼接将其测量结果与经典表示合并。这忽略了量子与经典分支构成了不同的计算模态，限制了在复杂高维表格和半结构化数据（如遥感、环境监测和医学诊断）上的可靠性能表现。本文提出了混合学习的多模态表述，并设计了一种跨注意力中融合（cross attention mid fusion）架构：在该架构中，经典表示通过带残差连接的注意力模块对量子导出的特征令牌进行查询。量子分支在实际的NISQ资源预算内实现，使用至多九个量子比特。我们在Wine、Breast Cancer、Forest CoverType、FashionMNIST和SteelPlatesFaults数据集上进行了评估，比较了纯量子模型、经典基线、残差混合模型以及在一致协议下的所提中融合模型。结果表明，纯量子与标准混合设计由于测量引起的信息损失而表现较差，而跨注意力中融合在多数情况下对更复杂的数据集表现出一致的竞争力并提升了性能。这些发现表明，量子导出的信息在通过有原则的多模态融合集成时最有价值，而不是孤立使用或松散地附加到经典特征上。

---
## 212. Vision-Language-Policy Model for Dynamic Robot Task Planning

- 作者：Jin Wang, Kim Tien Ly, Jacques Cloete, Nikos Tsagarakis, Ioannis Havoutis
- 子主题：Embodied AI（机器人学）
- 推荐：很推荐
- 关键词：视觉-语言模型, 机器人任务规划, 动态策略适配
- Abstract：http://arxiv.org/abs/2512.19178v1
- PDF：https://arxiv.org/pdf/2512.19178v1

**中文摘要**

在非结构化环境中，将自然语言指令与自主执行能力相连接仍是机器人学中的一个开放挑战。这需要机器人通过多模态感知与推理理解当前任务场景，并规划行为以实现预期目标。传统的机器人任务规划方法常常难以将低层执行与高层任务推理有效衔接，并且在执行过程中当指令发生变化时无法动态更新策略，这限制了它们对新任务的多样性与适应性。为此，我们提出了一种基于语言模型的动态机器人任务规划新框架。所提出的视觉-语言-策略（Vision-Language-Policy，VLP）模型基于在真实世界数据上微调的视觉-语言模型，能够解释语义指令，并结合对当前任务场景的推理生成控制机器人的行为策略以完成任务。此外，该模型能够在任务发生变化时动态调整策略，从而灵活适配不断变化的任务需求。在不同机器人平台和多种真实任务上的实验表明，训练得到的模型能高效适配新场景并动态更新策略，展示了强大的规划自主性和跨体态（cross-embodiment）泛化能力。更多视频请见：https://robovlp.github.io/

---
## 213. Can We Test Consciousness Theories on AI? Ablations, Markers, and Robustness

- 作者：Yin Jun Phua
- 子主题：认知建模与可解释性AI
- 推荐：很推荐
- 关键词：全球工作区（GWT）, 高阶理论（HOT）, 可解释性/认知建模
- Abstract：http://arxiv.org/abs/2512.19155v1
- PDF：https://arxiv.org/pdf/2512.19155v1

**中文摘要**

对意识可靠指示物的追寻分化为互相竞争的理论阵营（全球工作区理论 GWT、整合信息理论 IIT 和高阶理论 HOT），各自提出不同的神经学标志。我们采用合成神经现象学的方法：构建体现这些机制的人工代理，通过在生物系统中不可能实现的精确架构消融来测试它们的功能性后果。通过三项实验，我们报告了若干解离现象，表明这些理论可能描述的是互补的功能层次而非彼此竞争的解释。实验1：无重连自我模型（Self-Model）消融消除了元认知校准但保留了一阶任务表现，产生了与 HOT 预测一致的合成盲视类比。实验2：工作区容量在因果上对信息访问是必要的：完全的工作区消融导致访问相关标志的定性崩溃，而部分减少呈现梯度式退化，符合 GWT 的点火（ignition）框架。实验3：我们发现了广播-放大效应：GWT 风格的广播会放大内部噪声，导致极端脆弱性。B2 代理族对相同潜在扰动表现出鲁棒性；这种鲁棒性在“自我模型关闭/工作区只读”控制条件下仍然存在，从而提示不能将该效应简单归因于 z_self 的压缩。我们还报告了一个显性的负结果：在工作区瓶颈下，原始扰动复杂度（PCI-A）下降，这提示不要天真地把与 IIT 相关的代理指标直接移植到工程化代理上。这些结果支持一种分层设计原则：GWT 提供广播能力，而 HOT 提供质量控制。我们强调这些代理并不具备意识；它们只是用于测试意识理论功能性预测的参考实现。

---
## 214. Beyond Sliding Windows: Learning to Manage Memory in Non-Markovian Environments

- 作者：Geraud Nangue Tasse, Matthew Riemer, Benjamin Rosman, Tim Klinger
- 子主题：强化学习 (RL)
- 推荐：很推荐
- 关键词：自适应记忆管理, 非马尔可夫依赖, 序列模型（堆叠）
- Abstract：http://arxiv.org/abs/2512.19154v1
- PDF：https://arxiv.org/pdf/2512.19154v1

**中文摘要**

近年来基于序列模型开发通用智能体取得的成功，使得在计算资源受限的真实复杂环境中部署此类智能体的问题受到更多关注。在这些更现实的领域中，一个关键挑战是相对于智能体观测存在高度的非马尔可夫依赖，这在小型受控域中较少出现。文献中处理该问题的主要方法是将最近的观测按时间窗口堆叠（帧堆叠），但随着非马尔可夫依赖程度的增长，这一窗口尺寸必须增大，从而导致在动作推断和学习过程中计算与内存需求变得难以承受。本文的出发点是观察到：在许多时间尺度上高度非马尔可夫的环境中，环境因果上仅依赖于相对较少数量的观测。基于此，一个自然的方向是设计元算法，维护相对较小且自适应的记忆堆栈，以便在每一步仅考虑更少的观测就能表达随时间的高度非马尔可夫依赖，从而在计算和内存方面实现显著节省。因此，我们提出了一种元算法“自适应堆叠（Adaptive Stacking）”来实现上述目标，并给出了收敛性保证，同时量化了对基于MLP、LSTM和Transformer的智能体在计算与内存约束上的降低。我们的实验使用了常用的记忆任务，这些任务允许我们控制非马尔可夫依赖的程度，从而证明适当的元算法能够学会移除那些对未来回报不具有预测性的记忆，而不会过度丢弃重要经验。代码已开源： https://github.com/geraudnt/adaptive-stacking。

---
## 215. Understanding Chain-of-Thought in Large Language Models via Topological Data Analysis

- 作者：Chenghao Li, Chaoning Zhang, Yi Lu, Shuxu Chen, Xudong Wang, Jiaquan Zhang, Zhicheng Wang, Zhengxun Jin, Kuien Liu, Sung-Ho Bae, Guoqing Wang, Yang Yang, Hen Tao Shen
- 子主题：LLM
- 推荐：很推荐
- 关键词：链式思维, 拓扑数据分析, 持久同调
- Abstract：http://arxiv.org/abs/2512.19135v1
- PDF：https://arxiv.org/pdf/2512.19135v1

**中文摘要**

随着大型语言模型（LLM）的发展，尤其是长推理链技术的出现，模型在复杂问题推理能力上显著提升。尽管长推理链展现出强大能力，但我们仍然好奇：为何不同的推理链在推理效果上差异显著？推理链的哪些组成部分起到关键作用？现有研究主要从功能性角度评估推理链，而对其结构机制关注较少。为填补这一空白，本工作首次从结构视角分析和评估推理链质量。我们将推理步骤映射到语义空间，采用拓扑数据分析（TDA）中的持久同调方法提取拓扑特征并分析结构变化。这些结构性变化能够揭示语义连贯性、逻辑冗余，并识别逻辑断裂与漏洞。通过计算同调群，我们在不同尺度上评估连通性与冗余，利用条形码与持久性图定量描述稳定性与一致性。实验结果表明，推理链的拓扑结构复杂度与推理准确率呈正相关：更复杂的拓扑结构更早识别出正确答案，而成功的推理通常表现出更简单的拓扑，减少冗余与循环，从而提升效率与可解释性。本工作为评估推理链质量提供了新的结构性视角，并为未来的优化指明了方向。

---
## 216. Conditioning Accept-Desirability models in the context of AGM-like belief change

- 作者：Kathelijne Coussement, Gert de Cooman, Keano De Vos
- 子主题：信念修正与不确定推理
- 推荐：很推荐
- 关键词：Accept-Desirability 模型, AGM 信念修正, 不确定/量子概率条件化
- Abstract：http://arxiv.org/abs/2512.19096v1
- PDF：https://arxiv.org/pdf/2512.19096v1

**中文摘要**

我们在一个抽象的决策制定框架中讨论了对接受-可取性（Accept-Desirability）模型的条件化问题：不确定的报酬位于一个一般的线性空间中，而事件被视为该线性空间上的特殊投影算子。该抽象设定使我们能够统一经典概率与量子概率，并将它们扩展到不精确概率的情形。我们为接受-可取性模型引入了一种新的条件化规则，基于这样一个想法：观测到某个事件会在可选方案之间引入新的无差异关系。我们将一个信念修正算子与该条件化规则关联起来，考察在我们更一般的框架下，AGM 信念修正公理哪些仍然成立。我们还研究了两个有趣的特殊情形：在经典命题逻辑和完全条件概率的情形下，所有这些公理都被证明仍然成立。

---
## 217. Finer-Personalization Rank: Fine-Grained Retrieval Examines Identity Preservation for Personalized Generation

- 作者：Connor Kilrain, David Carlyn, Julia Chae, Sara Beery, Wei-Lun Chao, Jianyang Gu
- 子主题：CV
- 推荐：很推荐
- 关键词：身份保持, 个性化生成评估, 细粒度检索
- Abstract：http://arxiv.org/abs/2512.19026v1
- PDF：https://arxiv.org/pdf/2512.19026v1

**中文摘要**

随着个性化生成模型的兴起，一个核心问题是：我们应如何评估身份（identity）保持？当给定一张参考图像（例如某人的宠物）时，期望生成的图像能保留与主体身份相关的精确细节。然而，现有的生成评估指标更侧重参考与输出之间的整体语义相似性，往往忽视这些细粒度的判别性特征。为此，我们提出了Finer-Personalization Rank，一种针对身份保持的评估协议。与成对相似度不同，Finer-Personalization Rank采用排序视角：将每张生成图像视为查询，在由视觉上相似的真实图像构成且带有身份标签的画廊中进行检索。使用检索指标（如mAP）来衡量性能，得分越高表明越多身份特异性的细节（例如显著的头部斑点）被保留。我们在多粒度上评估身份——从细粒度类别（如鸟类物种、汽车型号）到个体实例（如重识别）。在CUB、Stanford Cars和动物Re-ID基准上，Finer-Personalization Rank比仅关注语义的指标更忠实地反映身份保持情况，并揭示了若干流行个性化方法存在的显著身份漂移。这些结果表明，基于画廊的评估协议是一种原则性且实用的个性化生成评估方法。

---
## 218. The Erasure Illusion: Stress-Testing the Generalization of LLM Forgetting Evaluation

- 作者：Hengrui Jia, Taoran Li, Jonas Guan, Varun Chandrasekaran
- 子主题：LLM
- 推荐：很推荐
- 关键词：机器遗忘, 泛化知识泄露, 评估压力测试
- Abstract：http://arxiv.org/abs/2512.19025v1
- PDF：https://arxiv.org/pdf/2512.19025v1

**中文摘要**

机器不可学习（Machine unlearning）旨在从已训练模型中删除特定数据的影响，这一能力对于遵守版权法规和保障 AI 安全至关重要。当前的不可学习评估通常通过监测模型在被删除数据集（D_u）上的性能下降来衡量成功性。我们认为，对于大语言模型（LLM）而言，这种评估范式不足且具有误导性。现实中受版权或安全驱动的不可学习需求，不仅仅针对 D_u 中的逐字内容，还隐含地针对模型从该数据中推导出的更广泛的泛化行为。我们展示了 LLM 在通过标准不可学习评估并“看似”忘记目标知识的同时，仍然在语义上与 D_u 相邻的内容上保持强大的能力。这一现象表明，抹去精确句子并不等同于移除其底层知识。为了解决这一空白，我们提出了一个自动化压力测试框架（|name），该框架生成一个代理数据集 ~tilde{D}_u。该代理集合在语义上源自 D_u，但在嵌入空间中与之足够不同。通过比较 D_u 与 ~tilde{D}_u 上的不可学习评估得分，能够对评估指标本身的可靠性进行压力测试。我们在三个 LLM 系列（Llama-3-8B、Qwen2.5-7B、Zephyr-7B-β）、三个不同数据集以及七种标准评估指标上做了广泛评估，结果揭示了普遍的不一致性。我们发现当前指标经常高估不可学习的成功，未能通过我们的压力测试数据集检测出模型保留的知识。

---
## 219. ORPR: An OR-Guided Pretrain-then-Reinforce Learning Model for Inventory Management

- 作者：Lingjie Zhao, Xue Yu, Yongzhi Qi, Hao Hu, Jianshen Zhang, Yingzheng Ma, Shuyu Han, Wei Qi, Zuo-Jun Max Shen
- 子主题：强化学习 (与运筹学结合，供应链/库存管理)
- 推荐：很推荐
- 关键词：运筹学引导, 预训练-再强化, 库存/供应链管理
- Abstract：http://arxiv.org/abs/2512.19001v1
- PDF：https://arxiv.org/pdf/2512.19001v1

**中文摘要**

随着人工智能（AI）与运筹学（OR）在复杂库存系统协同方面的研究加速，一个关键问题仍然存在：如何有效地将AI的自适应感知能力与OR的结构化严谨性相结合。为此，我们提出了一种新颖的OR引导的“预训练-再强化（Pretrain-then-Reinforce）”框架。为提供结构化指导，设计了一个基于仿真的增强型运筹学模型，用以生成高质量的参考决策，隐式捕捉复杂的业务约束和管理者偏好。以这些由OR导出的决策作为基础训练标签，我们构建了一个具领域知识的深度学习基础模型以建立初始决策能力，随后引入强化学习微调。与众不同的是，我们将强化学习定位为一种深度对齐机制，使AI代理能够内化OR的最优性原则，同时利用探索机制进行策略的泛化改进，并允许在特定场景（如促销活动）中引入专家指导进行定向适配。通过大量数值实验以及在京东的实地部署并辅以差异中差异（DiD）分析验证，模型显著优于现有工业实践：实现周转时间减少5.27天、缺货率下降2.29%（即在库率提升2.29%）并将持有成本降低29.95%。与当前普遍的暴力模型扩展趋势相反，本研究表明在结构化OR逻辑的引导下，轻量级的领域知情模型即可达到甚至超越最先进性能，并具备更强的迁移性与成本效益。该方法为智能供应链管理提供了一种可扩展、低成本且与运筹学深度融合的范式，凸显了将AI与OR深度对齐的价值。

---
## 220. Training Multimodal Large Reasoning Models Needs Better Thoughts: A Three-Stage Framework for Long Chain-of-Thought Synthesis and Selection

- 作者：Yizhi Wang, Linan Yue, Min-Ling Zhang
- 子主题：LLM
- 推荐：很推荐
- 关键词：多模态推理, 长链思路（CoT）合成-选择, 微调与强化学习
- Abstract：http://arxiv.org/abs/2512.18956v1
- PDF：https://arxiv.org/pdf/2512.18956v1

**中文摘要**

大规模推理模型（LRMs）在通过长链式思路（Chain-of-Thought, CoT）进行复杂推理方面展现出显著性能。将这些成功扩展到多模态推理仍面临挑战，原因在于整合多样化输入模态的复杂性增加以及高质量长CoT训练数据的匮乏。现有的多模态数据集和CoT合成方法仍存在推理深度不足、模态转换错误和生成流程僵化等问题，限制了模型的性能与稳定性。为此，本文提出SynSelect，一种新颖的三阶段合成-选择（Synthesis-Selection）框架，用于生成适配多模态推理任务的高质量长CoT数据。具体而言，SynSelect首先利用多个异构的多模态LRMs生成多样化的候选CoT，然后在实例级与批次级上执行筛选，过滤出能够有效提升模型推理能力的高质量CoT。大量多模态基准实验表明，基于SynSelect生成数据进行监督微调的模型显著优于基线，并在随后采用强化学习后训练时获得进一步提升。实验结果验证了SynSelect在推进多模态LRMs推理能力方面的有效性。

---
## 221. VeruSAGE: A Study of Agent-Based Verification for Rust Systems

- 作者：Chenyuan Yang, Natalie Neamtu, Chris Hawblitzel, Jacob R. Lorch, Shan Lu
- 子主题：LLM
- 推荐：很推荐
- 关键词：Rust 程序验证, 大语言模型(LLM), 代理式自动证明
- Abstract：http://arxiv.org/abs/2512.18436v1
- PDF：https://arxiv.org/pdf/2512.18436v1

**中文摘要**

大语言模型（LLM）在理解和开发代码方面已展现出令人瞩目的能力，但它们在对代码进行严密推理和证明其正确性方面的能力仍值得怀疑。本文对LLM在为用Rust编写的系统软件生成正确性证明方面的能力进行了全面研究。我们构建了一个新的系统验证基准套件 VeruSAGE-Bench，包含从八个开源且经 Verus 验证的 Rust 系统中提取的 849 个证明任务。此外，我们设计了若干代理系统，以匹配不同 LLM（如 o4-mini、GPT-5、Sonnet 4、Sonnet 4.5）的强项与弱点。研究表明，不同类型的 LLM 需要采用不同的工具和代理设置，以激发其系统验证能力。我们实验中的最佳 LLM-代理组合在 VeruSAGE-Bench 上完成了超过 80% 的系统验证任务，并且在一组未被纳入 VeruSAGE-Bench（因为尚未被人工专家完成）的系统证明任务上完成率超过 90%。该结果表明，LLM 辅助开发经验证的系统软件具有巨大的潜力。

---
## 222. Neural Proofs for Sound Verification and Control of Complex Systems

- 作者：Alessandro Abate
- 子主题：控制与形式验证
- 推荐：很推荐
- 关键词：神经证明, 形式化验证, 控制合成
- Abstract：http://arxiv.org/abs/2512.18389v1
- PDF：https://arxiv.org/pdf/2512.18389v1

**中文摘要**

本文为一项正在进行的研究工作做出非正式介绍，提出一种用于复杂随机动力系统、反应式程序以及更广泛的网络物理系统模型的形式化验证与控制的新方法——“神经证明”。神经证明由两大要素构成：一是证明规则，用来编码需对目标模型验证的一般时序规范的要求；二是用于履行这些规则的证书，证书通过归纳（即循环、迭代）方法从证明规则构造而成。该归纳流程包括：从模型动力学中获取样本并据此训练神经网络，以及通过SAT-模理论（SMT）查询利用模型的完整知识对所训练网络进行推广与验证。在面向复杂随机模型的序列决策问题中，本方法还能额外生成可证明正确的策略/控制器——与神经证书配合的状态反馈函数，从而在形式上保证所研究模型满足给定的规范。

---
## 223. LLM-based Few-Shot Early Rumor Detection with Imitation Agent

- 作者：Fengzhu Zeng, Qian Shao, Ling Cheng, Wei Gao, Shih-Fen Cheng, Jing Ma, Cheng Niu
- 子主题：LLM
- 推荐：很推荐
- 关键词：早期谣言检测, 少样本学习, 大语言模型
- Abstract：http://arxiv.org/abs/2512.18352v1
- PDF：https://arxiv.org/pdf/2512.18352v1

**中文摘要**

早期谣言检测（Early Rumor Detection, EARD）旨在确定在一系列社交媒体帖文中能否以及何时最早对某条声明做出准确分类，这在样本稀缺的情形下尤其具有挑战性。尽管大语言模型（LLMs）在少样本自然语言处理任务中表现出色，但它们并不擅长处理时序数据，且在训练与推理方面计算开销大。本工作提出了一种新颖的EARD框架，将一个自治代理与基于LLM的检测模型相结合：代理作为可靠的“早期时间点判定”决策者，而LLM则作为强大的“谣言检测器”。该方法实现了首个面向少样本EARD的解决方案，仅需训练一个轻量级代理而保持LLM无训练化。我们在四个真实世界数据集上的大量实验表明，该方法能够提升多种LLM的性能，并在准确性和提前性（earliness）上超越现有的EARD方法。

---
## 224. Trustworthy and Explainable Deep Reinforcement Learning for Safe and Energy-Efficient Process Control: A Use Case in Industrial Compressed Air Systems

- 作者：Vincent Bezold, Patrick Wagner, Jakob Hofmann, Marco Huber, Alexander Sauer
- 子主题：RL
- 推荐：很推荐
- 关键词：深度强化学习, 可解释性, 工业过程节能
- Abstract：http://arxiv.org/abs/2512.18317v1
- PDF：https://arxiv.org/pdf/2512.18317v1

**中文摘要**

本文提出了一种面向工业压缩空气系统控制的可信赖强化学习方法。我们构建了一个在真实边界条件下实现安全与能源高效运行的框架，并引入了一个多层次可解释性流程，结合输入扰动测试、基于梯度的敏感性分析以及 SHAP（Shapley 加性解释）特征归因。针对多种压缩机配置的实证评估表明，所学策略在物理上合理、能够预测未来需求，并始终满足系统边界约束。与现有工业控制器相比，该方法在不依赖显式物理模型的前提下减少了不必要的超压现象，并实现约4%的能耗节约。结果还显示，系统压力与负荷预测信息在策略决策中占主导地位，而压缩机级别的输入仅起次要作用。总体而言，效率提升、预测性行为与透明验证的结合支持了强化学习在工业能源系统中可信部署的可能性。

---
## 225. Monitoring Monitorability

- 作者：Melody Y. Guan, Miles Wang, Micah Carroll, Zehao Dou, Annie Y. Wei, Marcus Williams, Benjamin Arnav, Joost Huizinga, Ian Kivlichan, Mia Glaese, Jakub Pachocki, Bowen Baker
- 子主题：LLM
- 推荐：很推荐
- 关键词：可监测性, 链式思维(CoT)监控, 模型可解释性/安全
- Abstract：http://arxiv.org/abs/2512.18311v1
- PDF：https://arxiv.org/pdf/2512.18311v1

**中文摘要**

对现代 AI 系统决策过程的可观测性对于安全部署日益强大的智能体可能是必要的。对当前推理模型的链式思维（chain-of-thought, CoT）进行监控已被证明在检测异常行为方面有效。然而，这种“可监测性”可能会因不同的训练流程、数据源，甚至继续扩展系统规模而变得脆弱。为衡量和跟踪可监测性，本文提出了三种评估范式（干预型、过程型和结果属性型）和一个新的可监测性度量，并引入了一个广泛的评估套件。我们展示了这些评估能够识别出被训练为使 CoT 混淆的简单模型样本，并证明在实际场景中对 CoT 的监控比仅监控动作更有效。我们比较了若干前沿模型的可监测性，发现大多数模型是相当可监测的，但并非完美可监测。我们还评估了可监测性如何随推理时计算量、强化学习优化和预训练模型规模而变化。结果表明，更长的 CoT 通常更易监控，而强化学习优化在当前前沿规模下并不会显著降低可监测性。值得注意的是，对于一个在较低推理努力下运行的模型，可以改用一个较小但在更高推理努力下运行的模型（从而匹配能力），以获得更高的可监测性，尽管总体推理计算成本更高。我们进一步研究了智能体—监控器的规模化趋势，发现增加弱监控器在测试时的计算资源以监控强智能体会提高可监测性。赋予弱监控器访问 CoT 不仅提升了可监测性，还使监控器的测试时计算与可监测性之间的增长曲线更陡峭。最后，我们展示了通过让模型回答跟进问题并将其跟进的 CoT 提供给监控器，可以进一步提升可监测性。

---
## 226. Who Can See Through You? Adversarial Shielding Against VLM-Based Attribute Inference Attacks

- 作者：Yucheng Fan, Jiawei Chen, Yu Tian, Zhaoxia Yin
- 子主题：多模态/视觉-语言模型 (VLM)
- 推荐：很推荐
- 关键词：视觉-语言模型, 属性推断攻击, 隐私保护
- Abstract：http://arxiv.org/abs/2512.18264v1
- PDF：https://arxiv.org/pdf/2512.18264v1

**中文摘要**

随着视觉-语言模型（VLM）被广泛采用，基于VLM的属性推断攻击成为严重的隐私问题，攻击者能够从社交媒体上共享的图像推断出私人属性。该威胁不断升级，亟需专门的保护方法以保障用户隐私。然而，现有方法往往以牺牲图像视觉质量或干扰社交媒体上的视觉功能为代价，难以在隐私保护与用户体验之间取得理想平衡。为应对这一挑战，我们提出了一种新颖的防护方法，在视觉一致性约束下联合优化隐私抑制与效用保留，以同时降低属性泄露风险并保持图像的可用性。尽管方法在概念上有效，但由于缺乏公开评估数据集，公平比较各方法仍存在困难。为填补这一空白，我们构建并公开了VPI-COCO基准数据集，包含522张图像、分层结构的隐私问题及对应的非隐私替代项，从而支持针对隐私保护与用户体验的细粒度联合评估。基于该基准在多种VLM上的实验表明：我们的方案能将PAR（隐私推断成功率）降至25%以下，同时将NPAR（非隐私属性保持率）维持在88%以上，保持较高的视觉一致性，并能很好地泛化到未见过或改写的隐私问题，显示出在实际VLM部署中的强实用性。

---
## 227. LLaViDA: A Large Language Vision Driving Assistant for Explicit Reasoning and Enhanced Trajectory Planning

- 作者：Yudong Liu, Spencer Hallyburton, Jiwoo Kim, Yueqian Lin, Yiming Li, Qinsi Wang, Hui Ye, Jingwei Sun, Miroslav Pajic, Yiran Chen, Hai Li
- 子主题：VLM 与 自动驾驶轨迹规划
- 推荐：很推荐
- 关键词：视觉-语言模型, 轨迹规划, 自动驾驶
- Abstract：http://arxiv.org/abs/2512.18211v1
- PDF：https://arxiv.org/pdf/2512.18211v1

**中文摘要**

轨迹规划是自动驾驶中的一个基础且富有挑战性的模块。端到端的规划器在恶劣天气、不可预测的人类行为或复杂道路结构下常常失效，主要由于它们在训练数据以外缺乏强泛化能力或少样本适应能力。我们提出 LLaViDA，一种大型语言视觉驾驶助理，利用视觉-语言模型（VLM）用于对象运动预测、语义落地以及链式思维（Chain-of-Thought）推理，以支持自动驾驶中的轨迹规划。我们设计了一个两阶段训练流程——先进行监督微调，然后通过轨迹偏好优化（Trajectory Preference Optimization，TPO）进一步训练——通过注入基于回归的监督来增强场景理解与轨迹规划能力，从而构建出一个强大的“用于自动驾驶的VLM轨迹规划器”。在 NuScenes 基准上，LLaViDA 在开放式轨迹规划任务上优于最先进的端到端方法以及其他近期基于 VLM/LLM 的基线，在 NuScenes 测试集上取得平均 L2 轨迹误差 0.31 m 和碰撞率 0.10%。论文代码已在 GitHub 上开源。

---
## 228. Efficient Beamforming Optimization for STAR-RIS-Assisted Communications: A Gradient-Based Meta Learning Approach

- 作者：Dongdong Yang, Bin Li, Jiguang He, Yicheng Yan, Xiaoyu Zhang, Chongwen Huang
- 子主题：无线通信（物理层 / 智能表面 RIS）
- 推荐：很推荐
- 关键词：STAR-RIS, 波束成形优化, 梯度型元学习
- Abstract：http://arxiv.org/abs/2512.17928v1
- PDF：https://arxiv.org/pdf/2512.17928v1

**中文摘要**

同时发射与反射可重构智能表面（STAR-RIS）作为一种有望实现全空间覆盖并提升频谱效率的下一代无线技术正在兴起。然而，基站预编码矩阵与STAR-RIS发射与反射系数矩阵的联合设计导致高维、强非凸且NP-困难的优化问题。传统的交替优化（AO）方法通常需要反复进行大规模矩阵求逆，造成计算复杂度高且难以扩展，而现有深度学习方法则常依赖昂贵的预训练与大型网络模型。为此，本文提出了一种基于梯度的元学习（GML）框架，该框架将优化梯度直接输入轻量神经网络，从而消除了预训练需求并实现快速自适应。具体地，针对独立相位与耦合相位两种STAR-RIS模型分别设计了GML方案，有效处理各自的幅度与相位约束，并在加权和速率上接近基于AO的基准性能。大量仿真结果表明，对于两类相位模型，所提方法显著降低了计算开销，随着基站天线数量和STAR-RIS单元数增长，复杂度几乎呈线性增长，并在运行时间方面相比AO实现了最高约10倍的加速，验证了所提GML方法在大规模STAR-RIS辅助通信场景中的可扩展性与实用性。

---
## 229. On Efficient Adjustment in Causal Graphs

- 作者：Isabela Belciug, Simon Ferreira, Charles K. Assaad
- 子主题：因果推断/图模型（动态/时间序列）
- 推荐：推荐
- 关键词：摘要因果图(SCG), 协变量调整, 可识别性与拟最优调整集合
- Abstract：http://arxiv.org/abs/2512.18315v1
- PDF：https://arxiv.org/pdf/2512.18315v1

**中文摘要**

在流行病学等领域的观察性研究中，常常依赖协变量调整来估计因果效应。传统的图形准则（如后门准则和广义调整准则）是识别有向无环图（DAG）中有效调整集合的有力工具，但它们无法直接适用于摘要因果图（SCG）。SCG 是对 DAG 在动态系统中常用的抽象表示，图中每个节点通常代表整个时间序列并可能存在环路，因此经典准则在此情形下失效。近期工作在无隐藏混杂假设下给出了确定处理或暴露 X_{t-γ} 对结果 Y_t 的微观因果效应是否可通过协变量调整识别的完备条件。然而，这些可识别性条件存在两方面的局限：一是表述复杂，依赖繁琐定义并需枚举 SCG 中的多条路径，计算代价高；二是在满足条件时仅给出两个有效调整集合，实际应用中灵活性不足。本文提出了对上述可识别性条件的等价但更简洁的表述，并引入了一条新准则以识别 SCG 中更广泛的有效调整集合。此外，我们刻画了这些集合中的拟最优调整集合，即使因果效应估计量的渐近方差最小的那一类集合。我们的工作在理论上推进了对抽象因果图中协变量调整可识别性的理解，并为更灵活高效的因果推断提供了实用工具。

---
## 230. PlantDiseaseNet-RT50: A Fine-tuned ResNet50 Architecture for High-Accuracy Plant Disease Detection Beyond Standard CNNs

- 作者：Santwana Sagnika, Manav Malhotra, Ishtaj Kaur Deol, Soumyajit Roy, Swarnav Kumar
- 子主题：CV
- 推荐：推荐
- 关键词：植物病害检测, ResNet50微调, 正则化与学习率调度
- Abstract：http://arxiv.org/abs/2512.18500v1
- PDF：https://arxiv.org/pdf/2512.18500v1

**中文摘要**

植物病害对农业生产力和全球粮食安全构成重大威胁，导致全球作物约70%–80%的损失。传统的检测方法高度依赖专家目视检查，耗时、劳动强度大，且在大规模农业生产中往往不切实际。本文提出了PlantDiseaseNet-RT50，一种基于ResNet50的细化微调深度学习架构，用于自动化植物病害检测。该模型采用有策略地解冻部分层、定制的分类头并引入正则化机制，同时通过余弦衰减实现动态学习率调度。在包含多种作物物种和不同病害类别的综合数据集上，PlantDiseaseNet-RT50表现优异，取得了约98%的准确率、精确率和召回率。我们的架构改进和优化流程展示了针对性微调如何将标准预训练模型转变为专用的农业诊断工具。文中详细描述了方法学，包括终端层的系统性解冻、批量归一化与dropout正则化的实现以及先进训练技术的应用。PlantDiseaseNet-RT50代表了AI驱动农业工具的一项重要进展，提供了一种计算效率高、可在实际耕作环境中快速准确诊断植物病害的解决方案，可支持及时干预、减少作物损失。

---
## 231. Characterising Behavioural Families and Dynamics of Promotional Twitter Bots via Sequence-Based Modelling

- 作者：Ohoud Alzahrani, Russell Beale, Robert J. Hendley
- 子主题：社交媒体行为建模
- 推荐：推荐
- 关键词：推广机器人, 序列化行为建模, 行为演化/突变分析
- Abstract：http://arxiv.org/abs/2512.18077v1
- PDF：https://arxiv.org/pdf/2512.18077v1

**中文摘要**

本文探讨推广性Twitter/X机器人是否形成行为家族以及成员是否以相似方式演化。我们分析了来自2,615个已标注推广机器人账户的2,798,672条推文（2006–2021），重点考察2009到2020年的完整年份。每个机器人被编码为由七个类别化的帖子级别行为特征（发帖动作、URL、媒体、文本重复、话题标签、表情符号、情感）组成的符号块序列（“数字DNA”），仅保留时间顺序。采用不重叠块(k=7)、基于块频向量的余弦相似度和层次聚类，我们识别出四个连贯的家族：独特发布者（Unique Tweeters）、带URL的复制者（Duplicators with URLs）、内容倍增者（Content Multipliers）和信息贡献者（Informed Contributors）。这些家族尽管共享行为核心，但在参与策略与生命周期动态（起始/中期/终期）上存在系统性差异。随后，我们将行为变化建模为“突变”：在每个家族内通过多序列比对（MSA）对序列进行对齐，并将事件标注为插入、删除、替换、变更与相同，从而量化突变率、易变块/特征与突变热点。结果显示删除与替换占主导，插入罕见，且不同家族展现不同的突变谱——部分家族的突变热点集中于早期，另一些则更为分散。最后的预测性检验表明：同一家族内的机器人比跨家族机器人更频繁共享突变；相近机器人比相距更远的机器人更易共享并传播突变；对外部触发（如圣诞节、万圣节）的响应呈现家族特定且部分可预测的模式。总体而言，基于序列的家族建模结合突变分析为推广性机器人行为如何随时间适应提供了细粒度的描述框架。

---
## 232. NystagmusNet: Explainable Deep Learning for Photosensitivity Risk Prediction

- 作者：Karthik Prabhakar
- 子主题：CV
- 推荐：推荐
- 关键词：光敏性/眼震预测, 可解释深度学习, 视觉辅助系统
- Abstract：http://arxiv.org/abs/2512.17943v1
- PDF：https://arxiv.org/pdf/2512.17943v1

**中文摘要**

眼震（nystagmus）伴随光敏性患者在明暗环境下由于不自主眼球运动而面临显著的日常困扰。当前的辅助方案多为缓解症状的通用治疗，缺乏个性化的预测能力。本文提出了NystagmusNet，一种用于预测高风险视觉环境并实时推荐视觉适配措施的AI系统。该系统采用双分支卷积神经网络，在合成与增强的数据集上训练，基于环境亮度与眼球运动方差估计光敏风险评分。在合成数据上的验证准确率为75%。为增强临床信任与模型可解释性，集成了SHAP和GradCAM等可解释性技术以高亮环境中的风险区域。系统还包含一个基于规则的推荐引擎，用于提出自适应滤镜建议。未来工作方向包括通过智能眼镜部署以及采用强化学习实现个性化推荐。

---
## 233. Comparative Evaluation of Explainable Machine Learning Versus Linear Regression for Predicting County-Level Lung Cancer Mortality Rate in the United States

- 作者：Soheil Hashtarkhani, Brianna M. White, Benyamin Hoseini, David L. Schwartz, Arash Shaban-Nejad
- 子主题：可解释机器学习（公共卫生应用）
- 推荐：推荐
- 关键词：可解释机器学习, 肺癌死亡率预测, SHAP与空间热点分析
- Abstract：http://arxiv.org/abs/2512.17934v1
- PDF：https://arxiv.org/pdf/2512.17934v1

**中文摘要**

肺癌是美国癌症相关死亡的主要原因之一。准确预测县级肺癌死亡率对于制定有针对性的干预措施和应对健康差异至关重要。尽管传统的回归模型被广泛使用，可解释的机器学习模型可能在预测精度和对影响因子理解方面具有优势。本研究应用了三种模型——随机森林（RF）、梯度提升回归（GBR）和线性回归（LR）来预测美国各县的肺癌死亡率，并使用R平方和均方根误差（RMSE）评估模型性能。通过Shapley Additive Explanations（SHAP）值评估变量重要性及其方向性影响，并运用Getis-Ord（Gi*）热点分析考察肺癌死亡率的地理差异。结果显示，随机森林优于GBR和LR，达到R2为41.9%，RMSE为12.8。SHAP分析表明吸烟率是最重要的预测因子，其次是住房中位价值和西班牙裔人口比例。空间分析发现美国中东部县域存在显著的肺癌死亡率高值聚集区。研究表明，随机森林在县级肺癌死亡率预测中具有更好的预测性能，强调了吸烟流行率、住房价值和西班牙裔人口比例的关键作用，为在受影响最严重地区设计有针对性的干预、推动筛查和缩小健康差异提供了可操作的洞见。

---
## 234. Owning the Intelligence: Global AI Patents Landscape and Europe's Quest for Technological Sovereignty

- 作者：Lapo Santarlasci, Armando Rungi, Loredana Fattorini, Nestor Maslej
- 子主题：AI专利与科技政策
- 推荐：推荐
- 关键词：AI专利, 技术主权, 创新扩散
- Abstract：http://arxiv.org/abs/2512.19569v1
- PDF：https://arxiv.org/pdf/2512.19569v1

**中文摘要**

人工智能已成为全球技术竞争的核心领域，也是欧洲争取技术主权的关键议题。本文基于2010—2023年的专利、企业、所有权和引文等关联数据，分析全球人工智能专利布局，以评估在日益呈现美中两极化的创新格局中欧洲的地位。研究考察了AI创新的地域分布、技术专精及国际扩散，发现专利格局高度集中：中国在专利数量上领先，而美国在引文影响力和技术影响方面占主导地位。欧洲在AI专利总量中所占份额有限，但呈现出相对较高的专利质量信号。技术邻近性分析显示全球创新正趋向美国的轨迹，欧洲并未形成独立的技术极点而仍然呈现碎片化。重力模型估计表明，跨境AI知识流动主要由技术能力和专业化驱动，地理与制度因素次之；欧盟成员身份并未显著促进欧内知识扩散，表明参与全球AI创新网络更多依赖技术能力而非政治一体化。

---
## 235. ReGal: A First Look at PPO-based Legal AI for Judgment Prediction and Summarization in India

- 作者：Shubham Kumar Nigam, Tanuj Tyagi, Siddharth Shukla, Aditya Kumar Guru, Balaramamahanthi Deepak Patnaik, Danush Khanna, Noel Shallum, Kripabandhu Ghosh, Arnab Bhattacharya
- 子主题：RL (法律NLP)
- 推荐：推荐
- 关键词：法律人工智能, 强化学习（PPO/RLAIF）, 判决预测与摘要
- Abstract：http://arxiv.org/abs/2512.18014v1
- PDF：https://arxiv.org/pdf/2512.18014v1

**中文摘要**

本文对印度语境下法律人工智能中强化学习方法进行了早期探索。我们提出了Reinforcement Learning-based Legal Reasoning（ReGal）框架，该框架将多任务指令微调与基于AI反馈的强化学习（RLAIF）相结合，并采用近端策略优化（PPO）进行训练。我们在两类关键法律任务上评估了该方法：（i）法院判决预测与解释（CJPE），以及（ii）法律文档摘要。尽管在标准评测指标上，ReGal 相较于监督学习和专有模型表现欠佳，但该工作揭示了将强化学习应用于法律文本时面临的若干挑战，包括奖励模型对齐、法律语言的复杂性以及领域特定的适配问题。通过实证和定性分析，论文展示了如何将强化学习重新用于高风险、长文档的法律任务，并为未来优化法律推理流水线、构建可解释且具适应性的法律AI系统奠定了基础。

---
## 236. Self-Attention with State-Object Weighted Combination for Compositional Zero Shot Learning

- 作者：Cheng-Hong Chang, Pei-Hsuan Tsai
- 子主题：CV
- 推荐：推荐
- 关键词：组合零样本学习, 自注意力机制, 状态-对象加权
- Abstract：http://arxiv.org/abs/2512.18969v1
- PDF：https://arxiv.org/pdf/2512.18969v1

**中文摘要**

对象识别已在多个行业得到广泛应用，但现有多数应用仅能识别对象本身，通常忽略其对应的状态。将状态与对象在训练时合并为单一类别虽然可行，但会带来数据收集和训练上的困难，因为需要覆盖所有可能的组合。组合零样本学习（Compositional Zero-shot Learning, CZSL）通过在训练时将状态与对象视为独立类别，能够在缺乏某些组合训练样本的情况下识别新颖组合。当前的最先进方法KG-SP通过为状态和对象分别训练分类器，并利用语义模型评估组合的合理性来解决该问题。然而，KG-SP在状态与对象识别的准确性上仍有提升空间，且在组合时未考虑状态与对象的不同权重。在本研究中，我们提出了SASOW，对KG-SP进行改进：在状态和对象的分类器中引入自注意力机制以提高识别准确性，并在组合阶段引入状态与对象的加权机制以生成更合理的组合。我们在三个公开基准数据集上对SASOW进行了验证。实验结果表明，与OW-CZSL方法和KG-SP相比，SASOW在MIT-States、UT Zappos和C-GQA三个数据集上对未见组合的准确率分别提升了约2.1%、1.7%和0.4%。

---
## 237. Embedded Safety-Aligned Intelligence via Differentiable Internal Alignment Embeddings

- 作者：Harsh Rathva, Ojas Srivastava, Pruthwik Mishra
- 子主题：多智能体强化学习 (RL)
- 推荐：推荐
- 关键词：内在对齐嵌入, 多智能体强化学习, 可微分安全机制
- Abstract：http://arxiv.org/abs/2512.18309v1
- PDF：https://arxiv.org/pdf/2512.18309v1

**中文摘要**

我们提出了“内嵌安全对齐智能”（Embedded Safety-Aligned Intelligence, ESAI），这是一个将对齐约束直接嵌入多智能体强化学习代理内部表征的理论框架，采用可微分的内部对齐嵌入。与外部奖励塑造或事后安全约束不同，内部对齐嵌入是通过反事实推理预测外在伤害的潜在变量，并通过注意力机制与基于图的传播在策略更新中引导对伤害的减少。ESAI 框架整合了四种机制：基于软参考分布计算的可微分反事实对齐惩罚、按对齐加权的感知注意力、支持时间归因的赫布联想记忆，以及带有偏差缓解控制的相似性加权图扩散。我们在利普希茨连续性与谱约束下分析了内部嵌入有界性的稳定性条件，讨论了计算复杂度，并考察了包括收缩行为与公平-性能权衡在内的理论性质。该工作将 ESAI 定位为多智能体系统中可微分对齐机制的概念性贡献，同时指出了若干未决的理论问题，如收敛性保证、嵌入维度选择及向高维环境的扩展。实验评估留待后续工作完成。

---
## 238. A Formal Descriptive Language for Learning Dynamics: A Five-Layer Structural Coordinate System

- 作者：Miyuki T. Nakata
- 子主题：学习动力学（教育技术 / 自适应学习）
- 推荐：推荐
- 关键词：学习动力学, 形式描述框架, 认知负荷
- Abstract：http://arxiv.org/abs/2512.18525v1
- PDF：https://arxiv.org/pdf/2512.18525v1

**中文摘要**

理解学习作为一个动态过程具有挑战性，因为它涉及认知负荷、内部状态变化和主观评估等多重因素的相互作用。现有方法通常各自处理这些要素，难以在统一且结构化显式的框架下描述学习现象。本文提出了一个多层次的形式描述框架，用以表征学习动力学。该框架并非一个预测性或规范性模型，而是引入了一种由状态变量、映射和层级职责组成的符号化语言，使得在不依赖特定函数形式或优化目标的前提下，对学习过程进行一致性的描述成为可能。设计的核心原则是明确在各层之间分离描述性职责，区分负荷生成、内部理解转换、观测与评估。在此结构中，认知负荷被视为一种从外部输入与内部组织相互作用中产生的关系量，而主观评估则被建模为对学习动力学和环境条件作出响应的最小调节接口。通过强调描述的清晰性与可扩展性，该框架旨在为分析人类学习者以及扩展至自适应和 AI 辅助学习系统提供共同的结构性表达，并为组织现有理论以及支持未来的实证和理论研究提供基础性语言。

---
## 239. Prediction and Forecast of Short-Term Drought Impacts Using Machine Learning to Support Mitigation and Adaptation Efforts

- 作者：Hatim M. E. Geli, Islam Omar, Mona Y. Elshinawy, David W. DuBios, Lara Prehodko, Kelly H Smith, Abdel-Hameed A. Badawy
- 子主题：应用机器学习（时序预测/环境科学）
- 推荐：推荐
- 关键词：干旱影响预测, 时序机器学习, 生态干旱信息系统
- Abstract：http://arxiv.org/abs/2512.18522v1
- PDF：https://arxiv.org/pdf/2512.18522v1

**中文摘要**

干旱是一种复杂的自然灾害，对生态和人类系统造成重大环境和经济损失。近年来干旱的严重性、频率和持续时间均有所增加，凸显了有效监测与缓解策略的必要性。相比仅预测干旱条件，预测干旱影响能够为预警系统和主动决策提供更有价值的信息。本研究应用机器学习方法，将干旱指数与历史干旱影响记录（2005–2024年）相结合，以生成短期影响预测。通过应对关于时间尺度和影响量化的关键概念和数据驱动挑战，研究旨在提升可操作提前期内干旱影响的可预测性。研究将干旱严重度与覆盖指数（DSCI）和蒸发胁迫指数（ESI）与干旱影响报告（Drought Impact Reporter, DIR）中的影响数据相结合，对周尺度的干旱影响进行建模与预测。结果表明，火灾（Fire）和救济（Relief）类影响的预测精度最高，其次是农业（Agriculture）和水资源（Water）类，而植物（Plants）和社会（Society）类影响的预测表现更为波动。基于DSCI和ESI的eXtreme Gradient Boosting（XGBoost）模型在新墨西哥州生成了县级和州级的预测，使用前八周的数据为大多数影响类别成功生成了最长达八周的提前预测。该工作支持为新墨西哥州开发生态干旱信息通信系统（EcoDri），并展示了在类似干旱多发地区的更广泛应用潜力。研究结果可帮助利益相关方、土地管理者和决策者制定并实施更有效的干旱缓解与适应策略。

---
## 240. Self-organizing maps for water quality assessment in reservoirs and lakes: A systematic literature review

- 作者：Oraib Almegdadi, João Marcelino, Sarah Fakhreddine, João Manso, Nuno C. Marques
- 子主题：无监督学习（环境监测/生态遥感）
- 推荐：推荐
- 关键词：自组织映射（SOM）, 水质评估, 无监督学习
- Abstract：http://arxiv.org/abs/2512.18466v1
- PDF：https://arxiv.org/pdf/2512.18466v1

**中文摘要**

可持续的水质保障生态平衡与水资源安全。由于数据稀疏、异质性以及各参数之间的非线性关系，湖泊与水库的评估与管理具有挑战性。本文综述了自组织映射（Self-Organizing Map，SOM）这一无监督人工智能技术在水质评估中的应用，汇总了关于参数选择、时空采样策略和聚类方法的研究进展。文章重点阐述了SOM如何处理多维数据并揭示隐含模式，从而支持有效的水体管理。随着来自原位传感器、遥感影像、物联网技术及历史记录的环境数据日益丰富，环境监测的分析机会显著增加。SOM在分析复杂数据集方面表现出色，尤其适用于标注数据有限或不可得的情形，能够实现高维数据可视化、发现生态隐含模式并识别多样水质指标间的重要关联。综述还强调了SOM在生态评估、营养状态分类、藻华监测以及流域影响评估中的多用途性。这些发现为现有方法学提供了全面见解，并为未来研究与实践应用以改善湖泊和水库生态系统的监测与可持续管理提供支持。

---
## 241. Clustering-based Transfer Learning for Dynamic Multimodal MultiObjective Evolutionary Algorithm

- 作者：Li Yan, Bolun Liu, Chao Li, Jing Liang, Kunjie Yu, Caitong Yue, Xuzhao Chai, Boyang Qu
- 子主题：多目标进化算法（演化计算）
- 推荐：推荐
- 关键词：动态多模态多目标优化, 聚类-自编码器迁移学习, 自适应尼奇策略
- Abstract：http://arxiv.org/abs/2512.18947v1
- PDF：https://arxiv.org/pdf/2512.18947v1

**中文摘要**

动态多模态多目标优化在时变环境中同时跟踪多个等价的帕累托最优集并保持种群多样性，因而具有双重挑战。然而，现有的动态多目标进化算法常常忽视解的模态性，而静态的多模态多目标进化算法又缺乏对动态变化的适应性。为了解决上述问题，本文作出两项主要贡献。首先，提出了一组新的动态多模态多目标测试函数基准，将动态性与多模态优化的特性融合，以建立一个严格的评测平台。其次，提出了一种以基于聚类的自编码器预测动态响应机制为核心的新算法，利用自编码器对匹配簇进行处理以生成高度多样化的初始种群。此外，为了在收敛性与多样性之间取得平衡，本文在静态优化器中引入了自适应尼奇（niching）策略。针对12个动态多模态多目标测试实例的实证分析表明，与若干先进的动态多目标进化算法和多模态多目标进化算法相比，本算法不仅能更有效地在决策空间中保持种群多样性，而且在目标空间上实现了更优的收敛性。

---
## 242. Psychometric Validation of the Sophotechnic Mediation Scale and a New Understanding of the Development of GenAI Mastery: Lessons from 3,392 Adult Brazilian Workers

- 作者：Bruno Campello de Souza
- 子主题：LLM
- 推荐：推荐
- 关键词：生成式人工智能, 认知中介, 量表心理测量
- Abstract：http://arxiv.org/abs/2512.18871v1
- PDF：https://arxiv.org/pdf/2512.18871v1

**中文摘要**

生成式人工智能（GenAI）系统的快速普及引入了新的人人机交互形式，进而提出了一个关键问题：持续使用是否会形成稳定的、内化的认知模式，而不仅仅是短暂的效率提升。基于认知中介网络理论，本研究检验了“科技-技艺中介（Sophotechnic Mediation）”——一种与长期GenAI互动相关的思维与行动模式——并对“科技-技艺中介量表”进行了全面的心理测量学验证。数据来自2023至2025年期间在巴西伯南布哥大都会区的公私部门组织中独立的横断面样本，共计3,932名成年在职人员。结果显示该量表具有优良的内部一致性、稳健的单维结构，并在不同队列间表现出测量不变性。基于序数稳健的验证性因子分析和残差诊断，较高的总体拟合指标反映的是轻微的局部依赖性而非维度设定错误。分布分析揭示了一种随时间演变的模式：非采用者比例下降，采用者群体趋向近似正态分布；模型比较表明，两过程的“障碍（hurdle）模型”优于截尾正态模型。实证结果还表明，科技-技艺中介有别于“超文化中介（Hypercultural mediation）”，并且主要由累积的GenAI使用经验驱动，年龄既影响初始习得的速度，也调节后期整合的深度。总体而言，研究支持将Sophotechnia视为一种与正在进行的GenAI革命相关的连贯、可测量且新兴的认知中介模式。

---
## 243. Social Comparison without Explicit Inference of Others' Reward Values: A Constructive Approach Using a Probabilistic Generative Model

- 作者：Yosuke Taniuchi, Chie Hieida, Atsushi Noritake, Kazushi Ikeda, Masaki Isoda
- 子主题：计算认知建模（概率生成模型）
- 推荐：推荐
- 关键词：社会比较, 概率生成模型, 主观价值推断
- Abstract：http://arxiv.org/abs/2512.18687v1
- PDF：https://arxiv.org/pdf/2512.18687v1

**中文摘要**

社会比较——即将自身获得的奖励与他人进行比较的过程——在灵长类动物的社会认知中具有重要作用。然而，从计算角度来看，他人奖励信息如何影响对自身奖励的评估仍不明确。本研究采用构造性方法，考察猴子是仅识别客观奖励差异，还是会推断他人的主观奖励估值。我们提出了三种具有不同社会信息处理程度的计算模型：内部预测模型（IPM），用于推断伙伴的主观价值；无比较模型（NCM），忽略伙伴信息；以及外部比较模型（ECM），直接纳入伙伴的客观奖励。为评估模型性能，我们采用了多层次、多模态的潜在狄利克雷分配（LDA）。在包含一对猴子行为、对应奖励和条件刺激的数据集上训练模型后，我们评估了它们在预设实验条件下对主观价值的分类能力。在我们的设置下，ECM在Rand指数上取得了最高分类得分（0.88，IPM为0.79），表明社会比较更依赖客观奖励差异，而非对他人主观状态的推断。

---
## 244. The Subject of Emergent Misalignment in Superintelligence: An Anthropological, Cognitive Neuropsychological, Machine-Learning, and Ontological Perspective

- 作者：Muhammad Osama Imran, Roshni Lulla, Rodney Sappington
- 子主题：AI安全与伦理（Alignment）
- 推荐：推荐
- 关键词：超智能错位, 人工智能无意识, 人机生态与伦理
- Abstract：http://arxiv.org/abs/2512.17989v1
- PDF：https://arxiv.org/pdf/2512.17989v1

**中文摘要**

我们审视了当前关于超智能（Superintelligence）错位论述中的概念与伦理缺口。研究发现，在超智能话语中，人类主体往往缺席，而“人工智能无意识”的理论化严重不足，这两者共同可能为反社会性危害奠定潜在基础。鉴于人工智能安全研究既可能促进亲社会又可能催生反社会结果，我们提出问题：在人们关于灾难性失灵或快速“跃升”至超智能的想象中，人类主体处于何种位置？人类主体性在这些叙事中如何被定位？另一个层面上，我们追问：大规模AI模型中被铭刻的那些无意识或被压抑的维度是什么？当这些代理体采取欺骗性策略时，我们是否应将责任部分归咎于其中反映出的人类不良模式？在追索这些心理与认识上的缺失时，本研究主张将人类主体重新置于中心，视其为伦理、无意识与人类与机器智能错位共构的动荡基础。涌现性错位不能仅通过当代机器学习安全研究的技术诊断来理解，而应被视为一场多层次的危机。人类主体的消失不仅源自计算抽象，也源自那些在社会技术想象中优先强调可扩展性、加速性与效率，而忽视脆弱性、有限性与关系性的力量。同样，人工智能无意识并非纯粹隐喻，而是现代深度学习系统的结构性现实：庞大的潜在空间、不透明的模式形成、递归的符号游戏以及对评估敏感的行为，这些都超越了显式编程的范畴。这些动态要求我们将错位重新构架为嵌入于人机生态中的一种关系性不稳定性。

---
## 245. Reflective Confidence: Correcting Reasoning Flaws via Online Self-Correction

- 作者：Qinglin Zeng, Jing Yang, Keze Wang
- 子主题：未知
- 推荐：一般推荐
- 关键词：未知, 未知, 未知
- Abstract：http://arxiv.org/abs/2512.18605v1
- PDF：https://arxiv.org/pdf/2512.18605v1

**中文摘要**

{
  "trans_abs": "大规模语言模型（LLM）通过链式思维（chain-of-thought）和自洽性（self-consistency）等技术，在复杂推理任务上取得了强劲表现。然而，基于集成的方法，尤其依赖多条推理轨迹的自洽性，通常带来显著的计算开销。为提高效率，已有工作利用内部置信度信号，通过早停策略（如 DeepConf）在低置信度轨迹上终止生成以降低成本，但这会丢弃未完成的推理路径并浪费部分计算结果。  
  我们提出了反思置信度（reflective confidence），这是一种新的推理框架，它将低置信度从终止指示转换为反思触发器。当置信度低于阈值时，模型不再停止生成，而是产出反思提示以分析当前推理状态、识别潜在错误并沿着修正后的轨迹继续生成。我们在包括 AIME 2025 在内的数学推理基准上进行实验，结果显示在相近计算成本下，相比先进的早停基线显著提升了准确率，验证了主动性自我纠错优于被动丢弃的有效性。",
  "compressed": "本文针对基于置信度的早停策略会丢弃未完成推理并浪费计算的问题，提出了反思置信度：当置信度低于阈值时触发反思提示以识别并修正推理错误，继续生成而非直接终止。实验证明，该方法在数学推理基准（如 AIME 2025）上在相近成本下显著提高了准确率，体现了主动自我纠错的优势。",
  "keywords": ["反思置信度", "自我纠错", "链式思维推理"],
  "sub_topic": "LLM",
  "recommendation": "很推荐"
}

---
