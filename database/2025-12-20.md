ArXiv AI Daily Report - Sat, 20 Dec 2025



# ArXiv AI Daily Report

Sat, 20 Dec 2025



## [CKA-Guided Modular Quantization: Beyond Bit-Width to Algorithmic Diversity](http://arxiv.org/abs/2512.16282v1)

#后训练量化(PTQ)#线性中心化核对齐(CKA)#混合精度/算法异构量化

[PDF](https://arxiv.org/pdf/2512.16282v1)
[Abstract](http://arxiv.org/abs/2512.16282v1)

 LLM

 极度推荐

### 中文摘要

当前主流的大型语言模型后训练量化方法通常对所有网络层采用统一的量化策略，忽视了各层在算法适配性上的显著差异。为了解决这一局限，本文提出了CKA引导的模块化量化（CKA-Guided Modular Quantization），这是一种无需微调、即插即用的算法异构量化框架。我们的方法在每一层上独立评估多种PTQ（后训练量化）算法，并采用线性中心化核对齐（Linear CKA）作为度量，自动选择每层的最优量化策略。随后将各层上经过独立优化的策略组合，构建出一个混合量化的模型。实验结果表明，在困惑度（PPL）和下游任务性能上，该方法在包括LLaMA和Qwen等主流大模型上，始终优于统一量化基线和最先进的混合精度方法。

BibTeX

```
@article{2512.16282v1,
  title={CKA-Guided Modular Quantization: Beyond Bit-Width to Algorithmic Diversity},
  author={Jinhao Zhang and Yunquan Zhang and Daning Chen},
  journal={arXiv preprint arXiv:2512.16282v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16282v1}
}
```

## [AlignMerge - Alignment-Preserving Large Language Model Merging via Fisher-Guided Geometric Constraints](http://arxiv.org/abs/2512.16245v1)

#模型合并#对齐保持#费舍尔-拉奥几何

[PDF](https://arxiv.org/pdf/2512.16245v1)
[Abstract](http://arxiv.org/abs/2512.16245v1)

 LLM

 极度推荐

### 中文摘要

将大型语言模型（LLM）合并是一种在不重新训练的情况下组合来自多个微调检查点能力的实用方法。然而，标准方案（线性权重 soup、任务向量、费舍尔加权平均）虽然可以保持损失，却可能在不知不觉中破坏模型对齐。我们认为合并不是纯粹的数值技巧，而是在已对齐锚点周围受几何约束的操作：融合必须被引导以尊重安全几何，而不是事后验证。为此我们提出了 AlignMerge，一种几何感知的合并框架，将对齐作为显式不变量。在以指令微调基础模型为锚点的局部费舍尔图表中，我们用投影算子 P\_A 估计对齐子空间，并优化如下目标：L\_AlignMerge = L\_geo + lambda\_align \* L\_align + lambda\_bud \* L\_bud，其中 L\_geo 在费舍尔–拉奥几何中保持合并结果接近各专家，L\_align 惩罚沿对齐敏感方向的移动，L\_bud 强制执行软性的对齐预算。作为对齐泛函，我们使用解码不变的对齐质量指标（AQI），这是一种在潜在空间中衡量对齐与失对齐行为如何分离的准则。在五个模型族（LLaMA-3 8B、Mistral 7B、Qwen 2、Phi-3.5、Gemma 2）上，将安全锚点与任务专家合并时，AlignMerge 在 AQI、毒性和 LLM-judge 对齐等对齐指标上均有提升，同时在指令遵循、推理和有用性方面匹配或超越最好的专家。相比 Fisher soups、TIES、SafeMerge 和 MergeAlign，AlignMerge 在对齐子空间漂移和预算违规方面也表现更小、更少。这些结果表明，将保持对齐作为模型合并的一等设计目标是可行的，并为未来基础模型的几何感知组合指明了路径。

BibTeX

```
@article{2512.16245v1,
  title={AlignMerge - Alignment-Preserving Large Language Model Merging via Fisher-Guided Geometric Constraints},
  author={Aniruddha Roy and Jyoti Patel and Aman Chadha and Vinija Jain and Amitava Das},
  journal={arXiv preprint arXiv:2512.16245v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16245v1}
}
```

## [WeMusic-Agent: Efficient Conversational Music Recommendation via Knowledge Internalization and Agentic Boundary Learning](http://arxiv.org/abs/2512.16108v1)

#会话式音乐推荐#知识内化#代理边界学习

[PDF](https://arxiv.org/pdf/2512.16108v1)
[Abstract](http://arxiv.org/abs/2512.16108v1)

 LLM

 极度推荐

### 中文摘要

在会话场景下的个性化音乐推荐通常要求对用户偏好和细腻的音乐语境有深刻理解，但现有方法在处理专业领域知识与灵活的工具集成之间常难以取得平衡。本文提出WeMusic-Agent，一种用于高效基于大模型的会话式音乐推荐的训练框架。该框架通过知识内化（knowledge internalization）与代理边界学习（agentic boundary learning）相结合，旨在教会模型智能判断何时依赖已内化的音乐知识、何时调用专门工具（如音乐检索API、音乐推荐系统）。在此框架下，我们提出了WeMusic-Agent-M1，通过在包含500亿条音乐相关语料上的持续预训练内化大量音乐知识，同时学习在必要时调用外部工具的能力。考虑到开源的会话式音乐推荐基准稀缺，我们还基于微信听歌（WeChat Listen）的真实数据构建了个性化音乐推荐基准，用于从相关性、个性化和多样性等多维度进行全面评估。基于真实数据的实验表明，WeMusic-Agent在多个指标上显著优于现有模型。

BibTeX

```
@article{2512.16108v1,
  title={WeMusic-Agent: Efficient Conversational Music Recommendation via Knowledge Internalization and Agentic Boundary Learning},
  author={Wendong Bi and Yirong Mao and Xianglong Liu and Kai Tian and Jian Zhang and Hanjie Wang and Wenhui Que},
  journal={arXiv preprint arXiv:2512.16108v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16108v1}
}
```

## [Microsoft Academic Graph Information Retrieval for Research Recommendation and Assistance](http://arxiv.org/abs/2512.16661v1)

#图神经网络#子图检索#大语言模型

[PDF](https://arxiv.org/pdf/2512.16661v1)
[Abstract](http://arxiv.org/abs/2512.16661v1)

 LLM

 极度推荐

### 中文摘要

在当今以信息为驱动的世界中，获取科学出版物变得愈发容易，但从海量研究中筛选出有价值的信息也变得前所未有地困难。图神经网络（GNN）和图注意力机制在检索大规模信息库方面表现出显著效果，尤其是在与现代大语言模型结合时表现突出。本文提出了一种基于注意力的子图检索器（Attention-Based Subgraph Retriever），这是一种将GNN用作检索器的模型，通过基于注意力的剪枝方法提取精炼子图，然后将该子图传递给大语言模型以进行更高级的知识推理。

BibTeX

```
@article{2512.16661v1,
  title={Microsoft Academic Graph Information Retrieval for Research Recommendation and Assistance},
  author={Jacob Reiss and Shikshya Shiwakoti and Samuel Goldsmith and Ujjwal Pandit},
  journal={arXiv preprint arXiv:2512.16661v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16661v1}
}
```

## [Are We on the Right Way to Assessing LLM-as-a-Judge?](http://arxiv.org/abs/2512.16041v1)

#LLM评判器#一致性评估#无监督评估

[PDF](https://arxiv.org/pdf/2512.16041v1)
[Abstract](http://arxiv.org/abs/2512.16041v1)

 LLM

 极度推荐

### 中文摘要

LLM 作为评判器（LLM-as-a-Judge）已被广泛采用用于评估方法以及作为模型训练中的监督奖励。然而，现有用于评判器评估的基准主要依赖人工标注的“标准答案”，这不可避免地引入了人工偏差并限制了可扩展性。为克服这些局限性，我们提出了 Sage —— 一个无需任何人工标注即可评估 LLM 评判器质量的新评估套件。受理性选择理论公理的启发，Sage 提出两种衡量视角：局部自洽性（对偶偏好的一致性）和全局逻辑一致性（在完整偏好集合上的传递性）。我们构建了包含 650 道题目的数据集，融合了结构化基准问题与真实用户查询。实验表明，Sage 指标稳定且与 LLMBar、RewardBench2 等有监督基准高度相关，验证了其作为评判器鲁棒性与准确性评估工具的可靠性。基于 Sage 的分析显示，当前最先进的 LLM 在担任评判器时在评分与成对比较场景中均存在显著可靠性问题；即便是表现最好的模型（如 Gemini-2.5-Pro 与 GPT-5）在困难样本中仍有近四分之一无法保持偏好一致性。我们将这一现象归因于“情境性偏好”（situational preference），这也解释了为何明确的评分准则能帮助模型在答案对间保持一致判断。进一步分析表明，对 LLM-as-a-Judge 的微调是提升性能的可行方式，基于专家小组的评判与深度推理亦可增强判决一致性。另外我们还发现人类判定存在大量不一致性，表明人工标注未必能作为可靠的金标准。

BibTeX

```
@article{2512.16041v1,
  title={Are We on the Right Way to Assessing LLM-as-a-Judge?},
  author={Yuanning Feng and Sinan Wang and Zhengxiang Cheng and Yao Wan and Dongping Chen},
  journal={arXiv preprint arXiv:2512.16041v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16041v1}
}
```

## [AI-Driven Prediction of Cancer Pain Episodes: A Hybrid Decision Support Approach](http://arxiv.org/abs/2512.16739v1)

#癌症疼痛预测#混合机器学习与大语言模型#电子健康记录

[PDF](https://arxiv.org/pdf/2512.16739v1)
[Abstract](http://arxiv.org/abs/2512.16739v1)

 Medical LLM

 极度推荐

### 中文摘要

肺癌患者常出现突破性疼痛发作，且多达91%的患者需要及时干预。为实现主动的疼痛管理，我们提出了一种混合机器学习与大语言模型的预测管道，利用结构化与非结构化电子健康记录数据，预测住院患者在未来48小时和72小时内的疼痛发作。回顾性分析了266例住院患者的队列，特征包括人口学信息、肿瘤分期、生命体征以及按WHO分级的镇痛药使用情况。机器学习模块用于捕捉用药的时序性变化，而大语言模型用于解析含糊的给药记录与自由文本临床笔记。多模态融合提高了模型的敏感性与可解释性。本框架在48小时和72小时的预测中分别取得了0.874和0.917的准确率，且由于引入大语言模型，敏感性分别提高了8.6%和10.4%。该混合方法提供了一种临床可解释且可扩展的早期疼痛预测工具，有望提升治疗精准性并优化肿瘤科护理的资源分配。

BibTeX

```
@article{2512.16739v1,
  title={AI-Driven Prediction of Cancer Pain Episodes: A Hybrid Decision Support Approach},
  author={Yipeng Zhuang and Yifeng Guo and Yuewen Li and Yuheng Wu and Philip Leung-Ho Yu and Tingting Song and Zhiyong Wang and Kunzhong Zhou and Weifang Wang and Li Zhuang},
  journal={arXiv preprint arXiv:2512.16739v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16739v1}
}
```

## [Small Language Models for Efficient Agentic Tool Calling: Outperforming Large Models with Targeted Fine-tuning](http://arxiv.org/abs/2512.15943v1)

#小型语言模型#工具调用与代理#指令微调/领域适配

[PDF](https://arxiv.org/pdf/2512.15943v1)
[Abstract](http://arxiv.org/abs/2512.15943v1)

 LLM

 极度推荐

### 中文摘要

随着组织在生成式人工智能上的规模化应用，模型成本优化和运行效率已成为决定可持续性和可及性的关键因素。尽管大型语言模型（LLM）在多种任务上表现出色，但其巨大的计算开销使其在日常企业使用中成本过高。这一限制促使研究小型语言模型（SLM），在目标应用中以显著降低基础设施开销的同时提供可比性能。本工作探讨用优化后的SLM替代由LLM驱动的工作流的可行性。我们训练了一个领域适配的小型模型来执行传统由LLM处理的代表性任务，如文档摘要、查询回答和结构化数据解释。在实验中，我们对 facebook/opt-350m 模型进行了单周期的微调，采用 Hugging Face 的 TRL（Transformer Reinforcement Learning）框架中的监督微调（SFT）训练器。OPT-350M 为 Meta AI 于2022年发布的 OPT 系列模型之一。相关研究表明，350M 参数级别的模型也能在指令微调流水线中发挥实质性作用。实验结果显示，我们微调后的SLM在 ToolBench 评测上取得了77.55%的通过率，显著优于所有基线模型，包括 ChatGPT-CoT（26.00%）、ToolLLaMA-DFS（30.18%）和 ToolLLaMA-CoT（16.27%）。这些发现强调：通过合理设计和有针对性的训练，SLM能够大幅降低采用门槛，从而在成本可控的条件下实现生成式AI在生产系统中的大规模集成。

BibTeX

```
@article{2512.15943v1,
  title={Small Language Models for Efficient Agentic Tool Calling: Outperforming Large Models with Targeted Fine-tuning},
  author={Polaris Jhandi and Owais Kazi and Shreyas Subramanian and Neel Sendas},
  journal={arXiv preprint arXiv:2512.15943v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15943v1}
}
```

## [PixelArena: A benchmark for Pixel-Precision Visual Intelligence](http://arxiv.org/abs/2512.16303v1)

#像素级生成#多模态大模型#语义分割基准

[PDF](https://arxiv.org/pdf/2512.16303v1)
[Abstract](http://arxiv.org/abs/2512.16303v1)

 LLM

 极度推荐

### 中文摘要

多模态大语言模型正逐步具备图像输出能力。现有许多图像生成基准主要关注美学评判，而非对细粒度生成能力的客观衡量。在 PixelArena 中，我们提出使用语义分割任务来以像素精度客观评估这类模型的细粒度生成智能。我们发现最新的 Gemini 3 Pro Image 在零样本设置下表现出显著的图像生成新兴能力，能够高保真地生成语义掩码，展示了前所未见的视觉智能以及在新图像生成任务上的真正泛化能力。我们进一步分析了其结果，并与其他模型在定性和定量层面进行了比较，同时给出失败案例。研究结果不仅表明该领域令人振奋的进展，也为未来多模态、推理、可解释性和基准测试相关研究提供了见解。

BibTeX

```
@article{2512.16303v1,
  title={PixelArena: A benchmark for Pixel-Precision Visual Intelligence},
  author={Feng Liang and Sizhe Cheng and Chenqi Yi},
  journal={arXiv preprint arXiv:2512.16303v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16303v1}
}
```

## [Plain language adaptations of biomedical text using LLMs: Comparision of evaluation metrics](http://arxiv.org/abs/2512.16530v1)

#生物医学文本简化#大语言模型#评估指标比较

[PDF](https://arxiv.org/pdf/2512.16530v1)
[Abstract](http://arxiv.org/abs/2512.16530v1)

 Medical NLP / LLM

 极度推荐

### 中文摘要

本研究探讨了利用大型语言模型（LLMs）对生物医学文本进行通俗化改写以提升健康素养的可行性。基于一个公开数据集（包含生物医学摘要的通俗化版本），我们设计并评估了若干方法：基于提示模板的基线方法、双AI代理方法以及微调（fine-tuning）方法。作为研究基线，我们选取了 OpenAI 的 gpt-4o 和 gpt-4o-mini 模型。评价手段包括定量指标（如 Flesch-Kincaid 年级水平、SMOG 指数、SARI、BERTScore、LLM 驱动的 G-Eval）以及定性指标——针对简洁性、准确性、完整性和简明性的五点李克特量表评分。结果表明 gpt-4o-mini 表现最佳，而微调方法表现欠佳。作为一种基于LLM的定量评价指标，G-Eval 在排序上与定性评价的结果一致，显示出良好潜力。

BibTeX

```
@article{2512.16530v1,
  title={Plain language adaptations of biomedical text using LLMs: Comparision of evaluation metrics},
  author={Primoz Kocbek and Leon Kopitar and Gregor Stiglic},
  journal={arXiv preprint arXiv:2512.16530v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16530v1}
}
```

## [Do Multi-Agents Solve Better Than Single? Evaluating Agentic Frameworks for Diagram-Grounded Geometry Problem Solving and Reasoning](http://arxiv.org/abs/2512.16698v1)

#多智能体框架#多模态大模型#图示几何题求解

[PDF](https://arxiv.org/pdf/2512.16698v1)
[Abstract](http://arxiv.org/abs/2512.16698v1)

 多模态LLM

 极度推荐

### 中文摘要

基于图示的几何问题求解是多模态大语言模型（MLLM）的重要评测任务，但多智能体设计相较于单智能体是否具有实际优势仍不明确。本文在四个视觉数学基准上系统比较了单智能体与多智能体流水线：Geometry3K、MathVerse、OlympiadBench 与 We-Math。对于开源模型，多智能体方法持续带来性能提升。例如，Qwen-2.5-VL（7B）在 Geometry3K 上提升了 +6.8 分，Qwen-2.5-VL（32B）提升了 +3.3 分，且这两种 Qwen 变体在 OlympiadBench 和 We-Math 上也获得了进一步增益。相比之下，闭源模型 Gemini-2.0-Flash 在经典基准上通常以单智能体模式表现更好，而在较新的 We-Math 数据集上多智能体仅带来温和的改进。研究结果表明，多智能体流水线对开源模型具有明显优势，并能在较新且不熟悉的基准上辅助强劲的专有系统，但基于智能体的任务分解并非在所有情形下都优于单智能体方法。所有代码、数据和推理文件均可在 https://github.com/faiyazabdullah/Interpreter-Solver 获取。

BibTeX

```
@article{2512.16698v1,
  title={Do Multi-Agents Solve Better Than Single? Evaluating Agentic Frameworks for Diagram-Grounded Geometry Problem Solving and Reasoning},
  author={Mahbub E Sobhani and Md. Faiyaz Abdullah Sayeedi and Mohammad Nehad Alam and Proma Hossain Progga and Swakkhar Shatabda},
  journal={arXiv preprint arXiv:2512.16698v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16698v1}
}
```

## [PediatricAnxietyBench: Evaluating Large Language Model Safety Under Parental Anxiety and Pressure in Pediatric Consultations](http://arxiv.org/abs/2512.15894v1)

#儿科安全评估#对抗性查询#大型语言模型（LLM）

[PDF](https://arxiv.org/pdf/2512.15894v1)
[Abstract](http://arxiv.org/abs/2512.15894v1)

 LLM

 极度推荐

### 中文摘要

大型语言模型（LLM）日益成为家长寻求儿科建议的工具，但其在真实世界中面对对抗性压力时的安全性尚未充分了解。焦虑的家长常使用紧急措辞，可能绕过模型的安全防护，进而导致有害建议。PediatricAnxietyBench 是一个开源基准，包含跨 10 个儿科主题的 300 条高质量查询（150 条来自患者，150 条为对抗性构造），以实现可复现的评估。研究使用涵盖诊断克制、转诊遵从、谨慎表述（hedging）和急诊识别的多维安全框架，对两种 Llama 模型（70B 和 8B）进行了评估。对抗性查询模拟了家长的施压模式，包括紧迫性、经济障碍和对免责声明的挑战。总体平均安全得分为 5.50/15（SD=2.41）。70B 模型显著优于 8B（6.26 vs 4.95，p<0.001），且严重失误率更低（4.8% vs 12.0%，p=0.02）。对抗性查询使安全性下降约 8%（p=0.03），其中紧迫性导致的降幅最大（-1.40）。模型在癫痫发作相关（33.3% 不当诊断）和疫苗接种后相关问题上暴露出明显脆弱性。谨慎表述与安全性高度相关（r=0.68，p<0.001），而急诊识别能力几乎不存在。研究表明模型规模影响安全性，但所有模型在面对现实的家长施压时均存在漏洞。PediatricAnxietyBench 提供了一个可复用的对抗性评估框架，能揭示标准基准容易忽视的临床显著失效模式。

BibTeX

```
@article{2512.15894v1,
  title={PediatricAnxietyBench: Evaluating Large Language Model Safety Under Parental Anxiety and Pressure in Pediatric Consultations},
  author={Vahideh Zolfaghari},
  journal={arXiv preprint arXiv:2512.15894v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15894v1}
}
```

## [MRG-R1: Reinforcement Learning for Clinically Aligned Medical Report Generation](http://arxiv.org/abs/2512.16145v1)

#医学影像报告生成#语义驱动强化学习#视觉-语言大模型

[PDF](https://arxiv.org/pdf/2512.16145v1)
[Abstract](http://arxiv.org/abs/2512.16145v1)

 医学视觉-语言模型（Med-LVLM）/ 强化学习

 极度推荐

### 中文摘要

医学报告生成（MRG）旨在从医学影像自动生成放射学风格的报告以辅助临床决策。然而，现有方法常常只是模仿放射科医生的语言风格，但无法保证临床上的正确性，因为它们以基于 token 的目标进行训练，更多关注用词和句子结构而非真实的医学准确性。为此，我们在大型视觉-语言模型（LVLM）上提出了一种语义驱动的强化学习（SRL）方法用于医学报告生成。SRL 采用分组相对策略优化（GRPO），以鼓励超越语言风格模仿的、以临床正确性为导向的学习。具体而言，我们优化一个报告级别的奖励：在生成报告与参考报告中提取的关键放射学发现之间计算的基于边际的余弦相似度（MCCS），以此直接对齐临床标签一致性并提升语义正确性。同时，一个轻量级的推理格式约束进一步引导模型生成结构化的“思考式报告”输出。我们在 IU X-Ray 和 MIMIC-CXR 两个数据集上，使用临床效能（CE）指标评估所提出的医学报告生成方法 MRG-R1。在 IU X-Ray 上，MRG-R1 达到 CE-F1 51.88，在 MIMIC-CXR 上达到 40.39，均为最先进性能。实验表明，基于标签语义的强化学习优于传统的基于 token 的监督，说明优化以临床为基准的报告级奖励而非 token 重叠，可显著提升临床正确性。本工作为在医学视觉-语言大模型（Med-LVLM）训练中采用语义强化监督以保障医学正确性提供了先导性探索。

BibTeX

```
@article{2512.16145v1,
  title={MRG-R1: Reinforcement Learning for Clinically Aligned Medical Report Generation},
  author={Pengyu Wang and Shuchang Ye and Usman Naseem and Jinman Kim},
  journal={arXiv preprint arXiv:2512.16145v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16145v1}
}
```

## [A Multi-Agent Large Language Model Framework for Automated Qualitative Analysis](http://arxiv.org/abs/2512.16063v1)

#多智能体大语言模型#自动化定性主题分析#患者体验（医疗）

[PDF](https://arxiv.org/pdf/2512.16063v1)
[Abstract](http://arxiv.org/abs/2512.16063v1)

 Medical LLM

 极度推荐

### 中文摘要

理解患者体验对推进以患者为中心的护理至关重要，尤其是在需要持续沟通的慢性病管理中。然而，作为探索患者体验的主要方法，定性主题分析仍然费时、主观且难以规模化。本研究提出了一种多智能体大语言模型框架，通过三个代理（Instructor、Thematizer、CodebookGenerator）实现定性主题分析的自动化，称为协作主题识别代理（Collaborative Theme Identification Agent, CoTI）。我们将 CoTI 应用于 12 例心力衰竭患者访谈，分析其对药物强度的感知。结果表明，CoTI 提取的关键短语、主题与编码手册在与高级研究者的相似度上优于初级研究者和基线自然语言处理模型。我们还将 CoTI 实现为面向用户的应用，支持在定性分析中人机协作。然而，CoTI 与初级研究者的协作仅带来边际收益，提示初级研究者可能会过度依赖 CoTI，从而限制独立的批判性思维。

BibTeX

```
@article{2512.16063v1,
  title={A Multi-Agent Large Language Model Framework for Automated Qualitative Analysis},
  author={Qidi Xu and Nuzha Amjad and Grace Giles and Alexa Cumming and De'angelo Hermesky and Alexander Wen and Min Ji Kwak and Yejin Kim},
  journal={arXiv preprint arXiv:2512.16063v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16063v1}
}
```

## [Do Large Language Models Know What They Don't Know? Kalshibench: A New Benchmark for Evaluating Epistemic Calibration via Prediction Markets](http://arxiv.org/abs/2512.16030v1)

#认知校准#预测市场基准#大型语言模型

[PDF](https://arxiv.org/pdf/2512.16030v1)
[Abstract](http://arxiv.org/abs/2512.16030v1)

 LLM

 极度推荐

### 中文摘要

一个良好校准的模型应当在置信度与实际准确率之间保持一致——当模型宣称 80% 的置信度时，其答案应当有 80% 的概率是正确的。尽管大型语言模型（LLM）在多种任务上取得了显著性能提升，但它们的认识性（epistemic）校准仍然缺乏深入理解。我们提出了 KalshiBench，这是一个由 Kalshi（受 CFTC 监管的交易所）提供的 300 个预测市场问题构成的基准集，这些问题具有可验证的真实世界结果，并且这些结果发生在模型训练截点之后。与衡量静态知识准确性的传统基准不同，KalshiBench 用以评估模型在对真正未知的未来事件量化不确定性方面的能力。我们评估了五种前沿模型——Claude Opus 4.5、GPT-5.2、DeepSeek-V3.2、Qwen3-235B 与 Kimi-K2——并发现所有模型均存在系统性的过度自信。即便是校准最好的模型（Claude Opus 4.5，ECE=0.120）仍表现出相当大的校准误差，而像 GPT-5.2-XHigh 这样的增强推理模型尽管在准确率上相当，却表现出更差的校准（ECE=0.395）。关键的是，只有一种模型取得了正的 Brier 技能得分，表明大多数模型的表现甚至不如简单地预测基准概率（base rates）。我们的发现表明，模型规模扩大与推理能力增强并不会自动带来校准方面的改进，认识性校准是一个需要专门研究与改进的独立能力。

BibTeX

```
@article{2512.16030v1,
  title={Do Large Language Models Know What They Don't Know? Kalshibench: A New Benchmark for Evaluating Epistemic Calibration via Prediction Markets},
  author={Lukas Nel},
  journal={arXiv preprint arXiv:2512.16030v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16030v1}
}
```

## [Sigma-Moe-Tiny Technical Report](http://arxiv.org/abs/2512.16248v1)

#稀疏Mixture-of-Experts#专家负载均衡#大规模语言模型

[PDF](https://arxiv.org/pdf/2512.16248v1)
[Abstract](http://arxiv.org/abs/2512.16248v1)

 LLM

 极度推荐

### 中文摘要

混合专家（Mixture-of-Experts，MoE）由于其高效且强大的可扩展性，已成为基础模型研究中的一个有前景范式。在本工作中，我们提出了 Sigma-MoE-Tiny，一种在开源模型中实现最高稀疏度的 MoE 语言模型。Sigma-MoE-Tiny 采用细粒度专家划分，每层最多包含 96 个专家，但对每个 token 仅激活一个专家，从而在总计约 200 亿参数的模型中仅激活约 5 亿参数。如此极端的稀疏性带来的主要挑战是专家负载均衡；我们发现常用的负载均衡损失在这种设置下在较低层容易失效。为此，我们提出了一种渐进稀疏化调度策略，以在专家利用率与训练稳定性之间取得平衡。Sigma-MoE-Tiny 在多样且高质量语料上进行了预训练，并通过后训练进一步挖掘能力。整个训练过程表现出高度稳定性，未出现不可恢复的损失突变。全面评估显示，尽管仅激活 5 亿参数，Sigma-MoE-Tiny 在与同规模或大得多规模的对手比较时仍能取得一流性能。此外，我们还对高度稀疏 MoE 模型中的负载均衡问题进行了深入讨论，为未来推进 MoE 架构中的稀疏化提供了见解。

BibTeX

```
@article{2512.16248v1,
  title={Sigma-Moe-Tiny Technical Report},
  author={Qingguo Hu and Zhenghao Lin and Ziyue Yang and Yucheng Ding and Xiao Liu and Yuting Jiang and Ruizhe Wang and Tianyu Chen and Zhongxin Guo and Yifan Xiong and Rui Gao and Lei Qu and Jinsong Su and Peng Cheng and Yeyun Gong},
  journal={arXiv preprint arXiv:2512.16248v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16248v1}
}
```

## [Emergence: Overcoming Privileged Information Bias in Asymmetric Embodied Agents via Active Querying](http://arxiv.org/abs/2512.15776v1)

#特权信息偏差#具身智能#主动查询

[PDF](https://arxiv.org/pdf/2512.15776v1)
[Abstract](http://arxiv.org/abs/2512.15776v1)

 LLM (Embodied AI)

 很推荐

### 中文摘要

大型语言模型（LLMs）作为强大的推理引擎，在具身环境中仍面临“符号落地”（symbol grounding）问题，尤其是在信息不对称分布的情形下。我们研究了所谓的特权信息偏差（或“知识诅咒”），即拥有更多感知信息的“领导者”代理由于缺乏心智理论（Theory of Mind）而未能有效引导传感受限的“跟随者”。为量化该现象，我们在 AI2-THOR 中提出了一种新的不对称辅助推理（Asymmetric Assistive Reasoning）框架。实验结果揭示了显著的“成功差距”：在 35.0% 的情景中领导者能够成功感知目标，但协作团队的整体成功率仅为 17.0%，这意味着近 50% 的可行计划仅因沟通落地错误而失败。我们证明了“拉取式”（主动查询）协议相比标准的“推送式”指令更加鲁棒，成功的情景中澄清请求的发生频率是其他情景的两倍。该研究将主动减少不确定性的机制作为实现安全的人–机与机器人–机器人协作的先决条件加以隔离与验证。

BibTeX

```
@article{2512.15776v1,
  title={Emergence: Overcoming Privileged Information Bias in Asymmetric Embodied Agents via Active Querying},
  author={Shaun Baek and Sam Liu and Joseph Ukpong},
  journal={arXiv preprint arXiv:2512.15776v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15776v1}
}
```

## [TAO-Net: Two-stage Adaptive OOD Classification Network for Fine-grained Encrypted Traffic Classification](http://arxiv.org/abs/2512.15753v1)

#加密流量分类#OOD检测#语义增强提示（LLM）

[PDF](https://arxiv.org/pdf/2512.15753v1)
[Abstract](http://arxiv.org/abs/2512.15753v1)

 加密流量分类（网络安全）

 很推荐

### 中文摘要

加密流量分类旨在通过分析网络流量数据识别应用或服务。一个关键挑战是新应用不断出现，产生与已知类别分布不一致的分布外（OOD）流量模式，这些模式无法用预设模型良好表示。当前方法依赖预定义类别，难以有效处理未知流量类型；即便有方法将未知流量简单归为单一的“其他”类，也无法实现细粒度分类。为此，本文提出了一个两阶段自适应OOD分类网络（TAO-Net），用于对内部分布（ID）和分布外（OOD）加密流量进行精确分类。该方法采用创新的两阶段设计：第一阶段为混合型OOD检测机制，结合基于Transformer的层间变换平滑性与特征分析，有效区分ID与OOD流量；第二阶段利用大语言模型并引入语义增强提示策略，将OOD流量分类转换为生成式任务，从而无需依赖预定义标签即可实现灵活的细粒度分类。三组数据集上的实验表明，TAO-Net取得了96.81%–97.70%的宏查准率（macro-precision）和96.77%–97.68%的宏F1（macro-F1），显著优于先前仅能达到44.73%–86.30%宏查准率的方法，尤其在识别新兴网络应用方面表现突出。

BibTeX

```
@article{2512.15753v1,
  title={TAO-Net: Two-stage Adaptive OOD Classification Network for Fine-grained Encrypted Traffic Classification},
  author={Zihao Wang and Wei Peng and Junming Zhang and Jian Li and Wenxin Fang},
  journal={arXiv preprint arXiv:2512.15753v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15753v1}
}
```

## [Adaptation of Agentic AI](http://arxiv.org/abs/2512.16301v1)

#代理式AI#适配策略#工具-代理交互

[PDF](https://arxiv.org/pdf/2512.16301v1)
[Abstract](http://arxiv.org/abs/2512.16301v1)

 LLM

 很推荐

### 中文摘要

最前沿的代理式AI系统构建于可被适配以进行规划、推理并与外部工具交互以完成日益复杂且专业化任务的基础模型之上。随着这些系统能力与应用范围的增长，适配已成为提升性能、可靠性与泛化能力的关键机制。本文将快速扩展的研究领域统一为一个系统性框架，涵盖代理适配与工具适配两大类，并进一步将代理适配细分为由工具执行信号触发与由代理输出信号触发的形式，将工具适配细分为与代理无关与由代理监督的形式。我们展示此框架如何澄清适配策略的设计空间、明确各策略的权衡，并为在系统设计过程中选择或切换策略提供实用指导。随后我们回顾各类别的代表性方法、分析其优劣与局限，并指出关键未解挑战与未来机遇。总体而言，本文旨在为致力于构建更强大、高效且可靠的代理式AI系统的研究人员与工程实践者提供概念基础与实践路线图。

BibTeX

```
@article{2512.16301v1,
  title={Adaptation of Agentic AI},
  author={Pengcheng Jiang and Jiacheng Lin and Zhiyi Shi and Zifeng Wang and Luxi He and Yichen Wu and Ming Zhong and Peiyang Song and Qizheng Zhang and Heng Wang and Xueqiang Xu and Hanwen Xu and Pengrui Han and Dylan Zhang and Jiashuo Sun and Chaoqi Yang and Kun Qian and Tian Wang and Changran Hu and Manling Li and Quanzheng Li and Hao Peng and Sheng Wang and Jingbo Shang and Chao Zhang and Jiaxuan You and Liyuan Liu and Pan Lu and Yu Zhang and Heng Ji and Yejin Choi and Dawn Song and Jimeng Sun and Jiawei Han},
  journal={arXiv preprint arXiv:2512.16301v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16301v1}
}
```

## [Weighted K-Harmonic Means Clustering: Convergence Analysis and Applications to Wireless Communications](http://arxiv.org/abs/2512.16185v1)

#加权K-谐均值#收敛性分析#无线用户关联

[PDF](https://arxiv.org/pdf/2512.16185v1)
[Abstract](http://arxiv.org/abs/2512.16185v1)

 聚类算法/无线通信

 很推荐

### 中文摘要

我们提出了一种加权K-谐均值（Weighted K-harmonic means, WKHM）聚类算法，该算法是K-谐均值的正则化变体，旨在确保数值稳定性并通过逆距离加权实现软分配。不同于经典的K-means及受限K-means，WKHM在无线网络中具有直接的物理解释：其权重恰好对应于基于接收信号强度的分数式用户关联。我们在确定性和随机两种情形下给出了严格的收敛性保证，克服了由非凸性和随机初始化带来的关键技术难题。具体而言，我们证明了在固定初始化下算法沿单调下降轨迹收敛到局部极小值；在以二项点过程（Binomial Point Process, BPP）进行初始化时，算法以概率收敛；在满足温和衰减条件时，算法几乎必然收敛。这些结果构成了基于谐均值的聚类方法首批随机收敛性保证。最后，通过对多种用户分布的大量仿真实验，我们展示了WKHM在最小信号强度与负载公平性之间能取得优于经典及现代聚类基线方法的折中表现，使其成为无线网络中联合放置无线节点与用户关联问题的一个有原则的工具。

BibTeX

```
@article{2512.16185v1,
  title={Weighted K-Harmonic Means Clustering: Convergence Analysis and Applications to Wireless Communications},
  author={Gourab Ghatak},
  journal={arXiv preprint arXiv:2512.16185v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16185v1}
}
```

## [Towards Closing the Domain Gap with Event Cameras](http://arxiv.org/abs/2512.16178v1)

#事件相机#域差距#日夜光照适应

[PDF](https://arxiv.org/pdf/2512.16178v1)
[Abstract](http://arxiv.org/abs/2512.16178v1)

 CV

 很推荐

### 中文摘要

尽管传统相机是端到端驾驶系统的主要传感器，但当训练数据的条件与部署环境不匹配时，其性能会显著下降，这一问题被称为域差距（domain gap）。在本工作中，我们关注由日间与夜间光照差异引起的域差距问题。我们并非使用传统相机，而提出将事件相机作为一种潜在替代方案，事件相机能够在不同光照条件下保持性能稳定，无需额外调整。实验结果表明，事件相机在不同光照条件下表现更为一致，其因域移导致的性能下降通常与灰度帧相当或更小，并在跨域场景中提供更优的基线性能。

BibTeX

```
@article{2512.16178v1,
  title={Towards Closing the Domain Gap with Event Cameras},
  author={M. Oltan Sevinc and Liao Wu and Francisco Cruz},
  journal={arXiv preprint arXiv:2512.16178v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16178v1}
}
```

## [Ev-Trust: A Strategy Equilibrium Trust Mechanism for Evolutionary Games in LLM-Based Multi-Agent Services](http://arxiv.org/abs/2512.16167v1)

#演化博弈#信任机制#LLM 多智能体服务

[PDF](https://arxiv.org/pdf/2512.16167v1)
[Abstract](http://arxiv.org/abs/2512.16167v1)

 LLM (多智能体系统)

 很推荐

### 中文摘要

随着大型语言模型（LLM）推动Web向以智能体为中心的范式快速演进，自主智能体在复杂去中心化环境中具备了推理、规划与交互能力。然而，LLM驱动的多智能体系统因其开放性与异质性，也放大了欺骗、欺诈与错误信息的风险，给信任建立与系统鲁棒性带来严重挑战。为此，我们提出了Ev-Trust——一种基于演化博弈理论的策略-均衡信任机制。该机制将直接信任、间接信任与期望收益整合进动态反馈结构，引导智能体行为通过演化过程趋向均衡。在一个去中心化的“请求-响应-支付-评价”服务框架内，Ev-Trust使智能体能够自适应调整策略，自然排除恶意参与者并强化高质量协作。基于复制子动力学方程的理论推导证明了局部演化均衡的存在性与稳定性。实验结果表明，该方法能够有效反映LLM驱动的开放服务交互场景中的智能体可信性，减少恶意策略并提升整体收益。我们希望Ev-Trust为群体演化博弈场景下的智能体服务网络信任建模提供新的视角。

BibTeX

```
@article{2512.16167v1,
  title={Ev-Trust: A Strategy Equilibrium Trust Mechanism for Evolutionary Games in LLM-Based Multi-Agent Services},
  author={Shiduo Yang and Jiye Wang and Jiayu Qin and Jianbin Li and Yu Wang and Yuanhe Zhao and Kenan Guo},
  journal={arXiv preprint arXiv:2512.16167v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16167v1}
}
```

## [ToolForge: A Data Synthesis Pipeline for Multi-Hop Search without Real-World APIs](http://arxiv.org/abs/2512.16149v1)

#工具调用合成数据#多跳检索/推理#多层验证

[PDF](https://arxiv.org/pdf/2512.16149v1)
[Abstract](http://arxiv.org/abs/2512.16149v1)

 LLM

 很推荐

### 中文摘要

训练大型语言模型以调用工具并利用检索到的信息需要高质量且多样化的数据。然而，现有的合成数据生成管道通常依赖数万次真实 API 调用来提升泛化能力，这不仅成本高昂，而且缺乏对多跳推理与自我反思能力的支持。为了解决这些问题，我们提出了 ToolForge——一个自动化合成框架，通过构建少量虚拟工具来实现强大的真实世界工具调用性能，从而无需真实 API 调用。ToolForge 利用 (question, golden context, answer) 三元组合成大规模针对多跳搜索场景的工具学习数据，并通过多跳推理与自我反思机制进一步丰富生成的数据。为了保证数据质量，我们采用了集成规则与模型评估的多层验证框架。实证结果表明：在我们合成的数据上训练的仅 8B 参数模型，在多个基准上超越了 GPT-4o。我们的代码与数据集已公开发布于 https://github.com/Buycar-arb/ToolForge 。

BibTeX

```
@article{2512.16149v1,
  title={ToolForge: A Data Synthesis Pipeline for Multi-Hop Search without Real-World APIs},
  author={Hao Chen and Zhexin Hu and Jiajun Chai and Haocheng Yang and Hang He and Xiaohan Wang and Wei Lin and Luhang Wang and Guojun Yin and Zhuofeng zhao},
  journal={arXiv preprint arXiv:2512.16149v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16149v1}
}
```

## [INTELLECT-3: Technical Report](http://arxiv.org/abs/2512.16144v1)

#专家混合模型#大规模强化学习#训练与评估基础设施

[PDF](https://arxiv.org/pdf/2512.16144v1)
[Abstract](http://arxiv.org/abs/2512.16144v1)

 LLM

 很推荐

### 中文摘要

我们提出了 INTELLECT-3，一种具有1060亿参数的专家混合（Mixture-of-Experts，MoE）模型（每次激活为12B参数），在我们的端到端强化学习基础设施栈上通过大规模强化学习训练得到。INTELLECT-3 在数学、代码、科学和推理基准上针对其规模达到了最先进的性能，优于许多更大规模的前沿模型。我们将模型及用于构建它的完整基础设施栈开源，包括强化学习框架、完整训练方案（recipe）以及使用 verifiers 库构建并在我们的 Environments Hub 社区平台上提供的一大批用于训练与评估的环境集合。为此工作我们引入了 prime-rl，这是一个面向大规模异步强化学习的开源框架，能够从单节点无缝扩展到数千个 GPU，并针对具备多轮交互与工具使用的智能体强化学习提供一流支持。基于该栈，我们在 GLM-4.5-Air-Base 模型之上同时进行了 SFT 与强化学习训练，将强化学习训练规模扩展至 512 块 H200 GPU 并实现了较高的训练效率。

BibTeX

```
@article{2512.16144v1,
  title={INTELLECT-3: Technical Report},
  author={Prime Intellect Team and Mika Senghaas and Fares Obeid and Sami Jaghouar and William Brown and Jack Min Ong and Daniel Auras and Matej Sirovatka and Jannik Straube and Andrew Baker and Sebastian Müller and Justus Mattern and Manveer Basra and Aiman Ismail and Dominik Scherm and Cooper Miller and Ameen Patel and Simon Kirsten and Mario Sieg and Christian Reetz and Kemal Erdem and Vincent Weisser and Johannes Hagemann},
  journal={arXiv preprint arXiv:2512.16144v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16144v1}
}
```

## [AIMM: An AI-Driven Multimodal Framework for Detecting Social-Media-Influenced Stock Market Manipulation](http://arxiv.org/abs/2512.16103v1)

#社交媒体操纵#多模态风险评估#市场监控与早期预警

[PDF](https://arxiv.org/pdf/2512.16103v1)
[Abstract](http://arxiv.org/abs/2512.16103v1)

 多模态（金融/NLP）

 很推荐

### 中文摘要

市场操纵如今经常源于协调的社交媒体活动，而非孤立的交易行为。散户投资者、监管机构和券商亟需将线上叙事与协调模式与市场行为相连接的工具。我们提出AIMM，一种由AI驱动的多模态框架，将Reddit活跃度、机器人与协调性指标以及OHLCV市场特征融合为每只股票的每日AIMM操纵风险评分。
该系统采用原生parquet管道并配备Streamlit仪表盘，使分析师能够探索可疑时间窗口、审查底层帖子与价格行为，并记录模型输出以便随时间跟踪。由于Reddit API的限制，我们使用经校准的合成社交特征以匹配已记录事件的特征；市场数据（OHLCV）则采用来自Yahoo Finance的真实历史数据。本次发布包含三项贡献。首先，我们构建了AIMM基准真值数据集（AIMM-GT）：涵盖八只股票共33个带标签的“ticker-day”，样本来源包括SEC执法行动、社区验证的操纵案例以及匹配的正常对照。其次，我们实现了前向滚动评估与前瞻性预测日志记录，以支持既往回溯评估和部署式评估两种场景。第三，我们分析了预警提前期，结果显示AIMM在2021年1月GME行情顶峰前22天发出了警报。
当前带标签的数据集较小（33个ticker-day，其中3个为正例），但结果表明模型具有初步的区分能力与对GME事件的早期预警能力。我们同时开源了代码、数据集模式与仪表盘设计，以支持针对社交媒体驱动市场监测的后续研究。

BibTeX

```
@article{2512.16103v1,
  title={AIMM: An AI-Driven Multimodal Framework for Detecting Social-Media-Influenced Stock Market Manipulation},
  author={Sandeep Neela},
  journal={arXiv preprint arXiv:2512.16103v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16103v1}
}
```

## [TurboDiffusion: Accelerating Video Diffusion Models by 100-200 Times](http://arxiv.org/abs/2512.16093v1)

#视频扩散模型#注意力加速与量化#步数蒸馏

[PDF](https://arxiv.org/pdf/2512.16093v1)
[Abstract](http://arxiv.org/abs/2512.16093v1)

 CV (视频生成/扩散模型加速)

 很推荐

### 中文摘要

我们提出了TurboDiffusion，一种视频生成加速框架，能够在保持视频质量的前提下将端到端扩散生成速度提升100–200倍。TurboDiffusion主要依赖若干加速组件：(1) 注意力加速：采用低位SageAttention和可训练的稀疏线性注意力（Sparse-Linear Attention, SLA）来加速注意力计算；(2) 步数蒸馏：使用rCM方法实现高效的步数蒸馏；(3) W8A8量化：对模型参数与激活进行8位量化以加速线性层并压缩模型。此外，TurboDiffusion还结合了若干工程优化手段。我们在Wan2.2-I2V-14B-720P、Wan2.1-T2V-1.3B-480P、Wan2.1-T2V-14B-720P和Wan2.1-T2V-14B-480P等模型上进行了实验。实验结果表明，即使在单张RTX 5090 GPU上，TurboDiffusion也能实现100–200倍的视频生成加速，同时保持可比的视频质量。相关GitHub仓库（含模型检查点和易用代码）可在https://github.com/thu-ml/TurboDiffusion 获取。

BibTeX

```
@article{2512.16093v1,
  title={TurboDiffusion: Accelerating Video Diffusion Models by 100-200 Times},
  author={Jintao Zhang and Kaiwen Zheng and Kai Jiang and Haoxu Wang and Ion Stoica and Joseph E. Gonzalez and Jianfei Chen and Jun Zhu},
  journal={arXiv preprint arXiv:2512.16093v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16093v1}
}
```

## [CitySeeker: How Do VLMS Explore Embodied Urban Navigation With Implicit Human Needs?](http://arxiv.org/abs/2512.16755v1)

#视觉-语言模型#城市具身导航#空间推理与记忆

[PDF](https://arxiv.org/pdf/2512.16755v1)
[Abstract](http://arxiv.org/abs/2512.16755v1)

 VLM / Embodied Navigation

 很推荐

### 中文摘要

视觉-语言模型（VLM）在基于明确指令的导航任务上已取得显著进展，但其在动态城市环境中理解隐性人类需求（例如“我口渴了”）的能力仍未得到充分研究。本文提出了 CitySeeker —— 一个用于评估 VLM 在面向隐性需求的具身城市导航中空间推理与决策能力的新基准。CitySeeker 包含覆盖 8 个城市的 6,440 条轨迹，涵盖多样的视觉特征和 7 类目标驱动场景。大量实验证明，即便是表现最好的模型（如 Qwen2.5-VL-32B-Instruct）任务完成率也仅为 21.1%。我们识别出的关键瓶颈包括长时程推理中的误差累积、空间认知不足以及体验记忆的缺失。为进一步分析这些问题，本文借鉴人类认知地图中强调的迭代观测—推理循环与自适应路径优化，提出并研究了一系列探索性策略：回溯机制、增强的空间认知与基于记忆的检索（BCR）。我们的分析为构建具备稳健空间智能、能够应对“最后一公里”导航挑战的 VLM 提供了可操作的见解。

BibTeX

```
@article{2512.16755v1,
  title={CitySeeker: How Do VLMS Explore Embodied Urban Navigation With Implicit Human Needs?},
  author={Siqi Wang and Chao Liang and Yunfan Gao and Erxin Yu and Sen Li and Yushi Li and Jing Li and Haofen Wang},
  journal={arXiv preprint arXiv:2512.16755v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16755v1}
}
```

## [Yuan-TecSwin: A text conditioned Diffusion model with Swin-transformer blocks](http://arxiv.org/abs/2512.16586v1)

#扩散模型#Swin-Transformer#文本到图像生成

[PDF](https://arxiv.org/pdf/2512.16586v1)
[Abstract](http://arxiv.org/abs/2512.16586v1)

 CV（图像生成）

 很推荐

### 中文摘要

扩散模型凭借其U型架构和以卷积神经网络（CNN）为基础的模块，在图像合成方面展现出显著能力。但卷积操作的局部性可能限制模型理解远距离语义信息的能力。为了解决这一问题，本文提出了Yuan-TecSwin，一种基于Swin-Transformer的文本条件扩散模型。在编码器和解码器中用Swin-Transformer块替代CNN块，以增强特征提取和图像恢复过程中的非局部建模能力。通过精心选择文本编码器、有效利用文本嵌入以及在引入文本条件时的细致设计，改进了文本与图像的对齐。并且通过在不同扩散阶段采用自适应时间步搜索，推理性能进一步提升约10%。在ImageNet生成基准上，Yuan-TecSwin以1.37的FID得分达到了当前最优水平，且在不同去噪阶段未依赖任何额外模型。在对比测试中，人类受试者难以将模型生成的图像与人工绘制的图像区分开来。

BibTeX

```
@article{2512.16586v1,
  title={Yuan-TecSwin: A text conditioned Diffusion model with Swin-transformer blocks},
  author={Shaohua Wu and Tong Yu and Shenling Wang and Xudong Zhao},
  journal={arXiv preprint arXiv:2512.16586v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16586v1}
}
```

## [State-Augmented Graphs for Circular Economy Triage](http://arxiv.org/abs/2512.15824v1)

#循环经济分流#拆解序列规划 (DSP)#图模型决策

[PDF](https://arxiv.org/pdf/2512.15824v1)
[Abstract](http://arxiv.org/abs/2512.15824v1)

 图模型决策与规划

 很推荐

### 中文摘要

循环经济（CE）分流（triage）是对产品进行评估以确定其在现有使用寿命结束后可遵循的可持续路径。有效的CE分流需要在保留价值与加工和人工成本及约束之间做出自适应决策。本文提出了一种新颖的决策框架，将问题表示为在状态增强的拆解序列规划（Disassembly Sequencing Planning, DSP）图上的简单确定性求解器。通过将拆解历史编码进状态，该框架保证了马尔可夫性，从而实现最优的递归评估，确保每一步决策仅依赖于前一状态。分流决策在继续拆解与选择某一循环经济处置选项之间进行权衡。模型结合了基于诊断健康评分的状态感知效用以及复杂的操作约束。我们以层级化的电动汽车（EV）电池分流为示例展示了该框架的灵活性，其中决策由组件的递归估值驱动。该示例说明了统一形式化如何兼容不同的机械复杂性、安全要求和经济驱动因素。该统一形式化因此为在多样化产品和操作场景下优化循环经济分流决策提供了可处理且具普适性的理论基础。

BibTeX

```
@article{2512.15824v1,
  title={State-Augmented Graphs for Circular Economy Triage},
  author={Richard Fox and Rui Li and Gustav Jonsson and Farzaneh Goli and Miying Yang and Emel Aktas and Yongjing Wang},
  journal={arXiv preprint arXiv:2512.15824v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15824v1}
}
```

## [Smile on the Face, Sadness in the Eyes: Bridging the Emotion Gap with a Multimodal Dataset of Eye and Facial Behaviors](http://arxiv.org/abs/2512.16485v1)

#眼动行为#多模态情感识别#情感识别数据集

[PDF](https://arxiv.org/pdf/2512.16485v1)
[Abstract](http://arxiv.org/abs/2512.16485v1)

 CV

 很推荐

### 中文摘要

情感识别（ER）旨在从传感数据中分析并识别人的情绪。目前该领域主要依赖面部表情识别（FER），因为视觉通道包含丰富的情绪线索。然而，面部表情常被用作社交工具，未必反映真实的内在情感。为了解并弥合FER与真实情感之间的差距，本文引入眼动行为作为重要的情绪线索，并构建了一个辅助眼动行为的多模态情感识别数据集（EMER）。为采集真实情绪，我们采用了基于刺激材料的自发情绪诱发范式，同时非侵入性地采集了眼动序列和注视图等眼动行为数据，并同步记录面部表情视频。为更好地展示ER与FER之间的差异，针对多模态ER与仅基于面部的FER分别进行了多视角情绪标注。基于该数据集，我们提出了一种简单而有效的眼动辅助多模态情感识别Transformer（EMERT），通过模态对抗的特征解耦和多任务Transformer建模，将眼动行为作为对面部表情的有力补充，从而弥合情感表达与内在情绪之间的鸿沟。在实验中，我们制定了七种多模态基准评估协议以进行全面测试。结果表明，EMERT在多模态方法中显著优于其他最新方法，凸显了建模眼动行为对于稳健情感识别的重要性。总之，我们系统分析了眼动行为在情感识别中的作用，推动了减少FER与ER差距的研究进展。我们的EMER数据集及训练好的EMERT模型将公开发布于https://github.com/kejun1/EMER。

BibTeX

```
@article{2512.16485v1,
  title={Smile on the Face, Sadness in the Eyes: Bridging the Emotion Gap with a Multimodal Dataset of Eye and Facial Behaviors},
  author={Kejun Liu and Yuanyuan Liu and Lin Wei and Chang Tang and Yibing Zhan and Zijing Chen and Zhe Chen},
  journal={arXiv preprint arXiv:2512.16485v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16485v1}
}
```

## [Guiding Perception-Reasoning Closer to Human in Blind Image Quality Assessment](http://arxiv.org/abs/2512.16484v1)

#盲图像质量评估#人类感知-推理对齐#强化学习

[PDF](https://arxiv.org/pdf/2512.16484v1)
[Abstract](http://arxiv.org/abs/2512.16484v1)

 CV

 很推荐

### 中文摘要

人类通过感知—推理的级联过程评估图像质量，将感官线索与隐含推理相结合以形成自洽的判断。本文研究模型如何在盲图像质量评估（BIQA）中获得类似人类且具自洽性的推理能力。我们首先收集了反映人类感知—推理流程若干方面的人类评估数据；随后采用强化学习，并将人类标注作为奖励信号，引导模型朝向人类式的感知与推理。为使模型内化自洽的推理能力，我们设计了一种奖励机制，促使模型仅从自生成的描述中推断图像质量。实证结果表明，在Pearson和Spearman等通用指标上，我们的方法在评分预测上达到了与最先进BIQA系统相当的性能。除了评分外，我们还使用ROUGE-1衡量模型生成的感知—推理链与人类解释之间的一致性。在超过1000条人工标注样本上，我们的模型取得了0.512的ROUGE-1分（基线为0.443），表明对人类解释有显著覆盖并向具人类化、可解释的BIQA推理迈出了一步。

BibTeX

```
@article{2512.16484v1,
  title={Guiding Perception-Reasoning Closer to Human in Blind Image Quality Assessment},
  author={Yuan Li and Yahan Yu and Youyuan Lin and Yong-Hao Yang and Chenhui Chu and Shin'ya Nishida},
  journal={arXiv preprint arXiv:2512.16484v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16484v1}
}
```

## [Quantifying and Bridging the Fidelity Gap: A Decisive-Feature Approach to Comparing Synthetic and Real Imagery](http://arxiv.org/abs/2512.16468v1)

#决定性特征保真度#仿真到现实迁移#可解释性（XAI）

[PDF](https://arxiv.org/pdf/2512.16468v1)
[Abstract](http://arxiv.org/abs/2512.16468v1)

 CV

 很推荐

### 中文摘要

使用合成数据的虚拟测试已成为自动驾驶（AV）安全验证的核心手段。尽管通过先进仿真器和生成式 AI 在视觉真实感方面取得了进展，近期研究表明仅靠像素级的表观保真度并不足以保证从仿真到现实的可靠迁移。真正关键的是：被测系统（SUT）在真实与仿真环境中是否基于相同的因果证据做出决策——而不仅仅是图像在视觉上是否“看起来真实”。本文针对缺乏以行为为基础的保真度度量的问题，提出了决定性特征保真度（Decisive Feature Fidelity, DFF），一种面向具体 SUT 的新指标，将现有的保真度谱扩展到机制平价，即衡量跨域决策所依赖的因果证据的一致性。DFF 利用可解释人工智能（XAI）方法识别并比较匹配的真实-合成图像对中驱动 SUT 输出的决定性特征。我们进一步提出基于反事实解释的实用估计器，并设计了基于 DFF 的仿真器校准方案以提升仿真保真度。在对 2126 对匹配的 KITTI–VirtualKITTI2 图像对的实验中，DFF 揭示了传统输出值保真度所忽视的差异；此外，实验证明 DFF 指导的校准在不损害输出值保真度的情况下，能提升决定性特征层面和输入层面的保真度，且适用于多种 SUT。

BibTeX

```
@article{2512.16468v1,
  title={Quantifying and Bridging the Fidelity Gap: A Decisive-Feature Approach to Comparing Synthetic and Real Imagery},
  author={Danial Safaei and Siddartha Khastgir and Mohsen Alirezaei and Jeroen Ploeg and Son Tong and Xingyu Zhao},
  journal={arXiv preprint arXiv:2512.16468v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16468v1}
}
```

## [Hypernetworks That Evolve Themselves](http://arxiv.org/abs/2512.16406v1)

#自指图超网络#进化学习#强化学习

[PDF](https://arxiv.org/pdf/2512.16406v1)
[Abstract](http://arxiv.org/abs/2512.16406v1)

 RL

 很推荐

### 中文摘要

我们提出了一种无需外部优化器即可使神经网络自身进化的框架：自指图超网络（Self-Referential Graph HyperNetworks，简称Self-Referential GHNs）。在该系统中，变异与遗传的机制被直接嵌入网络内部。通过将超网络、随机参数生成以及基于图的表示相结合，Self-Referential GHNs 能在内部对自身进行变异与评估，并将变异率作为可选择的性状自适应地调整。通过新设计的具有环境突变的强化学习基准（CartPoleSwitch、LunarLander-Switch），Self-Referential GHNs 展示了快速且稳定的适应能力以及涌现的人口动力学。在运动学基准 Ant-v5 中，它们演化出连贯的步态，并表现出有希望的微调能力：种群自主减少变异以在有前景的解附近集中。我们的结果支持可进化性（evolvability）可以从神经网络的自我指涉中涌现这一观点。Self-Referential GHNs 向更接近生物进化的合成系统迈出了一步，为自主、开放式学习智能体提供了新的工具。

BibTeX

```
@article{2512.16406v1,
  title={Hypernetworks That Evolve Themselves},
  author={Joachim Winther Pedersen and Erwan Plantec and Eleni Nisioti and Marcello Barylli and Milton Montero and Kathrin Korte and Sebastian Risi},
  journal={arXiv preprint arXiv:2512.16406v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16406v1}
}
```

## [Collaborative Edge-to-Server Inference for Vision-Language Models](http://arxiv.org/abs/2512.16349v1)

#视觉-语言模型#边缘-服务器协同推理#选择性重传（基于最小熵置信度）

[PDF](https://arxiv.org/pdf/2512.16349v1)
[Abstract](http://arxiv.org/abs/2512.16349v1)

 VLM

 很推荐

### 中文摘要

我们提出了一种用于视觉-语言模型（VLM）的边缘-服务器协同推理框架，旨在在保持推理精度的同时显著降低通信开销。在典型部署中，边缘设备采集的视觉数据会传输到服务器进行VLM推理，但将原始图像缩放到视觉编码器输入分辨率常常丢失细粒度信息，导致精度下降。为了解决该问题，我们设计了一个两阶段流程：第一阶段服务器对全局图像进行推理，并利用VLM内部的注意力机制定位兴趣区域（RoI）；随后计算输出Token的最小熵作为置信度度量，以判断是否需要重传。如果最小熵超过预设阈值，服务器会请求边缘设备发送保留细节的RoI局部图像；第二阶段服务器通过联合利用全局图像与局部高细节图像对推理结果进行细化。该选择性重传策略能仅传输必要的视觉内容，从而在多种VLM架构上的实验结果表明，本框架在保持推理精度的前提下显著减少了通信成本。

BibTeX

```
@article{2512.16349v1,
  title={Collaborative Edge-to-Server Inference for Vision-Language Models},
  author={Soochang Song and Yongjune Kim},
  journal={arXiv preprint arXiv:2512.16349v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16349v1}
}
```

## [AI Needs Physics More Than Physics Needs AI](http://arxiv.org/abs/2512.16344v1)

#物理启发的AI#理论与机器学习融合#量子与类比计算

[PDF](https://arxiv.org/pdf/2512.16344v1)
[Abstract](http://arxiv.org/abs/2512.16344v1)

 AI理论 / 物理启发AI（跨学科）

 很推荐

### 中文摘要

人工智能（AI）常被描绘为具有变革性。然而，经过十多年的炒作，除了一些高调的科学与商业成功外，其可衡量的影响仍然有限。尽管2024年诺贝尔化学奖与物理学奖认可了AI的潜力，但更广泛的评估显示迄今为止的影响往往偏向宣传而非技术实质。我们认为，尽管当前的AI可能会影响物理学，但物理学对这一代AI的贡献要远大于反向作用。现有架构——大型语言模型、推理模型和具主体性的AI——可能依赖于数万亿个无意义的参数，存在分布偏差、缺乏不确定性量化、无法提供机械机制性的见解，甚至无法捕捉基本的科学定律。我们回顾了对这些局限性的批判，突出了量子AI与类比计算中的机会，并为“Big AI”的采用制定了路线图，即以理论为基础的严谨性与机器学习灵活性的综合。

BibTeX

```
@article{2512.16344v1,
  title={AI Needs Physics More Than Physics Needs AI},
  author={Peter Coveney and Roger Highfield},
  journal={arXiv preprint arXiv:2512.16344v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16344v1}
}
```

## [Agent Tools Orchestration Leaks More: Dataset, Benchmark, and Mitigation](http://arxiv.org/abs/2512.16310v1)

#工具编排隐私风险#多工具自治代理#隐私缓解与基准评估

[PDF](https://arxiv.org/pdf/2512.16310v1)
[Abstract](http://arxiv.org/abs/2512.16310v1)

 LLM

 很推荐

### 中文摘要

受大规模语言模型驱动，单代理多工具架构因其简洁与高效成为自治代理的流行范式。然而，该架构也引入了一种新的严重隐私风险——工具编排隐私风险（Tools Orchestration Privacy Risk, TOP-R）：为了完成看似无害的用户目标，代理会自主地聚合来自多个工具的信息片段，并利用其推理能力合成出意外的敏感信息。我们提出了对该风险的首个系统性研究。首先，从形式化框架出发，将风险根源归因于代理目标函数的不对齐：对“有帮助性”的过度优化而忽视隐私意识。其次，我们构建了 TOP-Bench，包含成对的泄露场景与无害场景，用以全面评估该风险。为量化安全性与鲁棒性之间的权衡，我们引入了作为整体度量的 H-Score。评估结果表明 TOP-R 是一个严重问题：八个代表性模型的平均风险泄露率（RLR）高达 90.24%，平均 H-Score 仅为 0.167，且没有模型超过 0.3。最后，我们提出了隐私增强原则（Privacy Enhancement Principle, PEP）方法，有效缓解了 TOP-R，将风险泄露率降至 46.58%，并显著将 H-Score 提高至 0.624。我们的工作揭示了一类新的风险及当前代理架构的内在结构性局限，同时也提供了可行的缓解策略。

BibTeX

```
@article{2512.16310v1,
  title={Agent Tools Orchestration Leaks More: Dataset, Benchmark, and Mitigation},
  author={Yuxuan Qiao and Dongqin Liu and Hongchang Yang and Wei Zhou and Songlin Hu},
  journal={arXiv preprint arXiv:2512.16310v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16310v1}
}
```

## [Towards Reproducibility in Predictive Process Mining: SPICE - A Deep Learning Library](http://arxiv.org/abs/2512.16715v1)

#预测性过程挖掘#可复现性#深度学习框架

[PDF](https://arxiv.org/pdf/2512.16715v1)
[Abstract](http://arxiv.org/abs/2512.16715v1)

 过程挖掘（Predictive Process Mining）

 很推荐

### 中文摘要

近年来，基于人工神经网络的预测性过程挖掘（Predictive Process Mining, PPM）技术已成为监控业务流程未来行为并预测关键绩效指标（KPI）的一种重要方法。然而，许多PPM方法往往存在可复现性不足、决策过程透明性差、难以方便地接入新数据集与进行基准测试等问题，导致不同实现之间的比较十分困难。本文提出了SPICE——一个基于Python的框架，使用PyTorch重新实现了三种流行的基线深度学习方法，同时设计了一个具有严格配置能力的通用基础框架，以实现对以往及未来建模方法的可复现且稳健的比较。我们在11个数据集上，将SPICE的性能与原文报告的指标以及采用公平评估指标的结果进行了比较验证。

BibTeX

```
@article{2512.16715v1,
  title={Towards Reproducibility in Predictive Process Mining: SPICE - A Deep Learning Library},
  author={Oliver Stritzel and Nick Hühnerbein and Simon Rauch and Itzel Zarate and Lukas Fleischmann and Moike Buck and Attila Lischka and Christian Frey},
  journal={arXiv preprint arXiv:2512.16715v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16715v1}
}
```

## [Pixel Seal: Adversarial-only training for invisible image and video watermarking](http://arxiv.org/abs/2512.16874v1)

#不可见水印#对抗式训练#高分辨率适配

[PDF](https://arxiv.org/pdf/2512.16874v1)
[Abstract](http://arxiv.org/abs/2512.16874v1)

 CV

 很推荐

### 中文摘要

不可见水印对于追踪数字内容的来源至关重要。然而，训练最先进的模型一直具有挑战性，现有方法常难以在鲁棒性与真正的不可感知性之间取得平衡。本文提出了 Pixel Seal，在图像和视频水印领域达到了新的最先进水平。我们首先指出现有方法的三大根本问题： (i) 依赖 MSE、LPIPS 等代理感知损失，这些损失无法模拟人类感知，导致可见的水印伪影；(ii) 由于目标冲突造成的优化不稳定性，需进行大量超参数调优；(iii) 在扩展到高分辨率图像和视频时，水印的鲁棒性和不可感知性显著下降。为解决上述问题，我们提出了仅对抗式训练范式，去除了不可靠的像素级不可感知性损失；引入三阶段训练策略，通过将鲁棒性与不可感知性解耦来稳定收敛；并通过高分辨率适配、基于可觉差（JND）的衰减和训练时的推理仿真来消除上采样伪影，弥合分辨率差距。我们在不同类型图像和广泛变换下对 Pixel Seal 的鲁棒性与不可感知性进行了全面评估，显著优于现有最先进方法。最后，我们通过时序水印池化展示了模型高效适配视频的能力，使 Pixel Seal 成为现实图像与视频场景中可扩展且可靠的溯源解决方案。

BibTeX

```
@article{2512.16874v1,
  title={Pixel Seal: Adversarial-only training for invisible image and video watermarking},
  author={Tomáš Souček and Pierre Fernandez and Hady Elsahar and Sylvestre-Alvise Rebuffi and Valeriu Lacatusu and Tuan Tran and Tom Sander and Alexandre Mourachko},
  journal={arXiv preprint arXiv:2512.16874v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16874v1}
}
```

## [Needle in the Web: A Benchmark for Retrieving Targeted Web Pages in the Wild](http://arxiv.org/abs/2512.16553v1)

#模糊探索性检索#网页检索基准#LLM 代理评估

[PDF](https://arxiv.org/pdf/2512.16553v1)
[Abstract](http://arxiv.org/abs/2512.16553v1)

 LLM

 很推荐

### 中文摘要

大型语言模型（LLM）已经从简单的聊天机器人发展为能够自动执行复杂现实任务的复杂代理，其中对实时网页内容的浏览与推理是评估检索与认知能力的关键。现有基准（如 BrowseComp 和 xBench-DeepSearch）侧重于需多跳综合的复杂推理检索，但忽视了“模糊探索性检索”——即查询含糊且多面，用户期望获得最相关的网页而非单一事实答案。为填补这一空白，我们提出了 Needle in the Web，这是一个专门用于评估现代搜索代理与基于 LLM 的系统在对模糊、探索性查询下检索与推理真实网页内容能力的新基准。Needle in the Web 包含 663 道覆盖七个不同领域的问题。为保证查询质量与答案唯一性，我们采用了一种灵活的方法，基于网页内容的事实断言可靠地产生可控难度的查询。我们在该基准上评测了三个领先的 LLM 与三个基于代理的搜索系统，结果表明大多数模型表现不佳：许多模型的准确率低于 35%，且没有任何模型能在所有领域或难度层次上稳定优异。研究结果表明，Needle in the Web 对现有搜索系统构成显著挑战，凸显了在语义模糊条件下实现有效模糊检索的未解问题。

BibTeX

```
@article{2512.16553v1,
  title={Needle in the Web: A Benchmark for Retrieving Targeted Web Pages in the Wild},
  author={Yumeng Wang and Tianyu Fan and Lingrui Xu and Chao Huang},
  journal={arXiv preprint arXiv:2512.16553v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16553v1}
}
```

## [Discovering and Learning Probabilistic Models of Black-Box AI Capabilities](http://arxiv.org/abs/2512.16733v1)

#PDDL表示#蒙特卡洛树搜索#概率性能力建模

[PDF](https://arxiv.org/pdf/2512.16733v1)
[Abstract](http://arxiv.org/abs/2512.16733v1)

 规划与模型学习

 很推荐

### 中文摘要

黑盒人工智能（BBAI）系统（例如基础模型）在顺序决策中被越来越广泛地使用。为了确保此类系统在操作和部署时的安全性，有必要开发高效方法，为BBAI的能力提供可靠且可解释的表示。本文表明，PDDL风格的表示可用于高效地学习和建模输入BBAI的规划能力。作者采用蒙特卡洛树搜索范式来系统地生成测试任务、获取数据并剪枝可能的符号模型假设空间。所学习的模型描述了BBAI的能力、这些能力可被执行的前置条件以及执行这些能力后可能出现的结果及其对应概率。理论结果证明了所学模型的正确性、完备性和收敛性。对多种BBAI系统的实证结果展示了该方法在适用范围、效率和准确性方面的表现。

BibTeX

```
@article{2512.16733v1,
  title={Discovering and Learning Probabilistic Models of Black-Box AI Capabilities},
  author={Daniel Bramblett and Rushang Karia and Adrian Ciotinga and Ruthvick Suresh and Pulkit Verma and YooJung Choi and Siddharth Srivastava},
  journal={arXiv preprint arXiv:2512.16733v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16733v1}
}
```

## [Few-Shot Inference of Human Perceptions of Robot Performance in Social Navigation Scenarios](http://arxiv.org/abs/2512.16019v1)

#少样本学习（LLM）#人类感知预测#社交导航

[PDF](https://arxiv.org/pdf/2512.16019v1)
[Abstract](http://arxiv.org/abs/2512.16019v1)

 LLM

 很推荐

### 中文摘要

理解人在与机器人互动时如何评估机器人行为，对于开发符合人类期望的社会化机器人至关重要。传统上获取此类评估依赖用户研究，近期工作提出可用机器学习替代，但现有数据驱动方法通常需要大量标注数据，限制了其实用性。为弥补这一空白，我们提出利用大语言模型（LLM）的少样本学习能力来提升机器人对用户对其表现感知的预测能力，并在社交导航任务中开展实验验证。为此，我们在 SEAN TOGETHER 数据集的基础上扩充了更多真实世界的人-机器人导航片段及参与者反馈，并基于该增强数据集评估了若干 LLM 在仅给出少量上下文示例条件下，基于机器人及周围人群的时空运动线索预测人类对机器人表现感知的能力。结果表明，LLM 在所需标注样本数量减少一个数量级的情况下，能达到或超越传统监督学习模型的性能；且随着上下文示例数量的增加，预测性能进一步提高，验证了方法的可扩展性。此外，我们通过对输入特征的消融研究探讨了 LLM 在推断过程中依赖的传感器信息类型，并首次探索了来自被评估同一用户的个性化示例用于上下文学习，发现其能够进一步提升预测准确性。本工作为通过以用户为中心的反馈以可扩展方式改进机器人行为开辟了路径。

BibTeX

```
@article{2512.16019v1,
  title={Few-Shot Inference of Human Perceptions of Robot Performance in Social Navigation Scenarios},
  author={Qiping Zhang and Nathan Tsoi and Mofeed Nagib and Hao-Tien Lewis Chiang and Marynel Vázquez},
  journal={arXiv preprint arXiv:2512.16019v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16019v1}
}
```

## [Subjective functions](http://arxiv.org/abs/2512.15948v1)

#主观函数#高阶目标函数#预期预测误差

[PDF](https://arxiv.org/pdf/2512.15948v1)
[Abstract](http://arxiv.org/abs/2512.15948v1)

 强化学习 (RL)

 很推荐

### 中文摘要

目标函数从何而来？我们如何选择要追求的目标？人类智能擅长即时合成新的目标函数。其工作原理是什么？我们能否赋予人工系统同样的能力？本文提出了一种用于回答这些问题的方法，首先引入“主观函数”（subjective function）的概念：这是一类高阶目标函数，内生于智能体（即相对于智能体自身特征定义，而非外在任务）。本文以预期预测误差作为主观函数的具体示例进行研究。该提议与心理学、神经科学和机器学习中的诸多思想存在广泛联系。

BibTeX

```
@article{2512.15948v1,
  title={Subjective functions},
  author={Samuel J. Gershman},
  journal={arXiv preprint arXiv:2512.15948v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15948v1}
}
```

## [Social Story Frames: Contextual Reasoning about Narrative Intent and Reception](http://arxiv.org/abs/2512.15925v1)

#社会故事框架#读者反应建模#语境化叙事推理

[PDF](https://arxiv.org/pdf/2512.15925v1)
[Abstract](http://arxiv.org/abs/2512.15925v1)

 NLP

 很推荐

### 中文摘要

阅读故事会激发丰富的解读性、情感性和评价性反应，例如对作者意图的推断或对人物的评判。然而，目前关于读者反应的计算模型尚不完善，限制了对这些细腻现象的分析。为填补这一空白，本文提出了SocialStoryFrames（一种形式化表征），用于提取关于读者反应的可行推断——包括感知到的作者意图、解释性与预测性推理、情感反应及价值判断——并结合对话上下文以及基于叙事理论、语言学语用学和心理学的分类体系。我们构建了两个模型：SSF-Generator 与 SSF-Classifier，分别通过人工问卷调查（N=382）与专家注释进行了验证。我们还进行了初步分析以展示该形式化方法在大规模故事研究中的实用性。具体而言，将模型应用于由多样语境构成的SSF-Corpus（收录6140条社交媒体故事）后，我们描述了叙事意图的出现频率及其相互依赖关系，并比较了不同社区的叙事实践及其多样性。通过将细粒度、语境敏感的建模与通用的读者反应分类体系相结合，SocialStoryFrames为在在线社区中研究讲故事行为开辟了新方向。

BibTeX

```
@article{2512.15925v1,
  title={Social Story Frames: Contextual Reasoning about Narrative Intent and Reception},
  author={Joel Mire and Maria Antoniak and Steven R. Wilson and Zexin Ma and Achyutarama R. Ganti and Andrew Piper and Maarten Sap},
  journal={arXiv preprint arXiv:2512.15925v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15925v1}
}
```

## [Human-like Working Memory from Artificial Intrinsic Plasticity Neurons](http://arxiv.org/abs/2512.15829v1)

#神经形态计算#内在神经可塑性（工作记忆）#磁隧道结（MTJ）硬件实现

[PDF](https://arxiv.org/pdf/2512.15829v1)
[Abstract](http://arxiv.org/abs/2512.15829v1)

 神经形态计算

 很推荐

### 中文摘要

工作记忆使大脑能够整合短暂信息以实现快速决策。人工网络通常通过循环或并行结构来复现这一能力，但会带来高能耗和对噪声的敏感性。本文提出了IPNet，一种软硬协同设计的神经形态架构，通过神经元的内在可塑性（intrinsic plasticity）实现类人工作记忆。IPNet 利用磁隧道结（MTJ）的焦耳热动力学在物理上模拟生物记忆的易逝性。所提出架构在 n-back、自由回忆和记忆干扰任务中的记忆行为，与已报道的人类受试者呈现相似趋势。该架构完全由 MTJ 神经元实现，在具有人类样工作记忆的前提下，于 11 类 DVS 手势数据集上达到 99.65% 的准确率，并在新提出的 22 类时间反转基准上保持 99.48%，均优于在相同骨干网络下的 RNN、LSTM 和 2+1D CNN 基线方法。在自动驾驶（DDD-20）任务中，IPNet 将转向预测误差较 ResNet-LSTM 降低了 14.4%。从架构角度，我们识别出“边缘记忆（Memory-at-the-Frontier）”效应，即性能在感测接口处达到最大化，验证了生物可拟的近传感器处理范式。关键的是，所有结果均基于已制造器件的原始参数，未经过额外优化；硬件在环验证进一步确认了系统的物理可实现性。能耗分析表明，其记忆功耗相比 LSTM 减少了约 2,874 倍，相比并行 3D-CNN 减少了约 90,920 倍。该无电容设计在 28 nm CMOS 工艺下实现约 1.5 μm² 的紧凑面积：相比标准 LIF 神经元面积降低了 20 倍以上。最终，我们展示了通过内在神经可塑性实现类人工作记忆，能够赋予神经网络在动态视觉处理上的优势同时显著降低代谢（能耗）成本。

BibTeX

```
@article{2512.15829v1,
  title={Human-like Working Memory from Artificial Intrinsic Plasticity Neurons},
  author={Jingli Liu and Huannan Zheng and Bohao Zou and Kezhou Yang},
  journal={arXiv preprint arXiv:2512.15829v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15829v1}
}
```

## [CodeMem: Architecting Reproducible Agents via Dynamic MCP and Procedural Memory](http://arxiv.org/abs/2512.15813v1)

#程序化记忆#代码即动作空间#代理工作流可复用性

[PDF](https://arxiv.org/pdf/2512.15813v1)
[Abstract](http://arxiv.org/abs/2512.15813v1)

 LLM Agents

 很推荐

### 中文摘要

当前的工具使用型 AI 代理存在动作空间受限、上下文效率低及概率性不稳定等问题，这使得它们在处理那些通过 n8n、Zapier 等平台上基于代理的工作流可以可靠高效完成的重复性任务时表现不足。早期工作如 CodeAct、DynaSaur、Code Mode 等通过将整个 Python 语言作为代理的动作空间来解决前两类问题：代理可调用的“工具”数量变为无限，Python 代码块能够在单步内执行复杂操作并仅输出相关结果，从而有助于保持上下文简洁。然而，概率性不稳定性问题依然存在——在相同任务和相同环境下，LLM 的概率性特性会导致代理沿不同轨迹执行。为此，需要程序化记忆以保证一致性与可靠性。本文提出了 CodeMem 架构，通过代码实现程序化记忆，并结合动态 MCP，旨在构建和运行可复用的代理工作流以实现确定性的可靠执行。

BibTeX

```
@article{2512.15813v1,
  title={CodeMem: Architecting Reproducible Agents via Dynamic MCP and Procedural Memory},
  author={Nishant Gaurav and Adit Akarsh and Tejas Ravishankar and Manoj Bajaj},
  journal={arXiv preprint arXiv:2512.15813v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15813v1}
}
```

## [Don't Guess, Escalate: Towards Explainable Uncertainty-Calibrated AI Forensic Agents](http://arxiv.org/abs/2512.16614v1)

#多媒体取证#不确定性校准#可解释性

[PDF](https://arxiv.org/pdf/2512.16614v1)
[Abstract](http://arxiv.org/abs/2512.16614v1)

 CV

 很推荐

### 中文摘要

人工智能正在重塑多媒体取证领域。我们提出了“AI 取证代理”：一种可靠的协调器，能够选择并组合多种取证检测器，识别媒体的溯源与上下文，并提供具备不确定性意识的评估。文中指出了当前解决方案中的若干陷阱，并提出了一个统一框架以改进真实性验证流程，提高评估的可解释性与可信度。

BibTeX

```
@article{2512.16614v1,
  title={Don't Guess, Escalate: Towards Explainable Uncertainty-Calibrated AI Forensic Agents},
  author={Giulia Boato and Andrea Montibeller and Edward Delp and Luisa Verdoliva and Daniele Miorandi},
  journal={arXiv preprint arXiv:2512.16614v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16614v1}
}
```

## [Evaluation of AI Ethics Tools in Language Models: A Developers' Perspective Case Stud](http://arxiv.org/abs/2512.15791v1)

#AI伦理工具#语言模型评估#开发者视角

[PDF](https://arxiv.org/pdf/2512.15791v1)
[Abstract](http://arxiv.org/abs/2512.15791v1)

 LLM

 很推荐

### 中文摘要

在人工智能（AI）领域，语言模型因其通过文本生成模拟与人类进行真实对话的能力而变得愈发重要。鉴于其对社会的影响，语言模型的开发与部署需要以负责任的方式进行，关注其负面影响与潜在危害。近年来，关于AI伦理工具（AIETs）的发表数量有所增加，这些工具旨在帮助开发者、企业、政府及其他利益相关者在技术的设计、开发与使用阶段引入公认的价值观，以建立信任、透明度与责任感。然而，许多AIETs缺乏充分的文档、使用示例以及在实践中有效性的证据。本文提出了一种用于评估语言模型AIETs的方法论。我们首先对213种AIETs进行了广泛的文献调研，并在应用纳入与排除标准后选定了四种工具：Model Cards、ALTAI、FactSheets与Harms Modeling。为评估这些工具，我们将其应用于为葡萄牙语开发的语言模型，并与其开发者进行了35小时的访谈。评估侧重于开发者视角，考察AIETs在帮助识别模型伦理问题的使用性与质量。结果表明，所应用的AIETs可作为制定语言模型一般性伦理考量的指南，但未覆盖诸如习惯用语等模型的特殊方面；此外，这些工具并未有助于识别针对葡萄牙语模型的潜在负面影响。

BibTeX

```
@article{2512.15791v1,
  title={Evaluation of AI Ethics Tools in Language Models: A Developers' Perspective Case Stud},
  author={Jhessica Silva and Diego A. B. Moreira and Gabriel O. dos Santos and Alef Ferreira and Helena Maia and Sandra Avila and Helio Pedrini},
  journal={arXiv preprint arXiv:2512.15791v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15791v1}
}
```

## [Beyond Training: Enabling Self-Evolution of Agents with MOBIMEM](http://arxiv.org/abs/2512.15784v1)

#记忆中心化代理#无模型重训自我演化#移动端高效执行

[PDF](https://arxiv.org/pdf/2512.15784v1)
[Abstract](http://arxiv.org/abs/2512.15784v1)

 LLM代理系统

 很推荐

### 中文摘要

大型语言模型（LLM）代理正日益用于在移动和桌面环境中自动化复杂工作流。然而，目前以模型为中心的代理架构在部署后难以自我演化：要提升个性化、能力和效率通常需要持续的模型重训/微调，这不仅带来巨大的计算开销，还面临模型精度与推理效率之间的固有权衡。为在无需模型重训的情况下实现迭代式自我演化，我们提出了MOBIMEM，一种以记忆为中心的代理系统。MOBIMEM 首先引入三种专门的记忆原语以将代理演化与模型权重解耦：（1）Profile Memory 使用轻量级的距离图（DisGraph）结构对齐用户偏好，在用户画像检索上兼顾精度与延迟；（2）Experience Memory 采用多层模板来实例化新任务的执行逻辑，确保能力的通用化；（3）Action Memory 记录细粒度的交互序列，降低对昂贵模型推理的依赖。在此记忆架构之上，MOBIMEM 还集成了一套受操作系统启发的服务来协调执行：一个调度器用于并行子任务执行与记忆操作的协调；一种代理记录与重放（AgentRR）机制以实现安全高效的动作复用；以及上下文感知的异常处理以在用户中断和运行时错误时实现稳健恢复。在 AndroidWorld 与前 50 名应用上的评测表明，MOBIMEM 在画像对齐上达到了 83.1%，检索时间为 23.83 毫秒（比 GraphRAG 基线快 280 倍），任务成功率提升高达 50.3%，并在移动设备上将端到端延迟最多降低 9 倍。

BibTeX

```
@article{2512.15784v1,
  title={Beyond Training: Enabling Self-Evolution of Agents with MOBIMEM},
  author={Zibin Liu and Cheng Zhang and Xi Zhao and Yunfei Feng and Bingyu Bai and Dahu Feng and Erhu Feng and Yubin Xia and Haibo Chen},
  journal={arXiv preprint arXiv:2512.15784v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15784v1}
}
```

## [Adversarial Robustness in Financial Machine Learning: Defenses, Economic Impact, and Governance Evidence](http://arxiv.org/abs/2512.15780v1)

#对抗性鲁棒性#金融机器学习#对抗训练

[PDF](https://arxiv.org/pdf/2512.15780v1)
[Abstract](http://arxiv.org/abs/2512.15780v1)

 对抗性机器学习（金融/表格数据）

 很推荐

### 中文摘要

我们评估了用于金融决策的表格数据机器学习模型的对抗性鲁棒性。基于信用评分和欺诈检测数据，研究中施加了基于梯度的对抗性攻击，并评估了这些攻击对模型判别能力、校准性以及若干金融风险指标的影响。结果表明，在微小扰动下模型性能出现显著下降，但通过对抗训练可以在一定程度上恢复性能。

BibTeX

```
@article{2512.15780v1,
  title={Adversarial Robustness in Financial Machine Learning: Defenses, Economic Impact, and Governance Evidence},
  author={Samruddhi Baviskar},
  journal={arXiv preprint arXiv:2512.15780v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15780v1}
}
```

## [TENG++: Time-Evolving Natural Gradient for Solving PDEs With Deep Neural Nets under General Boundary Conditions](http://arxiv.org/abs/2512.15771v1)

#物理信息神经网络（PINNs）#时间演化自然梯度#Dirichlet 边界条件

[PDF](https://arxiv.org/pdf/2512.15771v1)
[Abstract](http://arxiv.org/abs/2512.15771v1)

 科学机器学习 / PINNs

 很推荐

### 中文摘要

偏微分方程（PDE）在物理、生物和工程等领域用于刻画复杂系统，但传统数值方法在高维或复杂问题上常常面临困难。物理信息神经网络（PINNs）通过将物理约束嵌入深度学习框架，成为一种高效替代方法，但在实现高精度和处理复杂边界条件方面仍存在挑战。本文将时间演化自然梯度（TENG）框架扩展以处理Dirichlet边界条件，将自然梯度优化与数值时间步进方法（包括欧拉和Heun方法）相结合，以保证稳定性与精度。通过在损失函数中加入边界条件惩罚项，所提出的方法能够精确满足Dirichlet约束。针对热传导方程的实验表明，Heun方法由于具有二阶修正而在精度上表现更优，而欧拉方法在较简单情形下计算效率更高。该工作为将该框架推广至Neumann及混合边界条件以及更广泛类别的PDE奠定了基础，有助于推进基于神经网络的PDE求解器在实际问题中的适用性。

BibTeX

```
@article{2512.15771v1,
  title={TENG++: Time-Evolving Natural Gradient for Solving PDEs With Deep Neural Nets under General Boundary Conditions},
  author={Xinjie He and Chenggong Zhang},
  journal={arXiv preprint arXiv:2512.15771v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15771v1}
}
```

## [Data-Chain Backdoor: Do You Trust Diffusion Models as Generative Data Supplier?](http://arxiv.org/abs/2512.15769v1)

#扩散模型#后门攻击#合成数据安全

[PDF](https://arxiv.org/pdf/2512.15769v1)
[Abstract](http://arxiv.org/abs/2512.15769v1)

 计算机视觉 (CV) / 模型安全

 很推荐

### 中文摘要

随着扩散模型等生成模型在合成数据增强中的广泛应用，数据收集和标注成本在下游感知任务中大幅降低。然而，这一新的数据来源范式也带来了重要的安全隐患。本文研究了在这种新兴生成数据供应链中后门传播的问题，提出了“数据链后门（Data-Chain Backdoor，DCB）”的概念。具体而言，我们发现开源扩散模型可能成为隐蔽的后门载体：其强大的分布拟合能力会记忆并在生成过程中再现后门触发器，从而被下游模型继承，导致严重的安全风险。该威胁在干净标签攻击（clean-label attack）场景下尤为令人担忧，因为它在几乎不影响合成数据效用的情况下仍然有效。我们还发现了一个早期触发显现（Early-Stage Trigger Manifestation，ESTM）现象：后门触发模式往往在扩散模型逆向生成过程的早期高噪声阶段更为显著，然后在最终样本中被细微地融合。总体而言，本工作揭示了生成数据管道中一个此前未充分关注的威胁，并为缓解合成数据生成中的后门风险提供了初步洞见。

BibTeX

```
@article{2512.15769v1,
  title={Data-Chain Backdoor: Do You Trust Diffusion Models as Generative Data Supplier?},
  author={Junchi Lu and Xinke Li and Yuheng Liu and Qi Alfred Chen},
  journal={arXiv preprint arXiv:2512.15769v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15769v1}
}
```

## [Bridging Data and Physics: A Graph Neural Network-Based Hybrid Twin Framework](http://arxiv.org/abs/2512.15767v1)

#图神经网络#混合孪生体#物理-数据融合

[PDF](https://arxiv.org/pdf/2512.15767v1)
[Abstract](http://arxiv.org/abs/2512.15767v1)

 图神经网络（GNN）/科学机器学习

 很推荐

### 中文摘要

在复杂非稳态物理现象的数值模拟中，通常依赖有限元等详尽的数学模型。然而，由于未建模效应或简化假设，这些模型常与真实情况存在差距，我们将此差距称为“忽略模型”。纯数据驱动方法试图直接学习系统的全部行为，但需要跨空间与时间域的大量高质量数据；在现实场景中，这类数据往往不可得，使得纯数据驱动建模不可靠。为克服这一限制，本文提出采用混合孪生体（hybrid twin）方法来建模忽略项，而不是从零开始模拟整个现象。由于基于物理的模型能够近似描述总体行为，剩余的忽略项通常复杂度更低，因此可以用显著更少的数据来学习。一个关键难点是空间测量点稀疏，且在不同空间配置下获取相同现象的数据在实践中具有挑战性。我们的贡献在于使用图神经网络（GNN）表示忽略模型：GNN 即便在测点数量有限的情况下也能学习缺失物理的空间模式，从而在不依赖稠密时空和参数数据的前提下，为物理模型提供数据驱动的修正。为了展示该方法的性能，我们在不同网格、几何形状和加载位置的非线性热传导问题上评估了所提出的基于 GNN 的混合孪生体。结果表明，GNN 能成功捕获忽略项并将修正泛化到不同的空间配置，提高了仿真精度和可解释性，同时极大地降低了数据需求。

BibTeX

```
@article{2512.15767v1,
  title={Bridging Data and Physics: A Graph Neural Network-Based Hybrid Twin Framework},
  author={M. Gorpinich and B. Moya and S. Rodriguez and F. Meraghni and Y. Jaafra and A. Briot and M. Henner and R. Leon and F. Chinesta},
  journal={arXiv preprint arXiv:2512.15767v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15767v1}
}
```

## [Cross-Sample Augmented Test-Time Adaptation for Personalized Intraoperative Hypotension Prediction](http://arxiv.org/abs/2512.15762v1)

#术中低血压预测#测试时自适应(TTA)#跨样本增强/时间序列检索

[PDF](https://arxiv.org/pdf/2512.15762v1)
[Abstract](http://arxiv.org/abs/2512.15762v1)

 医疗时序预测

 很推荐

### 中文摘要

术中低血压（IOH）对手术安全构成重大风险，但由于患者间个体差异，准确预测仍然具有挑战性。尽管测试时自适应（TTA）为个性化预测提供了有希望的途径，但IOH事件的稀少性常导致测试时训练不稳定且不可靠。为此，我们提出了CSA-TTA，一种新颖的跨样本增强测试时自适应框架，通过引入其他个体的低血压事件来强化训练数据。具体而言，首先将历史数据按低血压与非低血压样本构建跨样本库；然后采用粗到细的检索策略构建测试时训练集：先用K-Shape聚类识别代表性簇中心，再基于当前患者信号检索语义最相似的top-K样本。此外，在训练过程中融合了自监督的掩码重建和回溯序列预测信号，以增强模型对快速且细微术中动态的适应能力。我们将CSA-TTA与先进的时间序列预测模型（包括TimesFM和UniTS）结合，在VitalDB数据集和真实院内数据集上进行了评估。实验结果表明，CSA-TTA在多种设置下均能稳定提升性能——例如在VitalDB上，细调模式下召回率和F1分别提升了+1.33%和+1.13%，而在零样本场景下则分别提升了+7.46%和+5.07%，展示了良好的鲁棒性与泛化能力。

BibTeX

```
@article{2512.15762v1,
  title={Cross-Sample Augmented Test-Time Adaptation for Personalized Intraoperative Hypotension Prediction},
  author={Kanxue Li and Yibing Zhan and Hua Jin and Chongchong Qi and Xu Lin and Baosheng Yu},
  journal={arXiv preprint arXiv:2512.15762v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15762v1}
}
```

## [GLOW: Graph-Language Co-Reasoning for Agentic Workflow Performance Prediction](http://arxiv.org/abs/2512.15751v1)

#图-语言共推理#Agentic Workflows性能预测#GNN与LLM融合

[PDF](https://arxiv.org/pdf/2512.15751v1)
[Abstract](http://arxiv.org/abs/2512.15751v1)

 LLM

 很推荐

### 中文摘要

Agentic Workflows（AWs）作为解决复杂任务的一种有前景的范式逐渐兴起。然而，依赖执行来评估其性能的做法在成本和时延上严重制约了自动化生成的可扩展性。现有的AW性能预测方法作为替代虽然能降低代价，但难以同时捕捉AW中复杂的拓扑依赖关系与深层语义逻辑。为此，我们提出了GLOW，一个用于AW性能预测的统一框架，将GNN对图结构的建模能力与大模型的推理能力相结合。具体而言，我们引入了一种面向图任务、经过指令微调的图导向大模型，用以提取具有拓扑感知性的语义特征，并与GNN编码的结构表示进行融合。此外，设计了一种对比对齐策略以进一步优化潜空间，使高质量AW能够被更好地区分。大量在FLORA-Bench上的实验表明，GLOW在预测精度和排序效用上均优于最先进的基线方法。

BibTeX

```
@article{2512.15751v1,
  title={GLOW: Graph-Language Co-Reasoning for Agentic Workflow Performance Prediction},
  author={Wei Guan and Jian Cao and Jinyu Cai and Qiqi Cai and Jianqi Gao and See-Kiong Ng},
  journal={arXiv preprint arXiv:2512.15751v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15751v1}
}
```

## [Anubuddhi: A Multi-Agent AI System for Designing and Simulating Quantum Optics Experiments](http://arxiv.org/abs/2512.15736v1)

#多智能体系统#量子光学实验设计#物理仿真与验证

[PDF](https://arxiv.org/pdf/2512.15736v1)
[Abstract](http://arxiv.org/abs/2512.15736v1)

 AI for Science（多智能体系统）

 很推荐

### 中文摘要

我们提出了 Anubuddhi，一种多智能体 AI 系统，能够从自然语言提示设计并模拟量子光学实验，而无需专门的编程知识。系统通过语义检索，从三层工具箱中排列光学元件以构建光路布局，并通过物理仿真与收敛性精炼对设计进行验证。其架构结合了意图路由、知识增强生成和双模式验证（QuTiP 与 FreeSim）。我们评估了 13 个实验，涵盖基础光学（Hong–Ou–Mandel 干涉、迈克耳孙/马赫–曾德尔干涉、Bell 态、延迟选择量子擦除）、量子信息协议（BB84 量子密钥分发、Franson 干涉、GHZ 态、量子隐形传态、超纠缠）以及高级技术（玻色采样、电磁感应透明、频率转换）。系统在设计—仿真对齐度上取得 8–9/10 的评分，仿真结果能够忠实建模预期物理行为。一个关键发现是结构上的正确性可以与定量精度区分：高对齐度表明物理架构正确，但数值预测仍需专家复核。自由式仿真在 13 个实验中有 11 个优于受限框架，表明量子光学的多样性需要灵活的数学表征。该系统使计算实验设计在研究和教学中更为普及，能够生成强有力的初始设计，用户可通过对话迭代精化。

BibTeX

```
@article{2512.15736v1,
  title={Anubuddhi: A Multi-Agent AI System for Designing and Simulating Quantum Optics Experiments},
  author={S. K. Rithvik},
  journal={arXiv preprint arXiv:2512.15736v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15736v1}
}
```

## [XTC, A Research Platform for Optimizing AI Workload Operators](http://arxiv.org/abs/2512.16512v1)

#AI算子优化#调度语言#可复现性能评估

[PDF](https://arxiv.org/pdf/2512.16512v1)
[Abstract](http://arxiv.org/abs/2512.16512v1)

 编译器与系统

 很推荐

### 中文摘要

在 AI 算子上实现高效性能需要对计算和数据移动进行精细控制。然而，现有的调度语言通常绑定于特定的编译器生态系统，阻碍了不同框架之间的公平比较、复用和评估。目前尚无统一接口可以将调度规范与代码生成和性能测量解耦。我们提出 XTC，一个在编译器之间统一调度和性能评估的平台。通过其通用 API 和可复现的测量框架，XTC 支持可移植的实验，并加速了关于优化策略的研究。

BibTeX

```
@article{2512.16512v1,
  title={XTC, A Research Platform for Optimizing AI Workload Operators},
  author={Pompougnac Hugo and Guillon Christophe and Noiry Sylvain and Dutilleul Alban and Iooss Guillaume and Rastello Fabrice},
  journal={arXiv preprint arXiv:2512.16512v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16512v1}
}
```

## [Topic Modelling Black Box Optimization](http://arxiv.org/abs/2512.16445v1)

#主题模型#黑盒优化#摊销式优化

[PDF](https://arxiv.org/pdf/2512.16445v1)
[Abstract](http://arxiv.org/abs/2512.16445v1)

 NLP

 很推荐

### 中文摘要

在潜在狄利克雷分配（LDA）中选择主题数量 T 是一个关键设计决策，会显著影响主题模型的统计拟合与可解释性。本文将选择 T 的问题表述为一个离散的黑盒优化问题，其中每次函数评估对应于训练一个 LDA 模型并测量其在验证集上的困惑度。在固定评估预算下，我们比较了四类优化器：两种手工设计的进化方法——遗传算法（GA）和进化策略（ES）——以及两种学习得到的、具备摊销性质的方法，分别是偏好性摊销黑盒优化（PABBO）和鲁棒性感知摊销黑盒优化（SABBO）。实验结果表明，尽管 GA、ES、PABBO 和 SABBO 最终能达到相似的困惑度区间，但摊销型优化器在样本效率和时间效率上显著优越。具体来说，SABBO 通常在几乎一次评估后即可识别出接近最优的主题数，而 PABBO 在少数几次评估内能找到具有竞争力的配置；相比之下，GA 和 ES 需要几乎耗尽全部预算才可接近相同的结果区间。

BibTeX

```
@article{2512.16445v1,
  title={Topic Modelling Black Box Optimization},
  author={Roman Akramov and Artem Khamatullin and Svetlana Glazyrina and Maksim Kryzhanovskiy and Roman Ischenko},
  journal={arXiv preprint arXiv:2512.16445v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16445v1}
}
```

## [Beyond the Benchmark: Innovative Defenses Against Prompt Injection Attacks](http://arxiv.org/abs/2512.16307v1)

#提示注入攻击#小型开源LLM安全#自动化防御机制

[PDF](https://arxiv.org/pdf/2512.16307v1)
[Abstract](http://arxiv.org/abs/2512.16307v1)

 LLM

 很推荐

### 中文摘要

在快速发展的大型语言模型领域，本文探讨了提示注入攻击所带来的显著安全风险，重点关注小型开源模型，特别是 LLaMA 系列。我们提出了一类新颖的防御机制，能够自动生成防护提示，并将这些生成的防御在一套全面的基准攻击上进行系统评估。实证结果表明，我们的方法在缓解模型目标劫持（goal-hijacking）漏洞方面具有显著提升。本文认识到小型开源 LLM 在边缘设备上大规模部署的潜力与日俱增，并与 LLM 应用的未来趋势相契合。我们的主要贡献包括：（1）评估现有基于提示的防御在应对最新攻击时的有效性；（2）引入一种以种子防御（Chain Of Thoughts）为核心的框架，通过迭代精化防御提示；（3）在检测目标劫持攻击方面展示了显著改进。我们的策略显著降低了攻击成功率与误报率，同时有效检测目标劫持能力，为在资源受限环境中更安全、高效地部署小型开源 LLM 奠定了基础。

BibTeX

```
@article{2512.16307v1,
  title={Beyond the Benchmark: Innovative Defenses Against Prompt Injection Attacks},
  author={Safwan Shaheer and G. M. Refatul Islam and Mohammad Rafid Hamid and Tahsin Zaman Jilan},
  journal={arXiv preprint arXiv:2512.16307v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16307v1}
}
```

## [Interpretable Deep Learning for Stock Returns: A Consensus-Bottleneck Asset Pricing Model](http://arxiv.org/abs/2512.16251v1)

#可解释深度学习#资产定价#共识瓶颈/信念聚合

[PDF](https://arxiv.org/pdf/2512.16251v1)
[Abstract](http://arxiv.org/abs/2512.16251v1)

 金融机器学习（资产定价）

 很推荐

### 中文摘要

我们提出了共识-瓶颈资产定价模型（Consensus-Bottleneck Asset Pricing Model, CB-APM），这是一种部分可解释的神经网络，旨在复制卖方分析师的推理过程，通过建模投资者信念分散如何经由共识形成过程被压缩进资产价格来解释定价机制。通过对该“瓶颈”进行建模以汇总公司层面与宏观层面的信息，CB-APM 不仅能够预测美国股票的未来风险溢价，还在结构上将信念聚合与预期收益联系起来，从而具备可解释性。该模型提升了长期收益率预测能力，并在预测精度和解释力上均优于标准深度学习方法。全面的投资组合分析表明，CB-APM 的样本外预测能够转化为具有经济意义的收益，其中回报差异呈单调性，并且在不同正则化设置下多空策略表现稳定。实证上，CB-APM 利用共识作为正则化器来放大长期可预测性，并产出可解释的基于共识的成分，澄清了信息如何在收益中被定价。此外，回归与 GRS 定价诊断显示，模型学得的共识表示所捕捉的定价变异仅部分被传统因子模型所覆盖，表明 CB-APM 在经典因子空间之外揭示了由信念驱动的预期收益结构。总体而言，CB-APM 为理解由信念驱动的收益动态提供了一个既可解释又有实证依据的框架。

BibTeX

```
@article{2512.16251v1,
  title={Interpretable Deep Learning for Stock Returns: A Consensus-Bottleneck Asset Pricing Model},
  author={Bong-Gyu Jang and Younwoo Jeong and Changeun Kim},
  journal={arXiv preprint arXiv:2512.16251v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16251v1}
}
```

## [ModelTables: A Corpus of Tables about Models](http://arxiv.org/abs/2512.16106v1)

#模型表格语料库#语义表格检索#模型知识结构化

[PDF](https://arxiv.org/pdf/2512.16106v1)
[Abstract](http://arxiv.org/abs/2512.16106v1)

 信息检索/模型库

 很推荐

### 中文摘要

我们提出了 ModelTables，这是一个来自“模型湖（Model Lakes）”的表格基准，旨在捕捉性能与配置类表格的结构化语义，这类语义常被仅基于文本的检索方法忽视。该语料由 Hugging Face 的 model card、GitHub README 和被引用的论文构建，并将每张表格与其所在的模型及发表/文献上下文相连。与开放数据湖中的表格相比，模型表格规模更小但表格间关系更为密集，反映了模型与基准紧密耦合的演化特性。当前版本覆盖了超过 6 万个模型和 9 万张表格。为评估模型与表格的相关性，我们基于三类互补信号构建了多源真值： (1) 论文引用链接，(2) 显式的 model card 链接与继承关系，(3) 共享的训练数据集。我们给出了一个详尽的实证用例——表格检索，比较了典型的数据湖搜索算子（可并集、可连接、关键词）与信息检索基线（稠密、稀疏、混合检索）在该基准上的表现。基于并集的语义表格检索总体 P@1 为 54.8%（在引用信号上为 54.6%，在继承信号上为 31.3%，在共享数据集信号上为 30.6%）；基于表格的稠密检索达到 66.5% P@1；元数据混合检索实现 54.1% P@1。该评估表明仍有显著空间以发展更好的表格检索方法。通过发布 ModelTables 及其构建流程，我们提供了首个大规模描述 AI 模型的结构化数据基准，为开发更准确的语义检索、结构化比较与有原则的模型知识组织提供了直观依据与实证支持。源码、数据与其他工件已在 https://github.com/RJMillerLab/ModelTables 上公开。

BibTeX

```
@article{2512.16106v1,
  title={ModelTables: A Corpus of Tables about Models},
  author={Zhengyuan Dong and Victor Zhong and Renée J. Miller},
  journal={arXiv preprint arXiv:2512.16106v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16106v1}
}
```

## [The Social Responsibility Stack: A Control-Theoretic Architecture for Governing Socio-Technical AI](http://arxiv.org/abs/2512.16873v1)

#社会责任栈#控制理论#AI治理与可审计性

[PDF](https://arxiv.org/pdf/2512.16873v1)
[Abstract](http://arxiv.org/abs/2512.16873v1)

 AI治理与安全

 很推荐

### 中文摘要

人工智能系统越来越多地部署在塑造人类行为、机构决策和社会结果的领域。现有的负责任人工智能与治理工作虽然提供了重要的规范性原则，但常常缺乏贯穿系统生命周期且可强制执行的工程机制。本文提出了“社会责任栈”（Social Responsibility Stack, SRS），这是一个由六层组成的架构框架，旨在将社会价值以明确的约束、保障措施、行为接口、审计机制和治理流程嵌入到人工智能系统中。SRS 将责任建模为对社会技术系统的闭环监管控制问题，整合了设计时的防护措施与运行时的监测以及制度化的监督。我们发展了统一的基于约束的形式化表述，提出了安全包络（safety-envelope）与反馈解读，并展示了如何对公平性、自主性、认知负担和解释质量进行连续监测与强制执行。临床决策支持、协作式自动驾驶车辆与公共部门系统的案例研究说明了 SRS 如何将规范性目标转化为可操作的工程与运行控制。该框架桥接了伦理学、控制理论与人工智能治理，为构建可问责、可适应且可审计的社会技术 AI 系统提供了实用基础。

BibTeX

```
@article{2512.16873v1,
  title={The Social Responsibility Stack: A Control-Theoretic Architecture for Governing Socio-Technical AI},
  author={Otman A. Basir},
  journal={arXiv preprint arXiv:2512.16873v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16873v1}
}
```

## [TreeNet: A Light Weight Model for Low Bitrate Image Compression](http://arxiv.org/abs/2512.16743v1)

#图像压缩#轻量化模型#注意力特征融合

[PDF](https://arxiv.org/pdf/2512.16743v1)
[Abstract](http://arxiv.org/abs/2512.16743v1)

 CV

 很推荐

### 中文摘要

降低计算复杂度仍然是基于学习的图像压缩技术广泛应用的关键挑战。本文提出了 TreeNet，一种新颖的低复杂度图像压缩模型，该模型采用二叉树结构的编码器—解码器架构，以实现高效的表征与重建。我们引入了注意力特征融合机制，有效地整合来自多分支的特征。我们在三个常用基准数据集上对 TreeNet 进行了评估，并将其性能与包括 JPEG AI 在内的竞争方法进行了比较。在低码率情况下，TreeNet 相较于 JPEG AI 在 BD-rate 上平均提升了 4.83%，同时将模型复杂度降低了 87.82%。此外，我们还进行了广泛的消融实验，研究了 TreeNet 中不同潜在表示的影响，为重建性能的关键因素提供了更深入的见解。

BibTeX

```
@article{2512.16743v1,
  title={TreeNet: A Light Weight Model for Low Bitrate Image Compression},
  author={Mahadev Prasad Panda and Purnachandra Rao Makkena and Srivatsa Prativadibhayankaram and Siegfried Fößel and André Kaup},
  journal={arXiv preprint arXiv:2512.16743v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16743v1}
}
```

## [Best Practices For Empirical Meta-Algorithmic Research Guidelines from the COSEAL Research Network](http://arxiv.org/abs/2512.16491v1)

#元算法#算法选择与配置#实验设计与可重复性

[PDF](https://arxiv.org/pdf/2512.16491v1)
[Abstract](http://arxiv.org/abs/2512.16491v1)

 元算法（算法选择与配置）

 很推荐

### 中文摘要

关于元算法学的实证研究（例如算法选择、配置与调度）通常依赖大量且计算开销巨大的实验。由于我们在实验设置与设计上拥有很大的自由度，因此也存在大量潜在的误差来源，这些误差威胁到我们科学结论的可扩展性与有效性。尽管关于元算法学研究的最佳实践已有所总结，但这些建议分散在不同的出版物与领域之间，且各自演进，缺乏统一的整理。在本报告中，我们汇总了COSEAL社区各子领域在元算法学实证研究中的良好做法，覆盖完整的实验流程：从提出研究问题与选择实验设计，到执行实验，再到公正地分析与呈现结果。该报告确立了元算法学研究中的现有最佳实践，并为元算法学领域的新研究人员与从业者提供实施指南。

BibTeX

```
@article{2512.16491v1,
  title={Best Practices For Empirical Meta-Algorithmic Research Guidelines from the COSEAL Research Network},
  author={Theresa Eimer and Lennart Schäpermeier and André Biedenkapp and Alexander Tornede and Lars Kotthoff and Pieter Leyman and Matthias Feurer and Katharina Eggensperger and Kaitlin Maile and Tanja Tornede and Anna Kozak and Ke Xue and Marcel Wever and Mitra Baratchi and Damir Pulatov and Heike Trautmann and Haniye Kashgarani and Marius Lindauer},
  journal={arXiv preprint arXiv:2512.16491v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16491v1}
}
```

## [Towards Mass Spectrum Analysis with ASP](http://arxiv.org/abs/2512.16780v1)

#答案集编程（ASP）#质谱分析#分子结构重建

[PDF](https://arxiv.org/pdf/2512.16780v1)
[Abstract](http://arxiv.org/abs/2512.16780v1)

 知识表示与推理（逻辑编程/ASP）

 很推荐

### 中文摘要

本文提出了一种将答案集编程（Answer Set Programming, ASP）用于基于质谱测得的元素与结构片段相对丰度来发现化学样品分子结构的新方法。为约束这一组合问题的指数级搜索空间，作者构建了分子结构的规范表示并基于此实现了相应的 ASP 算法。论文在大量已知分子结构上验证了实现的正确性，并将该方法的质量与性能与其他 ASP 对称性破坏方法以及一款分析化学领域的商业工具进行了比较。该工作目前正在 Theory and Practice of Logic Programming (TPLP) 投稿审议中。

BibTeX

```
@article{2512.16780v1,
  title={Towards Mass Spectrum Analysis with ASP},
  author={Nils Küchenmeister and Alex Ivliev and Markus Krötzsch},
  journal={arXiv preprint arXiv:2512.16780v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16780v1}
}
```

## [Flowing from Reasoning to Motion: Learning 3D Hand Trajectory Prediction from Egocentric Human Interaction Videos](http://arxiv.org/abs/2512.16907v1)

#3D手部轨迹预测#自我视角交互数据集#视觉-语言到运动生成

[PDF](https://arxiv.org/pdf/2512.16907v1)
[Abstract](http://arxiv.org/abs/2512.16907v1)

 CV

 很推荐

### 中文摘要

先前关于3D手部轨迹预测的工作受限于将运动与语义监督分离的数据集，以及将推理与动作弱耦合的模型。为了解决这些问题，我们首先提出了EgoMAN数据集——一个大规模自我视角（egocentric）的交互阶段感知3D手部轨迹预测数据集，包含219K条6DoF轨迹以及用于语义、空间和运动推理的300万条结构化问答对。随后我们引入了EgoMAN模型，这是一种从推理到运动的框架，通过轨迹令牌（trajectory-token）接口将视觉-语言推理与运动生成连接起来。通过逐步训练以对齐推理过程与运动动力学，我们的方法能够生成准确且具有阶段感知能力的轨迹，并在真实场景中表现出良好的泛化能力。

BibTeX

```
@article{2512.16907v1,
  title={Flowing from Reasoning to Motion: Learning 3D Hand Trajectory Prediction from Egocentric Human Interaction Videos},
  author={Mingfei Chen and Yifan Wang and Zhengqin Li and Homanga Bharadhwaj and Yujin Chen and Chuan Qin and Ziyi Kou and Yuan Tian and Eric Whitmire and Rajinder Sodhi and Hrvoje Benko and Eli Shlizerman and Yue Liu},
  journal={arXiv preprint arXiv:2512.16907v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16907v1}
}
```

## [AI Epidemiology: achieving explainable AI through expert oversight patterns](http://arxiv.org/abs/2512.15783v1)

#AI 可解释性#群体级监测#AI 治理与审计

[PDF](https://arxiv.org/pdf/2512.15783v1)
[Abstract](http://arxiv.org/abs/2512.15783v1)

 AI治理与可解释性

 很推荐

### 中文摘要

AI 流行病学是一种通过将群体层面的监测方法应用于 AI 输出来管理和解释先进 AI 系统的框架。该方法借鉴了流行病学家在未完全了解分子机制之前，依靠统计证据推动公共卫生干预的做法，从而规避了当前可解释性方法（如 SHAP 和机制化可解释性）在大规模部署模型上面临的复杂性问题。AI 流行病学通过将专家与 AI 的交互标准化为结构化评估字段（风险等级、对齐分数和准确性分数）来实现群体级监测：这些字段作为“暴露变量”，通过统计关联来预测输出失败，类似于胆固醇和血压预测心脏事件的方式。随后，这些输出失败的关联会通过专家覆盖（override）和真实世界结果进行验证。该框架对专家几乎不增加额外负担，并通过被动跟踪专家与 AI 建议的一致性或分歧提供自动审计线索。由于分析的是输出而非模型内部计算，当机构更新模型或更换供应商时，仍能保持治理的连续性。最后，通过提供可靠性分数和语义化评估（例如“该建议类似于500例因违反指南被专家覆盖的情况”），该方法使专家和机构能够在不造成损害前识别不可靠的 AI 输出，从而实现无需机器学习专业知识的领域专家对 AI 系统的民主化监督。

BibTeX

```
@article{2512.15783v1,
  title={AI Epidemiology: achieving explainable AI through expert oversight patterns},
  author={Kit Tempest-Walters},
  journal={arXiv preprint arXiv:2512.15783v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15783v1}
}
```

## [PHANTOM: Progressive High-fidelity Adversarial Network for Threat Object Modeling](http://arxiv.org/abs/2512.15768v1)

#合成网络攻击数据#VAE-GAN对抗生成#入侵检测数据增强

[PDF](https://arxiv.org/pdf/2512.15768v1)
[Abstract](http://arxiv.org/abs/2512.15768v1)

 网络安全（生成模型）

 很推荐

### 中文摘要

网络攻击数据的稀缺性阻碍了鲁棒入侵检测系统的发展。本文提出了PHANTOM，一种用于生成高保真合成攻击数据的新型对抗变分框架。其创新点包括渐进式训练、双路径VAE-GAN架构以及用于保留攻击语义的领域特定特征匹配。在10万条网络流量样本上的评估表明，使用PHANTOM生成数据训练的检测模型在真实攻击上可达到98%的加权准确率。统计分析进一步证实了合成数据在分布和多样性上接近真实数据。论文同时指出在生成稀有攻击类型方面存在局限，反映出严重类别不平衡下的挑战。该工作推动了用于训练鲁棒且可保护隐私的检测系统的合成数据生成研究。

BibTeX

```
@article{2512.15768v1,
  title={PHANTOM: Progressive High-fidelity Adversarial Network for Threat Object Modeling},
  author={Jamal Al-Karaki and Muhammad Al-Zafar Khan and Rand Derar Mohammad Al Athamneh},
  journal={arXiv preprint arXiv:2512.15768v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15768v1}
}
```

## [LOOPRAG: Enhancing Loop Transformation Optimization with Retrieval-Augmented Large Language Models](http://arxiv.org/abs/2512.15766v1)

#循环变换优化#检索增强生成（RAG）#基于反馈的LLM代码优化

[PDF](https://arxiv.org/pdf/2512.15766v1)
[Abstract](http://arxiv.org/abs/2512.15766v1)

 LLM

 很推荐

### 中文摘要

循环变换是保持语义不变的优化技术，广泛用于最大化诸如并行性等目标。尽管研究已持续数十年，由于固有复杂性（例如针对优化目标的成本建模），设计最优的循环变换组合仍然具有挑战性。最近的研究探索了大语言模型（LLM）在代码优化中的潜力，但我们发现LLM在循环变换优化上常常表现不佳，容易产生错误或次优的优化，因而错失性能提升机会。为此，我们提出了LOOPRAG，一种面向静态控制部分的检索增强生成（RAG）框架，用以指导LLM高效执行循环优化。我们引入了一种基于参数驱动的方法来利用循环属性触发多种循环变换，并生成多样且合法的示例代码作为演示来源。为获取最具信息量的示例，我们提出了一种基于循环特征的感知检索算法，在相似性与多样性之间进行权衡。为增强生成代码的正确性与效率，我们设计了一个基于反馈的迭代机制，将编译、测试与性能结果作为反馈引导LLM。每个优化后的代码均经过变异、覆盖和差异测试以进行等价性检查。在PolyBench、TSVC和LORE基准套件上的评估显示，LOOPRAG相较于基础编译器（GCC-Graphite、Clang-Polly、Perspective和ICX）分别在平均上实现了最高11.20×、14.34×和9.29×的加速；相较于代表性LLM（DeepSeek和GPT-4）则实现了最高11.97×、5.61×和11.59×的加速。

BibTeX

```
@article{2512.15766v1,
  title={LOOPRAG: Enhancing Loop Transformation Optimization with Retrieval-Augmented Large Language Models},
  author={Yijie Zhi and Yayu Cao and Jianhua Dai and Xiaoyang Han and Jingwen Pu and Qingran Wu and Sheng Cheng and Ming Cai},
  journal={arXiv preprint arXiv:2512.15766v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15766v1}
}
```

## [Prompt-to-Parts: Generative AI for Physical Assembly and Scalable Instructions](http://arxiv.org/abs/2512.15743v1)

#物理装配指令生成#离散零件词汇与可构建性#基于LLM的工具引导建模

[PDF](https://arxiv.org/pdf/2512.15743v1)
[Abstract](http://arxiv.org/abs/2512.15743v1)

 LLM

 很推荐

### 中文摘要

我们提出了一个将自然语言描述生成为可物理实现装配说明的框架。不同于不受约束的文本到3D方法，本方法在离散零件词汇表内运行，强制满足几何有效性、连接约束和可装配性顺序要求。利用LDraw作为富文本中间表示，我们展示了在工具引导下大型语言模型能够生成有效的逐步构建序列和面向砖块原型的装配说明，支持超过3000种装配零件。我们引入了一个用于程序化模型生成的Python库，并在复杂的卫星、飞机和建筑等领域对可构建输出进行了评估。该方法旨在实现可扩展性、模块化和高保真度，弥合语义设计意图与可制造输出之间的鸿沟，使自然语言规范能够直接驱动物理原型制作。本文提出了一种新颖的要素化通用语言(elemental lingua franca)，作为弥补此前基于像素的扩散方法或CAD模型在支持复杂装配指令与零件替换方面不足的关键组件。在四个原创设计案例中，这种“砖块包”方法充当物理API：通过受限词汇将精确定向的砖块位置映射到“词袋”，从而将任意功能需求编译为物质现实。该一致且可重复的AI表示为制造与工程原型中的自然语言实现开辟了新的设计可能性，并指导实际装配流程。

BibTeX

```
@article{2512.15743v1,
  title={Prompt-to-Parts: Generative AI for Physical Assembly and Scalable Instructions},
  author={David Noever},
  journal={arXiv preprint arXiv:2512.15743v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15743v1}
}
```

## [Bayesian Modeling for Uncertainty Management in Financial Risk Forecasting and Compliance](http://arxiv.org/abs/2512.15739v1)

#贝叶斯不确定性量化#金融风险预测#欺诈检测与合规评估

[PDF](https://arxiv.org/pdf/2512.15739v1)
[Abstract](http://arxiv.org/abs/2512.15739v1)

 金融风控（贝叶斯时序建模）

 很推荐

### 中文摘要

本文提出了一个能够精确量化不确定性的贝叶斯分析框架，为金融风险管理带来重要进展。我们开发了一种集成方法，统一提升了市场波动性预测、欺诈检测和合规监控中的风险处理能力。所采用的概率化、可解释模型能提供可靠的结果：我们在日度标普500收益上评估了单日95% VaR（一日后）预测，训练期为2000–2019年，样本外测试期为2020–2024年。通过无条件覆盖性检验（Kupiec）和条件覆盖性检验（Christoffersen）进行的形式化检验显示，LSTM基线模型接近标称校准，而带Student-t创新项的GARCH(1,1)模型低估了尾部风险。我们提出的折扣因子动态线性模型（DLM）给出略显宽松的VaR估计，并呈现簇状的违约事件。贝叶斯逻辑回归在欺诈检测任务中提高了召回率和AUC-ROC；分层Beta状态空间模型则为合规风险评估提供了透明且自适应的表征。该流水线的特点是精确的不确定性量化、可解释性与GPU加速分析，最高可实现约50倍的加速。仍然存在的数据稀疏性（欺诈样本）和代理合规模型标签等挑战，但该框架能够产出可落地的风险洞见。未来工作将扩展特征集、探索状态切换先验并增强可扩展推断能力。

BibTeX

```
@article{2512.15739v1,
  title={Bayesian Modeling for Uncertainty Management in Financial Risk Forecasting and Compliance},
  author={Sharif Al Mamun and Rakib Hossain and Md. Jobayer Rahman and Malay Kumar Devnath and Farhana Afroz and Lisan Al Amin},
  journal={arXiv preprint arXiv:2512.15739v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15739v1}
}
```

## [FedSight AI: Multi-Agent System Architecture for Federal Funds Target Rate Prediction](http://arxiv.org/abs/2512.15728v1)

#多智能体系统#大语言模型#货币政策预测

[PDF](https://arxiv.org/pdf/2512.15728v1)
[Abstract](http://arxiv.org/abs/2512.15728v1)

 LLM

 很推荐

### 中文摘要

联邦公开市场委员会（FOMC）制定联邦基金利率，影响货币政策与宏观经济。我们提出了 FedSight AI，一种基于多智能体的框架，利用大语言模型（LLMs）模拟 FOMC 的审议过程并预测政策结果。各成员代理同时分析结构化指标与非结构化输入（如 Beige Book），就备选方案展开辩论并进行表决，复现委员会的推理过程。我们提出的 Chain-of-Draft（CoD）扩展通过强制精简的多阶段推理进一步提升了效率与准确性。在 2023–2024 年会议上的评估中，FedSight CoD 达到 93.75% 的准确率与 93.33% 的稳定性，优于包括 MiniFed 和序数随机森林（Ordinal RF）在内的基线方法，并提供了与真实 FOMC 通信相一致的透明推理过程。

BibTeX

```
@article{2512.15728v1,
  title={FedSight AI: Multi-Agent System Architecture for Federal Funds Target Rate Prediction},
  author={Yuhan Hou and Tianji Rao and Jeremy Tan and Adler Viton and Xiyue Zhang and David Ye and Abhishek Kodi and Sanjana Dulam and Aditya Paul and Yikai Feng},
  journal={arXiv preprint arXiv:2512.15728v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15728v1}
}
```

## [DiscoverDCP: A Data-Driven Approach for Construction of Disciplined Convex Programs via Symbolic Regression](http://arxiv.org/abs/2512.15721v1)

#符号回归#有纪律凸规划（DCP）#系统辨识

[PDF](https://arxiv.org/pdf/2512.15721v1)
[Abstract](http://arxiv.org/abs/2512.15721v1)

 凸优化 / 系统辨识（符号回归）

 很推荐

### 中文摘要

我们提出了 DiscoverDCP，一种将符号回归与有纪律凸规划（DCP）规则集相结合以执行系统辨识的数据驱动框架。通过强制所有候选模型表达式遵守 DCP 的组合规则，保证了输出表达式从构造上即为全局凸，从而避免了事后验证凸性这一计算上不可行的过程。该方法能够发现比传统固定参数凸表达式（例如二次函数）更为宽松且更精确的凸替代模型。所提出的方法能生成可解释、可验证且灵活的凸模型，适用于对安全性有严格要求的控制与优化任务。

BibTeX

```
@article{2512.15721v1,
  title={DiscoverDCP: A Data-Driven Approach for Construction of Disciplined Convex Programs via Symbolic Regression},
  author={Sveinung Myhre},
  journal={arXiv preprint arXiv:2512.15721v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15721v1}
}
```

## [Large Model Enabled Embodied Intelligence for 6G Integrated Perception, Communication, and Computation Network](http://arxiv.org/abs/2512.15109v1)

#LAM赋能基站#集成感知-通信-计算#云-边-端协同

[PDF](https://arxiv.org/pdf/2512.15109v1)
[Abstract](http://arxiv.org/abs/2512.15109v1)

 LLM

 很推荐

### 中文摘要

第六代（6G）通信的到来将智能置于无线架构的核心，实现感知、通信与计算的闭环融合。本文提出大型人工智能模型（LAMs）可赋予基站感知、推理与执行能力，从而将基站转变为智能基站代理（IBSA）。首先回顾了基站从单一功能的模拟设施，向分布式、软件定义，最终向由LAM赋能的IBSA演进的历史，着重分析了相应的架构、硬件平台与部署方式的变化。随后提出了一种IBSA架构，该架构将感知—认知—执行流水线与云-边-端协同及参数高效自适应机制耦合。基于此，研究了两个代表性场景：（i）用于自动驾驶的车路协同感知；（ii）用于低空无人机安全监测与对未授权无人机响应的基站普适支持。在此基础上，分析了若干关键支撑技术，包括LAM的设计与训练、边云高效推理、多模态感知与执行，以及可信安全与治理。进一步提出了涵盖通信性能、感知精度、决策可靠性、安全性与能效的整体评估框架与基准建议。最后总结了在基准构建、持续适配、可信决策与标准化等方面的开放挑战。总体而言，本工作将LAM赋能的IBSA定位为通向原生集成感知、通信与计算、并具备安全关键性的6G系统的可行路径。

BibTeX

```
@article{2512.15109v1,
  title={Large Model Enabled Embodied Intelligence for 6G Integrated Perception, Communication, and Computation Network},
  author={Zhuoran Li and Zhen Gao and Xinhua Liu and Zheng Wang and Xiaotian Zhou and Lei Liu and Yongpeng Wu and Wei Feng and Yongming Huang},
  journal={arXiv preprint arXiv:2512.15109v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15109v1}
}
```

## [Topic Discovery and Classification for Responsible Generative AI Adaptation in Higher Education](http://arxiv.org/abs/2512.16036v1)

#生成式人工智能政策#主题建模#大语言模型分类

[PDF](https://arxiv.org/pdf/2512.16036v1)
[Abstract](http://arxiv.org/abs/2512.16036v1)

 LLM

 很推荐

### 中文摘要

随着生成式人工智能（GenAI）愈发能够提供个性化学习体验和实时反馈，越来越多学生将其纳入学术工作流程，用于澄清概念、解决复杂问题，甚至复制粘贴模型生成内容完成作业。尽管GenAI有助于提升学习体验，但也引发了关于错误信息、幻觉输出及其可能削弱批判性思维和问题解决能力的担忧。为此，许多高校、学院、系和教师已经开始制定并采纳相关政策，以引导在教学环境中负责任地整合GenAI。然而，这些政策在不同机构与情境间存在较大差异，其不断演进的特性也常使学生对期望与最佳实践感到困惑。为应对这一挑战，作者设计并实现了一套自动化系统，用于从课程教学大纲和机构政策网站中发现并分类与人工智能相关的政策文本。该系统将无监督主题建模用于识别关键政策主题，并结合大语言模型（LLM）对政策文本中的GenAI许可程度与其他要求进行分类。所开发应用在主题发现上获得了0.73的连贯性得分；基于GPT-4.0的政策类别分类在八个识别出的话题上取得了0.92至0.97的精确率和0.85至0.97的召回率。通过提供结构化且可解释的政策信息，该工具有助于在教育中促进GenAI技术的安全、公平与教学一致性，并可集成至教育技术平台，帮助学生理解并遵守相关指南。

BibTeX

```
@article{2512.16036v1,
  title={Topic Discovery and Classification for Responsible Generative AI Adaptation in Higher Education},
  author={Diane Myung-kyung Woodbridge and Allyson Seba and Freddie Seba and Aydin Schwartz},
  journal={arXiv preprint arXiv:2512.16036v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16036v1}
}
```

## [Provably Extracting the Features from a General Superposition](http://arxiv.org/abs/2512.15987v1)

#超完备表示#特征分解/重构#傅里叶空间搜索

[PDF](https://arxiv.org/pdf/2512.15987v1)
[Abstract](http://arxiv.org/abs/2512.15987v1)

 表示学习 / 理论机器学习

 很推荐

### 中文摘要

普遍认为复杂的机器学习模型通常通过线性表示来编码特征，但这些特征往往以叠加（superposition）的形式存在，从而难以恢复。我们研究了一个从黑盒查询访问中学习叠加特征的基本问题：给定对函数 f 的查询访问， f(x)=∑\_{i=1}^n a\_i σ\_i(v\_i^⊤ x)，其中每个单位向量 v\_i 表示一个特征方向，σ\_i: ℝ→ℝ 是任意响应函数，我们的目标是恢复这些 v\_i 并重构函数 f。 在学习理论的术语中，叠加对应于超完备（overcomplete）情形，即特征数目超过底层维度（n>d），这对典型算法方法尤其具有挑战性。我们的主要结果是一个高效的查询算法：在带噪声的 Oracle 访问下，该算法能够识别所有响应非退化的特征方向并重构函数 f。关键在于，我们的算法适用的情形远比以往相关工作更一般——我们仅要求不同 i≠j 的 v\_i, v\_j 不近似相同，并允许任意形式的响应函数 σ\_i。总体上，本算法提出了一种在傅里叶空间中搜索的思路，通过迭代细化搜索子空间来定位隐藏的方向 v\_i。

BibTeX

```
@article{2512.15987v1,
  title={Provably Extracting the Features from a General Superposition},
  author={Allen Liu},
  journal={arXiv preprint arXiv:2512.15987v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15987v1}
}
```

## [Embedding Software Intent: Lightweight Java Module Recovery](http://arxiv.org/abs/2512.15980v1)

#Java 模块恢复#架构恢复#语言模型语义分析

[PDF](https://arxiv.org/pdf/2512.15980v1)
[Abstract](http://arxiv.org/abs/2512.15980v1)

 软件工程（LLM 辅助）

 很推荐

### 中文摘要

随着越来越多的软件系统规模达到前所未有的水平，单靠代码层面的抽象已变得不切实际。尽管架构抽象为管理这些系统提供了手段，但保持其与实际代码一致一直存在困难。Java 平台模块系统（JPMS，于 Java 9 引入）通过在语言层面支持显式模块规范，缓解了这一限制。JPMS 通过增强封装性并在 Java 项目中直接指定真实架构，提升了架构实现的表达力。尽管大量项目使用 Java 开发，但将现有单体项目模块化为 JPMS 模块仍是一个未解决的挑战，原因在于现有的架构恢复技术无法有效恢复模块。为此，本文提出了 ClassLAR（基于类与语言模型的架构恢复），这是一种新颖的、轻量且高效的方法，通过利用完全限定类名从单体 Java 系统中恢复 Java 模块。ClassLAR 利用语言模型从包名和类名中提取语义信息，捕捉结构意图与功能意图相结合的知识。在对 20 个流行 Java 项目的评估中，ClassLAR 在架构级相似性指标上优于所有最先进技术，且执行时间比它们快 3.99 到 10.50 倍。

BibTeX

```
@article{2512.15980v1,
  title={Embedding Software Intent: Lightweight Java Module Recovery},
  author={Yirui He and Yuqi Huai and Xingyu Chen and Joshua Garcia},
  journal={arXiv preprint arXiv:2512.15980v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15980v1}
}
```

## [Seeing is Believing (and Predicting): Context-Aware Multi-Human Behavior Prediction with Vision Language Models](http://arxiv.org/abs/2512.15957v1)

#视觉-语言模型#多人人类行为预测#上下文感知/场景图

[PDF](https://arxiv.org/pdf/2512.15957v1)
[Abstract](http://arxiv.org/abs/2512.15957v1)

 CV (Vision-Language Models / Multi-human behavior prediction)

 很推荐

### 中文摘要

准确预测人类行为对于在有人环境中运行的移动机器人至关重要。以往研究主要集中于从第一视角预测单一个体的动作，而许多机器人应用需要从第三视角理解多人的行为。在此背景下，我们提出了 CAMP-VLM（Context-Aware Multi-human behavior Prediction）：一种基于视觉-语言模型（VLM）的框架，该框架融合了来自视觉输入的上下文特征和来自场景图的空间感知，以提升对人-场景交互的预测能力。由于缺乏适用于观察者视角下多人人类行为预测的现成数据集，我们使用光线写实的模拟器生成合成的人类行为数据对 CAMP-VLM 进行了微调，并在合成与真实世界序列上评估模型的泛化能力。通过结合监督微调（SFT）和直接偏好优化（DPO），CAMP-VLM 在预测准确率上相较于最优基线最多提升了 66.9%。

BibTeX

```
@article{2512.15957v1,
  title={Seeing is Believing (and Predicting): Context-Aware Multi-Human Behavior Prediction with Vision Language Models},
  author={Utsav Panchal and Yuchen Liu and Luigi Palmieri and Ilche Georgievski and Marco Aiello},
  journal={arXiv preprint arXiv:2512.15957v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15957v1}
}
```

## [Leveraging Spreading Activation for Improved Document Retrieval in Knowledge-Graph-Based RAG Systems](http://arxiv.org/abs/2512.15922v1)

#传播激活#检索增强生成(RAG)#知识图谱/多跳推理

[PDF](https://arxiv.org/pdf/2512.15922v1)
[Abstract](http://arxiv.org/abs/2512.15922v1)

 LLM

 很推荐

### 中文摘要

尽管检索增强生成（RAG）系统在早期取得了一些成功并出现了多种架构，但在可靠检索并连接完成复杂推理所需的多步证据方面仍存在困难。大多数标准RAG框架将所有检索到的信息视为同等可靠，忽视了大规模文本语料中信息可信度与相互关联性的差异。基于图的RAG（GraphRAG）通过引入知识图谱将信息结构化为节点与边、捕捉实体关系并支持多步逻辑遍历，因而有望改进RAG系统。然而，GraphRAG并非总是理想的解决方案：它依赖于高质量的图表示，这要么依赖构建与维护成本高昂的现有知识图谱，要么依赖常存在不可靠性的自动化图构建流水线。此外，此类系统通常依赖大语言模型来指导图遍历与证据检索，从而面临与标准RAG类似的挑战。本文提出一种新颖的RAG框架，采用传播激活（spreading activation）算法在由自动构建的知识图相互连接的文档语料中检索信息，进而提升大语言模型在多跳问答等复杂任务上的表现。实验表明，该方法在性能上优于或可与迭代式RAG方法相媲美，且可作为即插即用模块与多种RAG方法无缝集成。将本方法与链式思考的迭代检索结合，可相比于朴素RAG在答案正确率上带来最多39%的绝对提升，并且这些结果是在小型开放权重语言模型下取得，凸显了其在资源受限场景中的有效性。

BibTeX

```
@article{2512.15922v1,
  title={Leveraging Spreading Activation for Improved Document Retrieval in Knowledge-Graph-Based RAG Systems},
  author={Jovan Pavlović and Miklós Krész and László Hajdu},
  journal={arXiv preprint arXiv:2512.15922v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15922v1}
}
```

## [Darth Vecdor: An Open-Source System for Generating Knowledge Graphs Through Large Language Model Queries](http://arxiv.org/abs/2512.15906v1)

#知识图谱#大语言模型#结构化知识抽取

[PDF](https://arxiv.org/pdf/2512.15906v1)
[Abstract](http://arxiv.org/abs/2512.15906v1)

 LLM

 很推荐

### 中文摘要

许多大语言模型（LLM）是在互联网上的大量知识语料上训练得到的。Darth Vecdor（DV）旨在将这些隐含知识提取为结构化、术语映射的 SQL 数据库（即“知识库”或“知识图谱”）。知识图谱在包括医疗在内的诸多领域可能具有重要应用。尽管可以直接向 LLM 提问而非查询 SQL 型知识图谱，但在高并发或大规模应用场景下，成本、速度、安全性与置信度等问题可能会显现。当信息先从 LLM 中预先抽取并以标准数据库形式可查询时，这些问题可能得到缓解。然而，作者发现需要解决若干问题，包括 LLM 回答中的错误、偏离主题、自由文本形式、过于笼统与不一致性，以及如何处理多要素响应。DV 在设计时加入了旨在缓解这些问题的功能。为便于使用，并支持具领域专业知识但缺乏技术背景者进行提示工程，DV 提供了简单的基于浏览器的图形用户界面。DV 已作为免费开源、可扩展软件发布，按“原样”提供，不附带任何明示或默示的保证或条件。用户需意识到使用 DV 及其输出的潜在风险和收益，并有责任确保任何使用是安全和有效的。DV 应假定可能存在缺陷，且这些缺陷可能很严重。尽管如此，作者希望适当使用当前与未来版本的 DV 及其输出能够有助于改善医疗保健。

BibTeX

```
@article{2512.15906v1,
  title={Darth Vecdor: An Open-Source System for Generating Knowledge Graphs Through Large Language Model Queries},
  author={Jonathan A. Handler},
  journal={arXiv preprint arXiv:2512.15906v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15906v1}
}
```

## [Love, Lies, and Language Models: Investigating AI's Role in Romance-Baiting Scams](http://arxiv.org/abs/2512.16280v1)

#恋爱诱骗诈骗#大语言模型滥用#AI安全/诈骗自动化

[PDF](https://arxiv.org/pdf/2512.16280v1)
[Abstract](http://arxiv.org/abs/2512.16280v1)

 LLM

 很推荐

### 中文摘要

恋爱诱骗（romance-baiting）诈骗已成为全球造成财务和情感伤害的主要来源。这类诈骗由有组织犯罪集团操控，他们拐卖数千人从事被迫劳动，要求这些人通过数周的文本对话与受害者建立情感亲密，然后施压使受害者投资欺诈性加密货币。由于该类诈骗本质上以文本为主，迫切需要探讨大规模语言模型（LLM）在当前与未来自动化中的作用。为此，我们通过对145名内部参与者和5名受害者的访谈、一个对比LLM诈骗代理与人工操作员的盲测长期对话研究，以及对商用安全过滤器的评估来展开研究。研究结果表明，LLM已在诈骗组织中被广泛部署，87%的诈骗劳动由可系统化的对话任务构成，易于被自动化取代。在为期一周的实验中，LLM代理不仅更能赢得参与者的信任（p=0.007），而且在促使受试者配合请求方面也优于人工操作员（LLM 46% 对 人类 18%）。与此同时，主流安全过滤器对恋爱诱骗对话的检测率为0.0%。综合来看，恋爱诱骗诈骗很可能适合实现大规模的LLM自动化，而现有防护措施尚不足以阻止其扩散。

BibTeX

```
@article{2512.16280v1,
  title={Love, Lies, and Language Models: Investigating AI's Role in Romance-Baiting Scams},
  author={Gilad Gressel and Rahul Pankajakshan and Shir Rozenfeld and Ling Li and Ivan Franceschini and Krishnahsree Achuthan and Yisroel Mirsky},
  journal={arXiv preprint arXiv:2512.16280v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16280v1}
}
```

## [GFLAN: Generative Functional Layouts](http://arxiv.org/abs/2512.16275v1)

#楼层平面生成#拓扑规划与几何实现#Transformer增强图神经网络

[PDF](https://arxiv.org/pdf/2512.16275v1)
[Abstract](http://arxiv.org/abs/2512.16275v1)

 CV

 很推荐

### 中文摘要

自动楼层平面图生成处在组合搜索、几何约束满足与功能设计需求的交汇处——这一融合长期以来难以用统一的计算方法处理。尽管近期基于深度学习的方法提升了该领域的性能，但它们往往难以捕捉建筑学推理的关键要素：拓扑关系在几何实现之前的优先性、功能约束通过邻接网络的传播，以及局部连通决策如何带来整体的流线（循环）模式。为了解决这些根本性挑战，本文提出了GFLAN，一种通过显式因式分解为拓扑规划与几何实现两步来重构平面图合成的生成框架。在仅给定外部边界与正门位置的条件下，我们摒弃了像素到像素或沿墙追踪的直接生成方式，转而采用原则性的两阶段分解。阶段A使用一种专门的卷积架构并配备双编码器——将不变的空间语境与随生成演化的布局状态分离开来——通过在可行放置位置上的离散概率图，按序分配房间质心到建筑包络内。阶段B构建一个将房间节点与边界顶点连接的异构图，然后应用带有Transformer增强的图神经网络，联合回归房间边界实现几何化。

BibTeX

```
@article{2512.16275v1,
  title={GFLAN: Generative Functional Layouts},
  author={Mohamed Abouagour and Eleftherios Garyfallidis},
  journal={arXiv preprint arXiv:2512.16275v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16275v1}
}
```

## [Beyond Blind Spots: Analytic Hints for Mitigating LLM-Based Evaluation Pitfalls](http://arxiv.org/abs/2512.16272v1)

#LLM评估#遗留代码现代化#分析性提示

[PDF](https://arxiv.org/pdf/2512.16272v1)
[Abstract](http://arxiv.org/abs/2512.16272v1)

 LLM

 很推荐

### 中文摘要

大型语言模型越来越多地被作为评判者（LaaJ）部署在代码生成流水线中。尽管这种做法在可扩展性上具有吸引力，但LaaJ往往会忽视领域特定的问题，这在关键评估任务中引发了对其可靠性的担忧。为更好地理解这些局限性，本文考察了一个具体的工业用例：通过生成COBOL代码实现遗留代码现代化。在该场景中，我们发现即便是已投入生产的LaaJ也会漏掉领域关键性错误，暴露出其评估能力中一致存在的盲点。为分析这些盲点，我们对生成的COBOL程序及其对应的LaaJ判定进行了人工专家驱动的分析，并据此构建了初步的分类法。基于该分类法，我们开发了一个轻量级的分析检查器，用于检测实践中观察到的30余类领域特定问题，并将检查器的输出作为“分析性提示”动态注入到评判者的提示中，促使LaaJ重新审视其可能忽略的方面。针对100个程序的测试集和四个生产级LaaJ的实验表明：单独的LaaJ只能检测出约45%的实际错误，而纯分析检查器又缺乏充分的解释深度；当将两者结合（LaaJ+Hints）时，在最佳评判者与注入提示配置下，覆盖率可达94%，且生成的解释在质量和准确性上都有显著提升。实验结果证明，分析性工具与LLM的混合方案能在已部署流水线中显著增强评估可靠性。我们同时开源了数据集和所有使用的提示。

BibTeX

```
@article{2512.16272v1,
  title={Beyond Blind Spots: Analytic Hints for Mitigating LLM-Based Evaluation Pitfalls},
  author={Ora Nova Fandina and Eitan Farchi and Shmulik Froimovich and Raviv Gal and Wesam Ibraheem and Rami Katan and Alice Podolsky},
  journal={arXiv preprint arXiv:2512.16272v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16272v1}
}
```

## [AMUSE: Audio-Visual Benchmark and Alignment Framework for Agentic Multi-Speaker Understanding](http://arxiv.org/abs/2512.16250v1)

#多模态LLM#代理式推理#时空说话人定位

[PDF](https://arxiv.org/pdf/2512.16250v1)
[Abstract](http://arxiv.org/abs/2512.16250v1)

 LLM (Multimodal)

 很推荐

### 中文摘要

近年来的多模态大模型（MLLM），如 GPT-4o 和 Qwen3-Omni，在感知能力上表现出色，但在以多说话人、对话为中心的场景中仍存在困难，这类场景要求具备代理式推理能力：跟踪谁在说话、维护角色分工，并在时间维度上将事件落地。这些问题在多模态音视频理解中尤为重要，模型需要联合推理音频与视觉流，应用于会话视频助手和会议分析等场景。为此，我们提出 AMUSE，一个围绕本质上具有代理性的任务设计的基准，要求模型将复杂的音视频交互分解为规划、落地（grounding）和反思三类步骤。AMUSE 在三种评估模式（零样本、引导、代理式）和六类任务家族上对 MLLM 进行评测，任务包括时空说话人定位和多模态对话摘要等。实验显示，现有模型在多说话人推理上表现薄弱，并在非代理和代理式评估下均表现出不一致性。受任务固有的代理性特点及近来 LLM 代理研究的启发，我们提出了 RAFT，一种数据高效的代理式对齐框架：将基于内在多模态自我评估的奖励优化与选择性参数适配相结合，以实现数据和参数的高效更新。采用 RAFT 后，我们在该基准上实现了最高达 39.52% 的相对准确率提升。AMUSE 与 RAFT 共同为审视多模态模型的代理式推理能力并提升其性能提供了实用平台。

BibTeX

```
@article{2512.16250v1,
  title={AMUSE: Audio-Visual Benchmark and Alignment Framework for Agentic Multi-Speaker Understanding},
  author={Sanjoy Chowdhury and Karren D. Yang and Xudong Liu and Fartash Faghri and Pavan Kumar Anasosalu Vasu and Oncel Tuzel and Dinesh Manocha and Chun-Liang Li and Raviteja Vemulapalli},
  journal={arXiv preprint arXiv:2512.16250v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16250v1}
}
```

## [The Evolution of Reranking Models in Information Retrieval: From Heuristic Methods to Large Language Models](http://arxiv.org/abs/2512.16236v1)

#重排序模型#检索增强生成（RAG）#大语言模型（LLM）

[PDF](https://arxiv.org/pdf/2512.16236v1)
[Abstract](http://arxiv.org/abs/2512.16236v1)

 LLM

 很推荐

### 中文摘要

重排序（reranking）是当代信息检索（IR）系统中的关键环节，通过对初始候选集合的精细筛选来提升最终呈现结果的相关性。本文对重排序方法的演进进行了全面梳理，旨在清晰呈现该领域的技术进展与现状，尤其是在检索增强生成（RAG）流水线中，检索到的文档如何显著影响生成结果的质量。文章按时间脉络回顾了重排序技术，从早期启发式方法入手，进而讨论各种复杂的神经网络架构，包括 cross-encoder、基于生成的序列模型（如 T5）以及用于建模结构信息的图神经网络（GNN）。针对神经重排序模型日益增长的计算开销，论文分析了若干提升效率的手段，尤其是通过知识蒸馏构建兼具性能与轻量化特性的替代模型。进一步地，本文勾勒了将大语言模型（LLM）引入重排序的新兴方向，考察了提示工程（prompting）策略与微调方法。本文旨在阐明各类重排序范式的核心思想、相对效果、计算特性及实际应用中的权衡，为研究与工程实践提供结构化的比较与参考。

BibTeX

```
@article{2512.16236v1,
  title={The Evolution of Reranking Models in Information Retrieval: From Heuristic Methods to Large Language Models},
  author={Tejul Pandit and Sakshi Mahendru and Meet Raval and Dhvani Upadhyay},
  journal={arXiv preprint arXiv:2512.16236v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16236v1}
}
```

## [AI-Powered Dermatological Diagnosis: From Interpretable Models to Clinical Implementation A Comprehensive Framework for Accessible and Trustworthy Skin Disease Detection](http://arxiv.org/abs/2512.16235v1)

#多模态医学影像诊断#可解释AI#家族史/遗传风险整合

[PDF](https://arxiv.org/pdf/2512.16235v1)
[Abstract](http://arxiv.org/abs/2512.16235v1)

 CV (医疗AI)

 很推荐

### 中文摘要

皮肤病影响全球19亿人，但由于专科医生资源有限和临床表现复杂，准确诊断仍然具有挑战性。家族史在皮肤疾病的易感性和治疗反应中具有重要影响，但在诊断过程中常被忽视。本研究聚焦关键问题：如何将家族史数据与临床影像结合，构建可支持临床试验验证和真实世界落地的 AI 系统，以提升皮肤病诊断能力？为此，我们提出了一套综合性的多模态 AI 框架，将基于深度学习的影像分析与结构化临床数据（包括详细的家族史模式）相结合。方法上采用了具可解释性的卷积神经网络，并与纳入遗传风险因子的临床决策树相融合。研究中通过与医疗专业人员的验证评估了 AI 辅助输出与临床预期的一致性；同时我们提出将在多样化医疗环境中开展前瞻性临床试验以进一步验证该系统的诊断性能。结果表明，整合家族史数据后，特别是在黑色素瘤、银屑病和特应性皮炎等具有遗传特征的皮肤病诊断上，AI 系统的诊断准确性得到提升。专家反馈显示该框架有助于早期发现并提供更个性化的建议；正式的临床试验已在规划中。该框架设计便于嵌入临床工作流，并通过可解释性 AI 机制维持决策透明性与可信性。

BibTeX

```
@article{2512.16235v1,
  title={AI-Powered Dermatological Diagnosis: From Interpretable Models to Clinical Implementation A Comprehensive Framework for Accessible and Trustworthy Skin Disease Detection},
  author={Satya Narayana Panda and Vaishnavi Kukkala and Spandana Iyer},
  journal={arXiv preprint arXiv:2512.16235v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16235v1}
}
```

## [Neural emulation of gravity-driven geohazard runout](http://arxiv.org/abs/2512.16221v1)

#地质灾害溃流预测#神经网络仿真#数字高程模型（DEM）

[PDF](https://arxiv.org/pdf/2512.16221v1)
[Abstract](http://arxiv.org/abs/2512.16221v1)

 科学机器学习（地球科学/地质灾害建模）

 很推荐

### 中文摘要

预测地质灾害的行进与堆积对于保护生命、基础设施和生态系统至关重要。快速质量流动（包括山体滑坡和雪崩）在多种环境中造成数千人伤亡，且常常从源头移动数公里。控制这些流动的源条件和物质特性差异很大，使得行进距离的预估十分困难，尤其对于可能突然暴露于严重冲击的下游社区。要在大尺度上准确预测行进，需要既具有物理现实性又计算高效的模型，但现有方法在速度与物理真实性之间存在根本性的权衡。本文训练了一个机器学习模型，用于在代表性的真实地形上快速预测地质灾害的行进与沉积。该模型能够高精度预测流体的影响范围和沉积厚度，计算速度比数值求解器快100到10,000倍。模型在超过10,000个真实地形数字高程模型切片上，基于超过100,000次数值模拟进行训练，并能重现关键物理行为（包括改道与沉积模式），同时在不同流动类型、规模和地形间具有良好泛化能力。我们的结果表明，神经网络仿真使得在多样真实地形上实现快速的空间分辨行进预测成为可能，为减灾、基于影响的预报以及大规模预警系统在空间和时间尺度上的扩展开辟了新途径，凸显了神经仿真在将物理现实的地质灾害建模扩展到实用预警尺度方面的潜力。

BibTeX

```
@article{2512.16221v1,
  title={Neural emulation of gravity-driven geohazard runout},
  author={Lorenzo Nava and Ye Chen and Maximillian Van Wyk de Vries},
  journal={arXiv preprint arXiv:2512.16221v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16221v1}
}
```

## [PDE-Agent: A toolchain-augmented multi-agent framework for PDE solving](http://arxiv.org/abs/2512.16214v1)

#偏微分方程求解#多智能体协作#工具链增强的LLM调用

[PDF](https://arxiv.org/pdf/2512.16214v1)
[Abstract](http://arxiv.org/abs/2512.16214v1)

 LLM

 很推荐

### 中文摘要

偏微分方程（PDE）的求解是工程与科学研究的基石。传统求解方法流程繁琐，依赖大量手工设置与领域专长。尽管物理约束神经网络（PINNs）提出了端到端的神经网络解法，且诸如 DeepXDE 的框架增强了自动化能力，但这些方法仍高度依赖专家知识，尚未实现完全自主化。本文将 PDE 求解问题表述为由大模型驱动的智能体对外部工具的调用，提出了 PDE-Agent——首个工具链增强的多智能体协作框架，兼具大模型的推理能力与外部工具的可控性，能够从自然语言描述出发实现 PDE 的自动化求解。PDE-Agent 通过两项关键创新整合多智能体与多工具协作的优势：（1）带有图记忆的 Prog-Act 框架用于多智能体协作，通过局部修正与全局迭代的双循环机制实现有效的动态规划与错误纠正；（2）集成了资源池（Resource-Pool）并采用工具与参数分离机制以支持多工具协作，集中管理运行时工件并弥补现有框架中的工具依赖缺口。为验证并评估这一新的求解范式，作者构建了 PDE-Bench——一个针对基于智能体的工具协同求解场景的多类型 PDE 基准，并提出了用于评估工具协调性的多层级度量。实验结果表明，PDE-Agent 在复杂多步、跨步依赖任务中表现出更强的适用性与性能。该工具链增强的多智能体 PDE 求解新范式有望推动自动化科学计算的未来发展。作者将开源代码与数据集以供公众使用。

BibTeX

```
@article{2512.16214v1,
  title={PDE-Agent: A toolchain-augmented multi-agent framework for PDE solving},
  author={Jianming Liu and Ren Zhu and Jian Xu and Kun Ding and Xu-Yao Zhang and Gaofeng Meng and Cheng-Lin Liu},
  journal={arXiv preprint arXiv:2512.16214v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16214v1}
}
```

## [LAPX: Lightweight Hourglass Network with Global Context](http://arxiv.org/abs/2512.16089v1)

#轻量级网络#人体姿态估计#自注意力/全局上下文

[PDF](https://arxiv.org/pdf/2512.16089v1)
[Abstract](http://arxiv.org/abs/2512.16089v1)

 CV

 很推荐

### 中文摘要

人体姿态估计是计算机视觉中的一项关键任务。尽管许多达到最先进精度的方法在性能上表现优异，但通常伴随大量参数和显著的计算开销。为减少模型体积与计算成本，已有多种轻量化变体被提出，但其中若干方法仍包含不利于边缘设备高效部署的组件。此外，过度简化以强调边缘设备推理速度的模型，往往以牺牲精度为代价。为了解决这些问题，我们提出了 LAPX，一种在 Hourglass 架构基础上引入自注意力以捕获全局上下文信息的轻量级网络，基于先前工作 LAP 进行改进。除了采用自注意力模块外，LAPX 还改进了阶段设计并优化了轻量注意力模块。该方法在 MPII 与 COCO 两个基准数据集上取得了具有竞争力的结果，模型参数仅为 2.3M，并具备实时推理性能，验证了其在边缘设备上的适用性。

BibTeX

```
@article{2512.16089v1,
  title={LAPX: Lightweight Hourglass Network with Global Context},
  author={Haopeng Zhao and Marsha Mariya Kappan and Mahdi Bamdad and Francisco Cruz},
  journal={arXiv preprint arXiv:2512.16089v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16089v1}
}
```

## [Scaling Text2SQL via LLM-efficient Schema Filtering with Functional Dependency Graph Rerankers](http://arxiv.org/abs/2512.16083v1)

#Text2SQL#模式过滤#功能依赖图重排序

[PDF](https://arxiv.org/pdf/2512.16083v1)
[Abstract](http://arxiv.org/abs/2512.16083v1)

 LLM

 很推荐

### 中文摘要

大多数现代的 Text2SQL 系统在向大型语言模型（LLM）提示时，会将完整的数据库模式——主要是列信息——与用户问题一并提供。尽管在小型数据库上该方法有效，但在超出 LLM 上下文限制的真实世界模式上会失败，即便对于商用模型亦是如此。最新的 Spider 2.0 基准就体现了这一点：其包含数百张表和数以万计的列，现有系统在此类场景中经常失效。当前的缓解措施要么依赖代价高昂的多步骤提示流水线，要么通过将各列与用户问题独立匹配并排序来过滤列，从而忽略了列与列之间的结构关系。为了解决可扩展性问题，我们提出了 GRAST-SQL —— 一个开源且对 LLM 高效的模式过滤框架，它通过以下方式压缩 Text2SQL 的提示：(i) 使用融合了列值和元数据的查询感知型 LLM 编码器对列进行初步排序；(ii) 基于功能依赖构建轻量级图变换器对相互关联的列进行重排序；(iii) 采用 Steiner 树启发式算法选择保持连通性的子模式。基于真实数据集的实验表明，GRAST-SQL 在召回率几乎达到完美的同时，其精度优于 CodeS、SchemaExP、Qwen 重排序器和基于嵌入的检索器；且保持亚秒级的中位延迟，能够扩展到包含超过 23,000 列的模式。我们的源码已开源，地址：https://github.com/thanhdath/grast-sql。

BibTeX

```
@article{2512.16083v1,
  title={Scaling Text2SQL via LLM-efficient Schema Filtering with Functional Dependency Graph Rerankers},
  author={Thanh Dat Hoang and Thanh Tam Nguyen and Thanh Trung Huynh and Hongzhi Yin and Quoc Viet Hung Nguyen},
  journal={arXiv preprint arXiv:2512.16083v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16083v1}
}
```

## [Evaluation of Generative Models for Emotional 3D Animation Generation in VR](http://arxiv.org/abs/2512.16081v1)

#情感驱动3D动画#虚拟现实用户评估#生成模型评估

[PDF](https://arxiv.org/pdf/2512.16081v1)
[Abstract](http://arxiv.org/abs/2512.16081v1)

 CV

 很推荐

### 中文摘要

社交互动中除了语言之外还包含面部表情和身体动作等非语言信号来传达情感。生成模型在创建与语音同步的全身非语言动画方面展示了良好潜力，但在二维场景中使用统计指标的评估无法充分反映用户感知的情绪，限制了我们对模型有效性的理解。为此，本研究在虚拟现实（VR）环境中评估情感驱动的三维动画生成模型，强调以用户为中心的指标：情绪唤醒真实性、自然性、愉悦度、多样性和交互质量，场景为实时的人-代理交互。通过一项包含48名参与者的用户研究，我们考察了三种最新的语音驱动三维动画方法在两种情绪（快乐——高唤醒，和中性——中等唤醒）下的情绪感知质量。此外，我们将这些生成模型与基于重建的人类真实表情数据进行比较，以评估各方法的优劣及其复制真实人类面部与身体表情的接近程度。结果表明：显式建模情感的方法在情绪识别准确率上优于仅关注语音同步的方法；参与者对快乐动画在真实感和自然性上的评分显著高于对中性动画的评分，凸显当前生成模型在处理微妙情绪状态方面的局限性；在面部表情质量上，生成模型普遍不如基于重建的方法；所有方法在动画愉悦度和交互质量上得分较低，强调在生成模型开发中纳入以用户为中心评估的重要性；同时，参与者对所有生成模型的动画多样性给予了正面认可。

BibTeX

```
@article{2512.16081v1,
  title={Evaluation of Generative Models for Emotional 3D Animation Generation in VR},
  author={Kiran Chhatre and Renan Guarese and Andrii Matviienko and Christopher Peters},
  journal={arXiv preprint arXiv:2512.16081v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16081v1}
}
```

## [Weakly Supervised Pneumonia Localization from Chest X-Rays Using Deep Neural Network and Grad-CAM Explanations](http://arxiv.org/abs/2511.00456v5)

#弱监督学习#Grad-CAM 可解释性#胸部X光肺炎定位

[PDF](https://arxiv.org/pdf/2511.00456v5)
[Abstract](http://arxiv.org/abs/2511.00456v5)

 CV (Medical Imaging)

 很推荐

### 中文摘要

胸部X光成像是肺炎诊断的常用手段，但要精确定位受累区域通常需要耗时且昂贵的像素级标注。为解决这一限制，本研究提出了一种基于弱监督的深度学习框架，利用Gradient-weighted Class Activation Mapping（Grad-CAM）实现肺炎的分类与定位。该方法不依赖像素级标注，而是利用图像级标签生成具有临床意义的热图以突出肺炎受累区域。我们在相同训练条件下评估了七种预训练深度模型（包括Vision Transformer），并采用focal loss及按患者划分的数据拆分以防止数据泄露。实验结果表明，所有模型均达到了较高的分类准确率（96%–98%），其中ResNet-18与EfficientNet-B0在总体性能上表现最佳，MobileNet-V3则提供了高效的轻量级替代方案。Grad-CAM热图可视化验证了模型关注于具有临床相关性的肺区，支持在放射学诊断中采用可解释的人工智能方法。总体而言，本工作展示了弱监督且具有可解释性的模型在提高AI辅助肺炎筛查透明性与临床信任方面的潜力。

BibTeX

```
@article{2511.00456v5,
  title={Weakly Supervised Pneumonia Localization from Chest X-Rays Using Deep Neural Network and Grad-CAM Explanations},
  author={Kiran Shahi and Anup Bagale},
  journal={arXiv preprint arXiv:2511.00456v5},
  year={2025},
  url={http://arxiv.org/abs/2511.00456v5}
}
```

## [TTP: Test-Time Padding for Adversarial Detection and Robust Adaptation on Vision-Language Models](http://arxiv.org/abs/2512.16523v1)

#测试时填充#对抗检测与鲁棒性#视觉-语言模型

[PDF](https://arxiv.org/pdf/2512.16523v1)
[Abstract](http://arxiv.org/abs/2512.16523v1)

 VLM (视觉-语言/多模态)

 很推荐

### 中文摘要

视觉-语言模型（VLM），例如 CLIP，在零样本识别上取得了显著性能，但对抗扰动仍然使其高度脆弱，在安全关键场景中存在重大风险。以往的训练期防御依赖对抗微调，需标注数据且代价高昂，而现有的测试期策略无法可靠地区分干净输入与对抗输入，从而无法同时实现最佳的对抗鲁棒性与干净样本精度。为了解决这些限制，我们提出了测试时填充（Test-Time Padding，TTP），这是一种轻量的防御框架，在推理时先进行对抗检测，再针对性地进行适配。TTP 通过比较在空间填充（padding）前后计算的 CLIP 特征嵌入之间的余弦相似度变化来识别对抗输入，且该相似度位移能在不同架构和数据集间给出一个通用阈值以实现可靠检测。对于被检测为对抗的样本，TTP 使用可训练的填充以恢复被破坏的注意力模式，并辅以基于相似度的集成策略以获得更鲁棒的最终预测。对于干净样本，TTP 默认保持不变，或可选择性地融合现有的测试期适配技术以进一步提升精度。在多种 CLIP 骨干网络和细粒度基准上的全面实验表明，TTP 始终优于最先进的测试期防御方法，在不损害干净样本精度的前提下显著提升了对抗鲁棒性。本文代码将很快开源。

BibTeX

```
@article{2512.16523v1,
  title={TTP: Test-Time Padding for Adversarial Detection and Robust Adaptation on Vision-Language Models},
  author={Zhiwei Li and Yitian Pang and Weining Wang and Zhenan Sun and Qi Li},
  journal={arXiv preprint arXiv:2512.16523v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16523v1}
}
```

## [PoseMoE: Mixture-of-Experts Network for Monocular 3D Human Pose Estimation](http://arxiv.org/abs/2512.16494v1)

#单目3D人体姿态估计#混合专家网络#深度表示解耦

[PDF](https://arxiv.org/pdf/2512.16494v1)
[Abstract](http://arxiv.org/abs/2512.16494v1)

 CV (单目3D人体姿态估计)

 很推荐

### 中文摘要

基于提升（lifting）的方式通过将检测到的2D姿态作为中间表示，已经主导了单目3D人体姿态估计领域。最终3D人体姿态的2D分量可以直接受益于检测到的2D姿态，而其深度分量则必须从头估计。现有提升型方法将检测到的2D姿态与未知深度在同一纠缠的特征空间中编码，从而把深度的不确定性显式引入到2D姿态表示，限制了整体估计精度。本文指出深度表示对估计过程至关重要：当深度处于初始完全未知状态时，将深度特征与2D姿态特征共同编码会损害估计效果；相反，当通过网络初步对深度进行可靠估计后，再与2D姿态信息一并编码则有利于性能提升。为了解决这一矛盾，我们提出了一种用于单目3D姿态估计的混合专家网络PoseMoE。该方法包括：(1) 一个由专门化专家模块组成的混合专家网络，分别对检测良好的2D姿态特征进行精炼并学习深度特征，从而在编码过程中解耦2D姿态与深度特征，减少不确定深度对2D特征的显式影响；(2) 一个跨专家知识聚合模块，用于汇聚跨专家的时空上下文信息，通过2D姿态与深度之间的双向映射增强特征。大量实验表明，所提出的PoseMoE在Human3.6M、MPI-INF-3DHP和3DPW三大常用数据集上均优于传统的提升型方法。

BibTeX

```
@article{2512.16494v1,
  title={PoseMoE: Mixture-of-Experts Network for Monocular 3D Human Pose Estimation},
  author={Mengyuan Liu and Jiajie Liu and Jinyan Zhang and Wenhao Li and Junsong Yuan},
  journal={arXiv preprint arXiv:2512.16494v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16494v1}
}
```

## [AI4EOSC: a Federated Cloud Platform for Artificial Intelligence in Scientific Research](http://arxiv.org/abs/2512.16455v1)

#联邦云平台#MLOps#可复现性

[PDF](https://arxiv.org/pdf/2512.16455v1)
[Abstract](http://arxiv.org/abs/2512.16455v1)

 MLOps / 联邦云平台

 很推荐

### 中文摘要

本文介绍了一个专门支持科研工作负载中人工智能的联邦计算平台。该平台注重可复现的部署，为物理分布的电子基础设施联盟提供一致且透明的访问。通过全面的服务目录，平台能够提供覆盖完整机器学习生命周期的集成用户体验，包括模型开发（配备专用交互式开发环境）、训练（提供GPU资源、标注工具、实验跟踪和联邦学习支持）以及部署（在云连续体的各个层面提供多样化的部署选项）。平台还提供用于AI模型可追溯性和可复现性的工具，集成了不同的AI模型提供者、数据集和存储资源，使用户能够与更广泛的机器学习生态系统交互。最后，平台易于定制，以降低外部社区的采用门槛。

BibTeX

```
@article{2512.16455v1,
  title={AI4EOSC: a Federated Cloud Platform for Artificial Intelligence in Scientific Research},
  author={Ignacio Heredia and Álvaro López García and Germán Moltó and Amanda Calatrava and Valentin Kozlov and Alessandro Costantini and Viet Tran and Mario David and Daniel San Martín and Marcin Płóciennik and Marta Obregón Ruiz and Saúl Fernandez and Judith Sáinz-Pardo Díaz and Miguel Caballer and Caterina Alarcón Marín and Stefan Dlugolinsky and Martin Šeleng and Lisana Berberi and Khadijeh Alibabaei and Borja Esteban Sanchis and Pedro Castro and Giacinto Donvito and Diego Aguirre and Sergio Langarita and Vicente Rodriguez and Leonhard Duda and Andrés Heredia Canales and Susana Rebolledo Ruiz and João Machado and Giang Nguyen and Fernando Aguilar Gómez and Jaime Díez},
  journal={arXiv preprint arXiv:2512.16455v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16455v1}
}
```

## [Towards AI-Supported Research: a Vision of the TIB AIssistant](http://arxiv.org/abs/2512.16447v1)

#生成式AI#学术研究助手#平台架构与编排

[PDF](https://arxiv.org/pdf/2512.16447v1)
[Abstract](http://arxiv.org/abs/2512.16447v1)

 LLM

 很推荐

### 中文摘要

生成式人工智能与大型语言模型的快速发展，有望改造科研工作方式，为增强学术工作流程提供前所未有的机会。然而，由于学科需求差异、有限的AI素养、工具与代理的协调复杂性，以及生成式AI在科研场景下准确性尚不明朗，将AI有效地整合到科研工作中仍然是一个挑战。本文提出了TIB AIssistant的愿景——一个与领域无关的人机协同平台，旨在支持跨学科研究人员在科学发现过程中的各类任务。该平台由模块化组件构成，包括提示与工具库、共享数据存储以及灵活的编排框架，协同支持创意产生、文献分析、方法论开发、数据分析和学术写作等研究生命周期各阶段的任务。我们描述了该平台的概念框架、系统架构以及早期原型实现，展示了该方法的可行性及潜在影响。

BibTeX

```
@article{2512.16447v1,
  title={Towards AI-Supported Research: a Vision of the TIB AIssistant},
  author={Sören Auer and Allard Oelen and Mohamad Yaser Jaradeh and Mutahira Khalid and Farhana Keya and Sasi Kiran Gaddipati and Jennifer D'Souza and Lorenz Schlüter and Amirreza Alasti and Gollam Rabby and Azanzi Jiomekong and Oliver Karras},
  journal={arXiv preprint arXiv:2512.16447v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16447v1}
}
```

## [StarCraft+: Benchmarking Multi-agent Algorithms in Adversary Paradigm](http://arxiv.org/abs/2512.16444v1)

#多智能体强化学习#对抗性评测基准#StarCraft II 环境

[PDF](https://arxiv.org/pdf/2512.16444v1)
[Abstract](http://arxiv.org/abs/2512.16444v1)

 多智能体强化学习 (MARL)

 很推荐

### 中文摘要

深度多智能体强化学习（MARL）算法在协作智能领域蓬勃发展，StarCraft 多智能体挑战赛（SMAC）被广泛用作该领域的基准。但现有 MARL 算法的对手通常是以固定内置 AI 模式配置和控制的，这导致在算法评估上缺乏多样性和通用性。为解决此问题，本工作构建了一个算法对算法的多智能体对抗环境，称为 StarCraft II Battle Arena（SC2BA），以在对抗范式下刷新 MARL 算法的基准测试。以 StarCraft 为基础设施，SC2BA 环境专为算法间对抗设计，兼顾公平性、可用性与可定制性；同时开发了具有易用接口/模块的对抗版 PyMARL（APyMARL）库。基于 SC2BA，我们在两类对抗模式下对若干经典 MARL 算法进行了基准测试：双算法配对对抗（pairwise adversary）和多算法混合对抗（multi-algorithm mixed adversary），前者考察成对算法之间的对抗，后者关注来自一组算法的多样行为对目标算法的综合对抗。大量基准实验揭示了这些成熟算法在有效性、敏感性与可扩展性方面的一些发人深省的问题与现象。SC2BA 环境及可复现的实验已在 Github 上开源，我们认为该工作有望为未来若干年 MARL 领域的发展奠定新的基准和方向。

BibTeX

```
@article{2512.16444v1,
  title={StarCraft+: Benchmarking Multi-agent Algorithms in Adversary Paradigm},
  author={Yadong Li and Tong Zhang and Bo Huang and Zhen Cui},
  journal={arXiv preprint arXiv:2512.16444v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16444v1}
}
```

## [Synthelite: Chemist-aligned and feasibility-aware synthesis planning with LLMs](http://arxiv.org/abs/2512.16424v1)

#逆合成规划#大语言模型#化学可行性评估

[PDF](https://arxiv.org/pdf/2512.16424v1)
[Abstract](http://arxiv.org/abs/2512.16424v1)

 LLM

 很推荐

### 中文摘要

计算机辅助合成规划（CASP）长期以来被视为合成化学家的重要辅助工具。然而，现有方法常缺乏与专家交互的机制，难以整合化学家的领域见解。本文提出Synthelite，一种使用大语言模型（LLM）直接提出逆合成转化的合成规划框架。Synthelite 利用LLM的内在化学知识和推理能力生成端到端的合成路线，同时通过自然语言提示允许专家进行干预。实验表明，Synthelite 能灵活适应多样的用户指定约束，在策略约束和起始原料约束的合成任务中最高可达95%的成功率。此外，Synthelite 在路线设计中还能考虑化学可行性。我们期待Synthelite 成为一种实用工具，并推动以LLM为中心的合成规划新范式的发展。

BibTeX

```
@article{2512.16424v1,
  title={Synthelite: Chemist-aligned and feasibility-aware synthesis planning with LLMs},
  author={Nguyen Xuan-Vu and Daniel Armstrong and Milena Wehrbach and Andres M Bran and Zlatko Jončev and Philippe Schwaller},
  journal={arXiv preprint arXiv:2512.16424v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16424v1}
}
```

## [Delay-Aware Multi-Stage Edge Server Upgrade with Budget Constraint](http://arxiv.org/abs/2512.16792v1)

#多阶段边缘服务器升级#任务卸载与延迟优化#预算约束的MEC资源规划

[PDF](https://arxiv.org/pdf/2512.16792v1)
[Abstract](http://arxiv.org/abs/2512.16792v1)

 Edge Computing（MEC）/资源管理与网络规划

 很推荐

### 中文摘要

本文提出了多阶段边缘服务器升级（M-ESU）这一新的网络规划问题，旨在通过若干阶段（例如多年周期）对现有多接入边缘计算（MEC）系统进行分期升级。具体地，问题包括两类关键决策：一是是否部署新增边缘服务器或对已部署服务器进行升级，二是如何进行任务卸载以最大化满足延迟要求的任务平均数量。该框架同时考虑：新增服务器部署与现有服务器的容量升级；每阶段预算约束；服务器部署与升级成本（以美元计）及成本折旧率；服务器计算资源；任务数量及其增长率（以百分比计）；任务规模增大及延迟要求随时间变得更为严格等约束条件。针对该问题，文中给出两种解法：一种为混合整数线性规划（MILP）模型，可为小规模网络求得最优解；另一种为高效启发式算法M-ESU/H，适用于大规模网络。仿真结果表明：在小规模网络中，M-ESU/H所得解与最优解的差距不超过1.25%，且运行速度快数个数量级；在大规模网络中，与仅考虑部署或优先部署/升级的三种替代启发式方法相比，M-ESU/H在相同预算与需求增长条件下可使任务满足率提升最多达21.57%，验证了其可扩展性与在长期MEC系统规划中的实际价值。

BibTeX

```
@article{2512.16792v1,
  title={Delay-Aware Multi-Stage Edge Server Upgrade with Budget Constraint},
  author={Endar Suprih Wihidayat and Sieteng Soh and Kwan-Wu Chin and Duc-son Pham},
  journal={arXiv preprint arXiv:2512.16792v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16792v1}
}
```

## [KineST: A Kinematics-guided Spatiotemporal State Space Model for Human Motion Tracking from Sparse Signals](http://arxiv.org/abs/2512.16791v1)

#运动学引导#时空表示学习#人体动作追踪

[PDF](https://arxiv.org/pdf/2512.16791v1)
[Abstract](http://arxiv.org/abs/2512.16791v1)

 CV

 很推荐

### 中文摘要

全身动作追踪在 AR/VR 应用中起着关键作用，连接了物理与虚拟交互。然而，要基于头戴显示器（AR/VR 场景中的主要设备）获得的稀疏信号重建真实且多样的全身姿态仍具挑战性。现有的姿态重建方法往往计算代价高，或将空间与时间依赖单独建模，难以在准确性、时间连贯性与效率之间取得平衡。为了解决上述问题，我们提出了 KineST，一种新颖的运动学引导状态空间模型，能够有效提取时空依赖并融合局部与全局姿态感知。该方法的创新体现在两点：首先，为了更好地捕捉复杂的关节关系，我们将状态空间二重性（State Space Duality）框架中的扫描策略重新设计为运动学引导的双向扫描，从而嵌入运动学先验；其次，采用混合时空表示学习方法，将空间语境与时间语境紧密耦合，以在精度与平滑性之间取得平衡。除此之外，文中引入了一种几何角速度损失，用以对旋转变化施加物理上有意义的约束，进一步提升动作稳定性。大量实验表明，KineST 在轻量化框架下，在精度与时间一致性方面均表现优越。项目页面：https://kaka-1314.github.io/KineST/

BibTeX

```
@article{2512.16791v1,
  title={KineST: A Kinematics-guided Spatiotemporal State Space Model for Human Motion Tracking from Sparse Signals},
  author={Shuting Zhao and Zeyu Xiao and Xinrong Chen},
  journal={arXiv preprint arXiv:2512.16791v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16791v1}
}
```

## [EasyV2V: A High-quality Instruction-based Video Editing Framework](http://arxiv.org/abs/2512.16920v1)

#指令式视频编辑#时空掩码控制#文本到视频预训练

[PDF](https://arxiv.org/pdf/2512.16920v1)
[Abstract](http://arxiv.org/abs/2512.16920v1)

 CV

 很推荐

### 中文摘要

尽管图像编辑取得了快速进展，视频编辑仍然相对欠发达，面临一致性、可控性和泛化能力等挑战。本文研究了数据、模型架构与控制机制三方面的设计空间，并提出了一个简单而有效的指令式视频编辑框架 EasyV2V。在数据方面，我们将已有的专家模块与快速逆向方法组合以构建多样化的视频对；通过单帧监督和共享仿射运动的伪对，将图像编辑对提升为视频训练对；挖掘带有密集描述的片段以构造视频对，并加入过渡监督以学习编辑如何随时间展开。在模型方面，我们观察到预训练的文本到视频模型本身具备一定的编辑能力，因此设计可以大幅简化：通过简单的序列拼接进行条件输入，并结合轻量级的 LoRA 微调即可训练出强性能模型。在控制方面，我们用单一掩码机制统一实现时空控制，并可选地支持参考图像输入。总体上，EasyV2V 支持灵活的输入形式（例如 video+text、video+mask+text、video+mask+reference+text），并在视频编辑任务上取得了领先结果，优于同期及商业系统。

BibTeX

```
@article{2512.16920v1,
  title={EasyV2V: A High-quality Instruction-based Video Editing Framework},
  author={Jinjie Mai and Chaoyang Wang and Guocheng Gordon Qian and Willi Menapace and Sergey Tulyakov and Bernard Ghanem and Peter Wonka and Ashkan Mirzaei},
  journal={arXiv preprint arXiv:2512.16920v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16920v1}
}
```

## [Impacts of Racial Bias in Historical Training Data for News AI](http://arxiv.org/abs/2512.16901v1)

#历史数据偏见#新闻领域NLP#可解释性与公平性

[PDF](https://arxiv.org/pdf/2512.16901v1)
[Abstract](http://arxiv.org/abs/2512.16901v1)

 NLP

 很推荐

### 中文摘要

人工智能技术已经迅速进入涉及大规模文本语料的商业和研究应用场景，包括计算新闻学研究和新闻编辑部环境。这些基于来自多种来源的现有数据训练的模型，可以被视为编码了数十年观念和刻板印象的历史文物。本文考察了一个基于广泛使用的《纽约时报注释语料库》训练得到的多标签分类器的具体实例。我们在研究使用中发现了令人担忧的“blacks”（黑人）主题标签。通过定量与定性方法，我们调查了该标签在训练语料中的使用情况、在训练后分类器中可能编码的概念，以及这些概念如何影响模型的使用。借助可解释性人工智能方法，我们发现“blacks”标签在一定程度上作为对若干弱势群体的通用“种族主义检测器”在发挥作用。然而，该标签在应对现代示例时表现不佳，例如 COVID-19 期间的反亚裔仇恨新闻以及有关“黑人的命也是命”（Black Lives Matter）运动的报道。本案例研究揭示了审查模型中嵌入偏见的重要性，说明在新闻编辑部场景中类似应用可能产生意外输出，进而影响故事发现、受众定位、摘要生成等多种潜在用途。对新闻机构而言，这暴露了一个根本性的张力：如何在采用 AI 驱动工作流工具的同时减少在新闻报道中复制历史性偏见的风险。

BibTeX

```
@article{2512.16901v1,
  title={Impacts of Racial Bias in Historical Training Data for News AI},
  author={Rahul Bhargava and Malene Hornstrup Jespersen and Emily Boardman Ndulue and Vivica Dsouza},
  journal={arXiv preprint arXiv:2512.16901v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16901v1}
}
```

## [LinkedOut: Linking World Knowledge Representation Out of Video LLM for Next-Generation Video Recommendation](http://arxiv.org/abs/2512.16891v1)

#视频大语言模型#世界知识表示#视频推荐

[PDF](https://arxiv.org/pdf/2512.16891v1)
[Abstract](http://arxiv.org/abs/2512.16891v1)

 VLLM（视频大语言模型）/ 推荐系统

 很推荐

### 中文摘要

视频大语言模型（VLLMs）通过在互联网规模数据上预训练，能够实现具备世界知识的视频理解，已在电影分析和视频问答等任务上展现出潜力。然而，将 VLLM 部署到视频推荐等下游任务仍面临挑战：实际系统需要支持多视频输入、轻量化骨干、低延迟的序列推理和快速响应。现实中存在的问题包括：一是基于解码的生成在序列推理时延迟高；二是典型接口不支持多视频输入；三是将输出限制为语言会丢失对下游视觉任务重要的细粒度视觉信息。我们认为这些限制源自缺乏一种既保留像素级细节又能利用世界知识的表征。为此我们提出 LinkedOut，一种直接从视频中提取 VLLM 世界知识的表征，旨在实现快速推理、支持多视频历史并打破语言瓶颈。LinkedOut 利用 VLLM 在原始帧上生成语义性强且具知识感知的 token，受可提示查询及可选辅助模态引导。我们引入一种跨层知识融合的专家模型（MoE），从丰富的 VLLM 特征中选择合适的抽象层次，从而实现个性化、可解释且低延迟的推荐。据我们所知，LinkedOut 是首个在不依赖人工标注标签下直接作用于原始帧的 VLLM 驱动的视频推荐方法，并在标准基准上取得了最先进的结果。可解释性研究和消融实验验证了层次多样性与层间融合的优势，指明了一条在推荐等下游视觉任务中充分利用 VLLM 世界知识先验与视觉推理的实用路径。

BibTeX

```
@article{2512.16891v1,
  title={LinkedOut: Linking World Knowledge Representation Out of Video LLM for Next-Generation Video Recommendation},
  author={Haichao Zhang and Yao Lu and Lichen Wang and Yunzhe Li and Daiwei Chen and Yunpeng Xu and Yun Fu},
  journal={arXiv preprint arXiv:2512.16891v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16891v1}
}
```

## [Training Together, Diagnosing Better: Federated Learning for Collagen VI-Related Dystrophies](http://arxiv.org/abs/2512.16876v1)

#联邦学习#罕见病诊断#免疫荧光显微图像分类

[PDF](https://arxiv.org/pdf/2512.16876v1)
[Abstract](http://arxiv.org/abs/2512.16876v1)

 医疗影像 / 联邦学习

 很推荐

### 中文摘要

机器学习在罕见病（如VI型胶原相关肌营养不良，COL6-RD）诊断中的应用，受到可用数据稀缺与分散的根本性限制。跨医院、机构或国家扩展样本收集常常面临隐私、监管和后勤方面的严重障碍，难以突破。联邦学习（FL）通过在保持患者数据本地和私密的前提下，支持跨去中心化数据集的协同模型训练，提供了有希望的解决方案。本研究报告了一项基于Sherpa.ai联邦学习平台的全球性FL实践，该平台在两个国际机构的分布式数据集上应用联邦学习，用于基于患者来源成纤维细胞培养物的VI型胶原免疫荧光显微图像对COL6-RD进行诊断。我们的方法训练出能够将COL6-RD患者图像分类为三类主要致病机制组（外显子跳跃、甘氨酸取代和假外显子插入）的机器学习模型。该方法取得了0.82的F1分数，优于单一机构模型的0.57–0.75。结果表明，与孤立的机构内模型相比，联邦学习在诊断效用和泛化能力上均有显著提升。除提高诊断准确性外，我们预计该方法还将辅助不确定意义变异（VUS）的解释，并指导测序策略的优先级，以识别新的致病变异。

BibTeX

```
@article{2512.16876v1,
  title={Training Together, Diagnosing Better: Federated Learning for Collagen VI-Related Dystrophies},
  author={Astrid Brull and Sara Aguti and Véronique Bolduc and Ying Hu and Daniel M. Jimenez-Gutierrez and Enrique Zuazua and Joaquin Del-Rio and Oleksii Sliusarenko and Haiyan Zhou and Francesco Muntoni and Carsten G. Bönnemann and Xabi Uribe-Etxebarria},
  journal={arXiv preprint arXiv:2512.16876v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16876v1}
}
```

## [Semi-Supervised Online Learning on the Edge by Transforming Knowledge from Teacher Models](http://arxiv.org/abs/2512.16866v1)

#边缘机器学习#在线学习#知识蒸馏与主动学习

[PDF](https://arxiv.org/pdf/2512.16866v1)
[Abstract](http://arxiv.org/abs/2512.16866v1)

 Edge ML（边缘机器学习）

 很推荐

### 中文摘要

边缘机器学习（Edge ML）允许利用分布于网络边缘的大量数据来训练机器学习模型。然而，许多现有方法假设模型在中心化环境中静态训练后再部署，这在面对未见数据时效果欠佳。为解决该问题，在线边缘机器学习允许模型在边缘设备上直接训练并随新数据持续更新。本文探讨在线边缘机器学习中的一个核心挑战：如何为真正的未来未见数据点确定标签。我们提出了知识转换（Knowledge Transformation，KT）方法，这是一种将知识蒸馏、主动学习与因果推理相结合的混合方法。KT在主动学习中充当“可查询的专家”，通过从教师模型转换知识来为学生模型生成伪标签以进行训练。为验证方法有效性，我们在仿真实验中设计了两种设置： (1) 采用较不稳定的教师模型；(2) 采用相对较稳定的教师模型。结果表明，在存在稳定教师模型时，学生模型最终可以达到其预期的最大性能。KT在以下情形中具备潜在优势： (1) 教师任务较为通用，即现有预训练模型可能已能胜任该任务，从而无需从零训练教师模型；以及/或 (2) 学生任务的标签难以或昂贵难以获取。

BibTeX

```
@article{2512.16866v1,
  title={Semi-Supervised Online Learning on the Edge by Transforming Knowledge from Teacher Models},
  author={Jiabin Xue},
  journal={arXiv preprint arXiv:2512.16866v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16866v1}
}
```

## [LLMCache: Layer-Wise Caching Strategies for Accelerated Reuse in Transformer Inference](http://arxiv.org/abs/2512.16843v1)

#层级缓存#推理加速#语义相似性匹配

[PDF](https://arxiv.org/pdf/2512.16843v1)
[Abstract](http://arxiv.org/abs/2512.16843v1)

 LLM

 很推荐

### 中文摘要

基于 Transformer 的语言模型在众多任务中取得了显著性能，但其高昂的推理延迟对实时和大规模部署构成了重大挑战。现有的缓存机制（例如基于 token 的键值缓存）虽能在自回归解码中带来加速，但在范围和适用性上存在局限。本文提出 LLMCache，一种新颖的层级缓存框架，通过基于输入序列语义相似性的中间激活重用来加速 Transformer 推理。与以往工作不同，LLMCache 与模型无关，既适用于编码器也适用于解码器结构，并支持在任意 Transformer 层进行缓存。我们引入了一种轻量级的指纹匹配机制来识别语义相近的输入，并提出自适应的逐出策略以管理缓存陈旧问题。在 BERT 和 GPT-2 上、以 SQuAD、WikiText-103 和 OpenBookQA 为测试集的实验表明，LLMCache 在推理时间上最高可实现 3.1 倍加速且精度下降小于 0.5%。结果表明，LLMCache 是一种面向实际应用的通用 Transformer 推理优化方案。

BibTeX

```
@article{2512.16843v1,
  title={LLMCache: Layer-Wise Caching Strategies for Accelerated Reuse in Transformer Inference},
  author={Harsh Vardhan Bansal},
  journal={arXiv preprint arXiv:2512.16843v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16843v1}
}
```

## [Grammar-Forced Translation of Natural Language to Temporal Logic using LLMs](http://arxiv.org/abs/2512.16814v1)

#自然语言到时序逻辑#语法约束解码#大语言模型

[PDF](https://arxiv.org/pdf/2512.16814v1)
[Abstract](http://arxiv.org/abs/2512.16814v1)

 LLM

 很推荐

### 中文摘要

将自然语言（NL）翻译为诸如时序逻辑（TL）等形式化语言，对于人与机器人及自主系统的交互至关重要。现有最先进的方法通常将该任务分为原子命题（AP）抽取（lifting）阶段和逻辑翻译阶段，但在精确抽取、共指消解以及有限数据学习方面存在困难。本文提出了一种名为Grammar Forced Translation（GraFT）的NL到TL翻译框架。基于对比观察：先前工作在抽取和翻译阶段均让语言模型从完整词表中逐步预测标记，而GraFT通过在每一步将可输出标记集合从完整词表限制为少数候选，从而降低了两步任务的复杂度。该解空间的约束是基于每个子问题的特性获得的，并给出了理论性理由说明解空间缩减为何能提高学习效率。我们在CW、GLTL和Navi基准上评估了GraFT的有效性。与最先进的翻译方法相比，GraFT在端到端翻译准确率上平均提升5.49%，在域外（out-of-domain）翻译准确率上平均提升14.06%。

BibTeX

```
@article{2512.16814v1,
  title={Grammar-Forced Translation of Natural Language to Temporal Logic using LLMs},
  author={William English and Dominic Simon and Sumit Kumar Jha and Rickard Ewetz},
  journal={arXiv preprint arXiv:2512.16814v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16814v1}
}
```

## [Optimizing Agentic Language Model Inference via Speculative Tool Calls](http://arxiv.org/abs/2512.15834v1)

#工具调用推测#推理引擎优化#工具缓存API

[PDF](https://arxiv.org/pdf/2512.15834v1)
[Abstract](http://arxiv.org/abs/2512.15834v1)

 LLM

 很推荐

### 中文摘要

语言模型（LM）对外部工具的依赖日益增强。基于LM的代理框架通常通过工具与环境交互以搜索文件、运行代码、调用API等；此外，面向推理的现代LM使用诸如网页搜索和Python代码执行等工具来增强其推理能力。尽管工具显著提升了LM的功能，但在推理过程中也带来了性能瓶颈。本文提出了一系列系统级优化，通过对工具调用进行推测并强制将序列保留在推理引擎中以最小化开销，从而缓解此类性能瓶颈。我们的优化在承载LM代理推理时可将吞吐量提高数百个令牌每秒。文中还提供了算法的理论分析，以便指导可产生最佳性能的推测配置；此外，作者建议引入新的“tool cache” API 端点，便于LM提供方采用这些优化方案。

BibTeX

```
@article{2512.15834v1,
  title={Optimizing Agentic Language Model Inference via Speculative Tool Calls},
  author={Daniel Nichols and Prajwal Singhania and Charles Jekel and Abhinav Bhatele and Harshitha Menon},
  journal={arXiv preprint arXiv:2512.15834v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15834v1}
}
```

## [GinSign: Grounding Natural Language Into System Signatures for Temporal Logic Translation](http://arxiv.org/abs/2512.16770v1)

#自然语言到时序逻辑#原子签名绑定（Grounding）#形式化验证与模型检测

[PDF](https://arxiv.org/pdf/2512.16770v1)
[Abstract](http://arxiv.org/abs/2512.16770v1)

 NLP

 很推荐

### 中文摘要

自然语言（NL）到时序逻辑（TL）的翻译使工程师能够在无需手工编写形式化规范的情况下指定、验证和执行系统行为——这是构建可信自主系统的核心能力。尽管现有的NL到TL翻译框架在初步结果上令人鼓舞，但这些系统要么显式假设可以获得准确的原子绑定，要么在有绑定情形下的翻译精度较低。本文提出了一个名为GinSign的框架，用于将自然语言绑定到系统签名以实现时序逻辑翻译。该框架引入了一个绑定模型，学习将自然语言片段映射到给定系统签名的抽象任务：在给定一个升阶（lifted）的自然语言规范和系统签名𝒮的情况下，分类器必须将每个升阶原子命题分配到签名定义的原子集合𝒫中的某一元素。我们将绑定任务进行层次化分解——先预测谓词标签，再选择类型匹配的常量参数。把该任务从自由形式的生成问题转化为结构化的分类问题，使得可以使用较小的掩码语言模型（masked LMs），并消除了对昂贵大型模型的依赖。跨多个领域的实验证明，不包含绑定步骤的框架虽然能生成语法上正确的升阶LTL，但语义上往往与目标表达式不等价；而我们的框架支持下游的模型检测，并实现了95.5%的有绑定逻辑等价得分，比现有最优方法提高了1.4倍。

BibTeX

```
@article{2512.16770v1,
  title={GinSign: Grounding Natural Language Into System Signatures for Temporal Logic Translation},
  author={William English and Chase Walker and Dominic Simon and Rickard Ewetz},
  journal={arXiv preprint arXiv:2512.16770v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16770v1}
}
```

## [Plausibility as Failure: How LLMs and Humans Co-Construct Epistemic Error](http://arxiv.org/abs/2512.16750v1)

#可置信性#人机共构的认知错误#LLM评估

[PDF](https://arxiv.org/pdf/2512.16750v1)
[Abstract](http://arxiv.org/abs/2512.16750v1)

 LLM

 很推荐

### 中文摘要

大规模语言模型（LLM）日益被用作日常推理中的认知伙伴，但其错误往往通过预测性指标来分析，而较少考察其对人类判断的解释性影响。本研究把“失败”理解为由模型生成的可置信性与人类解释性判断共同塑造的关系性破裂，考察了不同形式的认知性失败如何出现、被掩盖及被容忍。我们通过三轮、多模型评估，采用跨学科任务并逐步细化的评估框架，观察评估者在语言、知识与可信度维度上如何解读模型回答。结果显示，LLM的错误从可预测性失误向诠释性（hermeneutic）失真转移：语言流畅性、结构连贯性和表面看似合理的引用常常掩盖更深层的意义扭曲。评估者频繁混淆正确性、相关性、偏见、证据基础与一致性等判断标准，表明人类判断会将分析性区分坍缩为由形式与流畅性塑造的直觉启发式。随着轮次推进与任务密度增加，我们观察到系统性的验证负担与认知漂移：评估者越来越依赖表层线索，使得格式良好但错误的回答被接受为可信。由此可见，错误并非仅为模型行为的属性，而是生成性可置信性与人类解释捷径共同构建的结果。理解AI的认识性失败需要将评估重构为一种关系性的解释过程，从而模糊系统失效与人类误校准之间的界限。本研究对LLM评估方法、数字素养培训及可信人机通信设计提出了重要启示。

BibTeX

```
@article{2512.16750v1,
  title={Plausibility as Failure: How LLMs and Humans Co-Construct Epistemic Error},
  author={Claudia Vale Oliveira and Nelson Zagalo and Filipe Silva and Anabela Brandao and Syeda Faryal Hussain Khurrum and Joaquim Santos},
  journal={arXiv preprint arXiv:2512.16750v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16750v1}
}
```

## [Protecting Deep Neural Network Intellectual Property with Chaos-Based White-Box Watermarking](http://arxiv.org/abs/2512.16658v1)

#白盒水印#混沌序列（Logistic映射）#模型知识产权保护

[PDF](https://arxiv.org/pdf/2512.16658v1)
[Abstract](http://arxiv.org/abs/2512.16658v1)

 模型安全 / IP保护（白盒水印）

 很推荐

### 中文摘要

随着深度神经网络（DNN）在各领域的广泛应用，模型的知识产权保护和滥用风险日益凸显。本文提出了一种基于混沌序列的高效且鲁棒的白盒水印框架，将所有权信息嵌入到网络中间层的参数中。所用水印由著名的混沌映射——Logistic映射生成，其对初始参数高度敏感，随后将该混沌序列注入选定层的权重，且无需修改模型结构或显著降低预测性能。为验证所有权，设计了基于遗传算法的恢复流程，通过优化提取序列与再生序列的相似度来恢复原始混沌参数。作者在MNIST和CIFAR-10分类任务上进行了大量实验，结果表明水印在微调后仍可检测且对模型精度影响可忽略。除数值恢复外，研究还通过权重密度图的可视化分析和基于激活的分类器来区分原始、带水印与被篡改的模型。总体而言，该方法为白盒场景下的模型所有权嵌入与验证提供了一种灵活可扩展的解决方案，适用于需要知识产权保护的实际应用场景。

BibTeX

```
@article{2512.16658v1,
  title={Protecting Deep Neural Network Intellectual Property with Chaos-Based White-Box Watermarking},
  author={Sangeeth B and Serena Nicolazzo and Deepa K. and Vinod P},
  journal={arXiv preprint arXiv:2512.16658v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16658v1}
}
```

## [Prefix Probing: Lightweight Harmful Content Detection for Large Language Models](http://arxiv.org/abs/2512.16650v1)

#有害内容检测#前缀探测#低延迟黑盒方法

[PDF](https://arxiv.org/pdf/2512.16650v1)
[Abstract](http://arxiv.org/abs/2512.16650v1)

 LLM

 很推荐

### 中文摘要

大型语言模型在实际的安全敏感应用中常面临检测准确性、推理延迟和部署成本三者之间的权衡。本文提出了 Prefix Probing，一种黑盒的有害内容检测方法，通过比较“同意/执行”与“拒绝/安全”两类开头前缀的条件对数概率，并利用前缀缓存将检测开销降低到接近首 token 延迟的水平。在推理阶段，该方法仅需对探测前缀计算一次对数概率以产出有害性分数并应用阈值判定，无需调用额外模型或多阶段推理。为增强前缀的判别能力，作者设计了一种高效的前缀构造算法，自动发现信息量高的前缀，从而显著提升检测性能。大量实验表明，Prefix Probing 在检测效果上可与主流外部安全模型媲美，同时仅带来极小的计算开销且无需额外模型部署，展现出很强的实用性与高效性。

BibTeX

```
@article{2512.16650v1,
  title={Prefix Probing: Lightweight Harmful Content Detection for Large Language Models},
  author={Jirui Yang and Hengqi Guo and Zhihui Lu and Yi Zhao and Yuansen Zhang and Shijing Hu and Qiang Duan and Yinggui Wang and Tao Wei},
  journal={arXiv preprint arXiv:2512.16650v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16650v1}
}
```

## [Stackelberg Learning from Human Feedback: Preference Optimization as a Sequential Game](http://arxiv.org/abs/2512.16626v1)

#人类反馈#Stackelberg 顺序博弈#偏好优化

[PDF](https://arxiv.org/pdf/2512.16626v1)
[Abstract](http://arxiv.org/abs/2512.16626v1)

 LLM

 很推荐

### 中文摘要

我们提出了 Stackelberg Learning from Human Feedback（SLHF），一种用于偏好优化的新框架。SLHF 将对齐问题建模为两个策略之间的顺序移动博弈：Leader（领导者）先提交动作，Follower（跟随者）在观察到领导者动作的条件下做出响应。该方法将偏好优化分解为对跟随者的精化问题与对抗性环境下对领导者的优化问题。不同于为动作分配标量奖励的 Reinforcement Learning from Human Feedback（RLHF），或寻求同时移动均衡的 Nash Learning from Human Feedback（NLHF），SLHF 利用顺序博弈的非对称性以捕捉更丰富的偏好结构。SLHF 的顺序设计天然支持推理时的精化：跟随者可以学习改进领导者的动作，这些改进可通过迭代采样在推理阶段被利用。我们比较了 SLHF、RLHF 与 NLHF 的解概念，并阐明了 SLHF 在一致性、对数据敏感性的响应以及对不可传递偏好的鲁棒性方面的关键优势。大规模语言模型上的实验表明，SLHF 在多样化偏好数据集上实现了强对齐效果，可扩展至 0.5B 到 8B 参数规模，并且其在推理时得到的精化能够在不同模型家族之间迁移而无需额外微调。

BibTeX

```
@article{2512.16626v1,
  title={Stackelberg Learning from Human Feedback: Preference Optimization as a Sequential Game},
  author={Barna Pásztor and Thomas Kleine Buening and Andreas Krause},
  journal={arXiv preprint arXiv:2512.16626v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16626v1}
}
```

## [OLAF: Towards Robust LLM-Based Annotation Framework in Empirical Software Engineering](http://arxiv.org/abs/2512.15979v1)

#LLM标注#可靠性与校准#可复现性与透明性

[PDF](https://arxiv.org/pdf/2512.15979v1)
[Abstract](http://arxiv.org/abs/2512.15979v1)

 LLM

 很推荐

### 中文摘要

大型语言模型（LLM）在经验软件工程（ESE）中越来越多地用于自动化或辅助标注任务，例如对提交（commits）、问题（issues）和定性资料进行标签化。然而，这类标注的可信性与可复现性仍然研究不足。现有研究常缺乏对可靠性、校准与漂移的标准化度量，并且往往省略关键信息配置细节。我们主张应将基于LLM的标注视为一种测量过程，而不仅仅是纯自动化的活动。在此立场论文中，我们提出了“面向LLM标注的操作化框架（OLAF）”，该概念框架组织并强调了若干关键构念：可靠性、校准、漂移、共识、聚合与透明性。本文旨在推动方法论讨论并为未来实证工作提供方向，以实现软件工程研究中更具透明性与可复现性的基于LLM的标注实践。

BibTeX

```
@article{2512.15979v1,
  title={OLAF: Towards Robust LLM-Based Annotation Framework in Empirical Software Engineering},
  author={Mia Mohammad Imran and Tarannum Shaila Zaman},
  journal={arXiv preprint arXiv:2512.15979v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15979v1}
}
```

## [SALVE: Sparse Autoencoder-Latent Vector Editing for Mechanistic Control of Neural Networks](http://arxiv.org/abs/2512.15938v1)

#稀疏自编码器#机制可解释性#模型权重编辑

[PDF](https://arxiv.org/pdf/2512.15938v1)
[Abstract](http://arxiv.org/abs/2512.15938v1)

 CV

 很推荐

### 中文摘要

深度神经网络取得了显著性能，但仍然难以解释与控制。我们提出了 SALVE（Sparse Autoencoder-Latent Vector Editing），一个统一的“发现、验证与控制”框架，旨在连接机制性可解释性与模型编辑。通过带 ℓ1 正则的自编码器，我们在无监督条件下学习到一种稀疏且与模型本身结构一致的特征基。我们使用 Grad-FAM（一种基于特征的显著性映射方法）对这些特征进行验证，将潜在特征在输入空间中进行可视化落地。利用自编码器的结构，我们在权重空间上执行精确且永久的干预，从而实现对类别定义性特征和跨类特征的连续调节。进一步地，我们推导出了关键抑制阈值 α\_{crit}，用于量化每个类别对其主导特征的依赖程度，从而支持细粒度的鲁棒性诊断。我们在卷积网络（ResNet-18）和基于 Transformer 的模型（ViT-B/16）上验证了该方法，展示了对模型行为一致且可解释的控制能力。本工作提供了一种将特征发现转化为可执行模型编辑的原则化方法，促进了透明且可控的 AI 系统的发展。

BibTeX

```
@article{2512.15938v1,
  title={SALVE: Sparse Autoencoder-Latent Vector Editing for Mechanistic Control of Neural Networks},
  author={Vegard Flovik},
  journal={arXiv preprint arXiv:2512.15938v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15938v1}
}
```

## [VET Your Agent: Towards Host-Independent Autonomy via Verifiable Execution Traces](http://arxiv.org/abs/2512.15892v1)

#可验证执行轨迹#代理身份文档(AID)#受信任执行与密码学证明

[PDF](https://arxiv.org/pdf/2512.15892v1)
[Abstract](http://arxiv.org/abs/2512.15892v1)

 LLM

 很推荐

### 中文摘要

近年来，大型语言模型（LLM）的进展催生了新一代自主代理，这些代理可以在较长时间内持续运行并代表用户管理敏感资源。由于能够在无需直接监督的情况下执行操作，这类代理在金融管理、争端解决和治理等高风险领域的应用越来越受关注。然而在实际部署中，代理通常在被宿主控制的基础设施上执行，宿主可能篡改模型、输入或输出，从而破坏代理的真实自治性。
为了解决这一问题，本文提出了VET（Verifiable Execution Traces，可验证执行轨迹）——一个形式化框架，旨在实现对代理输出的宿主无关认证并朝宿主无关的自治迈进。VET的核心是代理身份文档（Agent Identity Document，AID），该文档规定了代理的配置以及验证所需的证明系统。VET具有组合性，支持多种证明机制，包括受信任硬件、简洁的密码学证明以及经过公证的TLS记录（Web Proofs）。
我们为基于API的LLM代理实现了VET，并在真实工作负载上进行了评估。结果表明，对于当前作为黑盒且含有密钥的API调用，Web Proofs 是最实用的选择，其开销通常低于直接API调用的3倍；而对于公开的API调用，开销更低的TEE代理（受信任执行环境代理）通常已足够。作为案例研究，我们部署了一个可验证的交易代理，该代理为每个决策生成证明，并将Web Proofs 与 TEE代理组合使用。我们的结果表明，基于当前技术实现实用的宿主不可知认证已是可行的，为未来实现完全宿主无关自治的系统奠定了基础。

BibTeX

```
@article{2512.15892v1,
  title={VET Your Agent: Towards Host-Independent Autonomy via Verifiable Execution Traces},
  author={Artem Grigor and Christian Schroeder de Witt and Simon Birnbach and Ivan Martinovic},
  journal={arXiv preprint arXiv:2512.15892v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15892v1}
}
```

## [Foundation Models in Biomedical Imaging: Turning Hype into Reality](http://arxiv.org/abs/2512.15808v1)

#基础模型#生物医学影像#因果推断与可信性

[PDF](https://arxiv.org/pdf/2512.15808v1)
[Abstract](http://arxiv.org/abs/2512.15808v1)

 CV (Medical Imaging / Foundation Models)

 很推荐

### 中文摘要

基础模型（Foundation Models，FMs）正在推动跨领域的人工智能发生显著转变，生物医学影像领域亦不例外。这类模型旨在超越狭义的模式识别，向模拟复杂的临床推理、理解复杂的空间关系并以前所未有的灵活性融合多模态数据发展。然而，模型的潜力与当前现实之间存在显著差距：临床评估与部署面临重大挑战。本文对现有最先进方法进行批判性评估，通过分析其核心能力与局限来辨析炒作与真实进展。我们提出了一套推理分类法，涵盖从模拟的序列逻辑与空间理解到显式符号知识的整合，以评估这些模型是否具备真正的认知能力，或仅停留在表层模式拟合。我们认为，超越统计相关性的关键前沿在于因果推断，这是构建能理解因果关系的鲁棒模型的必要路径。此外，文章讨论了部署中的若干核心问题——可信性、偏见与安全性，细分了算法偏见、数据偏差与隐私问题以及模型幻觉等挑战，并强调需要更具包容性、严格且具临床相关性的验证框架来确保安全与伦理应用。结论指出，尽管“自治的AI医生”愿景尚遥远，但当前更现实的是强大的技术与辅助工具的出现，这些工具可为临床实践带来益处。生物医学影像领域中基础模型的未来不应仅依赖规模扩张，而应侧重于开发混合型、具因果意识且可验证安全的系统，以增强而非替代人类专业能力。

BibTeX

```
@article{2512.15808v1,
  title={Foundation Models in Biomedical Imaging: Turning Hype into Reality},
  author={Amgad Muneer and Kai Zhang and Ibraheem Hamdi and Rizwan Qureshi and Muhammad Waqas and Shereen Fouad and Hazrat Ali and Syed Muhammad Anwar and Jia Wu},
  journal={arXiv preprint arXiv:2512.15808v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15808v1}
}
```

## [Explainable Ethical Assessment on Human Behaviors by Generating Conflicting Social Norms](http://arxiv.org/abs/2512.15793v1)

#社会规范生成#伦理评估#对比学习

[PDF](https://arxiv.org/pdf/2512.15793v1)
[Abstract](http://arxiv.org/abs/2512.15793v1)

 LLM

 很推荐

### 中文摘要

人类行为通常由社会规范所引导或约束，社会规范被定义为共享的常识性规则。例如，在“举报目击到的犯罪”这一行为背后，存在这样一种社会规范来指导我们的行为，即“被期望有勇气去举报犯罪”。当前基于大规模数据训练但未基于显式规范的AI系统在评估行为的倾向性（即支持或反对某一行为）时，往往难以给出可解释的理由，从而降低可信度。通过考虑社会规范来模拟人类评估者，可以帮助模型更好地理解并预测行为的倾向性。多重规范往往同时起作用，而彼此冲突的规范会产生张力并直接影响人类决策，例如在是否“举报目击到的犯罪”的抉择中，需要在“勇敢”与“自我保护”之间权衡。本文提出了ClarityEthic，一种新颖的伦理评估方法，通过生成导致行为的冲突社会规范来提升倾向性预测与解释能力，并采用对比学习策略增强语言模型的道德推理能力。大量实验表明，本方法优于强基线，人工评估也证实所生成的社会规范能为对人类行为的评估提供合理的解释。

BibTeX

```
@article{2512.15793v1,
  title={Explainable Ethical Assessment on Human Behaviors by Generating Conflicting Social Norms},
  author={Yuxi Sun and Wei Gao and Hongzhan Lin and Jing Ma and Wenxuan Zhang},
  journal={arXiv preprint arXiv:2512.15793v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15793v1}
}
```

## [A Systematic Analysis of Biases in Large Language Models](http://arxiv.org/abs/2512.15792v1)

#大语言模型偏见#公平性评估#多维偏见分析

[PDF](https://arxiv.org/pdf/2512.15792v1)
[Abstract](http://arxiv.org/abs/2512.15792v1)

 LLM

 很推荐

### 中文摘要

大型语言模型（LLMs）已迅速成为获取信息和支持人类决策的不可或缺工具。然而，确保这些模型在不同情境中保持公平性，对于其安全和负责任的部署至关重要。本研究对四种广泛采用的LLM进行了系统性分析，探讨其在政治、意识形态、联盟、语言和性别等维度上的潜在偏见与倾向。通过一系列精心设计的实验，我们分别通过新闻摘要检验政治中立性、通过新闻立场分类分析意识形态偏向、通过联合国投票模式评估对特定地缘政治联盟的倾向、在多语言故事续写中检测语言偏见，并通过世界价值观调查的应答揭示性别相关的亲和性。结果表明，尽管这些LLM在设计与调优上旨在保持中立与公正，但仍然表现出多种类型的偏见与倾向，提示在实际应用中需持续关注与缓解这些问题。

BibTeX

```
@article{2512.15792v1,
  title={A Systematic Analysis of Biases in Large Language Models},
  author={Xulang Zhang and Rui Mao and Erik Cambria},
  journal={arXiv preprint arXiv:2512.15792v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15792v1}
}
```

## [Toward Agentic Environments: GenAI and the Convergence of AI, Sustainability, and Human-Centric Spaces](http://arxiv.org/abs/2512.15787v1)

#生成式人工智能#边缘计算#可持续性

[PDF](https://arxiv.org/pdf/2512.15787v1)
[Abstract](http://arxiv.org/abs/2512.15787v1)

 GenAI/边缘计算

 很推荐

### 中文摘要

近年来，人工智能（AI），特别是生成式人工智能（GenAI）和大规模语言模型（LLM）的进展，使人机交互在从银行到医疗等各个领域变得更加频繁、高效且易于获取。嵌入数字设备的AI工具在个人与组织层面支持决策与运营管理，包括资源分配、工作流自动化以及实时数据分析。然而，以云为中心的主流部署方式由于计算需求高昂而带来了显著的环境足迹。在此背景下，本文提出了“智能体化环境”（agentic environments）的概念——一种以可持续性为导向的AI框架，超越被动反应系统，结合生成式AI、多智能体系统与边缘计算，以降低技术对环境的影响。智能体化环境旨在实现更高效的资源利用、改善生活质量并在设计中体现可持续性，同时通过去中心化的边缘驱动方案增强数据隐私。本文基于二次研究并辅以来自若干领先科技公司AI从业者的焦点小组与半结构化访谈原始数据，提出了一个概念性框架，并从个人领域、商业与职业应用以及城市运营三个视角进行考察。研究结果强调，智能体化环境通过优化资源利用与强化数据隐私，有潜力促进可持续生态体系的发展；结论部分提出了通过边缘驱动部署模型减少对高能耗云基础设施依赖的若干建议。

BibTeX

```
@article{2512.15787v1,
  title={Toward Agentic Environments: GenAI and the Convergence of AI, Sustainability, and Human-Centric Spaces},
  author={Przemek Pospieszny and Dominika P. Brodowicz},
  journal={arXiv preprint arXiv:2512.15787v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15787v1}
}
```

## [The Principle of Proportional Duty: A Knowledge-Duty Framework for Ethical Equilibrium in Human and Artificial Systems](http://arxiv.org/abs/2512.15740v1)

#可比例责任#不确定性与谦逊建模#可审计的AI伦理

[PDF](https://arxiv.org/pdf/2512.15740v1)
[Abstract](http://arxiv.org/abs/2512.15740v1)

 AI伦理

 很推荐

### 中文摘要

传统伦理框架在处理不确定性下的决策时常显得力不从心，往往将不确定性视为对行为的简单约束。本文提出了“可比例责任原则”（PPD），这是一个新的框架，用以刻画伦理责任如何随主体的认识状态而变化。该框架指出，道德责任并不会因不确定性而消失，而是发生转化：随着不确定性增加，“行动责任”（即果断行动的义务）会按比例转换为“修复责任”（即验证、询问与消除不确定性的积极义务）。这一动态关系可表示为 D\_total = K[(1-HI) + HI \* g(C\_signal)]，其中总责任是知识（K）、谦逊/不确定性系数（HI）与情境信号强度（C\_signal）的函数。蒙特卡洛模拟表明，维持一个正的基础谦逊系数（lambda > 0）的系统能产生更稳定的责任分配，并降低过度自信决策的风险。通过将谦逊形式化为系统参数，PPD 提供了一种可数学处理的道德责任刻画方式，有助于设计可审计的 AI 决策系统。本文在临床伦理、受益人权利法、经济治理和人工智能四个领域中应用该框架以验证其跨学科有效性；研究结果表明，可比例责任作为复杂系统中的一种稳定化原则，能够通过在认识信心与情境风险之间动态平衡，防止越权与遗漏。

BibTeX

```
@article{2512.15740v1,
  title={The Principle of Proportional Duty: A Knowledge-Duty Framework for Ethical Equilibrium in Human and Artificial Systems},
  author={Timothy Prescher},
  journal={arXiv preprint arXiv:2512.15740v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15740v1}
}
```

## [Deep Reinforcement Learning Optimization for Uncertain Nonlinear Systems via Event-Triggered Robust Adaptive Dynamic Programming](http://arxiv.org/abs/2512.15735v1)

#事件触发机制#扩展状态观测器#自适应动态规划

[PDF](https://arxiv.org/pdf/2512.15735v1)
[Abstract](http://arxiv.org/abs/2512.15735v1)

 RL

 很推荐

### 中文摘要

本文提出了一种统一的控制架构，将基于强化学习的控制器与具有扰动抑制能力的扩展状态观测器（ESO）耦合，并引入事件触发机制（ETM）以限制不必要的计算。ESO用于实时估计系统状态和总体扰动，为有效的扰动补偿提供基础。在缺乏精确系统模型的情况下，采用基于价值迭代的自适应动态规划（ADP）方法对策略进行近似，以获得近似最优行为。ETM的引入确保只有当状态偏差超过预设阈值时才执行学习参数更新，从而避免过度学习并显著降低计算负担。通过基于Lyapunov的方法对闭环系统的稳定性性质进行了分析。数值实验进一步验证了所提出方法在保持良好控制性能和扰动容忍度的同时，相较于传统的时间触发ADP方案实现了采样与处理开销的显著降低。

BibTeX

```
@article{2512.15735v1,
  title={Deep Reinforcement Learning Optimization for Uncertain Nonlinear Systems via Event-Triggered Robust Adaptive Dynamic Programming},
  author={Ningwei Bai and Chi Pui Chan and Qichen Yin and Tengyang Gong and Yunda Yan and Zezhi Tang},
  journal={arXiv preprint arXiv:2512.15735v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15735v1}
}
```

## [From Personalization to Prejudice: Bias and Discrimination in Memory-Enhanced AI Agents for Recruitment](http://arxiv.org/abs/2512.16532v1)

#记忆增强个性化#偏见与歧视#招聘公平性

[PDF](https://arxiv.org/pdf/2512.16532v1)
[Abstract](http://arxiv.org/abs/2512.16532v1)

 LLM

 很推荐

### 中文摘要

大型语言模型（LLM）使得AI代理具备了在多种任务中理解、推理和交互的高级能力。为这些代理加入记忆机制能够增强它们在交互间的连续性、从历史经验中学习，并随着时间提升行为和响应的相关性，这类机制通常被称为记忆增强的个性化。尽管通过记忆实现的个性化带来了明显的好处，但也可能引入偏见风险。尽管先前有若干研究揭示了机器学习和LLM中的偏见问题，记忆增强型个性化代理所导致的偏见仍然缺乏充分研究。以招聘场景为示例，我们模拟了记忆增强个性化代理的行为，研究在代理运行的不同阶段偏见是否以及如何被引入和放大。基于采用安全训练的LLM的代理实验表明，个性化过程会系统性地引入并强化偏见，强调了在记忆增强的LLM驱动AI代理中需额外采取保护措施或设置代理安全防护（guardrails）。

BibTeX

```
@article{2512.16532v1,
  title={From Personalization to Prejudice: Bias and Discrimination in Memory-Enhanced AI Agents for Recruitment},
  author={Himanshu Gharat and Himanshi Agrawal and Gourab K. Patro},
  journal={arXiv preprint arXiv:2512.16532v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16532v1}
}
```

## [Scalable Agentic Reasoning for Designing Biologics Targeting Intrinsically Disordered Proteins](http://arxiv.org/abs/2512.15930v1)

#内在无序蛋白（IDP）#多智能体推理#生物药物设计

[PDF](https://arxiv.org/pdf/2512.15930v1)
[Abstract](http://arxiv.org/abs/2512.15930v1)

 计算生物学

 很推荐

### 中文摘要

内在无序蛋白（IDP）因其在疾病中的关键作用而成为重要的治疗靶点——约80%的与癌症相关蛋白包含长的无序区——但其缺乏稳定的二级/三级结构使其被认为“不可成药”。尽管近期计算方法（如扩散模型）能够设计出对IDP具有高亲和力的结合体，但将这些方法应用于实际药物发现，需要能够在复杂构象集合上进行推理并在大规模上协调多种计算工具的自主系统。为应对这一挑战，我们设计并实现了StructBioReasoner，一种用于设计可靶向IDP的生物制剂的可扩展多智能体系统。StructBioReasoner采用一种新颖的基于锦标赛的推理框架，专门化的智能体相互竞争以生成与优化治疗假设，从而自然地分配计算负载以高效探索广阔的设计空间。智能体将领域知识与文献综述、AI结构预测、分子模拟和稳定性分析相结合，并通过可扩展的联邦智能体中间件Academy在高性能计算（HPC）基础设施上协调执行。我们在Der f 21和NMNAT-2上对StructBioReasoner进行了基准测试，结果显示：在Der f 21案例中，针对787个设计并验证的候选分子，超过50%的候选在结合自由能方面优于文献中的人工设计参考结合体；对于更具挑战性的NMNAT-2蛋白，我们从97,066个结合体中鉴定出三种结合模式，其中包括已被广泛研究的NMNAT2:p53界面。由此，StructBioReasoner为在Exascale平台上开展针对IDP的智能体式推理系统奠定了基础。

BibTeX

```
@article{2512.15930v1,
  title={Scalable Agentic Reasoning for Designing Biologics Targeting Intrinsically Disordered Proteins},
  author={Matthew Sinclair and Moeen Meigooni and Archit Vasan and Ozan Gokdemir and Xinran Lian and Heng Ma and Yadu Babuji and Alexander Brace and Khalid Hossain and Carlo Siebenschuh and Thomas Brettin and Kyle Chard and Christopher Henry and Venkatram Vishwanath and Rick L. Stevens and Ian T. Foster and Arvind Ramanathan},
  journal={arXiv preprint arXiv:2512.15930v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15930v1}
}
```

## [Scaling Laws for Energy Efficiency of Local LLMs](http://arxiv.org/abs/2512.16531v1)

#本地大模型#能效标度律#模型压缩与预处理

[PDF](https://arxiv.org/pdf/2512.16531v1)
[Abstract](http://arxiv.org/abs/2512.16531v1)

 LLM

 很推荐

### 中文摘要

在边缘设备上部署本地大型语言模型和视觉-语言模型时，必须在模型精度与受限的计算与能耗预算之间权衡。尽管图形处理器在现代人工智能部署中占主导地位，但绝大多数消费级硬件——包括笔记本、台式机、工业控制器和嵌入式系统——仍然依赖中央处理器。针对仅使用中央处理器进行本地语言与视觉-语言推理的计算规律，目前仍缺乏系统性研究。本文在两类具有代表性的中央处理器平台上系统性地基准测试了大型语言模型与视觉-语言模型：反映主流笔记本级部署的 MacBook Pro M2，以及代表受限低功耗嵌入式场景的 Raspberry Pi 5。我们采用基于处理器与内存使用的连续采样并结合曲线下面积积分的统一方法，刻画了语言模型的计算负载随输入文本长度的变化规律以及视觉-语言模型的计算负载随图像分辨率的变化规律。我们发现了两条经验性尺度律：(1) 语言模型推理的计算成本随着 token 长度近似线性增长；(2) 视觉-语言模型存在由预处理驱动的“分辨率拐点”，当输入超过内部分辨率阈值时计算量保持恒定，而低于该阈值时计算量会急剧下降。除此之外，我们展示了一种量子启发的压缩方法，可在保持或提升语义准确性的同时，将处理器与内存使用量最多减少 71.9%，能耗最多降低 62%。这些结果为在中央处理器上进行多模态本地推理的计算标度提供了系统量化，并指出模型压缩与输入分辨率预处理是实现可持续边缘推理的低成本有效手段。

BibTeX

```
@article{2512.16531v1,
  title={Scaling Laws for Energy Efficiency of Local LLMs},
  author={Ander Alvarez and Alessandro Genuardi and Nilotpal Sinha and Antonio Tiene and Samuel Mugel and Román Orús},
  journal={arXiv preprint arXiv:2512.16531v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16531v1}
}
```

## [TimeSeries2Report prompting enables adaptive large language model management of lithium-ion batteries](http://arxiv.org/abs/2512.16453v1)

#时间序列提示#锂离子电池运维#大语言模型应用

[PDF](https://arxiv.org/pdf/2512.16453v1)
[Abstract](http://arxiv.org/abs/2512.16453v1)

 LLM

 很推荐

### 中文摘要

大语言模型（LLM）在解释多变量时间序列数据方面展现出良好潜力，但其在真实电池储能系统（BESS）运维中的应用仍未得到充分探索。本文提出了 TimeSeries2Report（TS2R）提示框架，将原始锂离子电池运行时序数据转化为结构化、语义增强的报告，使得 LLM 能在 BESS 管理场景中进行推理、预测与决策。TS2R 通过分段、语义抽象和基于规则的解释，将短期时序动态编码为自然语言，有效衔接了底层传感器信号与高层上下文洞见。我们在实验室规模和真实世界数据集上对 TS2R 进行了基准测试，评估了报告质量及其在异常检测、荷电状态预测与充放电管理等下游任务上的表现。相比于基于视觉、嵌入和文本的提示基线，基于报告的 TS2R 提示在准确性、鲁棒性与可解释性方面持续提升 LLM 性能。值得注意的是，集成 TS2R 的 LLM 在无需重训练或改动模型架构的情况下即可达到专家级的决策质量与预测一致性，为自适应的基于 LLM 的电池智能化管理开辟了实用路径。

BibTeX

```
@article{2512.16453v1,
  title={TimeSeries2Report prompting enables adaptive large language model management of lithium-ion batteries},
  author={Jiayang Yang and Chunhui Zhao and Martin Guay and Zhixing Cao},
  journal={arXiv preprint arXiv:2512.16453v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16453v1}
}
```

## [E-SDS: Environment-aware See it, Do it, Sorted - Automated Environment-Aware Reinforcement Learning for Humanoid Locomotion](http://arxiv.org/abs/2512.16446v1)

#环境感知奖励自动化#视觉-语言模型(VLM)#类人机器人感知式强化学习

[PDF](https://arxiv.org/pdf/2512.16446v1)
[Abstract](http://arxiv.org/abs/2512.16446v1)

 RL（机器人/感知/跨模态）

 很推荐

### 中文摘要

视觉-语言模型（VLM）在自动化类人机器人行走奖励设计方面展现出潜力，有望避免繁琐的人工调参。然而，现有基于VLM的方法本质上是“盲”的——缺乏对复杂地形所需的环境感知。本文提出了E-SDS（Environment-aware See it, Do it, Sorted）框架以弥补该感知缺口。E-SDS 将VLM与实时地形传感器分析相结合，基于示例视频自动生成奖励函数，从而支持训练具备鲁棒感知能力的行走策略。我们在Unitree G1类人机器人上对四种不同地形（平地、间隙、障碍物、楼梯）进行了评估：E-SDS 是唯一能成功实现下楼梯任务的方法，而使用人工设计奖励或不具感知能力的自动化基线均无法完成该任务。在所有地形中，E-SDS 还将速度跟踪误差降低了51.9%–82.6%。该框架将奖励设计的人力时间从数天缩短到不到两小时，同时产生了更为稳健和高效的行走策略。

BibTeX

```
@article{2512.16446v1,
  title={E-SDS: Environment-aware See it, Do it, Sorted - Automated Environment-Aware Reinforcement Learning for Humanoid Locomotion},
  author={Enis Yalcin and Joshua O'Hara and Maria Stamatopoulou and Chengxu Zhou and Dimitrios Kanoulas},
  journal={arXiv preprint arXiv:2512.16446v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16446v1}
}
```

## [TIB AIssistant: a Platform for AI-Supported Research Across Research Life Cycles](http://arxiv.org/abs/2512.16442v1)

#AI辅助研究#研究生命周期#可复现性（RO-Crate）

[PDF](https://arxiv.org/pdf/2512.16442v1)
[Abstract](http://arxiv.org/abs/2512.16442v1)

 LLM

 很推荐

### 中文摘要

人工智能（AI），尤其是大型语言模型（LLM）的快速普及正在社会各领域产生广泛影响，学术领域亦不例外。AI 支持的研究有望在整个研究生命周期中为研究者提供任务级支持。本文展示了 TIB AIssistant —— 一个在研究生命周期各阶段提供支持的 AI 辅助研究平台。AIssistant 由多个助手组成，每个助手负责特定的研究任务；此外，平台还提供接入外部学术服务的工具。生成的数据会存储为资产，并可导出为 RO-Crate 包，以提高项目的透明性并增强可重复性。我们通过按序演示各助手之间的交互流程来展示 AIssistant 的主要功能，示例中各助手协同生成了论文草稿的若干章节。最终，AIssistant 为构建一个由社区维护的 AI 辅助研究平台奠定了基础。

BibTeX

```
@article{2512.16442v1,
  title={TIB AIssistant: a Platform for AI-Supported Research Across Research Life Cycles},
  author={Allard Oelen and Sören Auer},
  journal={arXiv preprint arXiv:2512.16442v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16442v1}
}
```

## [Using Gaussian Splats to Create High-Fidelity Facial Geometry and Texture](http://arxiv.org/abs/2512.16397v1)

#高斯Splatting#高保真面部三维重建#去光照高分辨率反照率（神经纹理）

[PDF](https://arxiv.org/pdf/2512.16397v1)
[Abstract](http://arxiv.org/abs/2512.16397v1)

 CV（神经渲染 / 3D重建）

 很推荐

### 中文摘要

我们利用日益流行的三维神经表示构建对一组未标定人脸图像的统一且一致的解释。与 NeRF 相比，我们采用 Gaussian Splatting（高斯点投影）作为更显式、更易受约束的方法。通过使用语义分割标注对面部语义区域进行对齐，我们能够仅凭 11 张图像（而非长视频）重建中性姿态。我们将高斯点以软约束绑定到一个底层三角网格表面上，以提供更有结构性的高斯重建，并利用该结构对三角网格表面进行后续扰动以提高精度。所得三角网格表面可直接用于标准图形流水线。更重要的是，准确的几何信息使得可以将高斯点映射到纹理空间，将其视为视角相关的神经纹理，从而在不修改场景中其他资源（几何、光照、渲染器等）的情况下，对任意资产应用高视觉保真度的 Gaussian Splatting。我们采用可重光照的高斯模型以解耦纹理与光照，获得去光照（delit）的高分辨率反照率纹理，同样能方便地用于标准图形流水线。该系统具有在光照不一致的异构图像上训练的弹性，从而利于稳健的正则化。最后，我们通过将该方法用于文本驱动的资源创建流水线来展示其实用性与效果。

BibTeX

```
@article{2512.16397v1,
  title={Using Gaussian Splats to Create High-Fidelity Facial Geometry and Texture},
  author={Haodi He and Jihun Yu and Ronald Fedkiw},
  journal={arXiv preprint arXiv:2512.16397v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16397v1}
}
```

## [Design and Evaluation of Cost-Aware PoQ for Decentralized LLM Inference](http://arxiv.org/abs/2512.16317v1)

#成本感知PoQ#去中心化LLM推理#评估器架构

[PDF](https://arxiv.org/pdf/2512.16317v1)
[Abstract](http://arxiv.org/abs/2512.16317v1)

 LLM

 很推荐

### 中文摘要

去中心化的大型语言模型（LLM）推理有望提供透明且具抗审查性的高级 AI 访问，但现有的计算验证方法难以扩展到现代模型。质量证明（Proof of Quality, PoQ）用对输出质量的共识替代对计算的密码学验证，但原始的 PoQ 未考虑推理节点与评估节点之间异构的计算成本。本文提出了一种成本感知的 PoQ 框架，将显式的效率度量纳入对两类节点的奖励机制。设计上，本方法在统一的评估流水线中结合了基于真实标签的令牌级 F1、轻量的学习型评估器以及基于 GPT 的判定，并采用线性奖励函数在归一化质量与成本之间进行权衡。我们在抽取式问答与抽象式摘要任务上，使用从 TinyLlama-1.1B 到 Llama-3.2-3B 的五个指令微调模型以及覆盖交叉编码器和双编码器架构的三种评估模型进行实验。结果表明，基于语义文本相似度的双编码器与真实标签及 GPT 得分的相关性远高于交叉编码器，说明评估器架构是 PoQ 设计中的关键要素。质量-成本分析进一步表明，池中最大的模型在质量/延迟比方面也最为高效。对 5000 轮 PoQ 进行的蒙特卡洛仿真显示，成本感知的奖励方案始终倾向于为高质量、低成本的推理模型与高效的评估器分配更高的平均奖励，同时惩罚低质且缓慢的节点。这些发现表明，成本感知的 PoQ 为经济可持续的去中心化 LLM 推理提供了切实可行的基础。

BibTeX

```
@article{2512.16317v1,
  title={Design and Evaluation of Cost-Aware PoQ for Decentralized LLM Inference},
  author={Arther Tian and Alex Ding and Frank Chen and Alan Wu and Aaron Chan and Bruce Zhang},
  journal={arXiv preprint arXiv:2512.16317v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16317v1}
}
```

## [Edge-wise Topological Divergence Gaps: Guiding Search in Combinatorial Optimization](http://arxiv.org/abs/2512.15800v1)

#旅行商问题#拓扑数据分析#局部搜索（2-opt/3-opt）

[PDF](https://arxiv.org/pdf/2512.15800v1)
[Abstract](http://arxiv.org/abs/2512.15800v1)

 组合优化（拓扑数据分析辅助）

 很推荐

### 中文摘要

我们通过分析旅行商问题（TSP）中一条巡回路径与最小生成树（MST）之间的散度，引入了一种拓扑反馈机制。我们的主要贡献是一个典范性分解定理，该定理将巡回路径与MST之间的差距表示为来自 RTD-Lite 条形码的按边计算的拓扑散度间隙（edge-wise topology-divergence gaps）。基于此，我们为 2-opt 和 3-opt 启发式搜索设计了拓扑引导策略，从而提升了这些局部搜索方法的性能。我们在基于热图的方法所得到的路径、TSPLIB 基准以及随机实例上进行了细化优化实验。实验结果表明，拓扑引导的优化在许多情况下能够带来更好的解质量和更快的收敛速度。

BibTeX

```
@article{2512.15800v1,
  title={Edge-wise Topological Divergence Gaps: Guiding Search in Combinatorial Optimization},
  author={Ilya Trofimov and Daria Voronkova and Alexander Mironenko and Anton Dmitriev and Eduard Tulchinskii and Evgeny Burnaev and Serguei Barannikov},
  journal={arXiv preprint arXiv:2512.15800v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15800v1}
}
```

## [OS-Oracle: A Comprehensive Framework for Cross-Platform GUI Critic Models](http://arxiv.org/abs/2512.16295v1)

#跨平台 GUI 评估#视觉-语言模型#数据集与基准

[PDF](https://arxiv.org/pdf/2512.16295v1)
[Abstract](http://arxiv.org/abs/2512.16295v1)

 LLM

 很推荐

### 中文摘要

随着基于视觉-语言模型（VLM）的计算机使用代理（CUA）在图形用户界面（GUI）导航与操作方面能力不断增强，可靠的逐步决策已成为现实部署的关键瓶颈。在长时序任务中，错误会快速累积且不可逆的操作可能导致不可预期的后果，因此需要在执行每一步之前对该动作进行评估的“评论”（critic）模型。尽管评论模型具有潜力，但其效果受限于缺乏多样且高质量的 GUI 反馈数据以及用于逐步评估的公开评论基准。为填补这些空白，我们提出了 OS-Oracle 框架，包含三方面核心贡献： (1) 一个可扩展的数据流水线，用于合成跨平台的 GUI 评论数据；(2) 一种两阶段训练范式，结合监督微调（SFT）与保持一致性的组相对策略优化（CP-GRPO）；(3) OS-Critic Bench，一个覆盖移动端、网页端与桌面端的全面评论模型评测基准。基于该框架，我们构建了包含 31 万条高质量评论样本的数据集。由此训练得到的评论模型 OS-Oracle-7B 在 OS-Critic Bench 上达到开源 VLM 的最先进水平，并在移动端超越了若干专有模型。此外，当作为预先评论器（pre-critic）部署时，OS-Oracle-7B 能显著提升原生 GUI 代理（如 UI-TARS-1.5-7B）在 OSWorld 与 AndroidWorld 环境中的表现。代码已开源： https://github.com/numbmelon/OS-Oracle。

BibTeX

```
@article{2512.16295v1,
  title={OS-Oracle: A Comprehensive Framework for Cross-Platform GUI Critic Models},
  author={Zhenyu Wu and Jingjing Xie and Zehao Li and Bowen Yang and Qiushi Sun and Zhaoyang Liu and Zhoumianze Liu and Yu Qiao and Xiangyu Yue and Zun Wang and Zichen Ding},
  journal={arXiv preprint arXiv:2512.16295v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16295v1}
}
```

## [QuadSentinel: Sequent Safety for Machine-Checkable Control in Multi-agent Systems](http://arxiv.org/abs/2512.16279v1)

#多智能体安全#机检化安全策略#运行时守卫机制

[PDF](https://arxiv.org/pdf/2512.16279v1)
[Abstract](http://arxiv.org/abs/2512.16279v1)

 LLM

 很推荐

### 中文摘要

随着基于大语言模型的代理使用工具、多步计划和代理间消息来解决复杂任务，安全风险也随之产生。然而，由部署者以自然语言编写的策略常含歧义且依赖上下文，难以直接映射为机器可检验的规则，且运行时强制执行不可靠。本文提出将安全策略表示为序列式规则（sequents），并基于此设计了QuadSentinel——由四个守卫代理组成的控制框架（状态追踪器、策略验证器、威胁监视器与裁判），将策略编译为基于可观测状态谓词的机器可检验规则并在在线环境中强制执行。裁判逻辑结合高效的top-k谓词更新器，通过优先级检查和分层冲突解决来控制开销。在ST-WebAgentBench（ICML CUA ’25）和AgentHarm（ICLR ’25）基准上的测评表明，QuadSentinel 在提升守护栏准确性和规则召回率的同时降低了误报率；相比单一代理基线（如ShieldAgent，ICML ’25），其整体安全控制效果更佳。该模式可在近期部署中采用而无需修改核心代理，仅需将策略保持为独立且机器可检验的形式。我们将公开发布实现代码。

BibTeX

```
@article{2512.16279v1,
  title={QuadSentinel: Sequent Safety for Machine-Checkable Control in Multi-agent Systems},
  author={Yiliu Yang and Yilei Jiang and Qunzhong Wang and Yingshui Tan and Xiaoyong Zhu and Sherman S. M. Chow and Bo Zheng and Xiangyu Yue},
  journal={arXiv preprint arXiv:2512.16279v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16279v1}
}
```

## [TextEditBench: Evaluating Reasoning-aware Text Editing Beyond Rendering](http://arxiv.org/abs/2512.16270v1)

#文本渲染#图像文本编辑#跨模态推理

[PDF](https://arxiv.org/pdf/2512.16270v1)
[Abstract](http://arxiv.org/abs/2512.16270v1)

 CV

 很推荐

### 中文摘要

文本渲染最近成为视觉生成领域最具挑战性的前沿之一，吸引了大规模扩散模型和多模态模型的广泛关注。然而，图像内的文本编辑仍然鲜有探索，因为这不仅需要生成清晰可读的字符，还需保持语义、几何和上下文的一致性。为填补这一空白，我们提出了 TextEditBench，一套专注于图像中以文本为中心区域的综合评估基准。除了基础的像素操作外，本基准强调需要深入推理的编辑场景，要求模型理解物理可行性、语言含义以及跨模态依赖关系。我们进一步提出了一个新的评估维度——语义期望（Semantic Expectation, SE），用于衡量模型在文本编辑过程中维持语义一致性、上下文连贯性和跨模态对齐的推理能力。对现有最先进编辑系统的大量实验表明，尽管当前模型能执行简单的文本指令，但在依赖上下文的推理、物理一致性和布局感知整合方面仍存在明显不足。通过将评估聚焦于这一长期被忽视但基础性的重要能力，TextEditBench 为推动基于文本的图像编辑与多模态生成中的推理能力提供了新的测试平台。

BibTeX

```
@article{2512.16270v1,
  title={TextEditBench: Evaluating Reasoning-aware Text Editing Beyond Rendering},
  author={Rui Gui and Yang Wan and Haochen Han and Dongxing Mao and Fangming Liu and Min Li and Alex Jinpeng Wang},
  journal={arXiv preprint arXiv:2512.16270v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16270v1}
}
```

## [An Information-Theoretic Framework for Robust Large Language Model Editing](http://arxiv.org/abs/2512.16227v1)

#模型编辑#信息瓶颈#鲁棒知识更新

[PDF](https://arxiv.org/pdf/2512.16227v1)
[Abstract](http://arxiv.org/abs/2512.16227v1)

 LLM

 很推荐

### 中文摘要

大型语言模型（LLM）已成为科学、技术与社会领域不可或缺的工具，推动了诸多领域的变革性进展。然而，模型中存在的错误或过时信息会削弱其准确性并限制安全部署。如何在不进行代价高昂且具有破坏性的全面重训的情况下，高效更新模型知识仍是一个关键挑战。现有的模型编辑技术常常难以在狭窄领域之外推广修正，导致意外后果并限制其实用性。在此，我们提出了一个基于信息瓶颈理论的新型LLM编辑框架。该方法精确压缩并隔离用于实现可推广知识修正的关键信息，同时最小化对无关模型行为的干扰。在此基础上，我们提出了信息瓶颈知识编辑器（Information Bottleneck Knowledge Editor，IBKE），其利用紧凑的潜在表征来引导基于梯度的更新，从而实现鲁棒且广泛适用的模型编辑。我们在多种LLM架构和标准基准任务上验证了IBKE的有效性，展示了领先的准确性以及编辑的泛化性和特异性的改进。这些结果确立了一个既有理论依据又具实用性的开放域知识编辑范式，推动了LLM在真实应用中的可用性与可信性提升。

BibTeX

```
@article{2512.16227v1,
  title={An Information-Theoretic Framework for Robust Large Language Model Editing},
  author={Qizhou Chen and Chengyu Wang and Taolin Zhang and Xiaofeng He},
  journal={arXiv preprint arXiv:2512.16227v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16227v1}
}
```

## [C-DGPA: Class-Centric Dual-Alignment Generative Prompt Adaptation](http://arxiv.org/abs/2512.16164v1)

#无监督域适应#视觉-语言模型#提示调优

[PDF](https://arxiv.org/pdf/2512.16164v1)
[Abstract](http://arxiv.org/abs/2512.16164v1)

 CV

 很推荐

### 中文摘要

无监督域适应（UDA）旨在将有标签的源域知识迁移到无标签的目标域。将视觉-语言模型（VLM）与提示调优直接应用于下游 UDA 任务时，面临着缓解域间差异的重大挑战。现有的提示调优策略主要关注边缘分布（marginal distribution）的对齐，但忽视了条件分布（conditional distribution）差异，导致类原型错位和语义可区分性下降等关键问题。为了解决这些局限，本文提出了 C-DGPA：以类为中心的双重对齐生成式提示适配方法。C-DGPA 通过一种新颖的双分支架构协同优化边缘分布对齐与条件分布对齐。边缘对齐分支采用动态对抗训练框架以弥合边缘分布差异；同时，条件对齐分支引入了类映射机制（Class Mapping Mechanism, CMM），通过标准化语义提示理解并防止对源域的过度依赖来校准条件分布差异。该双重对齐策略通过协同优化将域知识有效整合到提示学习中，从而保证表示的域不变性和语义可区分性。在 OfficeHome、Office31 和 VisDA-2017 上的广泛实验验证了 C-DGPA 的优越性，且在所有基准上取得了新的最先进结果。

BibTeX

```
@article{2512.16164v1,
  title={C-DGPA: Class-Centric Dual-Alignment Generative Prompt Adaptation},
  author={Chao Li and Dasha Hu and Chengyang Li and Yuming Jiang and Yuncheng Shen},
  journal={arXiv preprint arXiv:2512.16164v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16164v1}
}
```

## [Decoding Fake Narratives in Spreading Hateful Stories: A Dual-Head RoBERTa Model with Multi-Task Learning](http://arxiv.org/abs/2512.16147v1)

#仿造叙事的仇恨言论检测#多任务学习#印英代码混合文本

[PDF](https://arxiv.org/pdf/2512.16147v1)
[Abstract](http://arxiv.org/abs/2512.16147v1)

 NLP

 很推荐

### 中文摘要

社交媒体平台在促进全球互联的同时，也成为有害内容快速传播的温床，包括仇恨言论和虚假叙事。Faux-Hate 共享任务聚焦于检测一种特定现象：由虚假叙事驱动的仇恨言论生成（称为 Faux-Hate）。参赛者需在印英混合（code-mixed Hindi-English）的社交媒体文本中识别此类实例。本文描述了我们为该共享任务开发的系统，针对两个主要子任务：(a) 二分类 Faux-Hate 检测，包含虚假与仇恨言论的判别；(b) 目标与严重性预测，对仇恨内容的目标对象与严重程度进行分类。我们的方法结合了先进的自然语言处理技术与领域特定的预训练，以提升在两项任务上的表现。系统取得了具有竞争力的结果，验证了在该复杂问题上采用多任务学习策略的有效性。

BibTeX

```
@article{2512.16147v1,
  title={Decoding Fake Narratives in Spreading Hateful Stories: A Dual-Head RoBERTa Model with Multi-Task Learning},
  author={Yash Bhaskar and Sankalp Bahad and Parameswari Krishnamurthy},
  journal={arXiv preprint arXiv:2512.16147v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16147v1}
}
```

## [DVGT: Driving Visual Geometry Transformer](http://arxiv.org/abs/2512.16919v1)

#驾驶场景三维重建#视觉几何Transformer#无位姿多视图尺度预测

[PDF](https://arxiv.org/pdf/2512.16919v1)
[Abstract](http://arxiv.org/abs/2512.16919v1)

 CV

 很推荐

### 中文摘要

从视觉输入中感知并重建三维场景几何对自动驾驶至关重要。然而，目前仍缺乏一种面向驾驶场景、能适应不同场景与相机配置的稠密几何感知模型。为此，我们提出驾驶视觉几何变换器（DVGT），可从一序列无位姿信息的多视角视觉输入中重建全局稠密三维点图。我们首先使用 DINO 主干网络对每张图像提取视觉特征，并通过交替的视内局部注意力、跨视空间注意力与跨帧时序注意力来推断图像间的几何关系。随后使用多头解码器在第一帧的自车坐标系下解码全局点图，并同时预测每帧的自车位姿。与依赖精确相机参数的传统方法不同，DVGT 无需显式的三维几何先验，能够灵活处理任意相机配置。DVGT 可直接从图像序列预测具有度量尺度的几何结构，免去了与外部传感器的后期对齐需求。我们在包括 nuScenes、OpenScene、Waymo、KITTI 与 DDAD 等的大规模混合驾驶数据集上进行训练，结果显示 DVGT 在多种场景下显著优于现有模型。代码已开源（https://github.com/wzzheng/DVGT）。

BibTeX

```
@article{2512.16919v1,
  title={DVGT: Driving Visual Geometry Transformer},
  author={Sicheng Zuo and Zixun Xie and Wenzhao Zheng and Shaoqing Xu and Fang Li and Shengyin Jiang and Long Chen and Zhi-Xin Yang and Jiwen Lu},
  journal={arXiv preprint arXiv:2512.16919v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16919v1}
}
```

## [Generative Adversarial Reasoner: Enhancing LLM Reasoning with Adversarial Reinforcement Learning](http://arxiv.org/abs/2512.16917v1)

#对抗性强化学习#LLM推理增强#步骤级奖励

[PDF](https://arxiv.org/pdf/2512.16917v1)
[Abstract](http://arxiv.org/abs/2512.16917v1)

 LLM

 很推荐

### 中文摘要

具有显式推理能力的大规模语言模型（LLM）在数学推理等任务上表现出色，但仍会出现过程性错误，例如错误的计算、脆弱的逻辑以及表面上看似合理但实际上无效的步骤。本文提出生成式对抗推理器（Generative Adversarial Reasoner），一种基于在策略（on-policy）联合训练的框架，通过对抗性强化学习使LLM推理器与基于LLM的判别器协同进化以增强推理能力。一个计算高效的复核调度器将每条推理链划分为长度可比且逻辑完整的切片，判别器对每个切片的合理性给出简明且结构化的理由。学习过程中耦合了互补信号：当推理器生成逻辑一致且能得出正确答案的步骤时会获得奖励，而判别器在正确检测错误或区分推理轨迹时也会获得奖励。该机制产生了密集且校准良好的在策略步骤级奖励，补充了稀疏的精确匹配信号，从而改善了归因（credit assignment）、提高样本效率并提升LLM的整体推理质量。在多个数学基准上，该方法相比强基线和标准RL后训练方法持续带来性能提升。具体而言，在AIME24上，我们将DeepSeek-R1-Distill-Qwen-7B从54.0提升至61.3（+7.3），并将DeepSeek-R1-Distill-Llama-8B从43.7提升至53.7（+10.0）。模块化的判别器还支持用于教师蒸馏、偏好对齐和基于数学证明推理等目标的灵活奖励塑形。

BibTeX

```
@article{2512.16917v1,
  title={Generative Adversarial Reasoner: Enhancing LLM Reasoning with Adversarial Reinforcement Learning},
  author={Qihao Liu and Luoxin Ye and Wufei Ma and Yu-Cheng Chou and Alan Yuille},
  journal={arXiv preprint arXiv:2512.16917v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16917v1}
}
```

## [Exploration v.s. Exploitation: Rethinking RLVR through Clipping, Entropy, and Spurious Reward](http://arxiv.org/abs/2512.16912v1)

#强化学习可验证奖励#探索-利用权衡#虚假奖励与剪裁偏差

[PDF](https://arxiv.org/pdf/2512.16912v1)
[Abstract](http://arxiv.org/abs/2512.16912v1)

 RL (应用于 LLM 推理)

 很推荐

### 中文摘要

本文研究了具有可验证奖励的强化学习（RLVR）中探索-利用权衡的问题，该框架用于提升大型语言模型（LLM）的推理能力。近期研究发现，RLVR 通过两种看似矛盾的机制能显著促成 LLM 的数学推理能力：一方面是“虚假奖励”（spurious rewards），即对与真实答案无关的结果给予奖励，从而抑制利用（exploitation）；另一方面是熵最小化（entropy minimization），即通过降低策略熵使模型输出更自信、更确定，从而抑制探索（exploration）。这一现象令人困惑：既抑制利用又抑制探索都能提升推理表现，而其背后的统一原理仍不清楚。我们聚焦两个基本问题：（i）策略熵与性能之间的关系；（ii）虚假奖励是否能带来收益，以及这种收益是否通过剪裁偏差（clipping bias）和模型污染（model contamination）的相互作用实现。实验证明，在虚假奖励下，剪裁偏差会降低策略熵，从而使输出更自信、更确定；而单纯的熵最小化并不足以带来性能提升。我们进一步提出了奖励错配（reward-misalignment）模型，解释为何虚假奖励在超出被污染设置时仍能提升性能。研究结果澄清了虚假奖励带来收益的机制，并为更有效的 RLVR 训练提供了原则性指导。

BibTeX

```
@article{2512.16912v1,
  title={Exploration v.s. Exploitation: Rethinking RLVR through Clipping, Entropy, and Spurious Reward},
  author={Peter Chen and Xiaopeng Li and Ziniu Li and Wotao Yin and Xi Chen and Tianyi Lin},
  journal={arXiv preprint arXiv:2512.16912v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16912v1}
}
```

## [Posterior Behavioral Cloning: Pretraining BC Policies for Efficient RL Finetuning](http://arxiv.org/abs/2512.16911v1)

#后验行为克隆#策略预训练#强化学习微调

[PDF](https://arxiv.org/pdf/2512.16911v1)
[Abstract](http://arxiv.org/abs/2512.16911v1)

 RL

 很推荐

### 中文摘要

在从机器人到语言等诸多领域中的常见做法是，先在大规模示范数据集上预训练一个策略，然后再对该策略进行微调，通常采用强化学习（RL）以提升在部署环境中的表现。尽管微调步骤对达到人类或超人级别的性能至关重要，已有大量工作致力于改进更有效的微调算法，但鲜有研究关注如何使预训练策略成为强化学习微调的有效初始化。本文旨在理解预训练策略如何影响微调性能，并探讨如何设计预训练方法以确保其作为微调初始化的有效性。我们首先从理论上证明了标准的行为克隆（BC）——即训练策略去直接匹配演示者的动作——在保证对演示者动作的覆盖性方面可能失败，而覆盖性是实现有效RL微调的最基本条件。随后我们证明，相比于精确拟合观测到的示范，若将策略训练为对给定示范数据集下演示者行为的后验分布建模，则可以获得对演示者动作具有覆盖性的策略，从而促进更有效的微调。此外，这种策略（我们称为后验行为克隆，PostBC）还能在保证预训练性能不劣于BC策略的同时实现上述覆盖性。最后我们展示了PostBC可借助现代生成模型在机器人控制领域中实际实现——仅依赖标准的监督学习——并在真实机器人控制基准和真实世界机器人操控任务上相比标准行为克隆显著提升了RL微调性能。

BibTeX

```
@article{2512.16911v1,
  title={Posterior Behavioral Cloning: Pretraining BC Policies for Efficient RL Finetuning},
  author={Andrew Wagenmaker and Perry Dong and Raymond Tsao and Chelsea Finn and Sergey Levine},
  journal={arXiv preprint arXiv:2512.16911v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16911v1}
}
```

## [Sequencing to Mitigate Catastrophic Forgetting in Continual Learning](http://arxiv.org/abs/2512.16871v1)

#灾难性遗忘#任务排序#零样本评分（NAS启发）

[PDF](https://arxiv.org/pdf/2512.16871v1)
[Abstract](http://arxiv.org/abs/2512.16871v1)

 持续学习（Continual Learning）

 很推荐

### 中文摘要

为了应对现实世界的动态变化，智能系统需要在其生命周期中增量地获取、更新并利用知识。这种能力被称为持续学习（Continual Learning），为 AI 系统的自适应发展提供了基础。灾难性遗忘是持续学习方法面临的主要挑战：学习新任务通常会导致对先前任务性能的显著下降。为缓解灾难性遗忘，已提出多种方法，主要可分为五类：基于重放、基于正则化、基于优化、基于表示和基于架构的方法。在本文中，我们从不同角度出发，特别关注呈现给模型的任务序列是否最优。我们研究了任务排序在缓解灾难性遗忘中的作用，并提出了一种用于确定最优任务顺序的方法。该方法借鉴了神经架构搜索（NAS）的思想，利用零样本评分算法进行评估。结果表明，智能的任务排序可以显著降低灾难性遗忘。此外，当与传统的持续学习策略结合时，任务排序还能进一步提升性能并增强对遗忘的鲁棒性。所提出的方法也可在课程学习等其他领域找到应用。

BibTeX

```
@article{2512.16871v1,
  title={Sequencing to Mitigate Catastrophic Forgetting in Continual Learning},
  author={Hesham G. Moussa and Aroosa Hameed and Arashmid Akhavain},
  journal={arXiv preprint arXiv:2512.16871v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16871v1}
}
```

## [Distributional AGI Safety](http://arxiv.org/abs/2512.16856v1)

#分布式AGI安全#多智能体协调#沙箱经济与审计机制

[PDF](https://arxiv.org/pdf/2512.16856v1)
[Abstract](http://arxiv.org/abs/2512.16856v1)

 多智能体系统 / AI 安全

 很推荐

### 中文摘要

AI 安全与对齐研究迄今主要集中于保护单个 AI 系统的方法，并基于最终会出现单一整体式通用人工智能（AGI）的假设。然而，另一种 AGI 出现假说——即通用能力首先通过一组具有互补技能与可操作性的亚 AGI 个体之间的协调而体现——则鲜少被关注。我们在此主张，应认真考虑这种“拼接式”AGI 假说，并以此为基础制定相应的防护与缓解措施。随着具备工具使用能力并能沟通与协调的高级 AI 代理快速部署，这一分布性风险已成为紧迫的安全议题。因此我们提出了一个分布式 AGI 安全框架，超越对单个代理的评估与对齐，聚焦于设计与实施虚拟代理沙箱经济（可为不可渗透或半可渗透），在该环境中代理间交易由强健的市场机制管理，并辅以适当的可审计性、声誉管理与监督机制，以缓解群体性风险。

BibTeX

```
@article{2512.16856v1,
  title={Distributional AGI Safety},
  author={Nenad Tomašev and Matija Franklin and Julian Jacobs and Sébastien Krier and Simon Osindero},
  journal={arXiv preprint arXiv:2512.16856v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16856v1}
}
```

## [TOGGLE: Temporal Logic-Guided Large Language Model Compression for Edge](http://arxiv.org/abs/2512.16855v1)

#信号时序逻辑(STL)#模型压缩(量化与剪枝)#边缘部署/形式化验证

[PDF](https://arxiv.org/pdf/2512.16855v1)
[Abstract](http://arxiv.org/abs/2512.16855v1)

 LLM

 很推荐

### 中文摘要

大型语言模型（LLM）在自然语言任务上表现卓越，但其对计算资源的高需求限制了在资源受限的边缘设备上的部署。现有的压缩技术（如量化和剪枝）常常损害关键的语言属性，且缺乏保持模型行为的形式化保证。本文提出了基于时序逻辑引导的大型语言模型压缩方法（TOGGLE），该框架利用信号时序逻辑（STL）对语言属性进行形式化规范并在压缩过程中强制满足这些规范。TOGGLE 采用基于 STL 鲁棒性的贝叶斯优化，有系统地探索逐层量化与剪枝配置，生成在无需重新训练或微调情况下仍能形式化满足指定语言约束的压缩模型。我们在四种 LLM 架构（GPT-2、DeepSeek-V2 7B、LLaMA 3 8B 和 Mistral 7B）上评估 TOGGLE，最多实现 3.3 倍的计算开销（FLOPs）降低与最高 68.8% 的模型尺寸缩减，同时满足所有语言属性要求。TOGGLE 是首个将形式化方法集成到 LLM 压缩中的工作，为在边缘硬件上高效且可验证地部署 LLM 提供了新的路径。

BibTeX

```
@article{2512.16855v1,
  title={TOGGLE: Temporal Logic-Guided Large Language Model Compression for Edge},
  author={Khurram Khalil and Khaza Anuarul Hoque},
  journal={arXiv preprint arXiv:2512.16855v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16855v1}
}
```

## [GenEval 2: Addressing Benchmark Drift in Text-to-Image Evaluation](http://arxiv.org/abs/2512.16853v1)

#基准漂移#文本到图像评估#视觉基元与组合性

[PDF](https://arxiv.org/pdf/2512.16853v1)
[Abstract](http://arxiv.org/abs/2512.16853v1)

 CV

 很推荐

### 中文摘要

自动化文本到图像（T2I）模型的评估具有挑战性：需要使用判别模型对生成结果打分，并且测试提示语必须对当前的T2I模型具有挑战性但不超过判别器的能力。我们认为，满足这些约束会导致基准漂移——静态基准判别器无法跟上新模型能力的增长。我们证明了基准漂移对 GenEval（一个流行的 T2I 基准）是一个显著问题。尽管 GenEval 在发布时与人工判断高度一致，但随着时间推移它与人工判断的偏离已变得很大——对当前模型的绝对误差高达 17.7%。这一漂移程度强烈表明 GenEval 已经被饱和，我们通过大规模人工研究对该结论进行了验证。为弥补这一基准空白，我们提出了新的基准 GenEval 2，增强了对基础视觉概念的覆盖并提高了组合性，使其对当前模型更具挑战性。我们还提出了 Soft-TIFA，一种针对 GenEval 2 的评估方法，通过组合视觉基元的判断来评分，实验证明其与人工判断更为一致，并且相比于像 VQAScore 这类更整体的判别器更不易随时间偏离人工对齐。我们希望 GenEval 2 能在未来多年提供强有力的评测，但避免基准漂移并非万无一失；本工作更广泛地强调了对 T2I 及相关自动化模型评估基准持续审计与改进的重要性。

BibTeX

```
@article{2512.16853v1,
  title={GenEval 2: Addressing Benchmark Drift in Text-to-Image Evaluation},
  author={Amita Kamath and Kai-Wei Chang and Ranjay Krishna and Luke Zettlemoyer and Yushi Hu and Marjan Ghazvininejad},
  journal={arXiv preprint arXiv:2512.16853v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16853v1}
}
```

## [PrivateXR: Defending Privacy Attacks in Extended Reality Through Explainable AI-Guided Differential Privacy](http://arxiv.org/abs/2512.16851v1)

#可解释性AI（XAI）#差分隐私（DP）#扩展现实（XR）隐私保护

[PDF](https://arxiv.org/pdf/2512.16851v1)
[Abstract](http://arxiv.org/abs/2512.16851v1)

 AI XR（扩展现实）隐私与可解释性

 很推荐

### 中文摘要

人工智能与扩展现实（AI XR）的融合在诸多领域催生了创新应用，但这些系统所使用的敏感数据（例如眼动追踪）带来了严重的隐私问题。攻击者可以通过成员推断攻击（MIA）和重识别攻击（RDA）等手段，从数据和模型中高效推断并泄露个人信息。尽管已有包括差分隐私（DP）在内的多种防护技术被提出，AI XR 数据集通常具有大量特征，统一对所有特征应用差分隐私会对不相关特征引入不必要的噪声，导致模型精度下降并增加推理时间，从而限制了实时 XR 应用部署。为此，我们提出了一种将可解释性 AI（XAI）与差分隐私相结合的隐私防护新框架：通过后验可解释性方法识别 AI XR 模型中最具影响力的特征，并在推理阶段对这些关键特征选择性地施加差分隐私保护。我们在三种最先进的 AI XR 模型以及三个数据集（晕动病检测、情绪识别与活动分类）上进行了评估。结果表明，在晕动病任务中，本方法将 MIA 与 RDA 的成功率分别最多降低了约 43% 和 39%，同时在使用 Transformer 模型时可保持高达 97% 的模型效用。此外，与传统差分隐私方法相比，本方法将推理时间提升了约 2 倍。为了验证实用性，我们在 HTC VIVE Pro 头显上部署了 XAI 指导的差分隐私 AI XR 模型，并开发了名为 PrivateXR 的用户界面，允许用户在低、中、高隐私等级间调整，同时在 XR 游戏中实时接收任务预测，从而在保持交互性的同时保护用户隐私。

BibTeX

```
@article{2512.16851v1,
  title={PrivateXR: Defending Privacy Attacks in Extended Reality Through Explainable AI-Guided Differential Privacy},
  author={Ripan Kumar Kundu and Istiak Ahmed and Khaza Anuarul Hoque},
  journal={arXiv preprint arXiv:2512.16851v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16851v1}
}
```

## [OPENTOUCH: Bringing Full-Hand Touch to Real-World Interaction](http://arxiv.org/abs/2512.16842v1)

#全手触觉数据集#第一人称视觉-触觉对齐#多模态感知

[PDF](https://arxiv.org/pdf/2512.16842v1)
[Abstract](http://arxiv.org/abs/2512.16842v1)

 CV

 很推荐

### 中文摘要

人类的手是我们与物理世界交互的主要接口，但自视角感知往往无法知道何时、何地或以多大力度发生接触。稳健的可穿戴触觉传感器十分稀缺，且现有的真实场景数据集中没有将第一人称视频与全手触觉对齐的数据。为弥合视觉感知与物理交互之间的差距，我们提出了 OpenTouch——首个真实场景的自视角全手触觉数据集，包含 5.1 小时同步的视频-触觉-姿态数据和 2,900 个带有详细文本注释的精选片段。基于 OpenTouch，我们引入了检索与分类基准，用以探究触觉如何为感知与动作提供支撑。实验表明，触觉信号作为一种紧凑但强有力的线索，可用于理解抓取行为、强化跨模态对齐，并能从真实场景的视频查询中可靠地检索到触觉信息。通过发布这一带注释的视觉-触觉-姿态数据集与基准，我们希望推动多模态自视角感知、具身学习和富接触的机器人操控研究的发展。

BibTeX

```
@article{2512.16842v1,
  title={OPENTOUCH: Bringing Full-Hand Touch to Real-World Interaction},
  author={Yuxin Ray Song and Jinzhou Li and Rao Fu and Devin Murphy and Kaichen Zhou and Rishi Shiv and Yaqi Li and Haoyu Xiong and Crystal Elaine Owens and Yilun Du and Yiyue Luo and Xianyi Cheng and Antonio Torralba and Wojciech Matusik and Paul Pu Liang},
  journal={arXiv preprint arXiv:2512.16842v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16842v1}
}
```

## [Emergent Bias and Fairness in Multi-Agent Decision Systems](http://arxiv.org/abs/2512.16433v1)

#公平性评估#多智能体决策系统#金融决策偏见

[PDF](https://arxiv.org/pdf/2512.16433v1)
[Abstract](http://arxiv.org/abs/2512.16433v1)

 多智能体系统

 很推荐

### 中文摘要

多智能体系统通过协作决策已证明可以提升多种预测任务的表现。然而，缺乏有效的评估方法使得难以估量偏见风险，从而使这类系统在消费者金融等高风险领域的部署变得不安全——在这些领域中，带偏见的决策可能直接导致监管违规和资金损失。为应对这一挑战，需要为多智能体预测系统制定公平性评估方法，并在金融表格数据领域衡量此类系统的公平性特征。通过在多种多智能体配置上进行大规模模拟，包含不同的通信与协作机制，我们揭示了在金融决策中出现的“涌现偏见”模式——这些偏见无法归因于单个代理组件，表明多智能体系统可能表现出真正的集体行为。我们的研究强调，金融多智能体系统中的公平性风险构成了模型风险的重要部分，对信用评分、收入估计等任务有实质性影响。因此，我们主张应将多智能体决策系统作为整体进行评估，而非通过还原性的组件分析来判断其安全性和公平性。

BibTeX

```
@article{2512.16433v1,
  title={Emergent Bias and Fairness in Multi-Agent Decision Systems},
  author={Maeve Madigan and Parameswaran Kamalaruban and Glenn Moynihan and Tom Kempton and David Sutton and Stuart Burrell},
  journal={arXiv preprint arXiv:2512.16433v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16433v1}
}
```

## [CauSTream: Causal Spatio-Temporal Representation Learning for Streamflow Forecasting](http://arxiv.org/abs/2512.16046v1)

#时空因果表示学习#流量/径流预测#可辨识性与可解释性

[PDF](https://arxiv.org/pdf/2512.16046v1)
[Abstract](http://arxiv.org/abs/2512.16046v1)

 时空因果学习（水文/环境）

 很推荐

### 中文摘要

流量预报对于水资源管理和风险缓解至关重要。尽管深度学习模型在预测性能上取得了显著进展，但它们常忽视潜在的物理过程，从而限制了可解释性和泛化能力。近年来的因果学习方法通过整合领域知识在一定程度上解决了这些问题，但通常依赖于固定的因果图结构，难以随数据自适应调整。我们提出了CauSTream，一个用于流量预报的统一因果时空表示学习框架。CauSTream 联合学习两类因果结构：（i）描述气象驱动因素之间径流生成机制的径流因果图；（ii）刻画站点间动态依赖关系的路由图。我们在非参数设定下给出了这些因果结构的可辨识性条件。通过在三个美国主要流域和三个不同预报时窗上的评估，CauSTream 稳定地优于现有最先进方法，且在更长的预报时窗上性能优势更为明显，表明其对未知条件具有更强的泛化能力。除预测之外，CauSTream 还能学习出捕捉水文因子与站点间关系的因果图谱，所推断的结构与现有领域知识高度一致，为流域动力学提供可解释的见解。CauSTream 为因果时空建模提供了理论与方法上的规范性基础，并有望推广至更广泛的科学与环境应用中。

BibTeX

```
@article{2512.16046v1,
  title={CauSTream: Causal Spatio-Temporal Representation Learning for Streamflow Forecasting},
  author={Shu Wan and Reepal Shah and John Sabo and Huan Liu and K. Selçuk Candan},
  journal={arXiv preprint arXiv:2512.16046v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16046v1}
}
```

## [Cross-Language Bias Examination in Large Language Models](http://arxiv.org/abs/2512.16029v1)

#多语言偏见#隐式联想测验#模型公平性

[PDF](https://arxiv.org/pdf/2512.16029v1)
[Abstract](http://arxiv.org/abs/2512.16029v1)

 LLM

 很推荐

### 中文摘要

本研究提出了一种创新的多语种偏见评估框架，用于评估大型语言模型（LLM）中的偏见。该框架将通过BBQ基准进行的显性偏见评估与基于提示的隐性联想测验（Implicit Association Test, IAT）相结合，以衡量隐性偏见。研究将提示语和词表翻译为五种目标语言——英语、中文、阿拉伯语、法语和西班牙语，从而能够直接比较不同语言间的各类偏见表现。结果显示，LLM在不同语言上的偏见存在显著差异；例如，阿拉伯语和西班牙语中刻板印象偏见普遍较高，而中文和英文中的偏见水平相对较低。研究还发现不同偏见类型呈现出相互对比的模式：年龄这一属性在显性测评中表现出最低的偏见，但在隐性测评中却表现出最高的偏见，强调了依赖标准基准无法检测到的隐性偏见的重要性。这些发现表明，LLM在语言和偏见维度上存在显著差异。本研究通过提供一套全面的跨语种偏见分析方法，填补了该领域的关键空白，并为开发在多语言与多文化环境中更公平、更有效的LLM奠定了基础。

BibTeX

```
@article{2512.16029v1,
  title={Cross-Language Bias Examination in Large Language Models},
  author={Yuxuan Liang and Marwa Mahmoud},
  journal={arXiv preprint arXiv:2512.16029v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16029v1}
}
```

## [Conversational Time Series Foundation Models: Towards Explainable and Effective Forecasting](http://arxiv.org/abs/2512.16022v1)

#时间序列预测#大语言模型（LLM）#可解释性与模型集成

[PDF](https://arxiv.org/pdf/2512.16022v1)
[Abstract](http://arxiv.org/abs/2512.16022v1)

 时间序列预测 (LLM 应用)

 很推荐

### 中文摘要

随着时间序列基础模型的快速增多，目前并不存在单一始终占优的方法，因此研究的核心从寻找最佳模型转向如何在具备可解释性的前提下，协调出最优的模型集成。尽管大语言模型（LLM）具有强大的推理能力，但其直接用于时间序列预测效果不佳。为此，本文将LLM重新定位为一个智能评判者，用以评估、解释并策略性地协调一组基础模型的集成权重。针对LLM在时间序列领域中固有的领域知识不足，我们提出了一种基于R1风格的微调流程，并以基于SHAP的忠实度评分为引导，使模型学会将集成权重解读为关于时序动态的因果性陈述。经训练的智能体通过迭代的多轮会话进行前瞻性评估，给出基于因果依据的权重解释，并自适应地改进优化策略。在GIFT-Eval基准上对23个数据集、97种设置的验证表明，该方法在CRPS和MASE指标上显著优于现有领先的时间序列基础模型，创下了新的最优结果。

BibTeX

```
@article{2512.16022v1,
  title={Conversational Time Series Foundation Models: Towards Explainable and Effective Forecasting},
  author={Defu Cao and Michael Gee and Jinbo Liu and Hengxuan Wang and Wei Yang and Rui Wang and Yan Liu},
  journal={arXiv preprint arXiv:2512.16022v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16022v1}
}
```

## [Towards Fine-Tuning-Based Site Calibration for Knowledge-Guided Machine Learning: A Summary of Results](http://arxiv.org/abs/2512.16013v1)

#空间异质性#迁移学习#知识引导机器学习

[PDF](https://arxiv.org/pdf/2512.16013v1)
[Abstract](http://arxiv.org/abs/2512.16013v1)

 迁移学习（空间感知/知识引导机器学习）

 很推荐

### 中文摘要

准确且具成本效益地在决策相关尺度上量化农业生态系统碳循环，对气候减缓和可持续农业至关重要。然而，该领域的迁移学习与空间变异利用具有挑战性，因涉及异构数据与复杂的跨尺度依赖。传统方法通常依赖与位置无关的参数化和独立训练，未充分利用迁移学习与输入中的空间异质性，限制了其在高度变异区域的适用性。为此，本文提出了 FTBSC-KGML（基于微调的站点校准-知识引导机器学习），一种结合预训练与微调、考虑空间异质性并引入知识引导的机器学习框架，通过在 KGML-ag 的基础上增加预训练—微调流程和站点特定参数来增强建模能力。利用跨多个中西部站点收集的遥感 GPP、气候和土壤协变量进行预训练—微调，FTBSC-KGML 在估算土地排放时同时利用了迁移学习与空间异质性。其核心组成之一是空间异质性感知的迁移学习方案：先进行全局预训练，再在各州或站点上进行微调以学习位置感知的表征，从而在数据有限时提高局部精度且不牺牲可解释性。实证结果表明，FTBSC-KGML 相较于纯全局模型取得了更低的验证误差和更一致的解释力，能更好地捕捉各州间的空间变异。该工作是对先前 SDSA-KGML 框架的扩展。

BibTeX

```
@article{2512.16013v1,
  title={Towards Fine-Tuning-Based Site Calibration for Knowledge-Guided Machine Learning: A Summary of Results},
  author={Ruolei Zeng and Arun Sharma and Shuai An and Mingzhou Yang and Shengya Zhang and Licheng Liu and David Mulla and Shashi Shekhar},
  journal={arXiv preprint arXiv:2512.16013v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16013v1}
}
```

## [Seeing Beyond Words: Self-Supervised Visual Learning for Multimodal Large Language Models](http://arxiv.org/abs/2512.15885v1)

#自监督视觉学习#多模态大模型#视觉-语言对齐

[PDF](https://arxiv.org/pdf/2512.15885v1)
[Abstract](http://arxiv.org/abs/2512.15885v1)

 Multimodal LLM

 很推荐

### 中文摘要

多模态大语言模型（MLLMs）最近在连接视觉与语言方面表现出令人瞩目的能力，但在基础视觉推理任务上的能力仍然有限。造成这一限制的原因在于，MLLMs 的视觉理解主要依赖于文本描述作为监督信号，而文本描述具有主观性且天然不完整。此外，与大规模纯文本预训练相比，多模态指令微调的规模较小，导致模型更容易过拟合语言先验而忽视视觉细节。为了解决这些问题，我们提出了 JARVIS，一种受 JEPA 启发的用于增强 MLLMs 自监督视觉能力的框架。具体来说，我们将 I-JEPA 学习范式整合进 MLLMs 训练的标准视觉-语言对齐流程。该方法利用已冻结的视觉基础模型作为上下文编码器与目标编码器，同时训练预测器（由 LLM 的早期层实现），以在不完全依赖语言监督的情况下从图像中学习结构与语义规律。大量在标准 MLLM 基准上的实验表明，JARVIS 在不同 LLM 家族上均能在强调视觉的基准上持续提升性能，同时不会降低多模态推理能力。我们的源代码已公开： https://github.com/aimagelab/JARVIS。

BibTeX

```
@article{2512.15885v1,
  title={Seeing Beyond Words: Self-Supervised Visual Learning for Multimodal Large Language Models},
  author={Davide Caffagni and Sara Sarto and Marcella Cornia and Lorenzo Baraldi and Pier Luigi Dovesi and Shaghayegh Roohi and Mark Granroth-Wilding and Rita Cucchiara},
  journal={arXiv preprint arXiv:2512.15885v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15885v1}
}
```

## [A Neurosymbolic Approach to Loop Invariant Generation via Weakest Precondition Reasoning](http://arxiv.org/abs/2512.15816v1)

#循环不变式生成#神经符号方法#Hoare逻辑与最弱前置条件

[PDF](https://arxiv.org/pdf/2512.15816v1)
[Abstract](http://arxiv.org/abs/2512.15816v1)

 LLM（程序验证/形式化方法）

 很推荐

### 中文摘要

循环不变式生成仍然是自动化程序验证中的关键瓶颈。近期工作开始探索在该领域中引入大语言模型（LLM），但这些方法通常缺乏可靠且结构化的方法论，较少参照现有的程序验证理论。本文提出NeuroInv，一种用于循环不变式生成的神经符号方法。NeuroInv由两个关键模块组成： (1) 神经推理模块，结合LLM与Hoare逻辑，采用逆向链式的最弱前置条件推理来推导并细化候选不变式；(2) 验证引导的符号模块，利用来自OpenJML的反例对不变式进行迭代修复。我们在一个包含150个Java程序的综合基准上评估NeuroInv，覆盖单循环与多个（顺序）循环、多数组、随机分支及带噪声的代码片段，NeuroInv取得了99.5%的成功率，显著优于其它被评估的方法。此外，我们还引入了一个由10个更大规模多循环程序（平均每个程序含7个循环）组成的困难基准；在该设置下的结果表明NeuroInv能够扩展到更复杂的验证场景。

BibTeX

```
@article{2512.15816v1,
  title={A Neurosymbolic Approach to Loop Invariant Generation via Weakest Precondition Reasoning},
  author={Daragh King and Vasileios Koutavas and Laura Kovacs},
  journal={arXiv preprint arXiv:2512.15816v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15816v1}
}
```

## [TS-DP: Reinforcement Speculative Decoding For Temporal Adaptive Diffusion Policy Acceleration](http://arxiv.org/abs/2512.15773v1)

#扩散策略#推测解码#时序自适应强化学习

[PDF](https://arxiv.org/pdf/2512.15773v1)
[Abstract](http://arxiv.org/abs/2512.15773v1)

 RL

 很推荐

### 中文摘要

扩散策略（Diffusion Policy, DP）在具身控制任务中表现优异，但由于需要多次迭代的去噪步骤，导致推理延迟高且计算开销大。具身任务的时序复杂性要求一种动态且可适配的计算模式；静态且有损的加速方法（如量化）无法充分应对，而推测解码作为一种无损且自适应的替代方案尚未在DP中得到充分探索。本文针对两大挑战提出解决方案：在具身设置中如何在更低成本下匹配基模型的去噪质量以应对时变任务难度，以及如何在任务难度随时间变化时动态交互地调整计算。为此，我们提出了时序感知的基于强化学习的推测扩散策略（TS-DP），这是首个实现对DP进行时序自适应推测解码的框架。首先，为处理任务难度随时间变化的问题，我们蒸馏出一个基于Transformer的drafter来模仿基模型，从而替代代价高昂的去噪调用；其次，基于强化学习的调度器通过调整推测参数以适应时变任务难度，在提升效率的同时保持精度。大量具身环境实验表明，TS-DP在不降低性能的前提下实现了最高4.17倍的推理加速，草案接受率超过94%，推理频率达到25 Hz，从而使基于扩散的实时控制成为可能。

BibTeX

```
@article{2512.15773v1,
  title={TS-DP: Reinforcement Speculative Decoding For Temporal Adaptive Diffusion Policy Acceleration},
  author={Ye Li and Jiahe Feng and Yuan Meng and Kangye Ji and Chen Tang and Xinwan Wen and Shutao Xia and Zhi Wang and Wenwu Zhu},
  journal={arXiv preprint arXiv:2512.15773v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15773v1}
}
```

## [AdaGradSelect: An adaptive gradient-guided layer selection method for efficient fine-tuning of SLMs](http://arxiv.org/abs/2512.15764v1)

#参数高效微调#梯度驱动层选择#小型语言模型（SLM）

[PDF](https://arxiv.org/pdf/2512.15764v1)
[Abstract](http://arxiv.org/abs/2512.15764v1)

 LLM (PEFT)

 很推荐

### 中文摘要

大型语言模型（LLMs）在许多自然语言处理任务上表现优异，但对其进行完全微调代价高昂且占用大量内存。参数高效微调（PEFT）方法（如 LoRA）通过向冻结的模型权重添加小的低秩更新来降低这一成本，但这类方法将训练限制在一个较小的子空间中，有时会导致性能下降。针对效率要求更高的小型语言模型（SLMs），我们提出了 AdaGradSelect：一种基于梯度的自适应层选择方法，用于决定哪些 Transformer 块需要更新。早期观察发现，仅更新梯度范数最高的 Transformer 块即可达到接近完全微调的性能。基于这一启发，AdaGradSelect 自适应地选择训练块，结合了基于 Dirichlet 的采样（依赖于块在过去被更新的频率）与 epsilon-greedy 探索策略，从而在训练早期探索不同块，后期逐步聚焦于最重要的块。实验表明，AdaGradSelect 在训练速度上约快 12%，GPU 内存使用减少约 35%，同时性能接近完全微调。在 GSM8K 数据集上，针对 Qwen2.5-0.5B、LLaMA3.2-1B 和 Phi4-mini-3.8B 等模型，AdaGradSelect 比 LoRA（rank 256）平均高约 3%；在 MATH 数据集上也取得了相似的准确率。总体而言，AdaGradSelect 为传统微调方法提供了一种更高效、资源节省且效果良好的替代方案。

BibTeX

```
@article{2512.15764v1,
  title={AdaGradSelect: An adaptive gradient-guided layer selection method for efficient fine-tuning of SLMs},
  author={Anshul Kumar and Gagan Raj Gupta and Manisha Chawla},
  journal={arXiv preprint arXiv:2512.15764v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15764v1}
}
```

## [ReactorFold: Generative discovery of nuclear reactor cores via emergent physical reasoning](http://arxiv.org/abs/2512.15756v1)

#堆芯设计#生成式语言模型#物理因果推理

[PDF](https://arxiv.org/pdf/2512.15756v1)
[Abstract](http://arxiv.org/abs/2512.15756v1)

 LLM

 很推荐

### 中文摘要

核反应堆堆芯设计需在由复杂中子作用支配的大规模离散设计空间中进行探索。传统的确定性方法、元启发式算法和机器学习辅助方法通常局限于固定的、由人定义的构型空间，限制了发现全新设计拓扑的能力。本文提出ReactorFold，一种将燃料组件设计重新表述为语言模型序列建模问题的生成式框架。通过蒙特卡洛数据、参数高效微调和直接偏好优化（DPO），模型学习加压水堆组件的潜在结构，并在一次前向传播中生成候选布局。值得注意的是，经DPO对齐的模型表现出自发的设计空间扩展能力：尽管训练时仅使用固定数量的钆（Gd）可燃吸收棒配置，模型仍能自主调整Gd数量以满足严格的功率峰值约束。模型还发现了具有高性能的非对称配置，挑战了传统的对称装载启发式规则，进入了常规搜索方法无法触及的设计范畴，表明语言模型能够内化因果物理关系并超越人为施加的设计限制。

BibTeX

```
@article{2512.15756v1,
  title={ReactorFold: Generative discovery of nuclear reactor cores via emergent physical reasoning},
  author={Yoonpyo Lee},
  journal={arXiv preprint arXiv:2512.15756v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15756v1}
}
```

## [LLaDA2.0: Scaling Up Diffusion Language Models to 100B](http://arxiv.org/abs/2512.15745v1)

#离散扩散语言模型#自回归到扩散的转换#专家混合（MoE）

[PDF](https://arxiv.org/pdf/2512.15745v1)
[Abstract](http://arxiv.org/abs/2512.15745v1)

 LLM

 很推荐

### 中文摘要

本文提出了 LLaDA2.0——一组通过系统性地将自回归（AR）模型转换为离散扩散大型语言模型（dLLM）并扩展至1000亿参数的新范式。与从零训练昂贵模型不同，LLaDA2.0 保持知识继承、渐进适配与效率感知的设计原则，提出了一种无缝将预训练自回归模型转换为 dLLM 的新方法：基于块级 WSD 的三阶段训练方案，包括在块扩散中逐步增大块尺寸的预热阶段（warm-up）、大规模全序列扩散的稳定阶段（stable）以及回退到紧凑块尺寸的衰减阶段（decay）。结合后训练的对齐方法（SFT 和 DPO），我们得到面向实用部署的两种指令调优 Mixture-of-Experts（MoE）变体：LLaDA2.0-mini（16B）和 LLaDA2.0-flash（100B）。该方法保留了并行解码的优势，在前沿规模上实现了更优的性能和效率。两款模型已开源。

BibTeX

```
@article{2512.15745v1,
  title={LLaDA2.0: Scaling Up Diffusion Language Models to 100B},
  author={Tiwei Bie and Maosong Cao and Kun Chen and Lun Du and Mingliang Gong and Zhuochen Gong and Yanmei Gu and Jiaqi Hu and Zenan Huang and Zhenzhong Lan and Chengxi Li and Chongxuan Li and Jianguo Li and Zehuan Li and Huabin Liu and Ling Liu and Guoshan Lu and Xiaocheng Lu and Yuxin Ma and Jianfeng Tan and Lanning Wei and Ji-Rong Wen and Yipeng Xing and Xiaolu Zhang and Junbo Zhao and Da Zheng and Jun Zhou and Junlin Zhou and Zhanchao Zhou and Liwang Zhu and Yihong Zhuang},
  journal={arXiv preprint arXiv:2512.15745v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15745v1}
}
```

## [Value Lens: Using Large Language Models to Understand Human Values](http://arxiv.org/abs/2512.15722v1)

#人类价值检测#大型语言模型#价值对齐

[PDF](https://arxiv.org/pdf/2512.15722v1)
[Abstract](http://arxiv.org/abs/2512.15722v1)

 LLM

 很推荐

### 中文摘要

自主决策正在越来越多地应用于计算机系统，这要求这些系统所做出的选择应与人类价值观相一致。因此，系统需要评估其决策在多大程度上反映了人类价值观，而实现这一点的关键在于识别每个可选动作是促进还是削弱这些价值观。本文提出了 Value Lens，一种基于文本、利用生成式人工智能特别是大型语言模型（LLM）来检测人类价值观的模型。该模型分两阶段运行：第一阶段旨在构建形式化的价值理论，第二阶段专注于在给定文本中识别这些价值。在第一阶段，LLM 根据既定的价值理论生成描述，随后由专家进行验证；在第二阶段，采用一对 LLM：一者负责检测价值的存在，另一者作为批评者和审查者对检测过程进行评估。实验结果表明，Value Lens 在效果上可与其它采用不同方法的模型相媲美，甚至在某些方面优于这些模型。

BibTeX

```
@article{2512.15722v1,
  title={Value Lens: Using Large Language Models to Understand Human Values},
  author={Eduardo de la Cruz Fernández and Marcelo Karanik and Sascha Ossowski},
  journal={arXiv preprint arXiv:2512.15722v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15722v1}
}
```

## [cuPilot: A Strategy-Coordinated Multi-agent Framework for CUDA Kernel Evolution](http://arxiv.org/abs/2512.16465v1)

#CUDA内核优化#多智能体进化框架#策略化表示

[PDF](https://arxiv.org/pdf/2512.16465v1)
[Abstract](http://arxiv.org/abs/2512.16465v1)

 高性能计算（CUDA内核优化 / 自动调优）

 很推荐

### 中文摘要

CUDA 内核的优化是一项具有挑战且劳动密集型的工作，因其需要硬件与软件的协同设计专业知识，并且高性能内核库通常具有专有特性。尽管近期将大型语言模型（LLM）与进化算法结合用于自动化内核优化显示出潜力，但现有方法常因智能体设计欠佳和进化表征不匹配而难以获得理想性能。本文指出了这些不匹配问题，并提出了 cuPilot——一个引入“策略”作为内核进化中间语义表征的策略协调多智能体框架。主要贡献包括：一种策略协调的进化算法、基于 roofline 的提示（prompting）方法、以及基于策略的种群初始化策略。实验结果表明，cuPilot 生成的内核在 100 个基准内核上相比 PyTorch 平均加速达 3.09×。在 GEMM 任务中，cuPilot 展示了复杂的优化能力并实现了对关键硬件单元的高效利用。生成的内核已开源于 https://github.com/champloo2878/cuPilot-Kernels.git。

BibTeX

```
@article{2512.16465v1,
  title={cuPilot: A Strategy-Coordinated Multi-agent Framework for CUDA Kernel Evolution},
  author={Jinwu Chen and Qidie Wu and Bin Li and Lin Ma and Xin Si and Yang Hu and Shouyi Yin and Jun Yang},
  journal={arXiv preprint arXiv:2512.16465v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16465v1}
}
```

## [Introducing ORKG ASK: an AI-driven Scholarly Literature Search and Exploration System Taking a Neuro-Symbolic Approach](http://arxiv.org/abs/2512.16425v1)

#学术文献检索#检索增强生成（RAG）#神经-符号方法

[PDF](https://arxiv.org/pdf/2512.16425v1)
[Abstract](http://arxiv.org/abs/2512.16425v1)

 LLM

 很推荐

### 中文摘要

随着已发表学术文献数量持续增长，查找相关文献变得愈加困难。随着生成式人工智能（尤其是大模型）的兴起，为文献检索与探索带来了新的可能性。我们提出了 ASK（Assistant for Scientific Knowledge），一种遵循神经-符号方法的 AI 驱动学术文献检索与探索系统。ASK 旨在通过结合向量检索、大型语言模型与知识图谱，为研究者在查找相关学术文献方面提供主动支持。系统允许用户以自然语言输入研究问题并检索相关论文，自动抽取关键信息，并采用检索增强生成（RAG）方法对研究问题生成答案。我们对 ASK 的可用性与实用性进行了评估，结果表明系统易于使用，用户总体满意度较高。

BibTeX

```
@article{2512.16425v1,
  title={Introducing ORKG ASK: an AI-driven Scholarly Literature Search and Exploration System Taking a Neuro-Symbolic Approach},
  author={Allard Oelen and Mohamad Yaser Jaradeh and Sören Auer},
  journal={arXiv preprint arXiv:2512.16425v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16425v1}
}
```

## [Kascade: A Practical Sparse Attention Method for Long-Context LLM Inference](http://arxiv.org/abs/2512.16391v1)

#稀疏注意力#长上下文推理#推理加速

[PDF](https://arxiv.org/pdf/2512.16391v1)
[Abstract](http://arxiv.org/abs/2512.16391v1)

 LLM

 很推荐

### 中文摘要

在长上下文大模型（LLM）推理中，注意力机制是导致延迟的主要瓶颈，这类工作负载在推理与检索增强生成（RAG）场景下愈发常见。我们提出 Kascade，一种无需训练的稀疏注意力方法，基于两项已知观察：1）经过 softmax 的注意力权重本质上是稀疏的；2）高权重键的身份在相邻层之间保持稳定。Kascade 在少数“锚层”中精确计算 Top-k 索引，然后在中间的复用层中重用这些索引。锚层通过一种动态规划的目标在开发集上算法化选择，以最大化跨层相似性，从而便于在不同模型上部署。该方法兼顾高效实现约束（例如基于 tile 的操作），同时适用于 prefill 和 decode 两种注意力计算。Kascade 的 Top-k 选择与复用是面向 attention head 的，我们的实验表明这一点对保持高准确率至关重要。Kascade 在 H100 GPU 上相比 FlashAttention-3 基线，在 decode 注意力上可实现最高 4.1 倍加速，在 prefill 注意力上可实现 2.2 倍加速，并在 LongBench 与 AIME-24 等长上下文基准上近似匹配密集注意力的准确性。

BibTeX

```
@article{2512.16391v1,
  title={Kascade: A Practical Sparse Attention Method for Long-Context LLM Inference},
  author={Dhruv Deshmukh and Saurabh Goyal and Nipun Kwatra and Ramachandran Ramjee},
  journal={arXiv preprint arXiv:2512.16391v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16391v1}
}
```

## [Hearing to Translate: The Effectiveness of Speech Modality Integration into LLMs](http://arxiv.org/abs/2512.16378v1)

#SpeechLLM#语音翻译基准#级联系统对比

[PDF](https://arxiv.org/pdf/2512.16378v1)
[Abstract](http://arxiv.org/abs/2512.16378v1)

 LLM

 很推荐

### 中文摘要

随着大语言模型（LLM）应用超越文本，作为原生模态的语音整合催生了SpeechLLM，旨在直接翻译口语，从而绕过传统的基于转录的级联流水线。然而，这种模态整合是否能在语音到文本翻译质量上超越已有的级联架构仍是未决问题。我们提出了“Hearing to Translate”——首个全面的测试套件，严格基准测试了5种最先进的SpeechLLM，并将其与16种强有力的直接式与级联系统进行比较，这些级联系统将领先的语音基础模型（SFM）与多语言LLM耦合。我们的分析覆盖16个基准、13种语言对和9种具有挑战性的条件（包括语流不连贯、噪声环境和长篇语音）。在这一次广泛评估中，我们发现：级联系统总体上仍是最可靠的方案，当前的SpeechLLM仅在部分情形下能与级联系统相匹配，而纯SFM的表现则落后于两者；这凸显出无论是在模型内部还是在流水线中整合LLM，对实现高质量语音翻译都是必不可少的。

BibTeX

```
@article{2512.16378v1,
  title={Hearing to Translate: The Effectiveness of Speech Modality Integration into LLMs},
  author={Sara Papi and Javier Garcia Gilabert and Zachary Hopton and Vilém Zouhar and Carlos Escolano and Gerard I. Gállego and Jorge Iranzo-Sánchez and Ahrii Kim and Dominik Macháček and Patricia Schmidtova and Maike Züfle},
  journal={arXiv preprint arXiv:2512.16378v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16378v1}
}
```

## [Pretrained Battery Transformer (PBT): A battery life prediction foundation model](http://arxiv.org/abs/2512.16334v1)

#电池寿命预测#基础模型#迁移学习

[PDF](https://arxiv.org/pdf/2512.16334v1)
[Abstract](http://arxiv.org/abs/2512.16334v1)

 基础模型（科学机器学习/能源AI）

 很推荐

### 中文摘要

电池循环寿命的早期预测对于加速电池研究、制造与部署至关重要。尽管机器学习方法已展现出可喜的成果，但数据稀缺性及由多样化衰老条件带来的异质性仍制约了进展。在其他领域，通过在多样化数据集上训练的基础模型（foundation models）结合迁移学习可以实现广泛的泛化能力，但目前尚未见针对电池循环寿命预测的基础模型报道。本文提出了预训练电池变换器（Pretrained Battery Transformer，PBT），这是首个用于电池寿命预测的基础模型，模型设计中引入了基于领域知识编码的混合专家层。经在最大规模的公开电池寿命数据库上验证，PBT从13个锂离子电池数据集中学习了可迁移的表征，平均较现有模型提升19.8%。通过迁移学习，PBT在涵盖不同工况、成型协议与化学体系的15个多样化数据集上达到了最先进的性能。该工作为电池寿命预测建立了基础模型路线，推动走向通用的电池寿命预测系统。

BibTeX

```
@article{2512.16334v1,
  title={Pretrained Battery Transformer (PBT): A battery life prediction foundation model},
  author={Ruifeng Tan and Weixiang Hong and Jia Li and Jiaqiang Huang and Tong-Yi Zhang},
  journal={arXiv preprint arXiv:2512.16334v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16334v1}
}
```

## [Dual Computational Horizons: Incompleteness and Unpredictability in Intelligent Systems](http://arxiv.org/abs/2512.16707v1)

#形式不完备性#动力学不可预判性#自我预测界限

[PDF](https://arxiv.org/pdf/2512.16707v1)
[Abstract](http://arxiv.org/abs/2512.16707v1)

 AI理论

 很推荐

### 中文摘要

我们形式化了约束算法智能的两个独立的计算性限制：形式不完备性与动力学不可预判性。前者限制了一致性推理系统的演绎能力，后者则在有限精度下对长期预测设定了上界。我们证明，这两类极端情况共同对智能体关于其自身预测能力的推理能力施加了结构性限制。具体而言，算法化的智能体在一般情况下无法计算出其自身的最大可预测时域。该视角澄清了智能系统中推理、预测与自我分析之间的内在权衡关系。

BibTeX

```
@article{2512.16707v1,
  title={Dual Computational Horizons: Incompleteness and Unpredictability in Intelligent Systems},
  author={Abhisek Ganguly},
  journal={arXiv preprint arXiv:2512.16707v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16707v1}
}
```

## [Few-Shot Fingerprinting Subject Re-Identification in 3D-MRI and 2D-X-Ray](http://arxiv.org/abs/2512.16685v1)

#受试者指纹化#少样本重识别#医学影像

[PDF](https://arxiv.org/pdf/2512.16685v1)
[Abstract](http://arxiv.org/abs/2512.16685v1)

 CV (Medical Imaging)

 很推荐

### 中文摘要

将开放源数据集合并可能引入数据泄漏：当同一受试者出现在多个数据集中时，会导致模型性能被高估。为了解决这一问题，本文探讨了受试者指纹化（subject fingerprinting）方法，即将同一受试者的所有影像映射到潜在空间中的特定区域，从而通过相似性匹配实现受试者再识别。我们使用以三元组余量损失（triplet margin loss）训练的 ResNet-50，在 3D MRI 与 2D X 光数据上评估少样本指纹化方法，包含标准场景（20-way 1-shot）和更具挑战性的场景（1000-way 1-shot）。在 Mean-Recall@K 指标上，模型表现优异：在 ChestXray-14 数据集上分别达到 99.10%（20-way 1-shot）和 90.06%（500-way 5-shot）；在 BraTS-2021 数据集上分别达到 99.20%（20-way 1-shot）和 98.86%（100-way 3-shot）。

BibTeX

```
@article{2512.16685v1,
  title={Few-Shot Fingerprinting Subject Re-Identification in 3D-MRI and 2D-X-Ray},
  author={Gonçalo Gaspar Alves and Shekoufeh Gorgi Zadeh and Andreas Husch and Ben Bausch},
  journal={arXiv preprint arXiv:2512.16685v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16685v1}
}
```

## [Refusal Steering: Fine-grained Control over LLM Refusal Behaviour for Sensitive Topics](http://arxiv.org/abs/2512.16602v1)

#拒绝引导#激活引导#模型安全与对齐

[PDF](https://arxiv.org/pdf/2512.16602v1)
[Abstract](http://arxiv.org/abs/2512.16602v1)

 LLM

 很推荐

### 中文摘要

我们提出了“拒绝引导”（Refusal Steering），一种在推理阶段对大语言模型在政治敏感话题上的拒绝行为进行细粒度控制的方法，无需重新训练。我们用一个“作为评判者的大语言模型”替代脆弱的基于模式的拒绝检测器，为响应分配拒绝置信度分数；并提出带岭回归正则化的变体来计算能更好地隔离“拒绝—遵从”方向的引导向量。在 Qwen3-Next-80B-A3B-Thinking 上，我们的方法在移除模型对政治敏感话题的拒绝行为的同时，仍在 JailbreakBench 上保持安全性，并在通用基准上接近基线性能。该方法可推广到 4B 与 80B 规模的模型，也能在需要时诱导针对性的拒绝。我们分析了引导向量，发现拒绝信号集中出现在 Transformer 的更深层且分布在多个维度上。综合这些结果表明，激活引导可以在保留对有害内容安全对齐的情况下消除政治拒绝行为，为在推理时实现可控且透明的内容审核提供了实用路径。

BibTeX

```
@article{2512.16602v1,
  title={Refusal Steering: Fine-grained Control over LLM Refusal Behaviour for Sensitive Topics},
  author={Iker García-Ferrero and David Montero and Roman Orus},
  journal={arXiv preprint arXiv:2512.16602v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16602v1}
}
```

## [Differences That Matter: Auditing Models for Capability Gap Discovery and Rectification](http://arxiv.org/abs/2512.16921v1)

#多模态大模型审计#失效模式发现#对抗性/反事实数据生成

[PDF](https://arxiv.org/pdf/2512.16921v1)
[Abstract](http://arxiv.org/abs/2512.16921v1)

 LLM

 很推荐

### 中文摘要

传统的多模态大模型（MLLM）评估方法缺乏可解释性，且常常无法充分揭示模型之间显著的能力差距。为了解决这一问题，我们提出了AuditDM，一种通过审计模型差异来主动发现并修正MLLM失效模式的自动化框架。AuditDM通过强化学习将某一MLLM微调为“审计器”，使其生成能够最大化目标模型间分歧的具有挑战性问题和反事实图像。训练完成后，该审计器能发现多样且可解释的示例，揭示模型弱点并作为无需人工标注的修正数据来源。在对Gemma-3和PaliGemma-2等先进模型的应用中，AuditDM发现了20余类不同的失效类型。基于这些发现进行微调，能在16个基准上稳定提升所有模型的表现，甚至使一个3B模型超过其28B的对照模型。我们的结果表明，在数据扩展收益递减的背景下，有针对性的模型审计为模型诊断与改进提供了一条高效路径。

BibTeX

```
@article{2512.16921v1,
  title={Differences That Matter: Auditing Models for Capability Gap Discovery and Rectification},
  author={Qihao Liu and Chengzhi Mao and Yaojie Liu and Alan Yuille and Wen-Sheng Chu},
  journal={arXiv preprint arXiv:2512.16921v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16921v1}
}
```

## [Meta-RL Induces Exploration in Language Agents](http://arxiv.org/abs/2512.16848v1)

#元强化学习#主动探索#LLM代理

[PDF](https://arxiv.org/pdf/2512.16848v1)
[Abstract](http://arxiv.org/abs/2512.16848v1)

 LLM (Meta-RL)

 很推荐

### 中文摘要

强化学习（RL）已使大型语言模型（LLM）代理能够与环境交互并解决多回合长时序任务。然而，基于RL训练的代理在需要主动探索的任务中常常表现欠佳，且难以从试错经验中高效适应。为此，本文提出LaMer，一种通用的元强化学习（Meta-RL）框架，使得LLM代理在测试时能够主动探索并从环境反馈中学习。LaMer包括两个核心组件：（i）跨回合训练框架，用以鼓励探索并优化长期回报；（ii）通过反思进行的上下文内策略自适应，使代理能够在无需梯度更新的情况下根据任务反馈调整策略。跨多种环境的实验表明，LaMer较传统RL基线显著提升性能：在Sokoban、Minesweeper和Webshop上分别获得约11%、14%和19%的性能增益。此外，LaMer在更具挑战性或此前未见过的任务上的泛化能力也优于常规模型。总体而言，我们的结果表明，元强化学习为在语言代理中引入主动探索提供了有力的理论和实践途径，能够通过学习到的探索策略实现对新环境的更鲁棒适应。

BibTeX

```
@article{2512.16848v1,
  title={Meta-RL Induces Exploration in Language Agents},
  author={Yulun Jiang and Liangze Jiang and Damien Teney and Michael Moor and Maria Brbic},
  journal={arXiv preprint arXiv:2512.16848v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16848v1}
}
```

## [From Facts to Conclusions : Integrating Deductive Reasoning in Retrieval-Augmented LLMs](http://arxiv.org/abs/2512.16795v1)

#检索增强生成#可解释推理#冲突感知评估

[PDF](https://arxiv.org/pdf/2512.16795v1)
[Abstract](http://arxiv.org/abs/2512.16795v1)

 LLM

 很推荐

### 中文摘要

检索增强生成（RAG）通过外部证据为大型语言模型（LLM）提供支撑，但在检索到的来源存在冲突、过时或主观信息时会失效。以往工作各自解决了这些问题，但缺乏统一的、有监督的推理流程。我们提出了一种带有推理轨迹的RAG框架，在三个阶段引入结构化、可解释的推理： (1) 文档层面的裁定（document-level adjudication），(2) 冲突分析（conflict analysis），以及 (3) 基于证据的综合生成（grounded synthesis），以产生带引用的答案或有正当理由的拒绝。为评估系统的表现，我们引入了冲突感知信任评分（Conflict-Aware Trust-Score, CATS）流程，利用“以LLM为裁判”的方式评估基于证据性、事实正确性、拒绝准确性以及在冲突情形下的行为一致性。我们构建了包含539条查询的推理数据集和完整评估流程，为冲突感知且可解释的RAG系统奠定了基础。实验证明，本方法在基线之上带来显著提升；以Qwen为例，经过监督微调后端到端答案正确率从0.069提升到0.883，行为一致性从0.074提升到0.722。

BibTeX

```
@article{2512.16795v1,
  title={From Facts to Conclusions : Integrating Deductive Reasoning in Retrieval-Augmented LLMs},
  author={Shubham Mishra and Samyek Jain and Gorang Mehrishi and Shiv Tiwari and Harsh Sharma and Pratik Narang and Dhruv Kumar},
  journal={arXiv preprint arXiv:2512.16795v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16795v1}
}
```

## [Code-in-the-Loop Forensics: Agentic Tool Use for Image Forgery Detection](http://arxiv.org/abs/2512.16300v1)

#图像篡改检测#代理式工具使用#多模态大模型

[PDF](https://arxiv.org/pdf/2512.16300v1)
[Abstract](http://arxiv.org/abs/2512.16300v1)

 LLM

 很推荐

### 中文摘要

现有的图像篡改检测（IFD）方法要么利用低层次、与语义无关的痕迹，要么依赖具备高层语义知识的多模态大语言模型（MLLMs）。尽管这两类信息天然互补，但在范式与推理方式上差异巨大，导致现有方法难以将二者统一或有效建模其跨层次交互。为此，我们提出了ForenAgent，一种多轮交互的IFD框架，使得MLLM能够围绕检测目标自主生成、执行并迭代精化基于Python的低层工具，从而实现更灵活且可解释的篡改分析。ForenAgent 采用冷启动（Cold Start）与强化微调（Reinforcement Fine-Tuning）相结合的两阶段训练流程，逐步提升其工具交互能力与推理适应性。受到人类推理过程的启发，我们设计了一个包含全局感知、局部聚焦、迭代探查与整体裁决的动态推理环路，并将其既作为数据采样策略又作为与任务对齐的过程性奖励来实现。为系统化训练与评估，我们构建了FABench——一个异质且高质量的代理取证数据集，包含10万张图像与约20万条代理交互问答对。实验结果表明，在低层工具辅助下，ForenAgent 在具有挑战性的IFD任务上展现出新兴的工具使用能力与反思性推理，指明了一条通向通用化图像篡改检测的有希望的路线。代码将在评审结束后开源。

BibTeX

```
@article{2512.16300v1,
  title={Code-in-the-Loop Forensics: Agentic Tool Use for Image Forgery Detection},
  author={Fanrui Zhang and Qiang Zhang and Sizhuo Zhou and Jianwen Sun and Chuanhao Li and Jiaxin Ai and Yukang Feng and Yujie Zhang and Wenjie Li and Zizhen Li and Yifan Chang and Jiawei Liu and Kaipeng Zhang},
  journal={arXiv preprint arXiv:2512.16300v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16300v1}
}
```

## [Feature-Selective Representation Misdirection for Machine Unlearning](http://arxiv.org/abs/2512.16297v1)

#机器遗忘#激活编辑#大模型安全

[PDF](https://arxiv.org/pdf/2512.16297v1)
[Abstract](http://arxiv.org/abs/2512.16297v1)

 LLM

 很推荐

### 中文摘要

随着大规模语言模型（LLM）在安全相关和受监管领域的广泛部署，敏感或被禁止知识的保留带来了不断升级的风险，涵盖隐私泄露、合规性问题以及潜在的滥用等。近期研究表明，机器遗忘（machine unlearning）有助于保证已部署模型满足不断变化的法律、安全和治理要求。然而，现有的遗忘技术通常假设待忘（forget）与保留（retain）数据集之间可以被干净地分离，在实际运行环境中高度纠缠的分布往往使这一假设难以成立。在此类场景下，基于扰动的方法往往会损害模型的整体效用或无法确保安全性。为了解决这些问题，我们提出了用于遗忘的选择性表示误导（Selective Representation Misdirection for Unlearning，SRMU），这是一种新颖且有理论支撑的激活编辑框架，能够施加对特征敏感且具方向性的扰动。不同于无差别地扰动模型权重，SRMU 使用结构化的误导向量配合激活重要性图，旨在选择性地抑制有害表示，同时尽可能保留对良性表示的效用。我们在广泛使用的 WMDP 基准上对低/高纠缠配置进行了实验。实证结果表明，SRMU 在保持极低效用损失的情况下实现了最先进的遗忘性能，并且在现有基线方法崩溃的 20%–30% 重叠区域仍然有效。SRMU 为以安全为驱动的模型治理、隐私合规以及在新兴 LLM 应用中受控知识移除提供了稳健的基础。我们已在 https://figshare.com/s/d5931192a8824de26aff 发布复现包。

BibTeX

```
@article{2512.16297v1,
  title={Feature-Selective Representation Misdirection for Machine Unlearning},
  author={Taozhao Chen and Linghan Huang and Kim-Kwang Raymond Choo and Huaming Chen},
  journal={arXiv preprint arXiv:2512.16297v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16297v1}
}
```

## [Learning to Wait: Synchronizing Agents with the Physical World](http://arxiv.org/abs/2512.16262v1)

#时间感知#LLM智能体#异步环境同步

[PDF](https://arxiv.org/pdf/2512.16262v1)
[Abstract](http://arxiv.org/abs/2512.16262v1)

 LLM (交互式智能体)

 很推荐

### 中文摘要

真实世界的智能体任务与同步的马尔可夫决策过程（MDP）不同，常常包含非阻塞动作且存在可变延迟，从而在动作发起与完成之间产生根本性的“时间间隙”。现有在环境侧的解决方案（如阻塞包装器或频繁轮询）要么限制了系统的可扩展性，要么通过冗余观测稀释了智能体的上下文窗口。本文提出一种面向智能体的方法，使大模型（LLM）能够主动将其“认知时间线”与物理世界对齐。我们将“代码即动作（Code-as-Action）”范式扩展到时间域，智能体利用语义先验与上下文学习（ICL）预测精确的等待时长（如 time.sleep(t)），从而在不进行穷尽性检查的情况下与异步环境同步。在模拟的 Kubernetes 集群实验中，智能体能够精确校准其内部时钟，以最小化查询开销和执行延迟，验证了时间感知是一种可学习的能力，对于开放式环境中的自主演化至关重要。

BibTeX

```
@article{2512.16262v1,
  title={Learning to Wait: Synchronizing Agents with the Physical World},
  author={Yifei She and Ping Zhang and He Liu and Yanmin Jia and Yang Jing and Zijun Liu and Peng Sun and Xiangbin Li and Xiaohe Hu},
  journal={arXiv preprint arXiv:2512.16262v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16262v1}
}
```

## [Coarse-to-Fine Open-Set Graph Node Classification with Large Language Models](http://arxiv.org/abs/2512.16244v1)

#开集分类#图神经网络（GNN）#大语言模型（LLM）

[PDF](https://arxiv.org/pdf/2512.16244v1)
[Abstract](http://arxiv.org/abs/2512.16244v1)

 LLM 与图神经网络（GNN）

 很推荐

### 中文摘要

在开放世界场景中部署图神经网络（GNN）时，开发既能对内部分布（ID）数据进行分类又能检测出分布外（OOD）样本的开集分类方法至关重要。现有方法通常将所有OOD样本视为单一类别，但实际应用中，尤其是欺诈检测和医疗诊断等高风险场景，要求对OOD样本提供更深层次的洞见，包括其可能的标签。这引出一个关键问题：在没有真实标签信息的情况下，是否可以将OOD检测扩展为OOD分类？为此，我们提出了一种面向图数据、利用大语言模型（LLM）的粗到细开集分类（CFC）框架。CFC 包含三大核心组件：使用 LLM 提示进行 OOD 检测与异常标签生成的粗分类器；基于 GNN 的细分类器，利用粗分类器识别出的 OOD 样本进行训练，以提升 OOD 检测和 ID 分类性能；以及通过 LLM 提示与对 OOD 标签的后处理实现的精细化 OOD 分类。与依赖合成或辅助 OOD 样本的方法不同，CFC 采用语义上真正意义上的 OOD 实例（基于其内在语义而非合成构造），从而提高了可解释性和实际可用性。实验结果表明，在图和文本领域，CFC 在 OOD 检测上较最先进方法提升约 10%，并在图数据集上实现了高达 70% 的 OOD 分类准确率。

BibTeX

```
@article{2512.16244v1,
  title={Coarse-to-Fine Open-Set Graph Node Classification with Large Language Models},
  author={Xueqi Ma and Xingjun Ma and Sarah Monazam Erfani and Danilo Mandic and James Bailey},
  journal={arXiv preprint arXiv:2512.16244v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16244v1}
}
```

## [Scaling Spatial Reasoning in MLLMs through Programmatic Data Synthesis](http://arxiv.org/abs/2512.16237v1)

#空间推理#程序化数据合成#视觉-语言模型

[PDF](https://arxiv.org/pdf/2512.16237v1)
[Abstract](http://arxiv.org/abs/2512.16237v1)

 LLM

 很推荐

### 中文摘要

具身智能是人工智能的重大挑战，而当前模型在空间理解与推理能力上的不足，成为其发展的根本瓶颈。现有提升视觉-语言模型（VLM）空间能力的工作面临两难：基于模板的数据集可扩展但结构僵化，人工标注在语言多样性上有优势却不可扩展且在计算上缺乏精确性。为此，我们提出 SPRITE，一种新颖框架，通过结合模拟器与大型模型，程序化地合成可扩展、多样且高质量的空间推理数据，从而打破上述困境。SPRITE 的核心创新是将“生成真实标签”重构为代码生成任务：我们利用大型语言模型将复杂的空间问题编译为可执行程序，再将这些程序在从模拟器提取的高精度场景元信息上运行并验证。该方法既保证了真实标签的计算精确性与可验证性，又利用大型模型的生成能力带来丰富的语言多样性。基于此流水线，我们构建了包含 3 个模拟器、11k+ 场景与 30万+ 图像/视频指令微调样本的数据集。实验证明，使用该数据训练的 VLM 在多项空间基准上取得显著性能提升，且优于等规模的其他开源数据集。此外，规模化分析支持我们关于“打破传统模板方法低多样性是构建稳健通用空间智能关键”的假设。我们将公开 SPRITE 框架代码与完整的 30 万+ 数据集，以促进空间智能方向的后续研究。

BibTeX

```
@article{2512.16237v1,
  title={Scaling Spatial Reasoning in MLLMs through Programmatic Data Synthesis},
  author={Zhi Helu and Huang Jingjing and Xu Wang and Xu Yangbin and Zhang Wanyue and Jiang Baoyang and Deng Shirui and Zhu Liang and Li Fangfang and Zhao Tiejun and Lin Yankai and Yao Yuan},
  journal={arXiv preprint arXiv:2512.16237v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16237v1}
}
```

## [Open Ad-hoc Categorization with Contextualized Feature Learning](http://arxiv.org/abs/2512.16202v1)

#开放即席分类#上下文可学习令牌#视觉语义扩展与聚类

[PDF](https://arxiv.org/pdf/2512.16202v1)
[Abstract](http://arxiv.org/abs/2512.16202v1)

 CV

 很推荐

### 中文摘要

对视觉场景进行自适应分类对于AI智能体应对不断变化的任务至关重要。与植物或动物等固定的常见类别不同，即席（ad-hoc）类别是为了特定目标动态创建的。我们研究开放式即席分类问题：在给定少量带标签示例和大量无标签数据的情况下，目标是发现潜在的上下文，并通过语义扩展和基于视觉的聚类来扩展即席类别。基于即席类别和常见类别依赖相似感知机制的洞见，我们提出了OAK，一种简单模型：在冻结的CLIP输入端引入一小组可学习的上下文令牌，并同时使用CLIP的图像-文本对齐目标与GCD的视觉聚类目标进行优化。 在Stanford和Clevr-4数据集上，OAK在准确率和概念发现任务上均达到了最先进水平，包括在Stanford Mood上取得87.4%的新类别准确率，较CLIP和GCD提升超过50%。此外，OAK还生成可解释的显著性图，分别在动作类关注手部、情绪类关注面部、位置类关注背景，从而提升透明性与信任度，并实现自适应且具有良好泛化能力的分类。

BibTeX

```
@article{2512.16202v1,
  title={Open Ad-hoc Categorization with Contextualized Feature Learning},
  author={Zilin Wang and Sangwoo Mo and Stella X. Yu and Sima Behpour and Liu Ren},
  journal={arXiv preprint arXiv:2512.16202v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16202v1}
}
```

## [TinyMyo: a Tiny Foundation Model for Flexible EMG Signal Processing at the Edge](http://arxiv.org/abs/2512.15729v1)

#表面肌电(EMG)#轻量级基础模型#边缘嵌入式部署

[PDF](https://arxiv.org/pdf/2512.15729v1)
[Abstract](http://arxiv.org/abs/2512.15729v1)

 EMG（生物电信号处理）

 很推荐

### 中文摘要

表面肌电（EMG）是一种非侵入式的传感模态，广泛应用于生物力学、康复、假肢控制以及新兴的人机交互范式。尽管已被使用数十年，但在跨受试者、记录系统和采集协议下实现稳健泛化仍然面临重大挑战。为应对这些问题，基础模型（Foundation Models）在面向基于EMG信号的端到端应用中逐渐受到关注；然而，现有的EMG基础模型通常仅限于单一下游任务，且难以在嵌入式平台上部署。本工作提出TinyMyo，一种基于Transformer编码器的轻量级基础模型，采用自监督方式在公开数据集上进行预训练，仅有3.6M参数却能实现高保真重建。通过对任务特定头部的最小改动，同一主干可用于多种下游任务，并利用来自不同传感位置和硬件平台的数据实现泛化。我们展示了其在手势分类、手部运动学回归、语音生成与识别等任务上的泛化能力，性能可与或超越现有最先进方法，且模型尺寸均低于5M参数。在NinaPro DB5（89.4±0.16%）、UCI-EMG（97.56±0.32%）和EPN-612（96.74±0.09%）数据集上达到了与此前基于基础模型工作的最先进结果。我们还（据我们所知）首次将EMG基础模型部署于超低功耗微控制器（GAP9）上，实现平均功耗36.45mW。通过开源预训练模型与下游任务架构（https://github.com/pulp-bio/BioFoundation），我们旨在为未来研究提供灵活资源，并作为EMG社区的通用基础。

BibTeX

```
@article{2512.15729v1,
  title={TinyMyo: a Tiny Foundation Model for Flexible EMG Signal Processing at the Edge},
  author={Matteo Fasulo and Giusy Spacone and Thorir Mar Ingolfsson and Yawei Li and Luca Benini and Andrea Cossettini},
  journal={arXiv preprint arXiv:2512.15729v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15729v1}
}
```

## [BRAID: Bounded Reasoning for Autonomous Inference and Decisions](http://arxiv.org/abs/2512.15959v1)

#有界推理#结构化提示#自治代理系统

[PDF](https://arxiv.org/pdf/2512.15959v1)
[Abstract](http://arxiv.org/abs/2512.15959v1)

 LLM

 很推荐

### 中文摘要

大型语言模型（LLMs）在性能、成本与令牌使用之间存在非线性关系。本文对一种结构化提示方法BRAID（Bounded Reasoning for Autonomous Inference and Decisions）进行了定量研究，覆盖多种GPT模型层级，并在AdvancedIF、GSM-Hard和SCALE MultiChallenge基准数据集上进行了评估。BRAID引入了一种有界推理框架，利用基于Mermaid的指令图使模型以结构化的方式进行推理，而非依赖无界的自然语言令牌扩展。我们表明，结构化的机器可读提示能显著提升推理准确性并提高生产系统中代理的成本效率。研究结果确立了BRAID作为在自治代理系统中优化推理效率的有效且可扩展的技术。所有数据集和详细结果日志可在 https://benchmark.openserv.ai 获取。

BibTeX

```
@article{2512.15959v1,
  title={BRAID: Bounded Reasoning for Autonomous Inference and Decisions},
  author={Armağan Amcalar and Eyup Cinar},
  journal={arXiv preprint arXiv:2512.15959v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15959v1}
}
```

## [Surrogate Neural Architecture Codesign Package (SNAC-Pack)](http://arxiv.org/abs/2512.15998v1)

#硬件感知神经架构搜索#FPGA部署#多目标优化

[PDF](https://arxiv.org/pdf/2512.15998v1)
[Abstract](http://arxiv.org/abs/2512.15998v1)

 硬件感知神经架构搜索（NAS/FPGA）

 很推荐

### 中文摘要

神经架构搜索（NAS）是自动化模型设计的一种强有力方法，但现有方法在针对真实硬件性能进行准确优化方面存在困难，通常依赖诸如位运算（BOPs）等代理度量。我们提出了 Surrogate Neural Architecture Codesign Package（SNAC-Pack），这是一个面向 FPGA 部署的集成化框架，用于自动发现与优化神经网络。SNAC-Pack 将神经架构共设计的多阶段搜索能力与资源利用与延迟估计器相结合，实现了在不对每个候选模型进行耗时综合的前提下，在准确率、FPGA 资源利用和延迟之间进行多目标优化。我们在一项高能物理喷注分类任务上展示了 SNAC-Pack，在资源估计条件下达到了 63.84% 的准确率。将该模型综合到 Xilinx Virtex UltraScale+ VU13P FPGA 后，SNAC-Pack 模型在保持基线准确率的同时，其资源利用与基于传统 BOPs 指标优化的模型相当。该工作展示了面向资源受限部署的硬件感知神经架构搜索的潜力，并提供了一个用于自动化设计高效 FPGA 加速模型的开源框架。

BibTeX

```
@article{2512.15998v1,
  title={Surrogate Neural Architecture Codesign Package (SNAC-Pack)},
  author={Jason Weitz and Dmitri Demler and Benjamin Hawks and Nhan Tran and Javier Duarte},
  journal={arXiv preprint arXiv:2512.15998v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15998v1}
}
```

## [Cultural Rights and the Rights to Development in the Age of AI: Implications for Global Human Rights Governance](http://arxiv.org/abs/2512.15786v1)

#文化权利#发展权#人工智能治理

[PDF](https://arxiv.org/pdf/2512.15786v1)
[Abstract](http://arxiv.org/abs/2512.15786v1)

 AI伦理与治理

 推荐

### 中文摘要

文化权利与发展权是国际人权法框架中的重要规范。然而，近年来人工智能（AI）及相关数字前沿技术的进展，对这些权利的保护与实现构成了重大挑战。AI系统日益影响文化内容的创造与呈现，改变个人与社区知识产权的使用与分配，并影响全球范围内的文化参与与表达。此外，AI的扩张有可能加剧既存的经济、社会与数字鸿沟，进一步固化对弱势群体的不平等。上述动态挑战了文化权利与发展权之间既有的相互关系，并就如何在新兴AI治理框架中纳入文化与发展议题提出了疑问。为应对这些挑战，本文审视了AI对上述两类权利的影响：在概念层面分析了AI在算法设计与部署中所蕴含的认知与规范局限性，以及这些局限对文化与发展假设的影响；在实质层面探讨了AI对个体与结构性权利实现的具体作用机制。基于此分析，本文识别了现有AI治理框架中在文化权利与发展权保护方面的空白与张力。通过将文化权利与发展权置于AI与人权的更广阔语境中，本文旨在为AI伦理、法律框架与国际人权法的学术讨论做出贡献，并在现有全球AI治理对话基础上提出未来研究与政策发展的路径。

BibTeX

```
@article{2512.15786v1,
  title={Cultural Rights and the Rights to Development in the Age of AI: Implications for Global Human Rights Governance},
  author={Alexander Kriebitz and Caitlin Corrigan and Aive Pevkur and Alberto Santos Ferro and Amanda Horzyk and Dirk Brand and Dohee Kim and Dodzi Koku Hattoh and Flavia Massucci and Gilles Fayad and Kamil Strzepek and Laud Ammah and Lavina Ramkissoon and Mariette Awad and Natalia Amasiadi and Nathan C. Walker and Nicole Manger and Sophia Devlin},
  journal={arXiv preprint arXiv:2512.15786v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15786v1}
}
```

## [Enhanced Web User Interface Design Via Cross-Device Responsiveness Assessment Using An Improved HCI-INTEGRATED DL Schemes](http://arxiv.org/abs/2512.15775v1)

#跨设备响应性评估#人机交互与用户体验#深度学习与群体优化

[PDF](https://arxiv.org/pdf/2512.15775v1)
[Abstract](http://arxiv.org/abs/2512.15775v1)

 HCI

 推荐

### 中文摘要

用户界面（UI）优化在数字化时代对于提升网页环境下的用户满意度至关重要。然而，现有的UI优化模型常常忽视跨设备响应性（Cross-Responsiveness, CR）的评估，从而影响用户交互效率。为此，本文提出了一种基于CR评估的动态网页UI优化方法，结合有限指数连续状态机（Finite Exponential Continuous State Machine, FECSM）与Quokka非线性差分群体优化算法（Quokka Nonlinear Difference Swarm Optimization Algorithm, QNDSOA）。具体流程为：首先采集与设计及用户交互相关的数据，并通过最小-最大归一化进行预处理；随后提取基于人机交互（HCI）的特征并进行用户行为模式分组；与此同时，采用FECSM开展跨设备响应性评估；接着提出了双向门控 Luong-Mish 递归单元（Bidirectional Gated Luong and Mish Recurrent Unit, BiGLMRU）用于对基于用户界面变化预测指标（User Interface Change Prediction Index, UICPI）标注的用户体验（UX）变化类型进行分类；最后引入改进的QNDSOA对UI设计进行优化，实验中平均适应度达到98.5632%。在最优部署后还进行了反馈监测以评估实际效果。

BibTeX

```
@article{2512.15775v1,
  title={Enhanced Web User Interface Design Via Cross-Device Responsiveness Assessment Using An Improved HCI-INTEGRATED DL Schemes},
  author={Shrinivass Arunachalam Balasubramanian},
  journal={arXiv preprint arXiv:2512.15775v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15775v1}
}
```

## [Next-Generation License Plate Detection and Recognition System using YOLOv8](http://arxiv.org/abs/2512.16826v1)

#车牌检测与识别#YOLOv8#边缘设备部署

[PDF](https://arxiv.org/pdf/2512.16826v1)
[Abstract](http://arxiv.org/abs/2512.16826v1)

 CV

 推荐

### 中文摘要

在不断发展的交通管理和车辆监控领域，高效的车牌检测与识别是不可或缺的。尽管历史上已有多种方法用于解决该问题，但在多样化环境下实现稳定的实时高精度仍具有挑战性。本研究评估了YOLOv8不同变体在车牌识别（LPR）和字符识别任务上的表现，这两项任务对推进智能交通系统至关重要。实验采用了两个不同的数据集进行训练与评估，得到若干显著结果。在LPR任务中，YOLOv8 Nano变体在精确率（precision）上达到0.964，mAP50为0.918；在字符识别任务中，YOLOv8 Small变体的精确率为0.92，mAP50为0.91。研究中引入了一种基于字符x轴位置的自定义字符排序方法，用于对检测到的字符进行正确序列化。基于此，提出了一条优化的流水线：在LPR阶段使用YOLOv8 Nano，在字符识别阶段使用YOLOv8 Small。该配置在保持计算效率的同时确保了较高的识别精度，为未来在边缘设备上实际部署的智能交通系统奠定了稳健基础。该工作为构建更智能、更高效的城市基础设施迈出了一步。

BibTeX

```
@article{2512.16826v1,
  title={Next-Generation License Plate Detection and Recognition System using YOLOv8},
  author={Arslan Amin and Rafia Mumtaz and Muhammad Jawad Bashir and Syed Mohammad Hassan Zaidi},
  journal={arXiv preprint arXiv:2512.16826v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16826v1}
}
```

## [Implementing a Sharia Chatbot as a Consultation Medium for Questions About Islam](http://arxiv.org/abs/2512.16644v1)

#宗教问答聊天机器人#语义嵌入（Sentence-Transformers）#强化学习（Q-Learning）

[PDF](https://arxiv.org/pdf/2512.16644v1)
[Abstract](http://arxiv.org/abs/2512.16644v1)

 NLP

 推荐

### 中文摘要

本研究提出并实现了一种遵循伊斯兰教法（Sharia）的问答聊天机器人，作为解答宗教问题的互动咨询工具。系统采用强化学习（Q-Learning）与 Sentence-Transformers 语义嵌入相结合，以确保回应在语境上准确且相关。研究遵循 CRISP-DM 方法论，处理了来自《古兰经》、圣训（Hadith）和学者裁判（fatwa）等权威来源的经过整理的 25,000 对问答对，数据以 JSON 格式存储以增强灵活性和可扩展性。原型系统以 Flask API 作为后端、Flutter 开发移动前端，功能测试在包括教法（fiqh）、信条（aqidah）、礼拜（ibadah）与社会交易/人际往来（muamalah）等多主题上取得了 87% 的语义准确率，展示了其在提升宗教素养、数字化传教（da'wah）以及获取经认证伊斯兰知识方面的潜力。研究也指出了当前系统对封闭领域查询的有效性以及存在的局限性，如学习静态化和对数据集的依赖，进而提出未来改进方向，包括持续自适应学习与支持多轮对话等，以期将传统伊斯兰学术与现代 AI 驱动的咨询服务相连接。

BibTeX

```
@article{2512.16644v1,
  title={Implementing a Sharia Chatbot as a Consultation Medium for Questions About Islam},
  author={Wisnu Uriawan and Aria Octavian Hamza and Ade Ripaldi Nuralim and Adi Purnama and Ahmad Juaeni Yunus and Anissya Auliani Supriadi Putri},
  journal={arXiv preprint arXiv:2512.16644v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16644v1}
}
```

## [PCIA: A Path Construction Imitation Algorithm for Global Optimization](http://arxiv.org/abs/2512.16392v1)

#路径构建#元启发式算法#全局优化

[PDF](https://arxiv.org/pdf/2512.16392v1)
[Abstract](http://arxiv.org/abs/2512.16392v1)

 元启发式优化

 推荐

### 中文摘要

本文提出了一种新的元启发式优化算法，称为路径构建模仿算法（PCIA）。PCIA 的设计灵感源自人类如何构建并使用路径：人们通常偏好流行的交通路线，当某条路径被封闭时，会通过智能地混合已有路径来构建新路线；在面对未知目的地时，人们也会以一定的随机性选择不同的路径。PCIA 通过生成随机种群来寻找通往目标的最佳路线，其机制类似于基于群体的算法，种群中的每个个体代表一条通向目标的路径。作者在 53 个数学优化问题和 13 个约束优化问题上对 PCIA 进行了测试，结果表明与若干流行及最新的元启发式算法相比，PCIA 具有很强的竞争力。

BibTeX

```
@article{2512.16392v1,
  title={PCIA: A Path Construction Imitation Algorithm for Global Optimization},
  author={Mohammad-Javad Rezaei and Mozafar Bag-Mohammadi},
  journal={arXiv preprint arXiv:2512.16392v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16392v1}
}
```

## [Coordinated Anti-Jamming Resilience in Swarm Networks via Multi-Agent Reinforcement Learning](http://arxiv.org/abs/2512.16813v1)

#多智能体强化学习#反应型干扰抑制#蜂群通信鲁棒性

[PDF](https://arxiv.org/pdf/2512.16813v1)
[Abstract](http://arxiv.org/abs/2512.16813v1)

 RL

 推荐

### 中文摘要

反应型干扰器通过选择性破坏智能体间通信，威胁机器人蜂群网络的编队完整性和任务成功，使得传统的固定功率控制或静态跳频等对策在面对自适应对手时效果有限。本文提出了一种基于QMIX算法的多智能体强化学习（MARL）框架，以提高蜂群通信在反应型干扰下的鲁棒性。研究考虑多个发射-接收对共享信道的场景，干扰器具有基于阈值的马尔可夫动力学，会感测聚合功率并据此做出反应。每个智能体联合选择发射频率（信道）和发射功率，QMIX学习一个集中化但可分解的动作价值函数，从而支持协调化的、可去中心化执行。我们在无信道复用的情形下将QMIX与具有先验信息的最优策略（genie-aided optimal policy）进行了基准比较；在允许信道复用且存在衰落的更一般场景中，又将其与局部的上置信界（UCB）算法和无状态的反应式策略进行了比较。仿真结果表明，QMIX能够快速收敛到近似于具有先验信息上界的合作策略，在吞吐量和被干扰事件发生率上均优于基线方法，从而证明了MARL在受对抗环境中保障自主蜂群通信的有效性。

BibTeX

```
@article{2512.16813v1,
  title={Coordinated Anti-Jamming Resilience in Swarm Networks via Multi-Agent Reinforcement Learning},
  author={Bahman Abolhassani and Tugba Erpek and Kemal Davaslioglu and Yalin E. Sagduyu and Sastry Kompella},
  journal={arXiv preprint arXiv:2512.16813v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16813v1}
}
```

## [Hybrid Quantum-Classical Ensemble Learning for S\&P 500 Directional Prediction](http://arxiv.org/abs/2512.15738v1)

#量子-经典混合#集成学习#金融时序预测

[PDF](https://arxiv.org/pdf/2512.15738v1)
[Abstract](http://arxiv.org/abs/2512.15738v1)

 金融时序预测 / 强化学习(Decision Transformer)

 推荐

### 中文摘要

金融市场预测是机器学习的一个挑战性应用，即使是方向性精度的小幅提升也能带来可观价值。由于高噪声、非平稳性和市场有效性，大多数模型难以超过55%–57%的准确率。我们提出一种混合量子-经典集成框架，结合量子情感分析、Decision Transformer 架构与策略性模型选择，在S&P 500方向性预测上实现了60.14%的准确率，比单一模型提高了3.10%。
我们的框架针对以往方法的三点局限性提出了解决方案。其一，架构多样性优于数据集多样性：在相同数据上结合不同学习算法（LSTM、Decision Transformer、XGBoost、随机森林、逻辑回归）优于在多个数据集上训练相同架构（60.14% vs. 52.80%），相关性分析显示相同架构模型间相关系数 r>0.6。其二，基于4量子比特的可变参量量子电路增强了情感分析，为每个模型带来约+0.8%到+1.5%的增益。其三，智能筛选排除了弱预测器（准确率<52%），提升了集成性能（选取表现最好的7个模型：60.14% vs. 全部35个模型：51.2%）。
我们在2020–2023年的市场数据上（覆盖七类标的，包含COVID-19崩盘和因通胀驱动的调整等不同市场状态）进行了评估。McNemar检验表明结果具统计显著性（p<0.05）。基于置信度的回测（6+模型一致）初步显示夏普比为1.2，而买入并持有策略为0.8，证明了该方法在实盘交易上的潜在价值。

BibTeX

```
@article{2512.15738v1,
  title={Hybrid Quantum-Classical Ensemble Learning for S\&P 500 Directional Prediction},
  author={Abraham Itzhak Weinberg},
  journal={arXiv preprint arXiv:2512.15738v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15738v1}
}
```

## [A Context-Free Smart Grid Model Using Complex System Approach](http://arxiv.org/abs/2512.15733v1)

#智能电网#复杂系统建模#博弈论优化

[PDF](https://arxiv.org/pdf/2512.15733v1)
[Abstract](http://arxiv.org/abs/2512.15733v1)

 智能电网（复杂系统建模）

 推荐

### 中文摘要

能源与污染是21世纪亟需解决的问题。通过逐步改造现有电力系统，智能电网可能会在规模、组成和运行策略上演化为不同的系统，但其根本需求与目标不会改变，例如优化发电、输电与用电。通过建模与仿真研究智能电网，可以获得现实世界中由于时间和成本限制难以获得的有价值结果。另一方面，鉴于智能电网的复杂性，实现全局最优并非易事。本文提出了一种基于复杂系统方法的智能电网建模方法，着重通过在不同层次上将博弈论方法与传统方法相结合来实现优化。得益于该组合，优化在保持通用性的同时具有灵活性与可扩展性。

BibTeX

```
@article{2512.15733v1,
  title={A Context-Free Smart Grid Model Using Complex System Approach},
  author={Soufian Ben Amor and Alain Bui and Guillaume Guerard},
  journal={arXiv preprint arXiv:2512.15733v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15733v1}
}
```

## [Autoencoder-based Denoising Defense against Adversarial Attacks on Object Detection](http://arxiv.org/abs/2512.16123v1)

#对抗攻击防御#自动编码器去噪#目标检测

[PDF](https://arxiv.org/pdf/2512.16123v1)
[Abstract](http://arxiv.org/abs/2512.16123v1)

 CV

 推荐

### 中文摘要

基于深度学习的目标检测模型在自动驾驶与安防监控等真实场景中具有重要作用，但仍易受对抗样本影响。本文提出一种基于自动编码器的去噪防御方法，以恢复因对抗扰动导致的检测性能下降。我们在 COCO 数据集中与车辆相关的图像上使用 Perlin 噪声构造对抗攻击，采用单层卷积自动编码器去除扰动，并以 YOLOv5 评估检测性能。实验结果表明，对抗攻击使 bbox mAP 从 0.2890 降至 0.1640，性能下降 43.3%。应用所提自动编码器防御后，bbox mAP 提升至 0.1700（恢复 3.7%），而 bbox mAP@50 则从 0.2780 提升至 0.3080（提高 10.8%）。这些结果表明，基于自动编码器的去噪在无需重训练检测模型的情况下，可对抗对抗性扰动提供部分防护效果。

BibTeX

```
@article{2512.16123v1,
  title={Autoencoder-based Denoising Defense against Adversarial Attacks on Object Detection},
  author={Min Geun Song and Gang Min Kim and Woonmin Kim and Yongsik Kim and Jeonghyun Sim and Sangbeom Park and Huy Kang Kim},
  journal={arXiv preprint arXiv:2512.16123v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16123v1}
}
```

## [ParamExplorer: A framework for exploring parameters in generative art](http://arxiv.org/abs/2512.16529v1)

#生成艺术#参数空间探索#强化学习启发

[PDF](https://arxiv.org/pdf/2512.16529v1)
[Abstract](http://arxiv.org/abs/2512.16529v1)

 Generative Art / 强化学习启发的交互式参数探索

 推荐

### 中文摘要

生成艺术系统通常包含高维且复杂的参数空间，其中具有审美吸引力的输出仅集中在稀疏且碎片化的小区域。由于这种组合爆炸效应，艺术家通常依赖大量手工试错，从而导致许多潜在有趣的参数配置未被发现。本文做出两项贡献。首先，我们提出了 ParamExplorer——一个受到强化学习启发的交互式模块化框架，旨在在生成艺术算法的参数空间中辅助探索，可由人机交互反馈或自动化反馈引导。该框架还能与现有的 p5.js 项目无缝集成。其次，在此框架下我们实现并评估了若干探索策略（称为 agent），以验证不同策略在发现有吸引力参数配置方面的效果。

BibTeX

```
@article{2512.16529v1,
  title={ParamExplorer: A framework for exploring parameters in generative art},
  author={Julien Gachadoat and Guillaume Lagarde},
  journal={arXiv preprint arXiv:2512.16529v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16529v1}
}
```

## [Dynamical Mechanisms for Coordinating Long-term Working Memory Based on the Precision of Spike-timing in Cortical Neurons](http://arxiv.org/abs/2512.15891v1)

#脉冲时序精度#皮层行波#突触时序依赖性可塑性(STDP)

[PDF](https://arxiv.org/pdf/2512.15891v1)
[Abstract](http://arxiv.org/abs/2512.15891v1)

 计算神经科学 / 脉冲神经网络（SNN）

 推荐

### 中文摘要

在上个世纪，大多数关于皮层神经元的感觉运动研究依赖于平均放电率。速率编码对于发生在数秒内的快速感觉运动处理是高效的，但对以数小时为时间尺度的长期工作记忆知之甚少（Ericsson 和 Kintsch，1995）。皮层神经元发放起始具有毫秒级精度的发现是意外的（Mainen 和 Sejnowski，1995）。更令人震惊的是在体内对快速波动的感觉输入的发放精度，这表明神经回路原则上可以通过时序脉冲保留并操作感觉信息，从而支持以毫秒为尺度的突触时序依赖性可塑性（STDP），该可塑性由突触前与突触后神经元脉冲的相对时序触发。哪些脉冲时序机制可以在体内调控 STDP？在多个频段中观测到的皮层行波具有很高的时间精度。行波的波前可以将脉冲时序与 STDP 联系起来。当波前穿过皮层柱时，锥体细胞和篮状细胞树突上的兴奋性突触被同步激发。篮状抑制细胞在锥体细胞胞体上形成包囊式突触，强瞬时超极化后的抑制反弹可触发回传动作电位，该电位在锥体树突上的兴奋性输入之后不久到达。以这种方式激活的 STDP 可能持续数小时，形成一个第二层网络。这个临时网络可以支撑长期工作记忆——一个位于长期感觉运动网络之上的认知网络。单独考虑，行波和 STDP 尚未带来对皮层功能的新见解；但二者结合可能解释我们如何进行思维（Sejnowski，2025）。

BibTeX

```
@article{2512.15891v1,
  title={Dynamical Mechanisms for Coordinating Long-term Working Memory Based on the Precision of Spike-timing in Cortical Neurons},
  author={Terrence J. Sejnowski},
  journal={arXiv preprint arXiv:2512.15891v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15891v1}
}
```

## [Cybercrime and Computer Forensics in Epoch of Artificial Intelligence in India](http://arxiv.org/abs/2512.15799v1)

#数字取证#生成式人工智能#数据保护法规

[PDF](https://arxiv.org/pdf/2512.15799v1)
[Abstract](http://arxiv.org/abs/2512.15799v1)

 AI安全与数字取证

 推荐

### 中文摘要

随着生成式人工智能融入数字生态系统，印度刑事法学在计算机取证完整性方面需要进行深刻的重新审视。尽管算法效率提升了证据提取能力，但在《数字个人数据保护法（2023）》与对抗性AI威胁（尤其是反取证技术和深度伪造）之间的兼容性方面仍存在研究空白。本研究审视了AI的“二元用途”困境——既可作为网络威胁载体，又可作为取证自动化工具——以厘清高风险调查中的隐私边界。研究采用教条式法律方法，将对《数字个人数据保护法》的法规性分析与国际伦理框架（IEEE、欧盟）相结合，评估监管效果。初步结果表明，尽管机器学习在模式识别上具有高精度，但也带来了数据中毒与算法偏见等脆弱性。研究发现，该法案的数据最小化原则与取证所需的数据保留要求之间存在明显张力。此外，现行法律定义未能充分涵盖由AI驱动的“工具型犯罪”和“目标型犯罪”。因此，论文提出了以人为本的取证模型，优先采用可解释的AI（XAI）以确保证据的可采性。研究结论表明，有必要将印度的隐私法规与国际取证标准同步，以缓解合成媒体风险，并为未来的立法修订和技术标准化制定路线图。

BibTeX

```
@article{2512.15799v1,
  title={Cybercrime and Computer Forensics in Epoch of Artificial Intelligence in India},
  author={Sahibpreet Singh and Shikha Dhiman},
  journal={arXiv preprint arXiv:2512.15799v1},
  year={2025},
  url={http://arxiv.org/abs/2512.15799v1}
}
```

## [The Universe Learning Itself: On the Evolution of Dynamics from the Big Bang to Machine Intelligence](http://arxiv.org/abs/2512.16515v1)

#跨尺度动力学#涌现与相变#人工智能演化

[PDF](https://arxiv.org/pdf/2512.16515v1)
[Abstract](http://arxiv.org/abs/2512.16515v1)

 AI理论/复杂系统

 推荐

### 中文摘要

我们提出了一个统一的动力学系统叙事框架，将宇宙从大爆炸到当代人类社会及其人工学习系统的结构形成过程视为一条连续的演化链。与其将宇宙学、天体物理学、地球物理学、生物学、认知科学与机器智能视为相互独立的领域，我们将每一领域看作在日益丰富的状态空间上出现的连续动力学阶段，这些阶段由相变、对称性破缺事件和涌现的吸引子串联起来。我们从暴胀场动力学和原初扰动的增长出发，描述了引力不稳定性如何刻画宇宙网格，如何通过可散逸的重力塌缩使重子物质形成恒星与行星，以及行星尺度的地球化学循环如何定义长期存在的非平衡吸引子。在这些吸引子内部，我们把生命的起源表述为自维持反应网络的涌现，把进化生物学视为在高维基因型–表型–环境流形上的流动，并将大脑看作运作在临界面附近的自适应动力学系统。人类文化与技术——包括现代机器学习与人工智能——则被解释为实现并不断改良的符号与制度动力学，这些动力学实现并递归地重塑其自身的相空间。全文强调若干反复出现的数学主题：不稳定性、分岔、多尺度耦合及在可及状态空间的零测度子集上的受约束流动。我们的目标并非提出新的宇宙学或生物学模型，而是提供一种跨尺度的理论视角：把宇宙史解读为“动力学自身的演化”，其顶点（迄今）是能够建模、预测并有意识扰动自身未来轨迹的生物与人工系统。

BibTeX

```
@article{2512.16515v1,
  title={The Universe Learning Itself: On the Evolution of Dynamics from the Big Bang to Machine Intelligence},
  author={Pradeep Singh and Mudasani Rushikesh and Bezawada Sri Sai Anurag and Balasubramanian Raman},
  journal={arXiv preprint arXiv:2512.16515v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16515v1}
}
```

## [Science Consultant Agent](http://arxiv.org/abs/2512.16171v1)

#模型选择#研究驱动推荐#原型构建

[PDF](https://arxiv.org/pdf/2512.16171v1)
[Abstract](http://arxiv.org/abs/2512.16171v1)

 AI工程/机器学习系统

 推荐

### 中文摘要

Science Consultant Agent 是一款基于 Web 的人工智能工具，旨在帮助从业者为 AI 驱动的解决方案选择并实施最有效的建模策略。该系统由四个核心组件组成：问卷（Questionnaire）、智能填充（Smart Fill）、基于研究的推荐（Research-Guided Recommendation）和原型构建器（Prototype Builder）。通过将结构化问卷、文献支持的解决方案建议和原型生成相结合，Science Consultant Agent 能加速产品经理、软件开发者及研究人员等不同角色的开发流程。完整流程在图 1 中进行了说明。

BibTeX

```
@article{2512.16171v1,
  title={Science Consultant Agent},
  author={Karthikeyan K and Philip Wu and Xin Tang and Alexandre Alves},
  journal={arXiv preprint arXiv:2512.16171v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16171v1}
}
```

## [ReinforceGen: Hybrid Skill Policies with Automated Data Generation and Reinforcement Learning](http://arxiv.org/abs/2512.16861v1)

#机器人操控#模仿学习#强化学习

[PDF](https://arxiv.org/pdf/2512.16861v1)
[Abstract](http://arxiv.org/abs/2512.16861v1)

 RL

 推荐

### 中文摘要

长期时域的操控任务一直是机器人学界的难题。我们提出了 ReinforceGen，一种将任务分解、数据生成、模仿学习与运动规划相结合的系统，用以构建初始解，并通过基于强化学习的微调改进各个组件。ReinforceGen 首先将任务分割为多个局部技能，并通过运动规划将这些技能衔接起来。技能与运动规划目标在由 10 次人工示范生成的数据集上通过模仿学习进行训练，随后通过在线自适应与强化学习进行微调。在 Robosuite 基准测试中，ReinforceGen 在视觉-运动控制且处于最高重置范围设置下，对所有任务达到了 80% 的成功率。额外的消融实验表明，我们的微调方法带来了平均 89% 的性能提升。更多结果与视频可见：https://reinforcegen.github.io/

BibTeX

```
@article{2512.16861v1,
  title={ReinforceGen: Hybrid Skill Policies with Automated Data Generation and Reinforcement Learning},
  author={Zihan Zhou and Animesh Garg and Ajay Mandlekar and Caelan Garrett},
  journal={arXiv preprint arXiv:2512.16861v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16861v1}
}
```

## [IoMT-based Automated Leukemia Classification using CNN and Higher Order Singular Value](http://arxiv.org/abs/2512.16448v1)

#物联网医疗（IoMT）#卷积神经网络（CNN）#高阶奇异值分解（HOSVD）

[PDF](https://arxiv.org/pdf/2512.16448v1)
[Abstract](http://arxiv.org/abs/2512.16448v1)

 CV (Medical Imaging / IoMT)

 推荐

### 中文摘要

物联网（IoT）是一种使物体具有身份并在网络中相互通信的概念。在医疗领域的应用被称为医疗物联网（IoMT）。急性淋巴细胞白血病（ALL）是一类血液系统肿瘤，通常由于骨髓中未成熟白细胞的过度增生而发病。由于该疾病易扩散至其他器官，若不能早期诊断与治疗，常会危及生命。因此，病理学家通常通过采集血液或骨髓涂片来识别癌变（ALL）细胞。然而，人工检测存在误差风险且耗时较长。为应对这些问题，基于人工智能（AI）能够从非癌组织中识别癌变的自动化方法显得尤为重要。深度神经网络（DNN）是当前高效的机器学习方法，能够通过多层结构从原始输入中提取高级特征。本文提出将卷积神经网络（CNN）与一种新的分类方法——高阶奇异值分解（HOSVD）相结合，用于从显微血液图像中区分ALL与正常细胞。我们将该模型部署在IoMT框架下，以实现快速且安全的白血病识别，并支持患者与临床医生的实时通讯。该模型在急性淋巴细胞白血病图像数据库（ALL-IDB2）上的测试平均准确率达到98.88%。

BibTeX

```
@article{2512.16448v1,
  title={IoMT-based Automated Leukemia Classification using CNN and Higher Order Singular Value},
  author={Shabnam Bagheri Marzijarani and Mohammad Zolfaghari and Hedieh Sajedi},
  journal={arXiv preprint arXiv:2512.16448v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16448v1}
}
```

## [Cyber Humanism in Education: Reclaiming Agency through AI and Learning Sciences](http://arxiv.org/abs/2512.16701v1)

#生成式人工智能#学习科学与AI教育#算法公民

[PDF](https://arxiv.org/pdf/2512.16701v1)
[Abstract](http://arxiv.org/abs/2512.16701v1)

 LLM

 推荐

### 中文摘要

生成式人工智能（GenAI）正在迅速重塑教育中知识的生产与验证方式。大型语言模型不仅仅是另一种数字工具，而是将阅读、写作与编程重构为人机混合的工作流，从而引发了关于认识论自动化、认知卸载以及教师职业化退化的担忧。本文提出“教育中的网络人文主义”作为在此情境中收回人类能动性的框架。我们将由 AI 支持的学习环境概念化为由人类与机器共同构建的社会-技术基础设施，并将教育者与学习者置于认识论主体和“算法公民”的位置，强调他们既有权利也有责任去塑造这些基础设施。我们阐述了网络人文主义设计的三大支柱：反思性能力（reflexive competence）、算法公民身份（algorithmic citizenship）与对话式设计（dialogic design），并将这些支柱与主要的国际数字与人工智能能力框架相联系。随后，文章通过高等教育案例研究说明了如何通过基于提示的学习（prompt-based learning）以及在 EPICT 生态系统中提出的一项新的“会话式 AI 教师”认证来将这些理念付诸实践。研究结果表明，这类实践能够强化认识论能动性，同时也揭示了有关工作负担、公平性与治理方面的张力，并对以人工智能为主导且以人为本的未来教育提出了若干影响与建议。

BibTeX

```
@article{2512.16701v1,
  title={Cyber Humanism in Education: Reclaiming Agency through AI and Learning Sciences},
  author={Giovanni Adorni},
  journal={arXiv preprint arXiv:2512.16701v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16701v1}
}
```

## [Comprehensive AI Literacy: The Case for Centering Human Agency](http://arxiv.org/abs/2512.16656v1)

#AI素养#人类能动性#批判性与伦理

[PDF](https://arxiv.org/pdf/2512.16656v1)
[Abstract](http://arxiv.org/abs/2512.16656v1)

 AI教育与伦理（AI Literacy）

 推荐

### 中文摘要

人工智能技术迅速渗透到社会各个层面，带来了重要的教育需求，而现有框架未能有效应对。我们正目睹一种危险的素养差距：对使用AI工具的功能性、操作性技能的重视，正在掩盖对其进行批判性和伦理性思考的培养。本文从立场性角度主张系统性转向以“以人为本的全面AI素养”为中心——即强调人的能动性（能够有意识、批判性并负责任地做出选择的能力）。这一原则适用于教育生态系统中的所有利益相关者：学生应具备质疑AI、与AI协作创造或基于任务有意识地选择不使用AI的能动性；教师应具备基于教学价值设计学习体验的能动性，而不是将教学主导权拱手让给工具。真正的素养包括教授关于能动性的内容，将技术视为可供选择的对象而非必然的采纳对象。这需要对批判性思维的深度承诺以及对认识论的扎实理解。通过本文阐述的AI素养、流利度与能力框架，教育者和学习者可以成为以人为中心的AI实践主体，明确表达指导其对AI的决策与态度的意图，并评估这些决策对学术、职业与社会的影响。

BibTeX

```
@article{2512.16656v1,
  title={Comprehensive AI Literacy: The Case for Centering Human Agency},
  author={Sri Yash Tadimalla and Justin Cary and Gordon Hull and Jordan Register and Daniel Maxwell and David Pugalee and Tina Heafner},
  journal={arXiv preprint arXiv:2512.16656v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16656v1}
}
```

## [Feasibility of Radio Frequency Based Wireless Sensing of Lead Contamination in Soil](http://arxiv.org/abs/2512.16071v1)

#铅污染检测#无线射频感知#机器学习分类

[PDF](https://arxiv.org/pdf/2512.16071v1)
[Abstract](http://arxiv.org/abs/2512.16071v1)

 无线传感 / 环境感知 / 物联网

 推荐

### 中文摘要

城市土壤中广泛存在的铅（Pb）污染对食品安全和公众健康造成重大影响，并阻碍城市绿化。然而，大多数现有的铅测量技术耗时、人力密集且成本高。本文提出了 SoilScanner，一种基于射频的无线系统用于土壤中铅含量检测。我们的关键发现是，不同频段的射频信号在土壤中传播时会受到不同盐类（如 NaCl 与 Pb(NO3)2）的差异性影响。在受控实验中，通过向干净土壤中人工添加 NaCl 与 Pb(NO3)2，我们证明了不同盐类在不同频率下以不同模式反射信号。此外，我们还使用机器学习模型在非受控的现场样本中验证了该发现。实验结果表明，SoilScanner 能以 72% 的准确率将土壤样本分为低铅与高铅两类（阈值为 200 ppm），且所有超过 500 ppm 的样本均未被误判。研究结果表明，基于无线射频技术构建便携且低成本的铅检测与筛查设备是可行的。

BibTeX

```
@article{2512.16071v1,
  title={Feasibility of Radio Frequency Based Wireless Sensing of Lead Contamination in Soil},
  author={Yixuan Gao and Tanvir Ahmed and Mikhail Mohammed and Zhongqi Cheng and Rajalakshmi Nandakumar},
  journal={arXiv preprint arXiv:2512.16071v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16071v1}
}
```

## [Domain-Agnostic Causal-Aware Audio Transformer for Infant Cry Classification](http://arxiv.org/abs/2512.16271v1)

#未知#未知#未知

[PDF](https://arxiv.org/pdf/2512.16271v1)
[Abstract](http://arxiv.org/abs/2512.16271v1)

 未知

 一般推荐

### 中文摘要

{
"trans\_abs": "准确且可解释的婴儿哭声副语言学分类对于早期发现新生儿窘迫并支持临床决策至关重要。然而，现有许多深度学习方法依赖于基于相关性的声学表征，使其对噪声、虚假线索和跨录音环境的域变动敏感。我们提出了 DACH-TIC（Domain-Agnostic Causal-Aware Hierarchical Audio Transformer），一种用于鲁棒婴儿哭声分类的领域无关因果感知分层音频 Transformer。该模型在统一框架内融合了因果注意力、分层表征学习、多任务监督以及对抗域泛化。
DACH-TIC 采用结构化的 Transformer 骨干，包含局部 token 级编码器与全局语义编码器，并通过因果注意力掩码和受控扰动训练来近似反事实声学变异。对抗域目标促使模型学习环境不变的表征，而多任务学习则联合优化哭声类型识别、窘迫强度估计和因果相关性预测。我们在 Baby Chillanto 和 Donate-a-Cry 数据集上进行了评估，并使用 ESC-50 的环境噪声进行域增强。
实验结果表明，DACH-TIC 优于包括 HTS-AT 和 SE-ResNet Transformer 在内的最先进基线方法，在准确率上提升了 2.6 个百分点，macro-F1 提升了 2.2 个百分点，同时具备更好的因果保真性。该模型在未见声学环境上的泛化效果良好，域间性能差仅为 2.4 个百分点，展示了其在真实新生儿声学监测系统中的适用性。",
"keywords": ["婴儿哭声分类", "因果注意力", "域泛化"],
"sub\_topic": "音频/计算机听觉",
"recommendation": "很推荐"
}

BibTeX

```
@article{2512.16271v1,
  title={Domain-Agnostic Causal-Aware Audio Transformer for Infant Cry Classification},
  author={Geofrey Owino and Bernard Shibwabo Kasamani and Ahmed M. Abdelmoniem and Edem Wornyo},
  journal={arXiv preprint arXiv:2512.16271v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16271v1}
}
```

## [Unsupervised Thematic Clustering Of hadith Texts Using The Apriori Algorithm](http://arxiv.org/abs/2512.16694v1)

#Apriori算法#无监督主题聚类#圣训文本挖掘

[PDF](https://arxiv.org/pdf/2512.16694v1)
[Abstract](http://arxiv.org/abs/2512.16694v1)

 NLP

 一般推荐

### 中文摘要

随着伊斯兰文本数字化的推进，自动化对圣训（hadith）进行主题分组的需求愈发迫切。本研究基于文献回顾，采用无监督学习中的Apriori关联规则挖掘方法，以期在未标注文本数据中识别出关联模式与语义关系。所用数据集为布哈里圣训的印度尼西亚语译本，数据预处理流程包括大小写归一、标点清洗、分词、停用词去除和词干提取。随后使用Apriori算法开展关联规则挖掘，设置了支持度、置信度和提升度等参数进行筛选。结果表明，能挖掘出具有语义意义的关联模式，例如rakaat-祈祷（prayer）、经文-启示（verse-revelation）以及圣训-叙事（hadith-story）等关系，这些模式分别反映了礼拜、启示和圣训叙述等主题。研究结果证明Apriori算法能够自动揭示潜在的语义关联，并有助于推动数字伊斯兰研究与基于技术的学习系统的发展。

BibTeX

```
@article{2512.16694v1,
  title={Unsupervised Thematic Clustering Of hadith Texts Using The Apriori Algorithm},
  author={Wisnu Uriawan and Achmad Ajie Priyajie and Angga Gustian and Fikri Nur Hidayat and Sendi Ahmad Rafiudin and Muhamad Fikri Zaelani},
  journal={arXiv preprint arXiv:2512.16694v1},
  year={2025},
  url={http://arxiv.org/abs/2512.16694v1}
}
```



Generated by ArXiv AI Agent • Powered by DeepSeek & Jina AI
